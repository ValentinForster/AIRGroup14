{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install logging\n",
        "!pip install farm-haystack\n",
        "!pip install sentence-transformers\n",
        "!pip install seqeval"
      ],
      "metadata": {
        "id": "lsKIbSzwYAUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c3795e8-706c-4d20-d792-962eaf320b67"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting logging\n",
            "  Downloading logging-0.4.9.6.tar.gz (96 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/96.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/96.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting farm-haystack\n",
            "  Downloading farm_haystack-1.23.0-py3-none-any.whl (764 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.4/764.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boilerpy3 (from farm-haystack)\n",
            "  Downloading boilerpy3-1.0.7-py3-none-any.whl (22 kB)\n",
            "Collecting events (from farm-haystack)\n",
            "  Downloading Events-0.5-py3-none-any.whl (6.8 kB)\n",
            "Collecting httpx (from farm-haystack)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (4.19.2)\n",
            "Collecting lazy-imports==0.3.1 (from farm-haystack)\n",
            "  Downloading lazy_imports-0.3.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (10.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (3.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (9.4.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (4.1.0)\n",
            "Collecting posthog (from farm-haystack)\n",
            "  Downloading posthog-3.1.0-py2.py3-none-any.whl (37 kB)\n",
            "Collecting prompthub-py==4.0.0 (from farm-haystack)\n",
            "  Downloading prompthub_py-4.0.0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (1.10.13)\n",
            "Collecting quantulum3 (from farm-haystack)\n",
            "  Downloading quantulum3-0.9.0-py3-none-any.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rank-bm25 (from farm-haystack)\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (2.31.0)\n",
            "Collecting requests-cache<1.0.0 (from farm-haystack)\n",
            "  Downloading requests_cache-0.9.8-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.7/48.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn>=1.3.0 (from farm-haystack)\n",
            "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sseclient-py (from farm-haystack)\n",
            "  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (8.2.3)\n",
            "Collecting tiktoken>=0.5.1 (from farm-haystack)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (4.66.1)\n",
            "Requirement already satisfied: transformers==4.35.2 in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (4.35.2)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from prompthub-py==4.0.0->farm-haystack) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->farm-haystack) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->farm-haystack) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->farm-haystack) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->farm-haystack) (23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->farm-haystack) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->farm-haystack) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->farm-haystack) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2->farm-haystack) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack) (2023.11.17)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack) (1.4.4)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack) (23.1.0)\n",
            "Collecting cattrs>=22.2 (from requests-cache<1.0.0->farm-haystack)\n",
            "  Downloading cattrs-23.2.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting url-normalize>=1.4 (from requests-cache<1.0.0->farm-haystack)\n",
            "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx->farm-haystack)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack) (1.3.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->farm-haystack)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog->farm-haystack)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog->farm-haystack)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from quantulum3->farm-haystack) (7.0.0)\n",
            "Collecting num2words (from quantulum3->farm-haystack)\n",
            "  Downloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache<1.0.0->farm-haystack) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->farm-haystack) (2023.6.0)\n",
            "Collecting docopt>=0.6.2 (from num2words->quantulum3->farm-haystack)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=d8606531eb4652b383778fedacf43b047644bdd99fd5b4092f9020ef029d5fb7\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: sseclient-py, monotonic, events, docopt, url-normalize, rank-bm25, num2words, lazy-imports, h11, cattrs, boilerpy3, backoff, tiktoken, scikit-learn, requests-cache, prompthub-py, posthog, httpcore, quantulum3, httpx, farm-haystack\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 boilerpy3-1.0.7 cattrs-23.2.3 docopt-0.6.2 events-0.5 farm-haystack-1.23.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 lazy-imports-0.3.1 monotonic-1.6 num2words-0.5.13 posthog-3.1.0 prompthub-py-4.0.0 quantulum3-0.9.0 rank-bm25-0.2.2 requests-cache-0.9.8 scikit-learn-1.3.2 sseclient-py-1.8.0 tiktoken-0.5.2 url-normalize-1.4.3\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=fd56b2ea86bc1e201d60c84a4df54a72d030d322f04ba213f19db27ce4c8d11d\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.1.99\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.3.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=d5ebfcda431c8080baea6852a10679b5a08b7dcd9bba98b63efbc0de40de11ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tEvG_2I7dQU",
        "outputId": "676162c5-0a8f-4267-b43a-9f42e982a303"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)\n",
        "\n",
        "from haystack.nodes import DensePassageRetriever\n",
        "from haystack.document_stores import InMemoryDocumentStore"
      ],
      "metadata": {
        "id": "ZMvZxMztEksA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f948fb6-920e-4254-b8c9-f5451665f5d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.telemetry:Haystack sends anonymous usage data to understand the actual usage and steer dev efforts towards features that are most meaningful to users. You can opt-out at anytime by manually setting the environment variable HAYSTACK_TELEMETRY_ENABLED as described for different operating systems in the [documentation page](https://docs.haystack.deepset.ai/docs/telemetry#how-can-i-opt-out). More information at [Telemetry](https://docs.haystack.deepset.ai/docs/telemetry).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UK-iPGHEXjie"
      },
      "outputs": [],
      "source": [
        "# Here are the variables you might want to use instead of the set above\n",
        "# in order to perform pretraining\n",
        "\n",
        "doc_dir = \"/content/drive/MyDrive/AIR Project\"\n",
        "train_filename_1 = \"GermanQuAD_train_converted.json\"\n",
        "dev_filename_1 = \"GermanQuAD_test_converted.json\"\n",
        "\n",
        "query_model = \"facebook/dpr-question_encoder-single-nq-base\"\n",
        "passage_model = \"facebook/dpr-ctx_encoder-single-nq-base\"\n",
        "train_empty = \"GermanDPR_empty_train_test.json\"\n",
        "model_dir = \"/content/drive/MyDrive/AIR Project/finetune_model_GermanQuAD\"\n",
        "train_filename_2 = \"GermanDPR_train.json\"\n",
        "dev_filename_2 = \"GermanDPR_test.json\"\n",
        "model_dir2 = \"/content/drive/MyDrive/AIR Project/finetune_model_GermanDPR\"\n",
        "model_dir_empty = \"/content/drive/MyDrive/AIR Project/empty\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_base_model = DensePassageRetriever(\n",
        "    document_store=InMemoryDocumentStore(),\n",
        "    query_embedding_model=query_model,\n",
        "    passage_embedding_model=passage_model,\n",
        "    max_seq_len_query=64,\n",
        "    max_seq_len_passage=256,\n",
        ")\n",
        "retriever_base_model.train(\n",
        "    data_dir=doc_dir,\n",
        "    train_filename=train_empty,\n",
        "    dev_filename=dev_filename_1,\n",
        "    test_filename=dev_filename_2,\n",
        "    n_epochs=1,\n",
        "    batch_size=4,\n",
        "    grad_acc_steps=8,\n",
        "    evaluate_every=3000,\n",
        "    embed_title=True,\n",
        "    num_positives=1,\n",
        "    num_hard_negatives=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhNdTZUSZIpA",
        "outputId": "06745502-f0a0-42cf-c5d8-2565b5629387"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n",
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|\n",
            " (o)(o)------'\\ _ /     ( )\n",
            " \n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TRAIN DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:==================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading train set from: /content/drive/MyDrive/AIR Project/GermanDPR_empty_train_test.json \n",
            "Preprocessing dataset: 100%|██████████| 1/1 [00:00<00:00, 168.63 Dicts/s]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING DEV DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading dev set from: /content/drive/MyDrive/AIR Project/GermanQuAD_test_converted.json\n",
            "Preprocessing dataset: 100%|██████████| 5/5 [00:09<00:00,  1.93s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TEST DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading test set from: /content/drive/MyDrive/AIR Project/GermanDPR_test.json\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:03<00:00,  1.14s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:DATASETS SUMMARY\n",
            "INFO:haystack.modeling.data_handler.data_silo:================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in train: 1\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in dev  : 2204\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in test : 1025\n",
            "INFO:haystack.modeling.data_handler.data_silo:Total examples   : 3230\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest query length observed after clipping: 21   - for max_query_len: 64\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average query length after clipping:          21.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion queries clipped:                   0.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest passage length observed after clipping: 256.0   - for max_passage_len: 256\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average passage length after clipping:          256.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion passages clipped:                    1.0\n",
            "INFO:haystack.modeling.model.optimization:Loading optimizer 'AdamW': {'correct_bias': True, 'weight_decay': 0.0, 'eps': 1e-08, 'lr': 1e-05}\n",
            "INFO:haystack.modeling.model.optimization:Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO:haystack.modeling.model.optimization:Loading schedule 'get_linear_schedule_with_warmup': '{'num_warmup_steps': 100, 'num_training_steps': 0}'\n",
            "INFO:haystack.modeling.training.base:No train checkpoints found. Starting a new training ...\n",
            "Train epoch 0/0 (Cur. train loss: 0.0000): 100%|██████████| 1/1 [00:00<00:00,  5.62it/s]\n",
            "Evaluating: 100%|██████████| 257/257 [00:41<00:00,  6.12it/s]\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 1 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            " _________ text_similarity _________\n",
            "INFO:haystack.modeling.evaluation.eval:loss: 0.5415056926148331\n",
            "INFO:haystack.modeling.evaluation.eval:task_name: text_similarity\n",
            "INFO:haystack.modeling.evaluation.eval:acc: 0.8984622894801074\n",
            "INFO:haystack.modeling.evaluation.eval:f1: 0.5941463414634146\n",
            "INFO:haystack.modeling.evaluation.eval:acc_and_f1: 0.746304315471761\n",
            "INFO:haystack.modeling.evaluation.eval:average_rank: 0.8546341463414634\n",
            "INFO:haystack.modeling.evaluation.eval:report: \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "hard_negative     0.9420    0.9420    0.9420      7169\n",
            "     positive     0.5941    0.5941    0.5941      1025\n",
            "\n",
            "     accuracy                         0.8985      8194\n",
            "    macro avg     0.7681    0.7681    0.7681      8194\n",
            " weighted avg     0.8985    0.8985    0.8985      8194\n",
            "\n",
            "INFO:haystack.modeling.model.biadaptive_model:prediction_head saving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_QuAD_fine = DensePassageRetriever(\n",
        "    document_store=InMemoryDocumentStore(),\n",
        "    query_embedding_model=query_model,\n",
        "    passage_embedding_model=passage_model,\n",
        "    max_seq_len_query=64,\n",
        "    max_seq_len_passage=256,\n",
        ")\n",
        "retriever_QuAD_fine.train(\n",
        "    data_dir=doc_dir,\n",
        "    train_filename=train_filename_1,\n",
        "    dev_filename=dev_filename_1,\n",
        "    test_filename=dev_filename_2,\n",
        "    n_epochs=1,\n",
        "    batch_size=4,\n",
        "    grad_acc_steps=8,\n",
        "    save_dir=model_dir,\n",
        "    evaluate_every=3000,\n",
        "    embed_title=True,\n",
        "    num_positives=1,\n",
        "    num_hard_negatives=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM8IihLGXvTy",
        "outputId": "3aa619f2-8947-47d1-bbae-d1f60ed33337"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n",
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|\n",
            " (o)(o)------'\\ _ /     ( )\n",
            " \n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TRAIN DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:==================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading train set from: /content/drive/MyDrive/AIR Project/GermanQuAD_train_converted.json \n",
            "Preprocessing dataset: 100%|██████████| 23/23 [00:27<00:00,  1.19s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING DEV DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading dev set from: /content/drive/MyDrive/AIR Project/GermanQuAD_test_converted.json\n",
            "Preprocessing dataset: 100%|██████████| 5/5 [00:07<00:00,  1.47s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TEST DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading test set from: /content/drive/MyDrive/AIR Project/GermanDPR_test.json\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:03<00:00,  1.14s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:DATASETS SUMMARY\n",
            "INFO:haystack.modeling.data_handler.data_silo:================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in train: 11518\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in dev  : 2204\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in test : 1025\n",
            "INFO:haystack.modeling.data_handler.data_silo:Total examples   : 14747\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest query length observed after clipping: 50   - for max_query_len: 64\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average query length after clipping:          20.60027782601146\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion queries clipped:                   0.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest passage length observed after clipping: 129.5   - for max_passage_len: 256\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average passage length after clipping:          126.57874631012328\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion passages clipped:                    0.0\n",
            "INFO:haystack.modeling.model.optimization:Loading optimizer 'AdamW': {'correct_bias': True, 'weight_decay': 0.0, 'eps': 1e-08, 'lr': 1e-05}\n",
            "INFO:haystack.modeling.model.optimization:Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO:haystack.modeling.model.optimization:Loading schedule 'get_linear_schedule_with_warmup': '{'num_warmup_steps': 100, 'num_training_steps': 360}'\n",
            "INFO:haystack.modeling.training.base:No train checkpoints found. Starting a new training ...\n",
            "Train epoch 0/0 (Cur. train loss: 0.0004): 100%|██████████| 2880/2880 [22:31<00:00,  2.13it/s]\n",
            "Evaluating: 100%|██████████| 257/257 [00:40<00:00,  6.40it/s]\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 2880 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            " _________ text_similarity _________\n",
            "INFO:haystack.modeling.evaluation.eval:loss: 0.740938199624777\n",
            "INFO:haystack.modeling.evaluation.eval:task_name: text_similarity\n",
            "INFO:haystack.modeling.evaluation.eval:acc: 0.93605076885526\n",
            "INFO:haystack.modeling.evaluation.eval:f1: 0.744390243902439\n",
            "INFO:haystack.modeling.evaluation.eval:acc_and_f1: 0.8402205063788495\n",
            "INFO:haystack.modeling.evaluation.eval:average_rank: 0.38634146341463416\n",
            "INFO:haystack.modeling.evaluation.eval:report: \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "hard_negative     0.9635    0.9635    0.9635      7169\n",
            "     positive     0.7444    0.7444    0.7444      1025\n",
            "\n",
            "     accuracy                         0.9361      8194\n",
            "    macro avg     0.8539    0.8539    0.8539      8194\n",
            " weighted avg     0.9361    0.9361    0.9361      8194\n",
            "\n",
            "INFO:haystack.modeling.model.biadaptive_model:prediction_head saving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fine-tuned model\n",
        "retriever_DPR_fine = DensePassageRetriever(document_store=InMemoryDocumentStore())\n",
        "retriever_DPR_fine.load(load_dir=model_dir, document_store=InMemoryDocumentStore())\n",
        "\n",
        "retriever_DPR_fine.train(\n",
        "    data_dir=doc_dir,\n",
        "    train_filename=train_filename_2,\n",
        "    dev_filename=dev_filename_2,\n",
        "    test_filename=dev_filename_2,\n",
        "    n_epochs=1,\n",
        "    batch_size=4,\n",
        "    grad_acc_steps=8,\n",
        "    save_dir=model_dir2,\n",
        "    evaluate_every=3000,\n",
        "    embed_title=True,\n",
        "    num_positives=1,\n",
        "    num_hard_negatives=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C2brVCHiepz",
        "outputId": "932f6734-60a3-4684-bf72-5c90d62e536b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n",
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n",
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.nodes.retriever.dense:DPR model loaded from /content/drive/MyDrive/AIR Project/finetune_model_GermanQuAD\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|\n",
            " (o)(o)------'\\ _ /     ( )\n",
            " \n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TRAIN DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:==================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading train set from: /content/drive/MyDrive/AIR Project/GermanDPR_train.json \n",
            "Preprocessing dataset: 100%|██████████| 19/19 [00:42<00:00,  2.25s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING DEV DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading dev set from: /content/drive/MyDrive/AIR Project/GermanDPR_test.json\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:03<00:00,  1.20s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TEST DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading test set from: /content/drive/MyDrive/AIR Project/GermanDPR_test.json\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:03<00:00,  1.17s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:DATASETS SUMMARY\n",
            "INFO:haystack.modeling.data_handler.data_silo:================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in train: 9275\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in dev  : 1025\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in test : 1025\n",
            "INFO:haystack.modeling.data_handler.data_silo:Total examples   : 11325\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest query length observed after clipping: 50   - for max_query_len: 64\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average query length after clipping:          20.343719676549867\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion queries clipped:                   0.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest passage length observed after clipping: 256.0   - for max_passage_len: 256\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average passage length after clipping:          249.488948787062\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion passages clipped:                    0.6939083557951482\n",
            "INFO:haystack.modeling.model.optimization:Loading optimizer 'AdamW': {'correct_bias': True, 'weight_decay': 0.0, 'eps': 1e-08, 'lr': 1e-05}\n",
            "INFO:haystack.modeling.model.optimization:Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO:haystack.modeling.model.optimization:Loading schedule 'get_linear_schedule_with_warmup': '{'num_warmup_steps': 100, 'num_training_steps': 289}'\n",
            "INFO:haystack.modeling.training.base:No train checkpoints found. Starting a new training ...\n",
            "Train epoch 0/0 (Cur. train loss: 0.1892): 100%|██████████| 2319/2319 [19:04<00:00,  2.03it/s]\n",
            "Evaluating: 100%|██████████| 257/257 [00:40<00:00,  6.32it/s]\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 2319 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            " _________ text_similarity _________\n",
            "INFO:haystack.modeling.evaluation.eval:loss: 0.42104266645807076\n",
            "INFO:haystack.modeling.evaluation.eval:task_name: text_similarity\n",
            "INFO:haystack.modeling.evaluation.eval:acc: 0.9450817671466927\n",
            "INFO:haystack.modeling.evaluation.eval:f1: 0.7804878048780488\n",
            "INFO:haystack.modeling.evaluation.eval:acc_and_f1: 0.8627847860123707\n",
            "INFO:haystack.modeling.evaluation.eval:average_rank: 0.3804878048780488\n",
            "INFO:haystack.modeling.evaluation.eval:report: \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "hard_negative     0.9686    0.9686    0.9686      7169\n",
            "     positive     0.7805    0.7805    0.7805      1025\n",
            "\n",
            "     accuracy                         0.9451      8194\n",
            "    macro avg     0.8746    0.8746    0.8746      8194\n",
            " weighted avg     0.9451    0.9451    0.9451      8194\n",
            "\n",
            "INFO:haystack.modeling.model.biadaptive_model:prediction_head saving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RTndkctOgrmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s5x4WzxukCAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_base_loaded = DensePassageRetriever(\n",
        "    document_store=InMemoryDocumentStore(),\n",
        "    query_embedding_model=query_model,\n",
        "    passage_embedding_model=passage_model,\n",
        "    max_seq_len_query=64,\n",
        "    max_seq_len_passage=256,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP1F2IQcnFQh",
        "outputId": "f4d4bd62-959f-47d9-f9fe-3cac3b64c16e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n",
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "retriever_base_loaded.train(\n",
        "    data_dir=doc_dir,\n",
        "    train_filename=train_empty,\n",
        "    dev_filename=dev_filename_1,\n",
        "    test_filename=dev_filename_1,\n",
        "    n_epochs=1,\n",
        "    batch_size=4,\n",
        "    grad_acc_steps=8,\n",
        "    save_dir=model_dir_empty,\n",
        "    evaluate_every=3000,\n",
        "    embed_title=True,\n",
        "    num_positives=1,\n",
        "    num_hard_negatives=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPhr8QcfkCbO",
        "outputId": "b466363c-0d38-4aea-93ef-cfd9627e3a9f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|\n",
            " (o)(o)------'\\ _ /     ( )\n",
            " \n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TRAIN DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:==================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading train set from: /content/drive/MyDrive/AIR Project/GermanDPR_empty_train_test.json \n",
            "Preprocessing dataset: 100%|██████████| 1/1 [00:00<00:00, 96.03 Dicts/s]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING DEV DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading dev set from: /content/drive/MyDrive/AIR Project/GermanQuAD_test_converted.json\n",
            "Preprocessing dataset: 100%|██████████| 5/5 [00:09<00:00,  1.89s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TEST DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading test set from: /content/drive/MyDrive/AIR Project/GermanQuAD_test_converted.json\n",
            "Preprocessing dataset: 100%|██████████| 5/5 [00:06<00:00,  1.30s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:DATASETS SUMMARY\n",
            "INFO:haystack.modeling.data_handler.data_silo:================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in train: 1\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in dev  : 2204\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in test : 2204\n",
            "INFO:haystack.modeling.data_handler.data_silo:Total examples   : 4409\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest query length observed after clipping: 21   - for max_query_len: 64\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average query length after clipping:          21.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion queries clipped:                   0.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest passage length observed after clipping: 256.0   - for max_passage_len: 256\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average passage length after clipping:          256.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion passages clipped:                    1.0\n",
            "INFO:haystack.modeling.model.optimization:Loading optimizer 'AdamW': {'correct_bias': True, 'weight_decay': 0.0, 'eps': 1e-08, 'lr': 1e-05}\n",
            "INFO:haystack.modeling.model.optimization:Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO:haystack.modeling.model.optimization:Loading schedule 'get_linear_schedule_with_warmup': '{'num_warmup_steps': 100, 'num_training_steps': 0}'\n",
            "INFO:haystack.modeling.training.base:No train checkpoints found. Starting a new training ...\n",
            "Train epoch 0/0 (Cur. train loss: 0.0000): 100%|██████████| 1/1 [00:00<00:00,  5.93it/s]\n",
            "Evaluating: 100%|██████████| 551/551 [01:15<00:00,  7.26it/s]\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 1 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            " _________ text_similarity _________\n",
            "INFO:haystack.modeling.evaluation.eval:loss: 0.2932318130946229\n",
            "INFO:haystack.modeling.evaluation.eval:task_name: text_similarity\n",
            "INFO:haystack.modeling.evaluation.eval:acc: 0.9432849364791288\n",
            "INFO:haystack.modeling.evaluation.eval:f1: 0.7731397459165156\n",
            "INFO:haystack.modeling.evaluation.eval:acc_and_f1: 0.8582123411978222\n",
            "INFO:haystack.modeling.evaluation.eval:average_rank: 0.3352994555353902\n",
            "INFO:haystack.modeling.evaluation.eval:report: \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "hard_negative     0.9676    0.9676    0.9676     15428\n",
            "     positive     0.7731    0.7731    0.7731      2204\n",
            "\n",
            "     accuracy                         0.9433     17632\n",
            "    macro avg     0.8704    0.8704    0.8704     17632\n",
            " weighted avg     0.9433    0.9433    0.9433     17632\n",
            "\n",
            "INFO:haystack.modeling.model.biadaptive_model:prediction_head saving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_base_loaded.train(\n",
        "    data_dir=doc_dir,\n",
        "    train_filename=train_empty,\n",
        "    dev_filename=dev_filename_2,\n",
        "    test_filename=dev_filename_2,\n",
        "    n_epochs=1,\n",
        "    batch_size=4,\n",
        "    grad_acc_steps=8,\n",
        "    save_dir=model_dir_empty,\n",
        "    evaluate_every=3000,\n",
        "    embed_title=True,\n",
        "    num_positives=1,\n",
        "    num_hard_negatives=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQUlAdFeWBel",
        "outputId": "09df44f5-4a73-4ffa-ebb7-6b6f14f59288"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|\n",
            " (o)(o)------'\\ _ /     ( )\n",
            " \n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TRAIN DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:==================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading train set from: /content/drive/MyDrive/AIR Project/GermanDPR_empty_train_test.json \n",
            "Preprocessing dataset: 100%|██████████| 1/1 [00:00<00:00, 112.11 Dicts/s]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING DEV DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading dev set from: /content/drive/MyDrive/AIR Project/GermanDPR_test.json\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:04<00:00,  1.59s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TEST DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading test set from: /content/drive/MyDrive/AIR Project/GermanDPR_test.json\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:05<00:00,  1.84s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:DATASETS SUMMARY\n",
            "INFO:haystack.modeling.data_handler.data_silo:================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in train: 1\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in dev  : 1025\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in test : 1025\n",
            "INFO:haystack.modeling.data_handler.data_silo:Total examples   : 2051\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest query length observed after clipping: 21   - for max_query_len: 64\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average query length after clipping:          21.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion queries clipped:                   0.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest passage length observed after clipping: 256.0   - for max_passage_len: 256\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average passage length after clipping:          256.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion passages clipped:                    1.0\n",
            "INFO:haystack.modeling.model.optimization:Loading optimizer 'AdamW': {'correct_bias': True, 'weight_decay': 0.0, 'eps': 1e-08, 'lr': 1e-05}\n",
            "INFO:haystack.modeling.model.optimization:Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO:haystack.modeling.model.optimization:Loading schedule 'get_linear_schedule_with_warmup': '{'num_warmup_steps': 100, 'num_training_steps': 0}'\n",
            "INFO:haystack.modeling.training.base:No train checkpoints found. Starting a new training ...\n",
            "Train epoch 0/0 (Cur. train loss: 0.0000): 100%|██████████| 1/1 [00:00<00:00,  5.50it/s]\n",
            "Evaluating: 100%|██████████| 257/257 [00:35<00:00,  7.19it/s]\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 1 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            " _________ text_similarity _________\n",
            "INFO:haystack.modeling.evaluation.eval:loss: 0.5369547309723974\n",
            "INFO:haystack.modeling.evaluation.eval:task_name: text_similarity\n",
            "INFO:haystack.modeling.evaluation.eval:acc: 0.8994386136197218\n",
            "INFO:haystack.modeling.evaluation.eval:f1: 0.5980487804878049\n",
            "INFO:haystack.modeling.evaluation.eval:acc_and_f1: 0.7487436970537633\n",
            "INFO:haystack.modeling.evaluation.eval:average_rank: 0.8273170731707317\n",
            "INFO:haystack.modeling.evaluation.eval:report: \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "hard_negative     0.9425    0.9425    0.9425      7169\n",
            "     positive     0.5980    0.5980    0.5980      1025\n",
            "\n",
            "     accuracy                         0.8994      8194\n",
            "    macro avg     0.7703    0.7703    0.7703      8194\n",
            " weighted avg     0.8994    0.8994    0.8994      8194\n",
            "\n",
            "INFO:haystack.modeling.model.biadaptive_model:prediction_head saving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_QuAD_fine_loaded = DensePassageRetriever.load(model_dir, document_store=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DChijfvci1bE",
        "outputId": "6d5e952a-fd44-444f-92cd-a15af830b7e4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.nodes.retriever.dense:DPR model loaded from /content/drive/MyDrive/AIR Project/finetune_model_GermanQuAD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_QuAD_fine_loaded.train(\n",
        "    data_dir=doc_dir,\n",
        "    train_filename=train_empty,\n",
        "    dev_filename=dev_filename_1,\n",
        "    test_filename=dev_filename_1,\n",
        "    n_epochs=1,\n",
        "    batch_size=4,\n",
        "    grad_acc_steps=8,\n",
        "    save_dir=model_dir_empty,\n",
        "    evaluate_every=3000,\n",
        "    embed_title=True,\n",
        "    num_positives=1,\n",
        "    num_hard_negatives=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J4hqlU5nTgx",
        "outputId": "d40853bd-945e-4bc1-899d-7ce1f167d261"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|\n",
            " (o)(o)------'\\ _ /     ( )\n",
            " \n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TRAIN DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:==================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading train set from: /content/drive/MyDrive/AIR Project/GermanDPR_empty_train_test.json \n",
            "Preprocessing dataset: 100%|██████████| 1/1 [00:00<00:00, 147.65 Dicts/s]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING DEV DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading dev set from: /content/drive/MyDrive/AIR Project/GermanQuAD_test_converted.json\n",
            "Preprocessing dataset: 100%|██████████| 5/5 [00:06<00:00,  1.34s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TEST DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading test set from: /content/drive/MyDrive/AIR Project/GermanQuAD_test_converted.json\n",
            "Preprocessing dataset: 100%|██████████| 5/5 [00:08<00:00,  1.72s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:DATASETS SUMMARY\n",
            "INFO:haystack.modeling.data_handler.data_silo:================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in train: 1\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in dev  : 2204\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in test : 2204\n",
            "INFO:haystack.modeling.data_handler.data_silo:Total examples   : 4409\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest query length observed after clipping: 21   - for max_query_len: 64\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average query length after clipping:          21.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion queries clipped:                   0.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest passage length observed after clipping: 256.0   - for max_passage_len: 256\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average passage length after clipping:          256.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion passages clipped:                    1.0\n",
            "INFO:haystack.modeling.model.optimization:Loading optimizer 'AdamW': {'correct_bias': True, 'weight_decay': 0.0, 'eps': 1e-08, 'lr': 1e-05}\n",
            "INFO:haystack.modeling.model.optimization:Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO:haystack.modeling.model.optimization:Loading schedule 'get_linear_schedule_with_warmup': '{'num_warmup_steps': 100, 'num_training_steps': 0}'\n",
            "INFO:haystack.modeling.training.base:No train checkpoints found. Starting a new training ...\n",
            "Train epoch 0/0 (Cur. train loss: 0.0000): 100%|██████████| 1/1 [00:00<00:00,  5.77it/s]\n",
            "Evaluating: 100%|██████████| 551/551 [01:16<00:00,  7.24it/s]\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 1 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            " _________ text_similarity _________\n",
            "INFO:haystack.modeling.evaluation.eval:loss: 0.21742588322743112\n",
            "INFO:haystack.modeling.evaluation.eval:task_name: text_similarity\n",
            "INFO:haystack.modeling.evaluation.eval:acc: 0.9748185117967332\n",
            "INFO:haystack.modeling.evaluation.eval:f1: 0.8992740471869328\n",
            "INFO:haystack.modeling.evaluation.eval:acc_and_f1: 0.9370462794918331\n",
            "INFO:haystack.modeling.evaluation.eval:average_rank: 0.15562613430127042\n",
            "INFO:haystack.modeling.evaluation.eval:report: \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "hard_negative     0.9856    0.9856    0.9856     15428\n",
            "     positive     0.8993    0.8993    0.8993      2204\n",
            "\n",
            "     accuracy                         0.9748     17632\n",
            "    macro avg     0.9424    0.9424    0.9424     17632\n",
            " weighted avg     0.9748    0.9748    0.9748     17632\n",
            "\n",
            "INFO:haystack.modeling.model.biadaptive_model:prediction_head saving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_QuAD_fine_loaded.train(\n",
        "    data_dir=doc_dir,\n",
        "    train_filename=train_empty,\n",
        "    dev_filename=dev_filename_2,\n",
        "    test_filename=dev_filename_2,\n",
        "    n_epochs=1,\n",
        "    batch_size=4,\n",
        "    grad_acc_steps=8,\n",
        "    save_dir=model_dir_empty,\n",
        "    evaluate_every=3000,\n",
        "    embed_title=True,\n",
        "    num_positives=1,\n",
        "    num_hard_negatives=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjLH6TcnnXoB",
        "outputId": "e1d60200-7bf8-4abf-baba-da065a1d3a11"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|\n",
            " (o)(o)------'\\ _ /     ( )\n",
            " \n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TRAIN DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:==================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading train set from: /content/drive/MyDrive/AIR Project/GermanDPR_empty_train_test.json \n",
            "Preprocessing dataset: 100%|██████████| 1/1 [00:00<00:00, 83.46 Dicts/s]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING DEV DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading dev set from: /content/drive/MyDrive/AIR Project/GermanDPR_test.json\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:05<00:00,  1.67s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TEST DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading test set from: /content/drive/MyDrive/AIR Project/GermanDPR_test.json\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:03<00:00,  1.16s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:DATASETS SUMMARY\n",
            "INFO:haystack.modeling.data_handler.data_silo:================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in train: 1\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in dev  : 1025\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in test : 1025\n",
            "INFO:haystack.modeling.data_handler.data_silo:Total examples   : 2051\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest query length observed after clipping: 21   - for max_query_len: 64\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average query length after clipping:          21.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion queries clipped:                   0.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest passage length observed after clipping: 256.0   - for max_passage_len: 256\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average passage length after clipping:          256.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion passages clipped:                    1.0\n",
            "INFO:haystack.modeling.model.optimization:Loading optimizer 'AdamW': {'correct_bias': True, 'weight_decay': 0.0, 'eps': 1e-08, 'lr': 1e-05}\n",
            "INFO:haystack.modeling.model.optimization:Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO:haystack.modeling.model.optimization:Loading schedule 'get_linear_schedule_with_warmup': '{'num_warmup_steps': 100, 'num_training_steps': 0}'\n",
            "INFO:haystack.modeling.training.base:No train checkpoints found. Starting a new training ...\n",
            "Train epoch 0/0 (Cur. train loss: 0.0000): 100%|██████████| 1/1 [00:00<00:00,  5.95it/s]\n",
            "Evaluating: 100%|██████████| 257/257 [00:36<00:00,  7.07it/s]\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 1 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            " _________ text_similarity _________\n",
            "INFO:haystack.modeling.evaluation.eval:loss: 0.7143888374891648\n",
            "INFO:haystack.modeling.evaluation.eval:task_name: text_similarity\n",
            "INFO:haystack.modeling.evaluation.eval:acc: 0.9384915792042958\n",
            "INFO:haystack.modeling.evaluation.eval:f1: 0.7541463414634146\n",
            "INFO:haystack.modeling.evaluation.eval:acc_and_f1: 0.8463189603338552\n",
            "INFO:haystack.modeling.evaluation.eval:average_rank: 0.3795121951219512\n",
            "INFO:haystack.modeling.evaluation.eval:report: \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "hard_negative     0.9648    0.9648    0.9648      7169\n",
            "     positive     0.7541    0.7541    0.7541      1025\n",
            "\n",
            "     accuracy                         0.9385      8194\n",
            "    macro avg     0.8595    0.8595    0.8595      8194\n",
            " weighted avg     0.9385    0.9385    0.9385      8194\n",
            "\n",
            "INFO:haystack.modeling.model.biadaptive_model:prediction_head saving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_PDR_fine_loaded = DensePassageRetriever.load(model_dir2, document_store=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdjUDuugWA59",
        "outputId": "3af8faec-1694-4aa6-adc8-186dc571414a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.nodes.retriever.dense:DPR model loaded from /content/drive/MyDrive/AIR Project/finetune_model_GermanDPR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_PDR_fine_loaded.train(\n",
        "    data_dir=doc_dir,\n",
        "    train_filename=train_empty,\n",
        "    dev_filename=dev_filename_1,\n",
        "    test_filename=dev_filename_1,\n",
        "    n_epochs=1,\n",
        "    batch_size=4,\n",
        "    grad_acc_steps=8,\n",
        "    save_dir=model_dir_empty,\n",
        "    evaluate_every=3000,\n",
        "    embed_title=True,\n",
        "    num_positives=1,\n",
        "    num_hard_negatives=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfGmxQYMnbbD",
        "outputId": "84c2c9c2-3769-43f4-dfe9-6118a6e10f3f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|\n",
            " (o)(o)------'\\ _ /     ( )\n",
            " \n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TRAIN DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:==================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading train set from: /content/drive/MyDrive/AIR Project/GermanDPR_empty_train_test.json \n",
            "Preprocessing dataset: 100%|██████████| 1/1 [00:00<00:00, 153.04 Dicts/s]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING DEV DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading dev set from: /content/drive/MyDrive/AIR Project/GermanQuAD_test_converted.json\n",
            "Preprocessing dataset: 100%|██████████| 5/5 [00:06<00:00,  1.29s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TEST DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading test set from: /content/drive/MyDrive/AIR Project/GermanQuAD_test_converted.json\n",
            "Preprocessing dataset: 100%|██████████| 5/5 [00:08<00:00,  1.65s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:DATASETS SUMMARY\n",
            "INFO:haystack.modeling.data_handler.data_silo:================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in train: 1\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in dev  : 2204\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in test : 2204\n",
            "INFO:haystack.modeling.data_handler.data_silo:Total examples   : 4409\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest query length observed after clipping: 21   - for max_query_len: 64\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average query length after clipping:          21.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion queries clipped:                   0.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest passage length observed after clipping: 256.0   - for max_passage_len: 256\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average passage length after clipping:          256.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion passages clipped:                    1.0\n",
            "INFO:haystack.modeling.model.optimization:Loading optimizer 'AdamW': {'correct_bias': True, 'weight_decay': 0.0, 'eps': 1e-08, 'lr': 1e-05}\n",
            "INFO:haystack.modeling.model.optimization:Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO:haystack.modeling.model.optimization:Loading schedule 'get_linear_schedule_with_warmup': '{'num_warmup_steps': 100, 'num_training_steps': 0}'\n",
            "INFO:haystack.modeling.training.base:No train checkpoints found. Starting a new training ...\n",
            "Train epoch 0/0 (Cur. train loss: 0.0000): 100%|██████████| 1/1 [00:00<00:00,  5.65it/s]\n",
            "Evaluating: 100%|██████████| 551/551 [01:17<00:00,  7.08it/s]\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 1 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            " _________ text_similarity _________\n",
            "INFO:haystack.modeling.evaluation.eval:loss: 0.16825160787114699\n",
            "INFO:haystack.modeling.evaluation.eval:task_name: text_similarity\n",
            "INFO:haystack.modeling.evaluation.eval:acc: 0.9686932849364791\n",
            "INFO:haystack.modeling.evaluation.eval:f1: 0.8747731397459164\n",
            "INFO:haystack.modeling.evaluation.eval:acc_and_f1: 0.9217332123411978\n",
            "INFO:haystack.modeling.evaluation.eval:average_rank: 0.2336660617059891\n",
            "INFO:haystack.modeling.evaluation.eval:report: \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "hard_negative     0.9821    0.9821    0.9821     15428\n",
            "     positive     0.8748    0.8748    0.8748      2204\n",
            "\n",
            "     accuracy                         0.9687     17632\n",
            "    macro avg     0.9284    0.9284    0.9284     17632\n",
            " weighted avg     0.9687    0.9687    0.9687     17632\n",
            "\n",
            "INFO:haystack.modeling.model.biadaptive_model:prediction_head saving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_PDR_fine_loaded.train(\n",
        "    data_dir=doc_dir,\n",
        "    train_filename=train_empty,\n",
        "    dev_filename=dev_filename_2,\n",
        "    test_filename=dev_filename_2,\n",
        "    n_epochs=1,\n",
        "    batch_size=4,\n",
        "    grad_acc_steps=8,\n",
        "    save_dir=model_dir_empty,\n",
        "    evaluate_every=3000,\n",
        "    embed_title=True,\n",
        "    num_positives=1,\n",
        "    num_hard_negatives=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pAcVjwnnf9q",
        "outputId": "89a0fce7-0127-4465-f22a-6fa78cd0ada3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|\n",
            " (o)(o)------'\\ _ /     ( )\n",
            " \n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TRAIN DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:==================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading train set from: /content/drive/MyDrive/AIR Project/GermanDPR_empty_train_test.json \n",
            "Preprocessing dataset: 100%|██████████| 1/1 [00:00<00:00, 73.52 Dicts/s]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING DEV DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading dev set from: /content/drive/MyDrive/AIR Project/GermanDPR_test.json\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:05<00:00,  1.88s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TEST DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading test set from: /content/drive/MyDrive/AIR Project/GermanDPR_test.json\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:04<00:00,  1.49s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:DATASETS SUMMARY\n",
            "INFO:haystack.modeling.data_handler.data_silo:================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in train: 1\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in dev  : 1025\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in test : 1025\n",
            "INFO:haystack.modeling.data_handler.data_silo:Total examples   : 2051\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest query length observed after clipping: 21   - for max_query_len: 64\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average query length after clipping:          21.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion queries clipped:                   0.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest passage length observed after clipping: 256.0   - for max_passage_len: 256\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average passage length after clipping:          256.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion passages clipped:                    1.0\n",
            "INFO:haystack.modeling.model.optimization:Loading optimizer 'AdamW': {'correct_bias': True, 'weight_decay': 0.0, 'eps': 1e-08, 'lr': 1e-05}\n",
            "INFO:haystack.modeling.model.optimization:Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO:haystack.modeling.model.optimization:Loading schedule 'get_linear_schedule_with_warmup': '{'num_warmup_steps': 100, 'num_training_steps': 0}'\n",
            "INFO:haystack.modeling.training.base:No train checkpoints found. Starting a new training ...\n",
            "Train epoch 0/0 (Cur. train loss: 0.0000): 100%|██████████| 1/1 [00:00<00:00,  5.89it/s]\n",
            "Evaluating: 100%|██████████| 257/257 [00:36<00:00,  6.97it/s]\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 1 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            " _________ text_similarity _________\n",
            "INFO:haystack.modeling.evaluation.eval:loss: 0.3730123194018962\n",
            "INFO:haystack.modeling.evaluation.eval:task_name: text_similarity\n",
            "INFO:haystack.modeling.evaluation.eval:acc: 0.9477666585306321\n",
            "INFO:haystack.modeling.evaluation.eval:f1: 0.791219512195122\n",
            "INFO:haystack.modeling.evaluation.eval:acc_and_f1: 0.8694930853628771\n",
            "INFO:haystack.modeling.evaluation.eval:average_rank: 0.3775609756097561\n",
            "INFO:haystack.modeling.evaluation.eval:report: \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "hard_negative     0.9701    0.9701    0.9701      7169\n",
            "     positive     0.7912    0.7912    0.7912      1025\n",
            "\n",
            "     accuracy                         0.9478      8194\n",
            "    macro avg     0.8807    0.8807    0.8807      8194\n",
            " weighted avg     0.9478    0.9478    0.9478      8194\n",
            "\n",
            "INFO:haystack.modeling.model.biadaptive_model:prediction_head saving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "models = ['Base Model', 'Fine-tuned', 'Testing with Train']\n",
        "values = [0.5458257713248639, 0.9060798548094374, 0.8825316895294322]\n",
        "f1_scores_germaquad = [0.5458257713248639, 0.9060798548094374, 0.8825316895294322]\n",
        "f1_scores_germandpr = [0.41853658536585364, 0.7736585365853659, 0.7715363881401616]\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n",
        "\n",
        "# germaquad\n",
        "axes[0].bar(models, f1_scores_germaquad, color=['blue', 'green', 'red'])\n",
        "axes[0].set_title('GermanQuAD')\n",
        "axes[0].set_xlabel('Model')\n",
        "axes[0].set_ylabel('F1-Score')\n",
        "axes[0].set_ylim(0, 1)\n",
        "\n",
        "# germandpr\n",
        "axes[1].bar(models, f1_scores_germandpr, color=['orange', 'purple', 'brown'])\n",
        "axes[1].set_title('GermanDPR')\n",
        "axes[1].set_xlabel('Model')\n",
        "axes[1].set_ylabel('F1-Score')\n",
        "axes[1].set_ylim(0, 1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D7xVGgG-jhrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.barh(models, f1_scores_germaquad, color='blue', alpha=0.7, label='GermaQuAD')\n",
        "ax.barh(models, f1_scores_germandpr, color='green', alpha=0.5, label='GermanDPR', left=f1_scores_germaquad)\n",
        "\n",
        "ax.set_xlabel('F1 Scores')\n",
        "ax.set_title('F1 Scores Comparison: GermaQuAD vs GermanDPR')\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SbfqQR_TdlHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(len(models))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "bars1 = ax.bar(x - width/2, f1_scores_germaquad, width, label='GermaQuAD', color='blue')\n",
        "bars2 = ax.bar(x + width/2, f1_scores_germandpr, width, label='GermanDPR', color='green')\n",
        "\n",
        "ax.set_ylabel('F1 Scores')\n",
        "ax.set_title('F1 Scores by Model and Dataset')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(models)\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wk2P3OQGjFjD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}