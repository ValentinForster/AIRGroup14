{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "47a3c533bd2f43b7bffbdeaeab29fd79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a0d81d9f8fa4b00b8b3f7a1f0f154be",
              "IPY_MODEL_76b4ad239a564a5e96d24e41b5774b2c",
              "IPY_MODEL_373d52cee79c49b4a5ca86bb01e5f092"
            ],
            "layout": "IPY_MODEL_657c0859a32544a2b08233c63c8e5e4f"
          }
        },
        "3a0d81d9f8fa4b00b8b3f7a1f0f154be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f722d74db2494c0289f12e12a279f23a",
            "placeholder": "​",
            "style": "IPY_MODEL_b936f9b1e3cd4848abc1d51b12337293",
            "value": "config.json: 100%"
          }
        },
        "76b4ad239a564a5e96d24e41b5774b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_377d0389a0d94dfea9a0bfb3992ce047",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff8683515a6040c09203fb0b6c9231e0",
            "value": 571
          }
        },
        "373d52cee79c49b4a5ca86bb01e5f092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7d416c91468481fa01458ffefaba92f",
            "placeholder": "​",
            "style": "IPY_MODEL_15875323271a439fbdbaed7e6f4ac536",
            "value": " 571/571 [00:00&lt;00:00, 9.67kB/s]"
          }
        },
        "657c0859a32544a2b08233c63c8e5e4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f722d74db2494c0289f12e12a279f23a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b936f9b1e3cd4848abc1d51b12337293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "377d0389a0d94dfea9a0bfb3992ce047": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff8683515a6040c09203fb0b6c9231e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7d416c91468481fa01458ffefaba92f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15875323271a439fbdbaed7e6f4ac536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7972ad052ec4e37863de59ffc250e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e13e17bfea144a488aef5d42f1673fa",
              "IPY_MODEL_097c5bee60b448c4bf070ea18077c881",
              "IPY_MODEL_31cff09ef09b477aa12286b08373fdbb"
            ],
            "layout": "IPY_MODEL_9aa52ba69d704e46a45a062714217e69"
          }
        },
        "1e13e17bfea144a488aef5d42f1673fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e28c4042c9164a33a54743568de932df",
            "placeholder": "​",
            "style": "IPY_MODEL_ba2bd6cd26084e6996853d4b53bb7676",
            "value": "model.safetensors: 100%"
          }
        },
        "097c5bee60b448c4bf070ea18077c881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d357432bc7b445cca486613f0c0b5e26",
            "max": 496254442,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10f7cb78239f4dc59aefc062c52ccfb4",
            "value": 496254442
          }
        },
        "31cff09ef09b477aa12286b08373fdbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_750ba90efc7f4ec896d02c7dec66823c",
            "placeholder": "​",
            "style": "IPY_MODEL_23ea95d62ed4446ba2ff2c9d65b5fb77",
            "value": " 496M/496M [00:06&lt;00:00, 159MB/s]"
          }
        },
        "9aa52ba69d704e46a45a062714217e69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e28c4042c9164a33a54743568de932df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba2bd6cd26084e6996853d4b53bb7676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d357432bc7b445cca486613f0c0b5e26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10f7cb78239f4dc59aefc062c52ccfb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "750ba90efc7f4ec896d02c7dec66823c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23ea95d62ed4446ba2ff2c9d65b5fb77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f78ef3f607a34007b1acfe65f2be1ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70ac5b5230844ba1b3f7082142109df4",
              "IPY_MODEL_c44b965f96e142df8df610318149b85a",
              "IPY_MODEL_c81762601ed74e2e824bfc7f59ccd176"
            ],
            "layout": "IPY_MODEL_6b965e73afb647b68d9416083b1a61c8"
          }
        },
        "70ac5b5230844ba1b3f7082142109df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_197ef2c4428c4e74b541d2c94e262b9d",
            "placeholder": "​",
            "style": "IPY_MODEL_09087bb24a5749fe8874263b6c9a57aa",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "c44b965f96e142df8df610318149b85a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84b8ecf2ffc344b197c8d24a25d7ed9b",
            "max": 79,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_788824f37aa74e3990a05b7401c06b15",
            "value": 79
          }
        },
        "c81762601ed74e2e824bfc7f59ccd176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c3ece08f23e47cfbd21e556d4865c88",
            "placeholder": "​",
            "style": "IPY_MODEL_a8587acc747c4b91b11c8078086db21d",
            "value": " 79.0/79.0 [00:00&lt;00:00, 5.63kB/s]"
          }
        },
        "6b965e73afb647b68d9416083b1a61c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "197ef2c4428c4e74b541d2c94e262b9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09087bb24a5749fe8874263b6c9a57aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84b8ecf2ffc344b197c8d24a25d7ed9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "788824f37aa74e3990a05b7401c06b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c3ece08f23e47cfbd21e556d4865c88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8587acc747c4b91b11c8078086db21d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a42d6cc9be54d57ae4cce8c8e8ea63f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92847244335648188392a0cc4a554c01",
              "IPY_MODEL_890d22d09cf7485e983fda310cac8d45",
              "IPY_MODEL_c6750e328eb548a8a6b42233bb9e7944"
            ],
            "layout": "IPY_MODEL_fdd5816761a845ccbe45a22717f039b1"
          }
        },
        "92847244335648188392a0cc4a554c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cc478e131534ad6bf06605812265d6e",
            "placeholder": "​",
            "style": "IPY_MODEL_0394b08fada0413bb8d440c54e082af9",
            "value": "vocab.json: 100%"
          }
        },
        "890d22d09cf7485e983fda310cac8d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96cabf15b3c246b4a63f03900b7c3412",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8eb46370c9204f35a62d25e1d885fce1",
            "value": 898822
          }
        },
        "c6750e328eb548a8a6b42233bb9e7944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b948fddeae1f47ad92a14ed08e3cf75f",
            "placeholder": "​",
            "style": "IPY_MODEL_f8528ddc9fac4ad89b8009eed2595b0b",
            "value": " 899k/899k [00:00&lt;00:00, 11.0MB/s]"
          }
        },
        "fdd5816761a845ccbe45a22717f039b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cc478e131534ad6bf06605812265d6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0394b08fada0413bb8d440c54e082af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96cabf15b3c246b4a63f03900b7c3412": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eb46370c9204f35a62d25e1d885fce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b948fddeae1f47ad92a14ed08e3cf75f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8528ddc9fac4ad89b8009eed2595b0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c25025d9fa04faca44972e6a795b877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7799685659d49f1ac15e6e8699bdf68",
              "IPY_MODEL_ba0d0ad7df71438aa0e82026cb17a522",
              "IPY_MODEL_0c3a7c84d02246cba644d6489f9d28f1"
            ],
            "layout": "IPY_MODEL_076f178659d0479f8ba2aff1a449ee15"
          }
        },
        "f7799685659d49f1ac15e6e8699bdf68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f3a82c900ca4ca190a15f14478fc7de",
            "placeholder": "​",
            "style": "IPY_MODEL_fb7c0b2d78b2447581c96484d3bc1222",
            "value": "merges.txt: 100%"
          }
        },
        "ba0d0ad7df71438aa0e82026cb17a522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_935bccb69b074e78b48f90b40d5025c3",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72c5d85295524f58be532efcb5c59d3d",
            "value": 456318
          }
        },
        "0c3a7c84d02246cba644d6489f9d28f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0153e4bd826e4e9697b3ea8f13c41d4d",
            "placeholder": "​",
            "style": "IPY_MODEL_db153668f5634b979af1b648425fe62b",
            "value": " 456k/456k [00:00&lt;00:00, 18.3MB/s]"
          }
        },
        "076f178659d0479f8ba2aff1a449ee15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f3a82c900ca4ca190a15f14478fc7de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb7c0b2d78b2447581c96484d3bc1222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "935bccb69b074e78b48f90b40d5025c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72c5d85295524f58be532efcb5c59d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0153e4bd826e4e9697b3ea8f13c41d4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db153668f5634b979af1b648425fe62b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79353740df1b45c29dc23caca470fdf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e60d103749e443039c325314a0c4b174",
              "IPY_MODEL_d51c8c8bdcaf477086ef0561168a465f",
              "IPY_MODEL_65004dbac5214cc9b1d9d642998479d9"
            ],
            "layout": "IPY_MODEL_a068e19a7b104330928b6a3063f41e96"
          }
        },
        "e60d103749e443039c325314a0c4b174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bd690df85c044b2ac492c8c6eeb1f57",
            "placeholder": "​",
            "style": "IPY_MODEL_8c3c88ac400641159f9d24372d907854",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "d51c8c8bdcaf477086ef0561168a465f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20b533648f7b422286cd9d1c9a3a3b7b",
            "max": 772,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0514ae30402e4c5a8ec839119a310b3a",
            "value": 772
          }
        },
        "65004dbac5214cc9b1d9d642998479d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5eb2f5e94ff94e7c8d0d376ed3429f84",
            "placeholder": "​",
            "style": "IPY_MODEL_4e097a0efb8447b78673c8486edd7666",
            "value": " 772/772 [00:00&lt;00:00, 46.8kB/s]"
          }
        },
        "a068e19a7b104330928b6a3063f41e96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bd690df85c044b2ac492c8c6eeb1f57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c3c88ac400641159f9d24372d907854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20b533648f7b422286cd9d1c9a3a3b7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0514ae30402e4c5a8ec839119a310b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5eb2f5e94ff94e7c8d0d376ed3429f84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e097a0efb8447b78673c8486edd7666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install logging\n",
        "!pip install farm-haystack\n",
        "!pip install sentence-transformers\n",
        "!pip install seqeval"
      ],
      "metadata": {
        "id": "lsKIbSzwYAUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f53b466-b9e5-41d1-b98d-e9c79caa2d46"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting logging\n",
            "  Downloading logging-0.4.9.6.tar.gz (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting farm-haystack\n",
            "  Downloading farm_haystack-1.23.0-py3-none-any.whl (764 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.4/764.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boilerpy3 (from farm-haystack)\n",
            "  Downloading boilerpy3-1.0.7-py3-none-any.whl (22 kB)\n",
            "Collecting events (from farm-haystack)\n",
            "  Downloading Events-0.5-py3-none-any.whl (6.8 kB)\n",
            "Collecting httpx (from farm-haystack)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (4.19.2)\n",
            "Collecting lazy-imports==0.3.1 (from farm-haystack)\n",
            "  Downloading lazy_imports-0.3.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (10.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (3.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (9.4.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (4.1.0)\n",
            "Collecting posthog (from farm-haystack)\n",
            "  Downloading posthog-3.1.0-py2.py3-none-any.whl (37 kB)\n",
            "Collecting prompthub-py==4.0.0 (from farm-haystack)\n",
            "  Downloading prompthub_py-4.0.0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (1.10.13)\n",
            "Collecting quantulum3 (from farm-haystack)\n",
            "  Downloading quantulum3-0.9.0-py3-none-any.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rank-bm25 (from farm-haystack)\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (2.31.0)\n",
            "Collecting requests-cache<1.0.0 (from farm-haystack)\n",
            "  Downloading requests_cache-0.9.8-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.7/48.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn>=1.3.0 (from farm-haystack)\n",
            "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sseclient-py (from farm-haystack)\n",
            "  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (8.2.3)\n",
            "Collecting tiktoken>=0.5.1 (from farm-haystack)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (4.66.1)\n",
            "Requirement already satisfied: transformers==4.35.2 in /usr/local/lib/python3.10/dist-packages (from farm-haystack) (4.35.2)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from prompthub-py==4.0.0->farm-haystack) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->farm-haystack) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->farm-haystack) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->farm-haystack) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->farm-haystack) (23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->farm-haystack) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->farm-haystack) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->farm-haystack) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2->farm-haystack) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack) (2023.11.17)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack) (1.4.4)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack) (23.2.0)\n",
            "Collecting cattrs>=22.2 (from requests-cache<1.0.0->farm-haystack)\n",
            "  Downloading cattrs-23.2.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting url-normalize>=1.4 (from requests-cache<1.0.0->farm-haystack)\n",
            "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx->farm-haystack)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack) (1.3.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->farm-haystack)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack) (0.16.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog->farm-haystack)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog->farm-haystack)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from quantulum3->farm-haystack) (7.0.0)\n",
            "Collecting num2words (from quantulum3->farm-haystack)\n",
            "  Downloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache<1.0.0->farm-haystack) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->farm-haystack) (2023.6.0)\n",
            "Collecting docopt>=0.6.2 (from num2words->quantulum3->farm-haystack)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=ebb9480447afe8645b89caaab11715800296c531bf0e8f53dab63cc24f5031c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: sseclient-py, monotonic, events, docopt, url-normalize, rank-bm25, num2words, lazy-imports, h11, cattrs, boilerpy3, backoff, tiktoken, scikit-learn, requests-cache, prompthub-py, posthog, httpcore, quantulum3, httpx, farm-haystack\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 boilerpy3-1.0.7 cattrs-23.2.3 docopt-0.6.2 events-0.5 farm-haystack-1.23.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 lazy-imports-0.3.1 monotonic-1.6 num2words-0.5.13 posthog-3.1.0 prompthub-py-4.0.0 quantulum3-0.9.0 rank-bm25-0.2.2 requests-cache-0.9.8 scikit-learn-1.3.2 sseclient-py-1.8.0 tiktoken-0.5.2 url-normalize-1.4.3\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=5ba6179e064f428cfc0b9875f4e3293924f7f2bb0367ee93e0a129d8a899a470\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.1.99\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m616.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.3.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=06042b89e52e7ee2f5d23c12ab9312aba61076c2c915be0dc452c888dd69f69f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tEvG_2I7dQU",
        "outputId": "a3a549d6-05fb-44b0-c1c2-380db23a80c6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)\n",
        "\n",
        "from haystack.nodes import DensePassageRetriever\n",
        "from haystack.document_stores import InMemoryDocumentStore"
      ],
      "metadata": {
        "id": "ZMvZxMztEksA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be862a0b-b388-465a-9e3a-f365ef22ea7f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.telemetry:Haystack sends anonymous usage data to understand the actual usage and steer dev efforts towards features that are most meaningful to users. You can opt-out at anytime by manually setting the environment variable HAYSTACK_TELEMETRY_ENABLED as described for different operating systems in the [documentation page](https://docs.haystack.deepset.ai/docs/telemetry#how-can-i-opt-out). More information at [Telemetry](https://docs.haystack.deepset.ai/docs/telemetry).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UK-iPGHEXjie"
      },
      "outputs": [],
      "source": [
        "# Here are the variables you might want to use instead of the set above\n",
        "# in order to perform pretraining\n",
        "\n",
        "doc_dir = \"/content/drive/MyDrive/AIR Project\"\n",
        "train_filename_1 = \"GermanQuAD_train_converted.json\"\n",
        "dev_filename_1 = \"GermanQuAD_test_converted.json\"\n",
        "\n",
        "query_model = \"facebook/dpr-question_encoder-single-nq-base\"\n",
        "passage_model = \"facebook/dpr-ctx_encoder-single-nq-base\"\n",
        "train_empty = \"GermanDPR_empty_train_test.json\"\n",
        "model_dir = \"/content/drive/MyDrive/AIR Project/finetune_model_GermanQuAD\"\n",
        "train_filename_2 = \"GermanDPR_train.json\"\n",
        "dev_filename_2 = \"GermanDPR_test.json\"\n",
        "model_dir2 = \"/content/drive/MyDrive/AIR Project/finetune_model_GermanDPR\"\n",
        "model_dir_empty = \"/content/drive/MyDrive/AIR Project/empty\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_base_model = DensePassageRetriever(\n",
        "    document_store=InMemoryDocumentStore(),\n",
        "    query_embedding_model=query_model,\n",
        "    passage_embedding_model=passage_model,\n",
        "    max_seq_len_query=64,\n",
        "    max_seq_len_passage=256,\n",
        ")\n",
        "retriever_base_model.train(\n",
        "    data_dir=doc_dir,\n",
        "    train_filename=train_empty,\n",
        "    dev_filename=dev_filename_1,\n",
        "    test_filename=dev_filename_2,\n",
        "    n_epochs=1,\n",
        "    batch_size=4,\n",
        "    grad_acc_steps=8,\n",
        "    evaluate_every=3000,\n",
        "    embed_title=True,\n",
        "    num_positives=1,\n",
        "    num_hard_negatives=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhNdTZUSZIpA",
        "outputId": "06745502-f0a0-42cf-c5d8-2565b5629387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n",
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|\n",
            " (o)(o)------'\\ _ /     ( )\n",
            " \n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TRAIN DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:==================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading train set from: /content/drive/MyDrive/AIR Project/GermanDPR_empty_train_test.json \n",
            "Preprocessing dataset: 100%|██████████| 1/1 [00:00<00:00, 168.63 Dicts/s]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING DEV DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading dev set from: /content/drive/MyDrive/AIR Project/GermanQuAD_test_converted.json\n",
            "Preprocessing dataset: 100%|██████████| 5/5 [00:09<00:00,  1.93s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TEST DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading test set from: /content/drive/MyDrive/AIR Project/GermanDPR_test.json\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:03<00:00,  1.14s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:DATASETS SUMMARY\n",
            "INFO:haystack.modeling.data_handler.data_silo:================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in train: 1\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in dev  : 2204\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in test : 1025\n",
            "INFO:haystack.modeling.data_handler.data_silo:Total examples   : 3230\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest query length observed after clipping: 21   - for max_query_len: 64\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average query length after clipping:          21.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion queries clipped:                   0.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest passage length observed after clipping: 256.0   - for max_passage_len: 256\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average passage length after clipping:          256.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion passages clipped:                    1.0\n",
            "INFO:haystack.modeling.model.optimization:Loading optimizer 'AdamW': {'correct_bias': True, 'weight_decay': 0.0, 'eps': 1e-08, 'lr': 1e-05}\n",
            "INFO:haystack.modeling.model.optimization:Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO:haystack.modeling.model.optimization:Loading schedule 'get_linear_schedule_with_warmup': '{'num_warmup_steps': 100, 'num_training_steps': 0}'\n",
            "INFO:haystack.modeling.training.base:No train checkpoints found. Starting a new training ...\n",
            "Train epoch 0/0 (Cur. train loss: 0.0000): 100%|██████████| 1/1 [00:00<00:00,  5.62it/s]\n",
            "Evaluating: 100%|██████████| 257/257 [00:41<00:00,  6.12it/s]\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 1 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            " _________ text_similarity _________\n",
            "INFO:haystack.modeling.evaluation.eval:loss: 0.5415056926148331\n",
            "INFO:haystack.modeling.evaluation.eval:task_name: text_similarity\n",
            "INFO:haystack.modeling.evaluation.eval:acc: 0.8984622894801074\n",
            "INFO:haystack.modeling.evaluation.eval:f1: 0.5941463414634146\n",
            "INFO:haystack.modeling.evaluation.eval:acc_and_f1: 0.746304315471761\n",
            "INFO:haystack.modeling.evaluation.eval:average_rank: 0.8546341463414634\n",
            "INFO:haystack.modeling.evaluation.eval:report: \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "hard_negative     0.9420    0.9420    0.9420      7169\n",
            "     positive     0.5941    0.5941    0.5941      1025\n",
            "\n",
            "     accuracy                         0.8985      8194\n",
            "    macro avg     0.7681    0.7681    0.7681      8194\n",
            " weighted avg     0.8985    0.8985    0.8985      8194\n",
            "\n",
            "INFO:haystack.modeling.model.biadaptive_model:prediction_head saving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_QuAD_fine = DensePassageRetriever(\n",
        "    document_store=InMemoryDocumentStore(),\n",
        "    query_embedding_model=query_model,\n",
        "    passage_embedding_model=passage_model,\n",
        "    max_seq_len_query=64,\n",
        "    max_seq_len_passage=256,\n",
        ")\n",
        "retriever_QuAD_fine.train(\n",
        "    data_dir=doc_dir,\n",
        "    train_filename=train_filename_1,\n",
        "    dev_filename=dev_filename_1,\n",
        "    test_filename=dev_filename_2,\n",
        "    n_epochs=1,\n",
        "    batch_size=4,\n",
        "    grad_acc_steps=8,\n",
        "    save_dir=model_dir,\n",
        "    evaluate_every=3000,\n",
        "    embed_title=True,\n",
        "    num_positives=1,\n",
        "    num_hard_negatives=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM8IihLGXvTy",
        "outputId": "3aa619f2-8947-47d1-bbae-d1f60ed33337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n",
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|\n",
            " (o)(o)------'\\ _ /     ( )\n",
            " \n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TRAIN DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:==================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading train set from: /content/drive/MyDrive/AIR Project/GermanQuAD_train_converted.json \n",
            "Preprocessing dataset: 100%|██████████| 23/23 [00:27<00:00,  1.19s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING DEV DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading dev set from: /content/drive/MyDrive/AIR Project/GermanQuAD_test_converted.json\n",
            "Preprocessing dataset: 100%|██████████| 5/5 [00:07<00:00,  1.47s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TEST DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading test set from: /content/drive/MyDrive/AIR Project/GermanDPR_test.json\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:03<00:00,  1.14s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:DATASETS SUMMARY\n",
            "INFO:haystack.modeling.data_handler.data_silo:================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in train: 11518\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in dev  : 2204\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in test : 1025\n",
            "INFO:haystack.modeling.data_handler.data_silo:Total examples   : 14747\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest query length observed after clipping: 50   - for max_query_len: 64\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average query length after clipping:          20.60027782601146\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion queries clipped:                   0.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest passage length observed after clipping: 129.5   - for max_passage_len: 256\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average passage length after clipping:          126.57874631012328\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion passages clipped:                    0.0\n",
            "INFO:haystack.modeling.model.optimization:Loading optimizer 'AdamW': {'correct_bias': True, 'weight_decay': 0.0, 'eps': 1e-08, 'lr': 1e-05}\n",
            "INFO:haystack.modeling.model.optimization:Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO:haystack.modeling.model.optimization:Loading schedule 'get_linear_schedule_with_warmup': '{'num_warmup_steps': 100, 'num_training_steps': 360}'\n",
            "INFO:haystack.modeling.training.base:No train checkpoints found. Starting a new training ...\n",
            "Train epoch 0/0 (Cur. train loss: 0.0004): 100%|██████████| 2880/2880 [22:31<00:00,  2.13it/s]\n",
            "Evaluating: 100%|██████████| 257/257 [00:40<00:00,  6.40it/s]\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 2880 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            " _________ text_similarity _________\n",
            "INFO:haystack.modeling.evaluation.eval:loss: 0.740938199624777\n",
            "INFO:haystack.modeling.evaluation.eval:task_name: text_similarity\n",
            "INFO:haystack.modeling.evaluation.eval:acc: 0.93605076885526\n",
            "INFO:haystack.modeling.evaluation.eval:f1: 0.744390243902439\n",
            "INFO:haystack.modeling.evaluation.eval:acc_and_f1: 0.8402205063788495\n",
            "INFO:haystack.modeling.evaluation.eval:average_rank: 0.38634146341463416\n",
            "INFO:haystack.modeling.evaluation.eval:report: \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "hard_negative     0.9635    0.9635    0.9635      7169\n",
            "     positive     0.7444    0.7444    0.7444      1025\n",
            "\n",
            "     accuracy                         0.9361      8194\n",
            "    macro avg     0.8539    0.8539    0.8539      8194\n",
            " weighted avg     0.9361    0.9361    0.9361      8194\n",
            "\n",
            "INFO:haystack.modeling.model.biadaptive_model:prediction_head saving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fine-tuned model\n",
        "retriever_DPR_fine = DensePassageRetriever(document_store=InMemoryDocumentStore())\n",
        "retriever_DPR_fine.load(load_dir=model_dir, document_store=InMemoryDocumentStore())\n",
        "\n",
        "retriever_DPR_fine.train(\n",
        "    data_dir=doc_dir,\n",
        "    train_filename=train_filename_2,\n",
        "    dev_filename=dev_filename_2,\n",
        "    test_filename=dev_filename_2,\n",
        "    n_epochs=1,\n",
        "    batch_size=4,\n",
        "    grad_acc_steps=8,\n",
        "    save_dir=model_dir2,\n",
        "    evaluate_every=3000,\n",
        "    embed_title=True,\n",
        "    num_positives=1,\n",
        "    num_hard_negatives=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C2brVCHiepz",
        "outputId": "932f6734-60a3-4684-bf72-5c90d62e536b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n",
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n",
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.nodes.retriever.dense:DPR model loaded from /content/drive/MyDrive/AIR Project/finetune_model_GermanQuAD\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|\n",
            " (o)(o)------'\\ _ /     ( )\n",
            " \n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TRAIN DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:==================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading train set from: /content/drive/MyDrive/AIR Project/GermanDPR_train.json \n",
            "Preprocessing dataset: 100%|██████████| 19/19 [00:42<00:00,  2.25s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING DEV DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading dev set from: /content/drive/MyDrive/AIR Project/GermanDPR_test.json\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:03<00:00,  1.20s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TEST DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading test set from: /content/drive/MyDrive/AIR Project/GermanDPR_test.json\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:03<00:00,  1.17s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:DATASETS SUMMARY\n",
            "INFO:haystack.modeling.data_handler.data_silo:================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in train: 9275\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in dev  : 1025\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in test : 1025\n",
            "INFO:haystack.modeling.data_handler.data_silo:Total examples   : 11325\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest query length observed after clipping: 50   - for max_query_len: 64\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average query length after clipping:          20.343719676549867\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion queries clipped:                   0.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest passage length observed after clipping: 256.0   - for max_passage_len: 256\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average passage length after clipping:          249.488948787062\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion passages clipped:                    0.6939083557951482\n",
            "INFO:haystack.modeling.model.optimization:Loading optimizer 'AdamW': {'correct_bias': True, 'weight_decay': 0.0, 'eps': 1e-08, 'lr': 1e-05}\n",
            "INFO:haystack.modeling.model.optimization:Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO:haystack.modeling.model.optimization:Loading schedule 'get_linear_schedule_with_warmup': '{'num_warmup_steps': 100, 'num_training_steps': 289}'\n",
            "INFO:haystack.modeling.training.base:No train checkpoints found. Starting a new training ...\n",
            "Train epoch 0/0 (Cur. train loss: 0.1892): 100%|██████████| 2319/2319 [19:04<00:00,  2.03it/s]\n",
            "Evaluating: 100%|██████████| 257/257 [00:40<00:00,  6.32it/s]\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 2319 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            " _________ text_similarity _________\n",
            "INFO:haystack.modeling.evaluation.eval:loss: 0.42104266645807076\n",
            "INFO:haystack.modeling.evaluation.eval:task_name: text_similarity\n",
            "INFO:haystack.modeling.evaluation.eval:acc: 0.9450817671466927\n",
            "INFO:haystack.modeling.evaluation.eval:f1: 0.7804878048780488\n",
            "INFO:haystack.modeling.evaluation.eval:acc_and_f1: 0.8627847860123707\n",
            "INFO:haystack.modeling.evaluation.eval:average_rank: 0.3804878048780488\n",
            "INFO:haystack.modeling.evaluation.eval:report: \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "hard_negative     0.9686    0.9686    0.9686      7169\n",
            "     positive     0.7805    0.7805    0.7805      1025\n",
            "\n",
            "     accuracy                         0.9451      8194\n",
            "    macro avg     0.8746    0.8746    0.8746      8194\n",
            " weighted avg     0.9451    0.9451    0.9451      8194\n",
            "\n",
            "INFO:haystack.modeling.model.biadaptive_model:prediction_head saving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RTndkctOgrmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s5x4WzxukCAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_base_loaded = DensePassageRetriever(\n",
        "    document_store=InMemoryDocumentStore(),\n",
        "    query_embedding_model=query_model,\n",
        "    passage_embedding_model=passage_model,\n",
        "    max_seq_len_query=64,\n",
        "    max_seq_len_passage=256,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP1F2IQcnFQh",
        "outputId": "f4d4bd62-959f-47d9-f9fe-3cac3b64c16e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n",
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "retriever_base_loaded.train(\n",
        "    data_dir=doc_dir,\n",
        "    train_filename=train_empty,\n",
        "    dev_filename=dev_filename_1,\n",
        "    test_filename=dev_filename_1,\n",
        "    n_epochs=1,\n",
        "    batch_size=4,\n",
        "    grad_acc_steps=8,\n",
        "    save_dir=model_dir_empty,\n",
        "    evaluate_every=3000,\n",
        "    embed_title=True,\n",
        "    num_positives=1,\n",
        "    num_hard_negatives=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPhr8QcfkCbO",
        "outputId": "b466363c-0d38-4aea-93ef-cfd9627e3a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|\n",
            " (o)(o)------'\\ _ /     ( )\n",
            " \n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TRAIN DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:==================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading train set from: /content/drive/MyDrive/AIR Project/GermanDPR_empty_train_test.json \n",
            "Preprocessing dataset: 100%|██████████| 1/1 [00:00<00:00, 96.03 Dicts/s]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING DEV DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading dev set from: /content/drive/MyDrive/AIR Project/GermanQuAD_test_converted.json\n",
            "Preprocessing dataset: 100%|██████████| 5/5 [00:09<00:00,  1.89s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TEST DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading test set from: /content/drive/MyDrive/AIR Project/GermanQuAD_test_converted.json\n",
            "Preprocessing dataset: 100%|██████████| 5/5 [00:06<00:00,  1.30s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:DATASETS SUMMARY\n",
            "INFO:haystack.modeling.data_handler.data_silo:================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in train: 1\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in dev  : 2204\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in test : 2204\n",
            "INFO:haystack.modeling.data_handler.data_silo:Total examples   : 4409\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest query length observed after clipping: 21   - for max_query_len: 64\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average query length after clipping:          21.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion queries clipped:                   0.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest passage length observed after clipping: 256.0   - for max_passage_len: 256\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average passage length after clipping:          256.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion passages clipped:                    1.0\n",
            "INFO:haystack.modeling.model.optimization:Loading optimizer 'AdamW': {'correct_bias': True, 'weight_decay': 0.0, 'eps': 1e-08, 'lr': 1e-05}\n",
            "INFO:haystack.modeling.model.optimization:Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO:haystack.modeling.model.optimization:Loading schedule 'get_linear_schedule_with_warmup': '{'num_warmup_steps': 100, 'num_training_steps': 0}'\n",
            "INFO:haystack.modeling.training.base:No train checkpoints found. Starting a new training ...\n",
            "Train epoch 0/0 (Cur. train loss: 0.0000): 100%|██████████| 1/1 [00:00<00:00,  5.93it/s]\n",
            "Evaluating: 100%|██████████| 551/551 [01:15<00:00,  7.26it/s]\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 1 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            " _________ text_similarity _________\n",
            "INFO:haystack.modeling.evaluation.eval:loss: 0.2932318130946229\n",
            "INFO:haystack.modeling.evaluation.eval:task_name: text_similarity\n",
            "INFO:haystack.modeling.evaluation.eval:acc: 0.9432849364791288\n",
            "INFO:haystack.modeling.evaluation.eval:f1: 0.7731397459165156\n",
            "INFO:haystack.modeling.evaluation.eval:acc_and_f1: 0.8582123411978222\n",
            "INFO:haystack.modeling.evaluation.eval:average_rank: 0.3352994555353902\n",
            "INFO:haystack.modeling.evaluation.eval:report: \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "hard_negative     0.9676    0.9676    0.9676     15428\n",
            "     positive     0.7731    0.7731    0.7731      2204\n",
            "\n",
            "     accuracy                         0.9433     17632\n",
            "    macro avg     0.8704    0.8704    0.8704     17632\n",
            " weighted avg     0.9433    0.9433    0.9433     17632\n",
            "\n",
            "INFO:haystack.modeling.model.biadaptive_model:prediction_head saving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_base_loaded.train(\n",
        "    data_dir=doc_dir,\n",
        "    train_filename=train_empty,\n",
        "    dev_filename=dev_filename_2,\n",
        "    test_filename=dev_filename_2,\n",
        "    n_epochs=1,\n",
        "    batch_size=4,\n",
        "    grad_acc_steps=8,\n",
        "    save_dir=model_dir_empty,\n",
        "    evaluate_every=3000,\n",
        "    embed_title=True,\n",
        "    num_positives=1,\n",
        "    num_hard_negatives=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQUlAdFeWBel",
        "outputId": "09df44f5-4a73-4ffa-ebb7-6b6f14f59288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|\n",
            " (o)(o)------'\\ _ /     ( )\n",
            " \n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TRAIN DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:==================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading train set from: /content/drive/MyDrive/AIR Project/GermanDPR_empty_train_test.json \n",
            "Preprocessing dataset: 100%|██████████| 1/1 [00:00<00:00, 112.11 Dicts/s]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING DEV DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading dev set from: /content/drive/MyDrive/AIR Project/GermanDPR_test.json\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:04<00:00,  1.59s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TEST DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading test set from: /content/drive/MyDrive/AIR Project/GermanDPR_test.json\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:05<00:00,  1.84s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:DATASETS SUMMARY\n",
            "INFO:haystack.modeling.data_handler.data_silo:================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in train: 1\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in dev  : 1025\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in test : 1025\n",
            "INFO:haystack.modeling.data_handler.data_silo:Total examples   : 2051\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest query length observed after clipping: 21   - for max_query_len: 64\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average query length after clipping:          21.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion queries clipped:                   0.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest passage length observed after clipping: 256.0   - for max_passage_len: 256\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average passage length after clipping:          256.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion passages clipped:                    1.0\n",
            "INFO:haystack.modeling.model.optimization:Loading optimizer 'AdamW': {'correct_bias': True, 'weight_decay': 0.0, 'eps': 1e-08, 'lr': 1e-05}\n",
            "INFO:haystack.modeling.model.optimization:Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO:haystack.modeling.model.optimization:Loading schedule 'get_linear_schedule_with_warmup': '{'num_warmup_steps': 100, 'num_training_steps': 0}'\n",
            "INFO:haystack.modeling.training.base:No train checkpoints found. Starting a new training ...\n",
            "Train epoch 0/0 (Cur. train loss: 0.0000): 100%|██████████| 1/1 [00:00<00:00,  5.50it/s]\n",
            "Evaluating: 100%|██████████| 257/257 [00:35<00:00,  7.19it/s]\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 1 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            " _________ text_similarity _________\n",
            "INFO:haystack.modeling.evaluation.eval:loss: 0.5369547309723974\n",
            "INFO:haystack.modeling.evaluation.eval:task_name: text_similarity\n",
            "INFO:haystack.modeling.evaluation.eval:acc: 0.8994386136197218\n",
            "INFO:haystack.modeling.evaluation.eval:f1: 0.5980487804878049\n",
            "INFO:haystack.modeling.evaluation.eval:acc_and_f1: 0.7487436970537633\n",
            "INFO:haystack.modeling.evaluation.eval:average_rank: 0.8273170731707317\n",
            "INFO:haystack.modeling.evaluation.eval:report: \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "hard_negative     0.9425    0.9425    0.9425      7169\n",
            "     positive     0.5980    0.5980    0.5980      1025\n",
            "\n",
            "     accuracy                         0.8994      8194\n",
            "    macro avg     0.7703    0.7703    0.7703      8194\n",
            " weighted avg     0.8994    0.8994    0.8994      8194\n",
            "\n",
            "INFO:haystack.modeling.model.biadaptive_model:prediction_head saving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_QuAD_fine_loaded = DensePassageRetriever.load(model_dir, document_store=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DChijfvci1bE",
        "outputId": "6d5e952a-fd44-444f-92cd-a15af830b7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.nodes.retriever.dense:DPR model loaded from /content/drive/MyDrive/AIR Project/finetune_model_GermanQuAD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_QuAD_fine_loaded.train(\n",
        "    data_dir=doc_dir,\n",
        "    train_filename=train_empty,\n",
        "    dev_filename=dev_filename_1,\n",
        "    test_filename=dev_filename_1,\n",
        "    n_epochs=1,\n",
        "    batch_size=4,\n",
        "    grad_acc_steps=8,\n",
        "    save_dir=model_dir_empty,\n",
        "    evaluate_every=3000,\n",
        "    embed_title=True,\n",
        "    num_positives=1,\n",
        "    num_hard_negatives=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J4hqlU5nTgx",
        "outputId": "d40853bd-945e-4bc1-899d-7ce1f167d261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|\n",
            " (o)(o)------'\\ _ /     ( )\n",
            " \n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TRAIN DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:==================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading train set from: /content/drive/MyDrive/AIR Project/GermanDPR_empty_train_test.json \n",
            "Preprocessing dataset: 100%|██████████| 1/1 [00:00<00:00, 147.65 Dicts/s]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING DEV DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading dev set from: /content/drive/MyDrive/AIR Project/GermanQuAD_test_converted.json\n",
            "Preprocessing dataset: 100%|██████████| 5/5 [00:06<00:00,  1.34s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TEST DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading test set from: /content/drive/MyDrive/AIR Project/GermanQuAD_test_converted.json\n",
            "Preprocessing dataset: 100%|██████████| 5/5 [00:08<00:00,  1.72s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:DATASETS SUMMARY\n",
            "INFO:haystack.modeling.data_handler.data_silo:================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in train: 1\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in dev  : 2204\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in test : 2204\n",
            "INFO:haystack.modeling.data_handler.data_silo:Total examples   : 4409\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest query length observed after clipping: 21   - for max_query_len: 64\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average query length after clipping:          21.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion queries clipped:                   0.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest passage length observed after clipping: 256.0   - for max_passage_len: 256\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average passage length after clipping:          256.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion passages clipped:                    1.0\n",
            "INFO:haystack.modeling.model.optimization:Loading optimizer 'AdamW': {'correct_bias': True, 'weight_decay': 0.0, 'eps': 1e-08, 'lr': 1e-05}\n",
            "INFO:haystack.modeling.model.optimization:Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO:haystack.modeling.model.optimization:Loading schedule 'get_linear_schedule_with_warmup': '{'num_warmup_steps': 100, 'num_training_steps': 0}'\n",
            "INFO:haystack.modeling.training.base:No train checkpoints found. Starting a new training ...\n",
            "Train epoch 0/0 (Cur. train loss: 0.0000): 100%|██████████| 1/1 [00:00<00:00,  5.77it/s]\n",
            "Evaluating: 100%|██████████| 551/551 [01:16<00:00,  7.24it/s]\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 1 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            " _________ text_similarity _________\n",
            "INFO:haystack.modeling.evaluation.eval:loss: 0.21742588322743112\n",
            "INFO:haystack.modeling.evaluation.eval:task_name: text_similarity\n",
            "INFO:haystack.modeling.evaluation.eval:acc: 0.9748185117967332\n",
            "INFO:haystack.modeling.evaluation.eval:f1: 0.8992740471869328\n",
            "INFO:haystack.modeling.evaluation.eval:acc_and_f1: 0.9370462794918331\n",
            "INFO:haystack.modeling.evaluation.eval:average_rank: 0.15562613430127042\n",
            "INFO:haystack.modeling.evaluation.eval:report: \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "hard_negative     0.9856    0.9856    0.9856     15428\n",
            "     positive     0.8993    0.8993    0.8993      2204\n",
            "\n",
            "     accuracy                         0.9748     17632\n",
            "    macro avg     0.9424    0.9424    0.9424     17632\n",
            " weighted avg     0.9748    0.9748    0.9748     17632\n",
            "\n",
            "INFO:haystack.modeling.model.biadaptive_model:prediction_head saving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_QuAD_fine_loaded.train(\n",
        "    data_dir=doc_dir,\n",
        "    train_filename=train_empty,\n",
        "    dev_filename=dev_filename_2,\n",
        "    test_filename=dev_filename_2,\n",
        "    n_epochs=1,\n",
        "    batch_size=4,\n",
        "    grad_acc_steps=8,\n",
        "    save_dir=model_dir_empty,\n",
        "    evaluate_every=3000,\n",
        "    embed_title=True,\n",
        "    num_positives=1,\n",
        "    num_hard_negatives=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjLH6TcnnXoB",
        "outputId": "e1d60200-7bf8-4abf-baba-da065a1d3a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|\n",
            " (o)(o)------'\\ _ /     ( )\n",
            " \n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TRAIN DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:==================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading train set from: /content/drive/MyDrive/AIR Project/GermanDPR_empty_train_test.json \n",
            "Preprocessing dataset: 100%|██████████| 1/1 [00:00<00:00, 83.46 Dicts/s]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING DEV DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading dev set from: /content/drive/MyDrive/AIR Project/GermanDPR_test.json\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:05<00:00,  1.67s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TEST DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading test set from: /content/drive/MyDrive/AIR Project/GermanDPR_test.json\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:03<00:00,  1.16s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:DATASETS SUMMARY\n",
            "INFO:haystack.modeling.data_handler.data_silo:================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in train: 1\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in dev  : 1025\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in test : 1025\n",
            "INFO:haystack.modeling.data_handler.data_silo:Total examples   : 2051\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest query length observed after clipping: 21   - for max_query_len: 64\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average query length after clipping:          21.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion queries clipped:                   0.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest passage length observed after clipping: 256.0   - for max_passage_len: 256\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average passage length after clipping:          256.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion passages clipped:                    1.0\n",
            "INFO:haystack.modeling.model.optimization:Loading optimizer 'AdamW': {'correct_bias': True, 'weight_decay': 0.0, 'eps': 1e-08, 'lr': 1e-05}\n",
            "INFO:haystack.modeling.model.optimization:Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO:haystack.modeling.model.optimization:Loading schedule 'get_linear_schedule_with_warmup': '{'num_warmup_steps': 100, 'num_training_steps': 0}'\n",
            "INFO:haystack.modeling.training.base:No train checkpoints found. Starting a new training ...\n",
            "Train epoch 0/0 (Cur. train loss: 0.0000): 100%|██████████| 1/1 [00:00<00:00,  5.95it/s]\n",
            "Evaluating: 100%|██████████| 257/257 [00:36<00:00,  7.07it/s]\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 1 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            " _________ text_similarity _________\n",
            "INFO:haystack.modeling.evaluation.eval:loss: 0.7143888374891648\n",
            "INFO:haystack.modeling.evaluation.eval:task_name: text_similarity\n",
            "INFO:haystack.modeling.evaluation.eval:acc: 0.9384915792042958\n",
            "INFO:haystack.modeling.evaluation.eval:f1: 0.7541463414634146\n",
            "INFO:haystack.modeling.evaluation.eval:acc_and_f1: 0.8463189603338552\n",
            "INFO:haystack.modeling.evaluation.eval:average_rank: 0.3795121951219512\n",
            "INFO:haystack.modeling.evaluation.eval:report: \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "hard_negative     0.9648    0.9648    0.9648      7169\n",
            "     positive     0.7541    0.7541    0.7541      1025\n",
            "\n",
            "     accuracy                         0.9385      8194\n",
            "    macro avg     0.8595    0.8595    0.8595      8194\n",
            " weighted avg     0.9385    0.9385    0.9385      8194\n",
            "\n",
            "INFO:haystack.modeling.model.biadaptive_model:prediction_head saving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_PDR_fine_loaded = DensePassageRetriever.load(model_dir2, document_store=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdjUDuugWA59",
        "outputId": "3af8faec-1694-4aa6-adc8-186dc571414a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.nodes.retriever.dense:DPR model loaded from /content/drive/MyDrive/AIR Project/finetune_model_GermanDPR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_PDR_fine_loaded.train(\n",
        "    data_dir=doc_dir,\n",
        "    train_filename=train_empty,\n",
        "    dev_filename=dev_filename_1,\n",
        "    test_filename=dev_filename_1,\n",
        "    n_epochs=1,\n",
        "    batch_size=4,\n",
        "    grad_acc_steps=8,\n",
        "    save_dir=model_dir_empty,\n",
        "    evaluate_every=3000,\n",
        "    embed_title=True,\n",
        "    num_positives=1,\n",
        "    num_hard_negatives=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfGmxQYMnbbD",
        "outputId": "84c2c9c2-3769-43f4-dfe9-6118a6e10f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|\n",
            " (o)(o)------'\\ _ /     ( )\n",
            " \n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TRAIN DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:==================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading train set from: /content/drive/MyDrive/AIR Project/GermanDPR_empty_train_test.json \n",
            "Preprocessing dataset: 100%|██████████| 1/1 [00:00<00:00, 153.04 Dicts/s]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING DEV DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading dev set from: /content/drive/MyDrive/AIR Project/GermanQuAD_test_converted.json\n",
            "Preprocessing dataset: 100%|██████████| 5/5 [00:06<00:00,  1.29s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TEST DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading test set from: /content/drive/MyDrive/AIR Project/GermanQuAD_test_converted.json\n",
            "Preprocessing dataset: 100%|██████████| 5/5 [00:08<00:00,  1.65s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:DATASETS SUMMARY\n",
            "INFO:haystack.modeling.data_handler.data_silo:================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in train: 1\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in dev  : 2204\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in test : 2204\n",
            "INFO:haystack.modeling.data_handler.data_silo:Total examples   : 4409\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest query length observed after clipping: 21   - for max_query_len: 64\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average query length after clipping:          21.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion queries clipped:                   0.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest passage length observed after clipping: 256.0   - for max_passage_len: 256\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average passage length after clipping:          256.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion passages clipped:                    1.0\n",
            "INFO:haystack.modeling.model.optimization:Loading optimizer 'AdamW': {'correct_bias': True, 'weight_decay': 0.0, 'eps': 1e-08, 'lr': 1e-05}\n",
            "INFO:haystack.modeling.model.optimization:Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO:haystack.modeling.model.optimization:Loading schedule 'get_linear_schedule_with_warmup': '{'num_warmup_steps': 100, 'num_training_steps': 0}'\n",
            "INFO:haystack.modeling.training.base:No train checkpoints found. Starting a new training ...\n",
            "Train epoch 0/0 (Cur. train loss: 0.0000): 100%|██████████| 1/1 [00:00<00:00,  5.65it/s]\n",
            "Evaluating: 100%|██████████| 551/551 [01:17<00:00,  7.08it/s]\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 1 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            " _________ text_similarity _________\n",
            "INFO:haystack.modeling.evaluation.eval:loss: 0.16825160787114699\n",
            "INFO:haystack.modeling.evaluation.eval:task_name: text_similarity\n",
            "INFO:haystack.modeling.evaluation.eval:acc: 0.9686932849364791\n",
            "INFO:haystack.modeling.evaluation.eval:f1: 0.8747731397459164\n",
            "INFO:haystack.modeling.evaluation.eval:acc_and_f1: 0.9217332123411978\n",
            "INFO:haystack.modeling.evaluation.eval:average_rank: 0.2336660617059891\n",
            "INFO:haystack.modeling.evaluation.eval:report: \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "hard_negative     0.9821    0.9821    0.9821     15428\n",
            "     positive     0.8748    0.8748    0.8748      2204\n",
            "\n",
            "     accuracy                         0.9687     17632\n",
            "    macro avg     0.9284    0.9284    0.9284     17632\n",
            " weighted avg     0.9687    0.9687    0.9687     17632\n",
            "\n",
            "INFO:haystack.modeling.model.biadaptive_model:prediction_head saving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_PDR_fine_loaded.train(\n",
        "    data_dir=doc_dir,\n",
        "    train_filename=train_empty,\n",
        "    dev_filename=dev_filename_2,\n",
        "    test_filename=dev_filename_2,\n",
        "    n_epochs=1,\n",
        "    batch_size=4,\n",
        "    grad_acc_steps=8,\n",
        "    save_dir=model_dir_empty,\n",
        "    evaluate_every=3000,\n",
        "    embed_title=True,\n",
        "    num_positives=1,\n",
        "    num_hard_negatives=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pAcVjwnnf9q",
        "outputId": "89a0fce7-0127-4465-f22a-6fa78cd0ada3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|\n",
            " (o)(o)------'\\ _ /     ( )\n",
            " \n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TRAIN DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:==================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading train set from: /content/drive/MyDrive/AIR Project/GermanDPR_empty_train_test.json \n",
            "Preprocessing dataset: 100%|██████████| 1/1 [00:00<00:00, 73.52 Dicts/s]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING DEV DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading dev set from: /content/drive/MyDrive/AIR Project/GermanDPR_test.json\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:05<00:00,  1.88s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TEST DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading test set from: /content/drive/MyDrive/AIR Project/GermanDPR_test.json\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:04<00:00,  1.49s/ Dicts]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:DATASETS SUMMARY\n",
            "INFO:haystack.modeling.data_handler.data_silo:================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in train: 1\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in dev  : 1025\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in test : 1025\n",
            "INFO:haystack.modeling.data_handler.data_silo:Total examples   : 2051\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest query length observed after clipping: 21   - for max_query_len: 64\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average query length after clipping:          21.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion queries clipped:                   0.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest passage length observed after clipping: 256.0   - for max_passage_len: 256\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average passage length after clipping:          256.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion passages clipped:                    1.0\n",
            "INFO:haystack.modeling.model.optimization:Loading optimizer 'AdamW': {'correct_bias': True, 'weight_decay': 0.0, 'eps': 1e-08, 'lr': 1e-05}\n",
            "INFO:haystack.modeling.model.optimization:Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO:haystack.modeling.model.optimization:Loading schedule 'get_linear_schedule_with_warmup': '{'num_warmup_steps': 100, 'num_training_steps': 0}'\n",
            "INFO:haystack.modeling.training.base:No train checkpoints found. Starting a new training ...\n",
            "Train epoch 0/0 (Cur. train loss: 0.0000): 100%|██████████| 1/1 [00:00<00:00,  5.89it/s]\n",
            "Evaluating: 100%|██████████| 257/257 [00:36<00:00,  6.97it/s]\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 1 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            " _________ text_similarity _________\n",
            "INFO:haystack.modeling.evaluation.eval:loss: 0.3730123194018962\n",
            "INFO:haystack.modeling.evaluation.eval:task_name: text_similarity\n",
            "INFO:haystack.modeling.evaluation.eval:acc: 0.9477666585306321\n",
            "INFO:haystack.modeling.evaluation.eval:f1: 0.791219512195122\n",
            "INFO:haystack.modeling.evaluation.eval:acc_and_f1: 0.8694930853628771\n",
            "INFO:haystack.modeling.evaluation.eval:average_rank: 0.3775609756097561\n",
            "INFO:haystack.modeling.evaluation.eval:report: \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "hard_negative     0.9701    0.9701    0.9701      7169\n",
            "     positive     0.7912    0.7912    0.7912      1025\n",
            "\n",
            "     accuracy                         0.9478      8194\n",
            "    macro avg     0.8807    0.8807    0.8807      8194\n",
            " weighted avg     0.9478    0.9478    0.9478      8194\n",
            "\n",
            "INFO:haystack.modeling.model.biadaptive_model:prediction_head saving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "models = ['Base Model', 'QuAD-Fine-tuned', 'QuAD+DPR-Fine-tuned']\n",
        "f1_scores_germaquad = [0.7731397459165156, 0.8992740471869328, 0.8747731397459164]\n",
        "f1_scores_germandpr = [0.5980487804878049, 0.7541463414634146, 0.791219512195122]\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n",
        "\n",
        "# germaquad\n",
        "bars1 = axes[0].bar(models, f1_scores_germaquad, color=['blue', 'green', 'red'])\n",
        "axes[0].set_title('GermanQuAD set train + test')\n",
        "axes[0].set_xlabel('Model')\n",
        "axes[0].set_ylabel('F1-Score')\n",
        "axes[0].set_ylim(0, 1)\n",
        "for bar in bars1:\n",
        "    yval = bar.get_height()\n",
        "    axes[0].text(bar.get_x() + bar.get_width()/2.0, yval, round(yval, 2), va='bottom')\n",
        "\n",
        "# germandpr\n",
        "bars2 = axes[1].bar(models, f1_scores_germandpr, color=['orange', 'purple', 'brown'])\n",
        "axes[1].set_title('GermanDPR set train + test')\n",
        "axes[1].set_xlabel('Model')\n",
        "axes[1].set_ylabel('F1-Score')\n",
        "axes[1].set_ylim(0, 1)\n",
        "for bar in bars2:\n",
        "    yval = bar.get_height()\n",
        "    axes[1].text(bar.get_x() + bar.get_width()/2.0, yval, round(yval, 2), va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D7xVGgG-jhrm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "1e4ba2f9-ec71-4910-afb9-5d44f8ff75fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores_germandpr_test = [0.5941463414634146, 0.744390243902439, 0.7804878048780488]\n",
        "fig, ax = plt.subplots()\n",
        "bars = ax.barh(models, f1_scores_germandpr_test, color='blue', alpha=0.7, label='GermaQuAD')\n",
        "\n",
        "ax.set_xlabel('F1 Scores')\n",
        "ax.set_title('F1 Scores Comparison: GermanQuAD vs GermanQuAD + GermanDPR on DPR test')\n",
        "\n",
        "for bar in bars:\n",
        "    width = bar.get_width()\n",
        "    ax.text(width, bar.get_y() + bar.get_height() / 2, f'{width:.2f}',ha='left', va='center')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SbfqQR_TdlHj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "bc97ff64-a633-4784-a9fe-b6e8e1a311b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.arange(len(models))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "bars1 = ax.bar(x - width/2, f1_scores_germandpr_test, width, label='GermaQuAD', color='blue')\n",
        "\n",
        "ax.set_ylabel('F1 Scores')\n",
        "ax.set_title('F1 Scores by Model and Dataset')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(models)\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "wk2P3OQGjFjD",
        "outputId": "1a59dbf4-52c0-4f26-f3e6-4d06ae87f59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from haystack.document_stores import InMemoryDocumentStore\n",
        "from haystack.nodes import TfidfRetriever\n",
        "\n",
        "def extract_queries_and_doc_ids(json_file):\n",
        "    with open(json_file, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "        return [(item['question'], ctx['passage_id']) for item in data for ctx in item['positive_ctxs']]\n",
        "\n",
        "def load_documents_to_store(json_file, document_store):\n",
        "    with open(json_file, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "        documents = []\n",
        "        for item in data:\n",
        "            for ctx in item['positive_ctxs']:\n",
        "                documents.append({\n",
        "                    'content': ctx['text'],  # 'content' is the expected field for the document text\n",
        "                    'meta': {'name': ctx['title'], 'passage_id': ctx['passage_id']}\n",
        "                })\n",
        "        document_store.write_documents(documents)\n",
        "\n",
        "\n",
        "german_dpr_test_file = '/content/drive/MyDrive/AIR/project/GermanDPR_test_test_converted.json'\n",
        "german_quad_test_file = '/content/drive/MyDrive/AIR/project/GermanQuAD_test_converted.json'\n",
        "\n",
        "queries_and_doc_ids_dpr = extract_queries_and_doc_ids(german_dpr_test_file)\n",
        "queries_and_doc_ids_quad = extract_queries_and_doc_ids(german_quad_test_file)\n",
        "\n",
        "queries_and_doc_ids = queries_and_doc_ids_dpr + queries_and_doc_ids_quad\n",
        "\n",
        "document_store = InMemoryDocumentStore()\n",
        "\n",
        "load_documents_to_store(german_dpr_test_file, document_store)\n",
        "load_documents_to_store(german_quad_test_file, document_store)\n",
        "\n",
        "retriever = TfidfRetriever(document_store=document_store)\n",
        "\n",
        "#retriever.fit()\n",
        "\n",
        "for query, correct_doc_id in queries_and_doc_ids:\n",
        "    retrieved_documents = retriever.retrieve(query)\n",
        "\n"
      ],
      "metadata": {
        "id": "tFpM4HC_3ztn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the retriever\n",
        "for query, correct_doc_id in queries_and_doc_ids:\n",
        "    retrieved_documents = retriever.retrieve(query)\n",
        "\n",
        "    # Check if the correct document is among the retrieved documents\n",
        "    retrieved_doc_ids = [doc.meta['passage_id'] for doc in retrieved_documents]\n",
        "    is_correct_doc_retrieved = correct_doc_id in retrieved_doc_ids\n",
        "\n",
        "    print(f\"Query: {query}, Correct Retrieved: {is_correct_doc_retrieved}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy28gZTU-QLm",
        "outputId": "67c0161e-f3b0-47db-a5de-81827cf8608b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches ist die zweitgrößte Stadt in den Alpen?, Correct Retrieved: True\n",
            "Query: Wie hoch ist die Staatsverschuldung von Thüringen?, Correct Retrieved: True\n",
            "Query: Was beeinflusst das Abarbeiten von USB-Transaktionslisten?, Correct Retrieved: True\n",
            "Query: Welche Zinkverbindung wird bei der Vulkanisation von Kautschuk eingesetzt?, Correct Retrieved: True\n",
            "Query: welche Drittstaaten waren mit der Überwachung des Abkommens zwischen Nord- und Südkorea nach dem Koreakrieg betraut?, Correct Retrieved: True\n",
            "Query: Zu welcher übergeordneten Klasse gehören Vögel?, Correct Retrieved: True\n",
            "Query: Welche vereinheitlichen Gesetze gibt es in den USA für alle Bundesstaaten?, Correct Retrieved: True\n",
            "Query: Wer stürzte 1968 Keita in Mali durch einen Putsch?, Correct Retrieved: True\n",
            "Query: Mit wem setzte Kerry Assad gleich?, Correct Retrieved: True\n",
            "Query: Welche Institution organisiert den öffentlichen Verkehr in London?, Correct Retrieved: True\n",
            "Query: Auf die Siedlung welchen Stammes geht Paris zurück?, Correct Retrieved: True\n",
            "Query: In welchen Fällen kann im orthodoxen Judentum ein Säugling zum Judentum kovnertiert werden?, Correct Retrieved: True\n",
            "Query: In welchem US-Bundesstaat liegt Detroit?, Correct Retrieved: True\n",
            "Query: gegen wen gingen die Jayhawker in Kansas während des Amerikanischen Bürgerkrieges vor?, Correct Retrieved: True\n",
            "Query: Was ist der Gegenstand der Phytologie?, Correct Retrieved: True\n",
            "Query: Was ist das malische Dloki-Ba?, Correct Retrieved: True\n",
            "Query: In welchem Film spricht Charles Elkins die deutsche Stimme von Arnold Schwarzenegger?, Correct Retrieved: True\n",
            "Query: Für welches Verbrechen urteilte der Supreme Court die Todesstrafe in Louisiana nicht als verfassungskonform?, Correct Retrieved: True\n",
            "Query: Wann hatte das britische Reich seine größte Ausdehnung?, Correct Retrieved: True\n",
            "Query: Welche Datenübertragungsrate hatte der  kabellose Netzwerkadapter der XBox vor 2009?, Correct Retrieved: True\n",
            "Query: Was ist die Montgolfiere?, Correct Retrieved: True\n",
            "Query: Wie werden Wörter in phonetischer Schreibung in der chinesischen Schrift dargestellt?, Correct Retrieved: True\n",
            "Query: Wann erschien „Zaynab“ von Muhammed Husayn Haykal erstmals?, Correct Retrieved: True\n",
            "Query: Wie wird Uranmunition eingesetzt?, Correct Retrieved: True\n",
            "Query: Durch was wird Nordirland im britischen Königswappen symbolisiert?, Correct Retrieved: True\n",
            "Query: In welchem Jahr erhielt Mali die Berechtigung zur Teilnahme an den Olympischen Spielen?, Correct Retrieved: True\n",
            "Query: Wann wurde die Bezeichnung Kubismus das erste mal geschrieben verwendet?, Correct Retrieved: True\n",
            "Query: wie viele Juden leben in Tadschikistan?, Correct Retrieved: True\n",
            "Query: In welchem Bereich des Physik arbeitete Feynmann hauptsächlich?, Correct Retrieved: True\n",
            "Query: Wie sieht die Handelsbilanz von Guinea-Bissau aus?, Correct Retrieved: True\n",
            "Query: Bei wem suchte sich der osmanische Sultan Hilfe während des griechischen Unabhängigkeitskrieges?, Correct Retrieved: True\n",
            "Query: Was ist der tiefste Punkt der Antarktis?, Correct Retrieved: True\n",
            "Query: Aus welchen Ländern stammen die meisten der in der Schweiz lebenden Ausländer?, Correct Retrieved: True\n",
            "Query: Was war das Ziel hinter der geplanten Eroberung von Prag durch Friedrich II.?, Correct Retrieved: True\n",
            "Query: Für welche Musikrichtung war Detroit in der ersten Hälfte des 20. Jhd. bekannt?, Correct Retrieved: True\n",
            "Query: Wer ist Mary Youngblood?, Correct Retrieved: True\n",
            "Query: Wo befinden sich beim Hund die Geschmacksknospen?, Correct Retrieved: True\n",
            "Query: Der wie vielte Bundesstaat der USA wäre Puerto Rico nach offiziellem Beitritt in die USA?, Correct Retrieved: True\n",
            "Query: Welche Art der Politik betrieb Keita in Mali?, Correct Retrieved: True\n",
            "Query: In welcher erdgeschichtlichen Epoche sind die Dinosaurier ausgestorben?, Correct Retrieved: True\n",
            "Query: Welche Behörden des Bundes sind in Hannover angesiedelt?, Correct Retrieved: True\n",
            "Query: In welchem Zustand ist der Energiebedarf von  Aufzüge höher?, Correct Retrieved: True\n",
            "Query: Wie lange hatten die Republikaner während Eisenhowers Präsidentschaft die Mehrheit im Parlament?, Correct Retrieved: True\n",
            "Query: Welche Partei erhielt bei den Wahlen in Galizien 2005 die meisten Stimmen?, Correct Retrieved: True\n",
            "Query: In welchem Jahr befürwortete die Mehrheit im Referendum in Puerto Rico die Aufnahme in die USA?, Correct Retrieved: True\n",
            "Query: Was veranstaltete die US-Army, um eine Hymne zu finden?, Correct Retrieved: True\n",
            "Query: Was ist neben Hinayana die andere Hauptströmung des Buddhismus?, Correct Retrieved: True\n",
            "Query: Wozu wird ein Daysimeter benutzt?, Correct Retrieved: True\n",
            "Query: Wann wurden Hinrichtungen in Iowa nach der ersten Abschaffung wieder etabliert?, Correct Retrieved: True\n",
            "Query: Wie hoch ist BIP in North Carolina?, Correct Retrieved: True\n",
            "Query: Welche Partei kam nach dem Militärputsch 1968 an die Macht?, Correct Retrieved: True\n",
            "Query: Durch was unterscheidet sich die Historiographie des 19. Jahrhunderts von der vorhergehenden?, Correct Retrieved: True\n",
            "Query: Welche Menschenrechtsverletzungen erreigneten sich in Mali infolge des Putsches 2012?, Correct Retrieved: True\n",
            "Query: wer wurde zu Beginn des amerikanischen Unabhängigkeitskrieges zum obersten Kommandanten bestimmt?, Correct Retrieved: True\n",
            "Query: Wie hoch ist das Pro-Kopf-BIP von Portugal?, Correct Retrieved: True\n",
            "Query: Wie groß ist das Intervall der Planck-Zeit?, Correct Retrieved: True\n",
            "Query: Ab wann wurde Glasproduktion im Römischen Reich in größerem Umfang möglich?, Correct Retrieved: True\n",
            "Query: Seit wann ist Paris eigenständiges Departement?, Correct Retrieved: True\n",
            "Query: Welche Art von Mosaiken wurden im Römischen Reich im ersten Jahrhundert nach Christus verwendet?, Correct Retrieved: True\n",
            "Query: Wie ist die estnische Arbeitslosenquote im Vergleich mit anderen EU-Ländern?, Correct Retrieved: True\n",
            "Query: Wann verbreitete sich das Christentum im Elsass aus?, Correct Retrieved: True\n",
            "Query: Wo kann man nachschauen, welche alten Spiele auf den neuen XBox-Modelle spielbar sind?, Correct Retrieved: True\n",
            "Query: In welchem Krieg lieferte Israel Waffen an den Iran?, Correct Retrieved: True\n",
            "Query: Welcher Zeit entspricht die westeuropäische Normalzeit?, Correct Retrieved: True\n",
            "Query: Welches Sexualhormon spielt bei der Entwicklung der sexuellen Orientierung eine besondere Rolle?, Correct Retrieved: True\n",
            "Query: Was gilt seit der Revolution im Iran als Basis für Gesetze?, Correct Retrieved: True\n",
            "Query: Seit wann gibt es in Iowa keine Todesstrafe mehr?, Correct Retrieved: True\n",
            "Query: Was wurde unter Eisenhower als Dynamic Conservatism bezeichnet?, Correct Retrieved: True\n",
            "Query: Wann war die Entdeckung von Lutetium?, Correct Retrieved: True\n",
            "Query: Wie viele Reisende fliegen jährlich von den Airports um New York?, Correct Retrieved: True\n",
            "Query: Welche Länder wären durch einen Anstieg des Meeresspiegels besonders betroffen?, Correct Retrieved: True\n",
            "Query: Welche Gliedmaße sind bei Insekten am Thorax verankert?, Correct Retrieved: True\n",
            "Query: Welches Transportmittel wurde im Sezessionskrieg erstmals im großen Stil eingesetzt?, Correct Retrieved: True\n",
            "Query: Wie wurde das Dionysos-Mosaik in Köln wieder entdeckt?, Correct Retrieved: True\n",
            "Query: Welcher Anteil der Arbeitnehmer in estland ist weiblich?, Correct Retrieved: True\n",
            "Query: Welche Schlacht entschied den Feldzug von Johann Ohneland nach Frankreich?, Correct Retrieved: True\n",
            "Query: Wann wurde Seoul nach der nordkoreanischen Offensive wieder zurückerobert?, Correct Retrieved: True\n",
            "Query: Wie lange dauerte der Bau der Bahnverbindung zwischen LA und Santa Monica?, Correct Retrieved: True\n",
            "Query: Hat Mose wirklich gelebt?, Correct Retrieved: True\n",
            "Query: welche Bedeutung hat Kanye West als Musiker?, Correct Retrieved: True\n",
            "Query: Bei welchem Verein spielte Seydou Keita?, Correct Retrieved: True\n",
            "Query: Welcher Einfluss zeigt sich bei den christlichen Mosaiken in Ravenna?, Correct Retrieved: True\n",
            "Query: Wer regiert in Eritrea?, Correct Retrieved: True\n",
            "Query: Welchen Status erhielt Richmond 1861?, Correct Retrieved: True\n",
            "Query: Wann gelten Vögel als Zugvögel?, Correct Retrieved: True\n",
            "Query: Was bezeichnet der Begriff \"Avifauna\"?, Correct Retrieved: True\n",
            "Query: Zu welcher Künstlervereinigung gehörte Albert Bloch?, Correct Retrieved: True\n",
            "Query: Welchen Rang im Index von Reporter ohne Grenzen belegt Nigeria?, Correct Retrieved: True\n",
            "Query: Was forderte Kerry als Konsequenz für den russischen Einsatz auf der Krim?, Correct Retrieved: True\n",
            "Query: Wie heißt das Buch, das die Weltreise von Erika und Klaus Mann erzählt?, Correct Retrieved: True\n",
            "Query: Welche Aufgabe wurde dem NNSC durch das Abkommen zwischen Nord- und Südkorea nach dem Koreakrieg zugeteilt?, Correct Retrieved: True\n",
            "Query: Wie heißt das Hauptgebäude von Comcast Corporation?, Correct Retrieved: True\n",
            "Query: Mittels was werden Urankerne gespalten?, Correct Retrieved: True\n",
            "Query: Welche Ordnungszahl hat Uran?, Correct Retrieved: True\n",
            "Query: In welcher Zeit sollen Abraham und seine Nachkommen gelebt haben?, Correct Retrieved: True\n",
            "Query: Wie heißen die drei Teile des Insektenthorax?, Correct Retrieved: True\n",
            "Query: Wie wird die diplomatische Vertretung des Vatikans bezeichnet?, Correct Retrieved: True\n",
            "Query: Welche lokalen Volksgruppen lebten in der deutschen Kolonie Südwest-Afrika?, Correct Retrieved: True\n",
            "Query: Auf was hofften die römischen Legionäre nach dem Ende ihrer Dienstzeit?, Correct Retrieved: True\n",
            "Query: Welche Informationen wird in den Properties der Unicode-Zeichen festgehalten?, Correct Retrieved: True\n",
            "Query: Was waren die Räumlichkeiten der Galleria d’Arte Moderna in Palermo früher?, Correct Retrieved: True\n",
            "Query: Wie starb Tiberius Gracchus?, Correct Retrieved: True\n",
            "Query: Welche Materialien sind in der DIN 6730 festgelegt?, Correct Retrieved: True\n",
            "Query: Für welche Geräte  konnte USB 1.0 auch als Stromzufuhr eingesetzt werden?, Correct Retrieved: True\n",
            "Query: In Abgrenzung zu was entstand der Neoklassizismus in Deutschland hautpsächlich?, Correct Retrieved: True\n",
            "Query: Als was zählt das Research Triangle in North Carolina?, Correct Retrieved: True\n",
            "Query: Welche Städte verbindet die Sunset Limited-Zuglinie?, Correct Retrieved: True\n",
            "Query: Welche Gebiete erhielt Großbritannien durch den Vertrag von Versailles?, Correct Retrieved: True\n",
            "Query: Unter welchem Namen war eine frühere Version der US-Army-Hymne bekannt?, Correct Retrieved: True\n",
            "Query: Von welchen Flüssen wird der Caprivizipfel in Namibia eingeschlossen?, Correct Retrieved: True\n",
            "Query: Was ist die Hauptaussage der Powell-Doktrin?, Correct Retrieved: True\n",
            "Query: Was lösen transplantierte Organe im Körper des Empfängers aus?, Correct Retrieved: True\n",
            "Query: Seit wann hat Hage Geingob das Präsidentenamt in Namibia inne?, Correct Retrieved: True\n",
            "Query: Wer entwickelte Platons Metaphysik weiter?, Correct Retrieved: True\n",
            "Query: Welchen Beruf hatte Edgar Allan Poes Mutter?, Correct Retrieved: True\n",
            "Query: Welcher deutsche Synchronsprecher synchronisiert die aktuellen Filme von Arnold Schwarzenegger?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen arbeiten bei den drei größten Biotechnologie-Unternehmen in North Carolina?, Correct Retrieved: True\n",
            "Query: In welchem Verhältnis stand  Gaius Sempronius Gracchus zu Tiberius Gracchus?, Correct Retrieved: True\n",
            "Query: wo wird der Mensch in der Zoologie eingeordnet?, Correct Retrieved: True\n",
            "Query: Was bezeichnet man als genetische Variabilität?, Correct Retrieved: True\n",
            "Query: Wie viel liegt der Bentley-Subglazialgraben unter dem Meer?, Correct Retrieved: True\n",
            "Query: Wieso schrumpfte die Wirtschaft der Republik Kongo im Jahr 2017?, Correct Retrieved: True\n",
            "Query: Wohin flüchteten die Juden während und nach der Shoa?, Correct Retrieved: True\n",
            "Query: Welche Personen sitzen im akademischen Senat?, Correct Retrieved: True\n",
            "Query: Wieso wurde der Text von Gruber Caission Song für die Übernahme als Army-Hymne geändert?, Correct Retrieved: True\n",
            "Query: Wie groß war Warren Buffets Vermögen, bevor er Geld an Stiftungen spendete?, Correct Retrieved: True\n",
            "Query: Welche Aufgabe hat die biologische Anthropologie?, Correct Retrieved: True\n",
            "Query: In der Regierungszeit welches Königs hatte das Königreich Urartu die maximale Ausdehnung?, Correct Retrieved: True\n",
            "Query: wie viele Kinder werden pro Frau in Tadschikistan geboren?, Correct Retrieved: True\n",
            "Query: In welcher Stadt ist die Zentrale der Comcast Corporation?, Correct Retrieved: True\n",
            "Query: Welche Materialeigenschaft eines Kondensators beeinflusst die maximale Ladungsmenge?, Correct Retrieved: True\n",
            "Query: Was stellte Remafedi 1991 bezüglich der sexuellen Orientierung und Selbstmord unter Jugendlichen fest?, Correct Retrieved: True\n",
            "Query: Teil welches Departements war Paris im 18. Jhd.?, Correct Retrieved: True\n",
            "Query: Auf welchen Platz kam die malische U20-Mannschaft bei der WM 2015?, Correct Retrieved: True\n",
            "Query: Welche Temperatur wird für den Urknall angenommen?, Correct Retrieved: True\n",
            "Query: Welche Flüsse bilden die Grenze zwischen Namibia und Südafrika?, Correct Retrieved: True\n",
            "Query: Wo errichteten die Römer in Paris ihre Stadt?, Correct Retrieved: True\n",
            "Query: Welche Übertragungsgeschwindigkeit hat der neuere WLAN-Adapter N der XBox?, Correct Retrieved: True\n",
            "Query: was prangerte August von Platen in den Polenliedern an?, Correct Retrieved: True\n",
            "Query: Aus welchem Jahrhundert stammt das erste Zeichenlexikon der chinesischen Schriftzeichen?, Correct Retrieved: True\n",
            "Query: Zu welcher Industrieregion in den USA gehört Detroit?, Correct Retrieved: True\n",
            "Query: Wegen welchen Verbrechens wurden in Iowa die meisten Menschen hingerichtet?, Correct Retrieved: True\n",
            "Query: Welchen Umfang hat das BIP der Republik Kongo?, Correct Retrieved: True\n",
            "Query: Wie sind katholische Religionslehrer von dem Scheidungsverbot betroffen?, Correct Retrieved: False\n",
            "Query: Welche Menschenrechtsverletzungen wird den staatlichen Organen und Vertretern in Mali vorgeworfen?, Correct Retrieved: True\n",
            "Query: Auf wie viele Kilometer wurde das von Militär befreite Gebiet im Waffenstillstand 1953 zwischen Nord- und Südkorea festgelegt? , Correct Retrieved: True\n",
            "Query: Woher stammt der Name Uran?, Correct Retrieved: True\n",
            "Query: Welchen Jahresumsatz hatte Comcast Corporation 2015?, Correct Retrieved: True\n",
            "Query: Durch welche Struktur ist die Gesellschaft in Liberia gekennzeichnet?, Correct Retrieved: True\n",
            "Query: Was sind Allele?, Correct Retrieved: True\n",
            "Query: Welcher deutsche Synchrosprecher synchronisierte die meisten von Schwarzeneggers Filmen?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen in den USA sind jüdischen Glaubens?, Correct Retrieved: True\n",
            "Query: Wie hieß die deutsche Ausgabe der Dernieres Nouvelle d'Alsace?, Correct Retrieved: True\n",
            "Query: Um wie viel ist die Anzahl der Beschäftigen in der Textilindustrie in North Carolina seit 1990 gefallen?, Correct Retrieved: True\n",
            "Query: Welcher Service wird in Fachgeschäften bereitgestellt?, Correct Retrieved: True\n",
            "Query: Welche Möglichkeit bietet der Ersatzausweis für Nichtbürger in Estland?, Correct Retrieved: True\n",
            "Query: Welche Stadt war vor Richmond Hauptstadt der Südstaaten?, Correct Retrieved: True\n",
            "Query: Seit wann hat Portugal den Euro als Währung?, Correct Retrieved: True\n",
            "Query: Durch welche Gebiete wurde Eritrea als italienische Kolonie erweitert?, Correct Retrieved: True\n",
            "Query: Wie viele Jahre mussten die Chicago Cubs nach ihrem Meisterschaftssieg von 1908 auf einen weiteren Titel warten?, Correct Retrieved: True\n",
            "Query: Was war das Hauptmerkmal der Heeresreform von Gaius Marius im Römischen Reich?, Correct Retrieved: True\n",
            "Query: Was war der Grund für den Absturz der Boeing 747-300 über Guam 1997?, Correct Retrieved: True\n",
            "Query: Was nimmt die Kosmologie als Ursprung der Entstehung von Materie an?, Correct Retrieved: True\n",
            "Query: Was wurde 1888 in Richmond eingeführt?, Correct Retrieved: True\n",
            "Query: Wann galt die doppelte Sommerzeit?, Correct Retrieved: True\n",
            "Query: Welches politische System gab es in Mali nach der Unabhängigkeit?, Correct Retrieved: True\n",
            "Query: was ist einer der Hauptfaktoren, die Kinderarbeit begünstigen?, Correct Retrieved: True\n",
            "Query: Wie heißt die Hauptstadt von Eritrea?, Correct Retrieved: True\n",
            "Query: Zwischen welchen Werten liegt die  untere Grenze für das Flächengewicht für Pappe?, Correct Retrieved: True\n",
            "Query: Welcher Teil von Zypern ist als Staat anerkannt?, Correct Retrieved: True\n",
            "Query: Durch welche Maßnahmen begründete Esra das Brauchtum des Judentum?, Correct Retrieved: True\n",
            "Query: Welcher Fluss bildet in der Gegend von Detroit die Grenze zu Kanada?, Correct Retrieved: True\n",
            "Query: Wie lange ist die Amtszeit des liberianischen Präsidenten?, Correct Retrieved: True\n",
            "Query: Wie unterscheidet sich das Intervall zwischen zwei Spielzügen beim Canadian Football vom American Football?, Correct Retrieved: True\n",
            "Query: Welche Folgen hatte die japanische Eroberung von Lasio für die allierten Mächte?, Correct Retrieved: True\n",
            "Query: Die Hauptstadt welchen Landes ist Vaduz?, Correct Retrieved: True\n",
            "Query: Was ist ein Jayhawk?, Correct Retrieved: True\n",
            "Query: Welche Airports gibt es in New York City?, Correct Retrieved: True\n",
            "Query: Wann sind die Dinosaurier ausgestorben?, Correct Retrieved: True\n",
            "Query: Was ist die durchschnittliche Höhe über dem Meeresspiegel der Marshallinseln?, Correct Retrieved: True\n",
            "Query: Welche Auswirkung für die Gesellschaft hatte die Etablierung eines einheitlichen Schriftsystems in China 200 v. Chr?, Correct Retrieved: True\n",
            "Query: Wann wurde das Ende der Kämpfe zwischen Vereinten Nationen und Norkorea im Koreakrieg beschlossen?, Correct Retrieved: True\n",
            "Query: Wie viele täglich erscheinende, landesweite Zeitungen gibt es in Nigeria?, Correct Retrieved: True\n",
            "Query: Wie sieht die Oberfläche des Sixaxis-Controllers aus?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen waren 1990 in der Textilindustrie in North Carolina beschäftigt?, Correct Retrieved: True\n",
            "Query: Welcher Gruppe gehören die meisten US-amerikanischen Juden an?, Correct Retrieved: True\n",
            "Query: Welches Gebiet von Paris war als erstes besiedelt?, Correct Retrieved: True\n",
            "Query: wer führte die englischen Truppen in der Schlacht bei Damme 1213?, Correct Retrieved: True\n",
            "Query: Wie viele verschiedene Arten von Vögeln gibt es ?, Correct Retrieved: True\n",
            "Query: Wie viel Prozent der Menschen in Puerto Rico stimmten im Referendum 2012 für einen eigenständigen Staat?, Correct Retrieved: True\n",
            "Query: Was wird durch den Hamiltonoperator festgelegt?, Correct Retrieved: True\n",
            "Query: Wann trat Portugal der EU bei?, Correct Retrieved: True\n",
            "Query: Wie groß ist die Fläche der Belle Isle in Detroit?, Correct Retrieved: True\n",
            "Query: was war die Todesursache von Papst Paul VI.?, Correct Retrieved: True\n",
            "Query: Welche militärischen Konflikte waren Anlass für eine Heeresreform im Römischen Reich um 100 v. Chr.?, Correct Retrieved: True\n",
            "Query: Was beeinträchtigt das Spielen alter XBox-Spiele per Emulator?, Correct Retrieved: True\n",
            "Query: Welche französischen Gebiete gab es nach dem Krieg Mitte des 18. Jhd. mit Großbritannien noch in Indien?, Correct Retrieved: True\n",
            "Query: An welcher Flussmündung liegt Valencia?, Correct Retrieved: True\n",
            "Query: Welcher Unterschied ergibt sich durch die Quantisierung von Schwingungsenergie in Bezug auf die Wärmeenergie von festen Körpern?, Correct Retrieved: True\n",
            "Query: Welches Ereignis im Syrien-Krieg führte zu Kerrys Forderung nach einem militärischen Einsatz?, Correct Retrieved: True\n",
            "Query: Wer veranlasste den Bau einer Zugstrecke zwischen LA und Santa Monica?, Correct Retrieved: True\n",
            "Query: Was war die höchste Platzierung, die Mali in der Afrikameisterschaft erreichte?, Correct Retrieved: True\n",
            "Query: Für was steht die Bezeichnung UTC?, Correct Retrieved: True\n",
            "Query: Was war der Grund, dass im Sezessionskrieg vergleichsweise mehr Menschen starben als bei früheren Kriegen?, Correct Retrieved: True\n",
            "Query: Wie wird der Chef oder die Chefin einer Universität genannt?, Correct Retrieved: True\n",
            "Query: Wie viele Einwohner:innen hat Iran im Vergleich mit der BRD?, Correct Retrieved: True\n",
            "Query: Bis wann wurde der Sixaxis-Controller produziert?, Correct Retrieved: True\n",
            "Query: Durch welches Phänomen konnte Einstein den Wärmeverlust von Körpern bei tiefen Temperaturen erklären?, Correct Retrieved: True\n",
            "Query: Aus wie vielen Teilen besteht der Thorax von Insekten?, Correct Retrieved: True\n",
            "Query: wann wurde in Frankreich der Laizismus eingeführt?, Correct Retrieved: True\n",
            "Query: welches neue Verständnis von Poesie etablierte sich Mitte des 18. Jahrhudnerts?, Correct Retrieved: True\n",
            "Query: Welcher Anteil aller Menschen hat sich mit Tuberkulose angesteckt?, Correct Retrieved: True\n",
            "Query: Wie wird die Hymne des US-Army im umgangssprachlich meist genannt?, Correct Retrieved: True\n",
            "Query: Welche Auswirkung hatte die Teilnahme an der Schlacht von Gallipoli auf die britischen Dominions Australien und Neuseeland?, Correct Retrieved: True\n",
            "Query: In Zusammenhang mit welchem Reformpaket wurde in den USA das Sozialstaatskonzept umgesetzt?, Correct Retrieved: True\n",
            "Query: Wann endete der Kampf um die Unabhängigkeit Eritreas von Äthiopien?, Correct Retrieved: True\n",
            "Query: Welcher Papst versuchte die Entführung von Aldo Moro zu beenden?, Correct Retrieved: True\n",
            "Query: Unter welchem Namen wurde die Stadt Van gegründet?, Correct Retrieved: True\n",
            "Query: Durch was unterscheidet sich ein Warenhaus von einen Kaufhaus?, Correct Retrieved: True\n",
            "Query: Wie viele Juden lebten vor dem Fall Der Sowjetunion in Tadschikistan?, Correct Retrieved: True\n",
            "Query: Welche Durchschnittshöhe hat das Hochland von Namibia?, Correct Retrieved: True\n",
            "Query: Wie haben sich die Bedienelemente des Sixaxis-Controllers im Vergleich zum DualShock verändert?, Correct Retrieved: True\n",
            "Query: Wie groß ist das gebiet, in dem die Inseln der Marshallinseln verteilt sind?, Correct Retrieved: True\n",
            "Query: Wer führte die Truppen der Konföderation im Sezessionskrieg?, Correct Retrieved: True\n",
            "Query: Welcher römische Feldherr reformierte um 100 v. Chr. das Herr des römischen Reiches?, Correct Retrieved: True\n",
            "Query: Als was entstand die Stadt Kolmannskuppe in Namibia?, Correct Retrieved: True\n",
            "Query: Zu welcher Gruppe von Ballsportarten gehört Canadian Football?, Correct Retrieved: True\n",
            "Query: Wer wurde 2009 galizischer Regierungschef?, Correct Retrieved: True\n",
            "Query: Auf was haben Pheromone beim Menschen Einfluss?, Correct Retrieved: True\n",
            "Query: Wieso gibt es unterschiedliche Werte für die Grenze zwischen Pappe und Papier?, Correct Retrieved: True\n",
            "Query: Was findet in der Cobo Hall in Detroit vor allem statt?, Correct Retrieved: True\n",
            "Query: Wie wird die Zeit nach dem internationalen Einheitensystem angegeben?, Correct Retrieved: True\n",
            "Query: Wie hoch ist das BIP pro Kopf in Myanmar?, Correct Retrieved: True\n",
            "Query: Welcher Tag ist besonders wichtig für die anti-israelische Propaganda im Iran?, Correct Retrieved: True\n",
            "Query: Durch was werden Vögel biologisch gekennzeichnet?, Correct Retrieved: True\n",
            "Query: Wann startete die Aktion \"Call  to Action\" des Polizeichefs von Philadelphia?, Correct Retrieved: True\n",
            "Query: welche negativen witschaftlichen Folgen entstehen durch Kinderarbeit?, Correct Retrieved: True\n",
            "Query: Was ist das Shoiwen Jiezi?, Correct Retrieved: True\n",
            "Query: Was wird durch die genetische Variabilität einer Population beeinflusst?, Correct Retrieved: True\n",
            "Query: Wo liegen die Marshallinseln?, Correct Retrieved: True\n",
            "Query: Welche Institution veranlasste die Gründung des Nationalarchivs?, Correct Retrieved: True\n",
            "Query: Bei welchen Xbox-Modellen ist der WLAN-Empfänger bereits fest verbaut?, Correct Retrieved: True\n",
            "Query: Bei welchen Nintendo-Spielen wurde der R.O.B. eingebunden?, Correct Retrieved: True\n",
            "Query: Von wem wurde Arnold Schwarzenegger bei seiner Kandidatur in Kalifornien als Mogelkandidat bezeichnet?, Correct Retrieved: True\n",
            "Query: Wo in Neu-Delhi liegt das Observatorium Jantar Mantar?, Correct Retrieved: True\n",
            "Query: Welche Auswirkungen hatte die Niederlage von Kolin für das preußische Heer?, Correct Retrieved: True\n",
            "Query: Was wurde neben religiösen Fächern an den Nizamiya-Madrasas unterrichtet?, Correct Retrieved: True\n",
            "Query: Wer war designierter Vize-Präsident Im Wahlkampf von John Kerry?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen leben in Israel pro Quadratkilometer?, Correct Retrieved: True\n",
            "Query: Welche Bereiche der Physik soll die Quantengravitation theoretische zusammenführen?, Correct Retrieved: True\n",
            "Query: Welche Bedeutung hat die Schlacht von Plassey für die Ostindien-Kompanie?, Correct Retrieved: True\n",
            "Query: Zu welcher Klasse von Metallen gehört Zink?, Correct Retrieved: True\n",
            "Query: Was wird am ANZAC Day gedacht?, Correct Retrieved: True\n",
            "Query: Wer war König von Frankreich während Johann Ohnelands Feldzug nach Frankreich?, Correct Retrieved: True\n",
            "Query: Für was kandidierte Arnold Schwarzenegger 2003?, Correct Retrieved: True\n",
            "Query: Was wird in der Transaktionsliste eines USB-Anschlusses verwaltet?, Correct Retrieved: True\n",
            "Query: Was war das Ziel von Sylvester Johnsons Aktion \" Call to Action\" in Philadelphia?, Correct Retrieved: True\n",
            "Query: Wieso verweigerten einige englische Fürsten Johann Ohneland die Gefolgschaft, als er gegen Frankreich ziehen wollte?, Correct Retrieved: True\n",
            "Query: Welche Anforderung stellt die Powell-Doktrin an das Ende eines militärischen Konflikts?, Correct Retrieved: True\n",
            "Query: Wer führte den Putsch gegen Traore in Mali an?, Correct Retrieved: True\n",
            "Query: Welches Amt bekleidete der Feldherr Gaius Marius in Rom?, Correct Retrieved: True\n",
            "Query: In welchem Jahr annektierte Haile Selassie Eritrea?, Correct Retrieved: True\n",
            "Query: Welche der nigerianischen Tageszeitungen werden auf Englisch publiziert?, Correct Retrieved: True\n",
            "Query: Welche Beleuchtung zählt als Außenbeleuchtung?, Correct Retrieved: True\n",
            "Query: Wo wurde der Waffenstillstand für den Koreakrieg beschlossen?, Correct Retrieved: True\n",
            "Query: welches Phänomen tritt bei elektromagnetischer Strahlungsenergie auf?, Correct Retrieved: True\n",
            "Query: Welche Funktionen sind mit dem Hypothalamus verknüpft?, Correct Retrieved: True\n",
            "Query: Wieso ist Thüringen auch in Zukunft auf Finanzhilfen vom Bund  oder EU angewiesen?, Correct Retrieved: True\n",
            "Query: Was wurde durch das Abkommen zur Beendigung des Koreakrieges als Grenzlinie zwischen den beiden Teilen Koreas festgelegt?, Correct Retrieved: False\n",
            "Query: Welche Funktion fällt bei dem SIXAXIS-Controller im Vergleich mit dem Vorgängermodell weg?, Correct Retrieved: True\n",
            "Query: Wie entsteht außer durch Mutation noch Genvariationen und Allele?, Correct Retrieved: True\n",
            "Query: Wie ist Paris verwaltungstechnisch gegliedert?, Correct Retrieved: True\n",
            "Query: Wie viel Prozent erhielt Schwarzenegger bei der Wahl zum Gouverneur 2003?, Correct Retrieved: True\n",
            "Query: Welchen Anteil hat die Ölförderung am Staatshaushalt von Alaska?, Correct Retrieved: True\n",
            "Query: Welche von Schwarzeneggers Büchern waren Bestseller?, Correct Retrieved: True\n",
            "Query: Nach welcher Einteilung sind Zink und Quecksilber in Gruppe 12?, Correct Retrieved: True\n",
            "Query: Was ist die größte Stadt in der Umgebung der Alpen?, Correct Retrieved: True\n",
            "Query: Unter welchem chinesischen Kaiser wurde das Schriftsystem vereinheitlicht?, Correct Retrieved: True\n",
            "Query: Wie hieß Paris vor der römischen Eroberung?, Correct Retrieved: True\n",
            "Query: Welches Organ ist meist von Tuberkulose betroffen?, Correct Retrieved: True\n",
            "Query: Welche an Land lebenden Säugetiere werden nach dem Menschen am ältesten?, Correct Retrieved: True\n",
            "Query: Was ist der größte Internet- und Telefonanbieter in den USA?, Correct Retrieved: True\n",
            "Query: Wann spalteten sich die Südstaaten vom Rest der USA ab?, Correct Retrieved: True\n",
            "Query: Welche Partei bestimmt die politische Landschaft in Eritrea?, Correct Retrieved: True\n",
            "Query: Wie viele Geschmacksknospen haben Menschen?, Correct Retrieved: True\n",
            "Query: Für welche Art von Nahrung ist der flüssigere Speichel bei Hunden gedacht?, Correct Retrieved: True\n",
            "Query: Welche Position übernahm Schwarzenegger im März 2013?, Correct Retrieved: True\n",
            "Query: Woran liegt es, dass viele Redereien ihre Schiffe in Liberia anmelden?, Correct Retrieved: True\n",
            "Query: Welche Tiere sind mit dem Gott Wotan unterwegs?, Correct Retrieved: True\n",
            "Query: Wie wird der R.O.B. von Nintendo in Spiele eingebunden?, Correct Retrieved: True\n",
            "Query: Was ist der Selbstwert einer Sache?, Correct Retrieved: True\n",
            "Query: Wann ist John Kerrys älteste Schwester geboren?, Correct Retrieved: True\n",
            "Query: Welcher Wert eines Kondensators wird durch die Temperatur beeinflusst?, Correct Retrieved: True\n",
            "Query: In welchem Alter sind Kinder im Judentum religionsmündig?, Correct Retrieved: True\n",
            "Query: Vertreter welcher iranischen MInderheit ist Ciamak Moresadegh?, Correct Retrieved: True\n",
            "Query: Welche Position hatte Chalkali im iranischen Staat nach der Revolution?, Correct Retrieved: True\n",
            "Query: In welche Zeitspanne fällt für Volker Reinhardt der Humanismus?, Correct Retrieved: True\n",
            "Query: wie viele Menschen lebte um 1850 in Richmond, Virginia?, Correct Retrieved: True\n",
            "Query: Wie viele Spieler hat ein Team beim American Football?, Correct Retrieved: True\n",
            "Query: Wie würden die Küsten von Westantarktika sich verändern, wenn die Eisdecke verschwindet?, Correct Retrieved: True\n",
            "Query: Ab wann war Kerry offiziell Kandidat für die Präsidentenwahl 2004?, Correct Retrieved: True\n",
            "Query: Welche Bevölkerungsgruppe macht den größten Teil der Bevölkerung in Tadschikistan aus?, Correct Retrieved: True\n",
            "Query: Zu welcher Literaturgattung wurde der Roman ab der Mitte des 18. Jhd gezählt?, Correct Retrieved: True\n",
            "Query: Was ist die außenpolitische Maxime von Hage Geingob?, Correct Retrieved: True\n",
            "Query: Welche farbe haben die Bruchkanten von Zink?, Correct Retrieved: True\n",
            "Query: Welchen Auszeichnung erhielt Ellen Johnson-Sirleaf 2018?, Correct Retrieved: True\n",
            "Query: Wo wird der Begriff \"Völkermord\" das erste Mal schriftlich verwendet?, Correct Retrieved: True\n",
            "Query: Welches ist die bevölkerungsreichste Stadt in den Alpen?, Correct Retrieved: True\n",
            "Query: Wie heißt das Zentrum der neuronalen Zellen bei Ringelwürmern? , Correct Retrieved: True\n",
            "Query: Wie entstehen Elemente höher als Eisen?, Correct Retrieved: True\n",
            "Query: Wie viele Opfer verursachte der Krieg in der deutschen Kolonie Südwest-Afrika unter der lokalen Bevölkerung?, Correct Retrieved: True\n",
            "Query: Welcher controller ist Standard für die Playstation?, Correct Retrieved: True\n",
            "Query: Welcher Wirkstoff wurde bei Hinrichtungen in Ohio bis 2011 benutzt?, Correct Retrieved: True\n",
            "Query: Welche Aufgabe hat die Hochschulrektorenkonferenz?, Correct Retrieved: True\n",
            "Query: Ab wann war Eritrea italienisches Territorium?, Correct Retrieved: True\n",
            "Query: Wieso haben Säugetiere einen höheren Energiebedarf als andere Arten?, Correct Retrieved: True\n",
            "Query: Zu welcher Region in Frankreich gehört Paris?, Correct Retrieved: True\n",
            "Query: Mit welcher Maßnahme könnten Urheberrechtsverstöße auf Servern aus dem Ausland in Deutschland verhindert werden?, Correct Retrieved: True\n",
            "Query: Als was gilt Ellen Johnson-Sirleaf in Afrika?, Correct Retrieved: True\n",
            "Query: In welchem Bereich sind die Kru in Liberia vor allem tätig?, Correct Retrieved: True\n",
            "Query: Mit wem erhielt Richard Feynmann den Nobelpreis?, Correct Retrieved: True\n",
            "Query: Welche Gruppe will die WWE in letzter Zeit als Wrestling-Fans gewinnen?, Correct Retrieved: True\n",
            "Query: Welchen Spitznamen hat Arnold Schwarzenegger in den USA?, Correct Retrieved: True\n",
            "Query: Welches Isotop von Uran wird bei der Kernspaltung verwendet?, Correct Retrieved: True\n",
            "Query: Wieso ist die Entstehung des Universums nicht unmittelbar mit dem Urknall beschreibbar?, Correct Retrieved: True\n",
            "Query: Durch welche Prüfschritte wird ein Elektromotor abschließend geprüft?, Correct Retrieved: True\n",
            "Query: Wie versuchte Papst Paul VI. die Entführung von Also Moro zu beenden?, Correct Retrieved: True\n",
            "Query: Wie werden Vögel bezeichnet, die keine Zugvögel sind?, Correct Retrieved: True\n",
            "Query: Wer strebte 1211 nach der schottischen Königswürde?, Correct Retrieved: True\n",
            "Query: Welche Last konnten die Ballonbomben aus Papier, die Japan im 2. Weltkrieg einsetzte, tragen?, Correct Retrieved: True\n",
            "Query: Wie unterschied sich der Hawaii-Dollar von den regulären Dollar-Scheinen?, Correct Retrieved: True\n",
            "Query: welche ist die größte indigene Gruppe in LIberia?, Correct Retrieved: True\n",
            "Query: Welche Auswirkung auf die Umfragen hatte die Fernsehdebatte zwischen Bush und Kerry im Wahlkampf?, Correct Retrieved: True\n",
            "Query: Welche öffentlichen Nahverkehrsmittel gibt es in Raleigh, North Carolina?, Correct Retrieved: True\n",
            "Query: Wann eroberten die Alliierten Eritrea von Italien?, Correct Retrieved: True\n",
            "Query: Welche Staaten herrschten im 19. Jahrhundert jeweils über Teile des heutigen Polen?, Correct Retrieved: True\n",
            "Query: Wie viele aschkenasische Juden gibt es weltweit?, Correct Retrieved: True\n",
            "Query: Wie unterscheidet sich die Innenausstattung von Pubs von anderen Schankwirtschaften?, Correct Retrieved: True\n",
            "Query: In welchem Zeitraum war Namibia deutsche Kolonie?, Correct Retrieved: True\n",
            "Query: welche Auflagen gelten für Sharehoster in Bezug auf das Verhalten der User:innen?, Correct Retrieved: True\n",
            "Query: In welcher Stadt ist die elsässische Handelskammer angesiedelt?, Correct Retrieved: True\n",
            "Query: Wann wurde der malische Präsident Traoré abgesetzt?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen lebten vor 1945 im Britischen Empire?, Correct Retrieved: True\n",
            "Query: Welche Titel wurden früher für die Amtsträger an Universitäten verwendet?, Correct Retrieved: True\n",
            "Query: Wie ist laut Einstein Wärmeenergie in Festkörpern gespeichert?, Correct Retrieved: True\n",
            "Query: Was gilt als Ursprung des Neoklassizmus in den USA?, Correct Retrieved: True\n",
            "Query: Welche besonderen Vögel gibt es in Mythen weltweit?, Correct Retrieved: True\n",
            "Query: Was ist die Grenze zwischen Pappe und Papier in der DI-Norm?, Correct Retrieved: True\n",
            "Query: Wie viele Downs gibt es beim Canadian Football in einem Angriff?, Correct Retrieved: True\n",
            "Query: Welche Rezeptoren befinden sich im Kopfbereich von Ringelwürmern?, Correct Retrieved: True\n",
            "Query: Was war die Ursache für das Hinrichtungsmoratorium in Ohio 2014?, Correct Retrieved: True\n",
            "Query: Was ist das Ziel von am Selbstwert der Biodiversität orientierten Einstellungen?, Correct Retrieved: True\n",
            "Query: welche Städte sind an das Netz der Triangle Transit Authority in North Carolina angeschlossen?, Correct Retrieved: True\n",
            "Query: Was ist das Zentrum der britischen Infrastruktur?, Correct Retrieved: True\n",
            "Query: Wann fängt die Sommerzeit an?, Correct Retrieved: True\n",
            "Query: Welcher Fluss bildet die Grenze zwischen Namibia und Südafrika?, Correct Retrieved: True\n",
            "Query: Was setzen die Copyright-Inhaber zur Vermeidung von illegalen Kopien ein?, Correct Retrieved: True\n",
            "Query: wie wird die doppelte Stunde am Ende der Sommerzeit unterschieden?, Correct Retrieved: True\n",
            "Query: Wie ist das Einkommen in Palermo im Vergleich mit ganz Italien?, Correct Retrieved: True\n",
            "Query: Wie wurde die UTC früher bezeichnet?, Correct Retrieved: True\n",
            "Query: Welches Amt hatte Hifikepunye Pohamba inne, bevor er namibischer Präsident wurde?, Correct Retrieved: True\n",
            "Query: Was kann man an der Kopfbedeckung einer Frau in Mali erkennen?, Correct Retrieved: True\n",
            "Query: Für was wird das Musepack-Audiformat vor allem eingesetzt?, Correct Retrieved: True\n",
            "Query: Welches Bakterium löst Tuberkulose aus?, Correct Retrieved: True\n",
            "Query: Wieso steht es um die Wirtschaft in Guinea-Bissau trotz Investitionen nach der Unabhängigkeit schlecht?, Correct Retrieved: True\n",
            "Query: Welcher Bereich der Alpen wird nach der in Italien und Frankreich verwendeten Gliederung als Zentralalpen bezeichnet?, Correct Retrieved: True\n",
            "Query: Welcher Konfession gehören die meisten Menschen im Elsass an?, Correct Retrieved: True\n",
            "Query: Wieso war Schwarzenegger als Gouverneur zur Zusammenarbeit mit den Demokraten gezwungen?, Correct Retrieved: True\n",
            "Query: Welches sind die renomiertesten Universitäten in Detroit?, Correct Retrieved: True\n",
            "Query: Für welche Regionen ist die in Hannover ansässige Bundesbank zuständig?, Correct Retrieved: True\n",
            "Query: Wie ging die Schlacht bei Roche-aux-Moines aus?, Correct Retrieved: True\n",
            "Query: Welches Fach wurde am 1890 an  der University of Kansas gelehrt?, Correct Retrieved: True\n",
            "Query: Was geschah mit den russischen Zeugen Jehovas in der Operation Nord?, Correct Retrieved: True\n",
            "Query: Wann entstand der Lykurgosbecher?, Correct Retrieved: True\n",
            "Query: Was war die Essenz von Abd al-Wahhabs Lehren?, Correct Retrieved: True\n",
            "Query: Wer war der Pflegevater von Edgar Allan Poe?, Correct Retrieved: True\n",
            "Query: Wer folgte auf Johnson-Sirleaf als Präsident von Liberia?, Correct Retrieved: True\n",
            "Query: Was wird als Karton bezeichnet?, Correct Retrieved: True\n",
            "Query: Was wird bei der Endmontage eines Elektromotors nach dem Fertigstellen des Stators eingebaut?, Correct Retrieved: True\n",
            "Query: Was bedeutet der Eigenwert der Biodiversität?, Correct Retrieved: True\n",
            "Query: Als was wird Zinkchlorid beim Aufbereiten von Wasser eingesetzt?, Correct Retrieved: True\n",
            "Query: Was sind die meisten chinesischen Schriftzeichen?, Correct Retrieved: True\n",
            "Query: Was ersetzt das Restatements of the Law in den USA?, Correct Retrieved: True\n",
            "Query: Welche Summe gab der FC Arsenal 2012 für die Gehälter von Spielern und Angestellten aus?, Correct Retrieved: True\n",
            "Query: Woher stammte John Kerrys Großvater väterlicherseits?, Correct Retrieved: True\n",
            "Query: Welche Tiere halten den Schild im Wappen der englischen Krone?, Correct Retrieved: True\n",
            "Query: An welchen Krankheiten sterben auf dem afrikanischen Kontinent die meisten Menschen?, Correct Retrieved: True\n",
            "Query: Seit wann hat der Iran keine Beziehungen zu Israel mehr?, Correct Retrieved: True\n",
            "Query: Welche Summe erhielten die Einwohner:innen Alaskas pro Kopf aus dem Öl-Fond 2011?, Correct Retrieved: True\n",
            "Query: Welche Wüste liegt im östlichen Namibia?, Correct Retrieved: True\n",
            "Query: Ab wann verstärkte Mali die Beziehungen zu den westlichen Ländern?, Correct Retrieved: True\n",
            "Query: Wann nach Chr. wurden im Römischen Reich zunehmend bildliche Darstellungen in Mosaiken verwendet? , Correct Retrieved: True\n",
            "Query: Wann drohte Großbritannien in der Nachkriegszeit bankrott zu gehen?, Correct Retrieved: True\n",
            "Query: Wer ist nominal für die Ordnung des Verkehrs in London zuständig?, Correct Retrieved: True\n",
            "Query: Unter welcher Bedingung ist  nach der Powell-Doktrin im Verteidigungsfall der Streitkräfteeinsatz legitim?, Correct Retrieved: True\n",
            "Query: Wie lange dauerte der Krieg zwischem dem Osmanischen Reich und den Anhängern al-Wahhabs?, Correct Retrieved: True\n",
            "Query: Wo befindet sich das Internat, das John Kerry in Europa besuchte?, Correct Retrieved: True\n",
            "Query: In welchem Jahr wurde erstmals eine Kernspaltung durchgeführt?, Correct Retrieved: True\n",
            "Query: Was galt als Ideal in der Literatur für die Anhänger Gottscheds?, Correct Retrieved: True\n",
            "Query: welchen Status hat Armenisch auf Zypern?, Correct Retrieved: True\n",
            "Query: Wie heißt das traditionelle Kleidungsstück für Frauen in Mali?, Correct Retrieved: True\n",
            "Query: Wieso ist der Verdauungstrakt bei Karnivoren vergleichsweise kurz?, Correct Retrieved: True\n",
            "Query: Anführer welcher politischen Gruppe in der Römischen Republik war Gaius Marius?, Correct Retrieved: True\n",
            "Query: Wie groß ist die Landmasse der Marshallinseln?, Correct Retrieved: True\n",
            "Query: Wann wurde das Dionysos-Mosaik in Köln wieder entdeckt?, Correct Retrieved: True\n",
            "Query: Welcher Vogel ist Symbol der University of Kansas?, Correct Retrieved: True\n",
            "Query: Wie kann eine katholisch geschlossene Ehe annulliert werden?, Correct Retrieved: True\n",
            "Query: Was steht beim Hinayana-Buddhismus im Zentrum des Strebens nach Erwachen?, Correct Retrieved: True\n",
            "Query: Wie viele Stunden weicht die Westeuropäische Normalzeit von der Koordinierten Weltzeit ab?, Correct Retrieved: True\n",
            "Query: Welche These wird in der Sprachphilosophie in Bezug auf Übersetzung vertreten?, Correct Retrieved: True\n",
            "Query: Welche Schweizer Städte gehören zur Alpenregion?, Correct Retrieved: True\n",
            "Query: Wer gründete nach der Zerstörung der Dynastie von Ur durch die Elamer ein Reich auf dem Gebiet von Sumer?, Correct Retrieved: True\n",
            "Query: Welche Gemeinden in Thüringen leiden besonders an Schulden?, Correct Retrieved: True\n",
            "Query: Wofür wird bei Modellflugzeugen Papier als Material eingesetzt?, Correct Retrieved: True\n",
            "Query: An welchem Meer liegt Eritrea?, Correct Retrieved: True\n",
            "Query: Wo leben urtümliche Hunde?, Correct Retrieved: True\n",
            "Query: Wo bekommt man die Emulator-Software für alte XBox-Spiele?, Correct Retrieved: True\n",
            "Query: Was bedeutet Energiequantelung bei elektromagnetischen Wellen?, Correct Retrieved: True\n",
            "Query: Welches Museum in Palermo beherbergt eine Ausstellung über die historische Entwicklung der Stadt?, Correct Retrieved: True\n",
            "Query: Wie hat sich die Funktionalität der Schultertasten beim Sixaxis-Contoller im Vergleich mit dem Vorgänger verändert?, Correct Retrieved: True\n",
            "Query: Welches Bauteil wird bei der endgültigen Montage von Elektromotoren als erstes verbaut?, Correct Retrieved: True\n",
            "Query: Wo befindet sich die diplomatische Vertretung des Vatikans in Guinea-Bissau?, Correct Retrieved: True\n",
            "Query: Was erklärte Einstein 1907 durch die Quantelung von  Schwingungsenergie?, Correct Retrieved: True\n",
            "Query: Seit wann gibt es das für Unicode verantwortliche Konsortium?, Correct Retrieved: True\n",
            "Query: Was versuchte das Absinken des Meeresniveaus während der Eiszeiten?, Correct Retrieved: True\n",
            "Query: Was war die Grundform des ursprünglichen Santa Monica?, Correct Retrieved: True\n",
            "Query: Wie viele Personen spielen beim Canadian Football für ein Team?, Correct Retrieved: True\n",
            "Query: Wie ordnet Forbes den Marktwert des FC Arsenal ein?, Correct Retrieved: True\n",
            "Query: Wie werden Tuberkuloseinfektionen oder Verdachtsfälle darauf behandelt?, Correct Retrieved: True\n",
            "Query: Wieso wird Botanik heute eher als Pflanzenwissenschaft bezeichnet?, Correct Retrieved: True\n",
            "Query: Auf wen geht die Philosophie der Metaphysik zurück?, Correct Retrieved: True\n",
            "Query: Welche vogelartigen Kreaturen gibt es in der griechischen Mythologie?, Correct Retrieved: True\n",
            "Query: Von wem wurde Aldo Moro als Geisel genommen?, Correct Retrieved: True\n",
            "Query: Welche Elemente entstanden nach dem Urknall als erstes?, Correct Retrieved: True\n",
            "Query: Welcher Konfliktpartei im amerikanischen Bürgerkrieg wird Ohio zugeordnet?, Correct Retrieved: True\n",
            "Query: Welche Epoche umfassen die Ausstellungstücke des archäologischen Museums in Palermo?, Correct Retrieved: True\n",
            "Query: Wann wird einer Infektion mit Tuberkuloseerregern als latent bezeichnet?, Correct Retrieved: True\n",
            "Query: Für welche Eismasse sagen Forscher:innen ein durch den Klimawandel bedingtes Abschmelzen voraus?, Correct Retrieved: True\n",
            "Query: Wer verbündete sich mit Johann Ohneland in Flandern?, Correct Retrieved: True\n",
            "Query: welche Whiskey-Marken werden in Tennessee produziert?, Correct Retrieved: True\n",
            "Query: Wann ging des langjährige Synchronsprecher von Arnold Schwarzenegger in Ruhestand?, Correct Retrieved: True\n",
            "Query: Welche Funktionen im Staat erfüllt der Präsident in Liberia?, Correct Retrieved: True\n",
            "Query: Was war die Ursache für den Brand, durch den Richmond im Bürgerkrieg zerstört wurde?, Correct Retrieved: True\n",
            "Query: Auf welcher Messe hat Nintendo den R.O.B. erstmals präsentiert?, Correct Retrieved: True\n",
            "Query: Wie wurden die Gebiete des heutigen Namibia unter deutscher Herrschaft genannt?, Correct Retrieved: True\n",
            "Query: In welchem County liegt Detroit?, Correct Retrieved: True\n",
            "Query: Wann wurde in Louisiana die Hinrichtung als Strafe nach Aussetzung in den 1970 wieder eingeführt?, Correct Retrieved: True\n",
            "Query: Nach welchen Kriterien sind die chinesischen Schriftzeichen im Shuowen Jiezi geordnet?, Correct Retrieved: True\n",
            "Query: Was kann eine Begleiterscheinung von Implantaten sein?, Correct Retrieved: True\n",
            "Query: Was waren die landwirtschaftlichen Haupterzeugnisse von North Carolina vor dem Sezessionskrieg?, Correct Retrieved: True\n",
            "Query: Welche Rolle hat der Hohepriester Esra für die jüdische Religionsgemeinschaft?, Correct Retrieved: True\n",
            "Query: Wann wird ein Fahrstuhl als indirekt hydraulisch bezeichnet?, Correct Retrieved: True\n",
            "Query: Wo befindet sich das Nervensystem bei Ringelwürmern?, Correct Retrieved: True\n",
            "Query: Welche Stadt eroberten die Japaner Ende April 1942 im Pazifikkrieg?, Correct Retrieved: True\n",
            "Query: Welches war der erste Kinofilm, in dem Schwarzenegger mitmachte?, Correct Retrieved: True\n",
            "Query: Welcher bedeutende Reformator stammt aus dem Elsass?, Correct Retrieved: True\n",
            "Query: Was ist ein Schleimhautödem?, Correct Retrieved: True\n",
            "Query: Was ist die These von der Unbestimmtheit von Übersetzung?, Correct Retrieved: True\n",
            "Query: Wer gilt als die Urahnen des jüdischen Volkes?, Correct Retrieved: True\n",
            "Query: Wohin führte die Emigration der aschkenasischen Juden aus Europa um 1900?, Correct Retrieved: True\n",
            "Query: Welche Branche ist innerhalb des Dienstleistungssektors in Palermo besonders wichtig?, Correct Retrieved: True\n",
            "Query: In welchem Film wurde eine Meisterschaftssieg der Chicago Cubs für 2015 vorausgesagt?, Correct Retrieved: True\n",
            "Query: zu welcher Art von Geschossen gehört Uranmunition?, Correct Retrieved: True\n",
            "Query: Welchen Problemen musste die malische Regierung unter Keita begegnen?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen stecken sich jährlich mit Tuberkulose an?, Correct Retrieved: True\n",
            "Query: Welche grundlegende Neuerung wurde bei den Contollern ab Sixaxis eingeführt?, Correct Retrieved: True\n",
            "Query: Durch wen wurde der Abriss des Dorfes el Cabanyal bei valencia 2010 vorübergehend gestoppt?, Correct Retrieved: True\n",
            "Query: Wie viele Hochseehäfen gibt es in Liberia?, Correct Retrieved: True\n",
            "Query: Welche Funktionen erfüllen Säugetiere heute für den Menschen?, Correct Retrieved: True\n",
            "Query: Wann wurde Keita in Mali abgesetzt?, Correct Retrieved: True\n",
            "Query: Wie wird der WLAN-Adapter an die XBox 360 angeschlossen?, Correct Retrieved: True\n",
            "Query: Welcher Bereich der Hundezunge nimmt süße Stoffe war?, Correct Retrieved: True\n",
            "Query: Wodurch werden Warenhäuser und Kaufhäuser unterschieden?, Correct Retrieved: True\n",
            "Query: Wie viele Soldaten hatten die Nordstaaten im Amerikanischen Bürgerkrieg?, Correct Retrieved: True\n",
            "Query: Was für ein politisches System entwickelte sich nach Ende der Dekolonialisierung in Tansania?, Correct Retrieved: True\n",
            "Query: In welchem Zeitraum war Albert Bloch Department Chair an der University of Kansas?, Correct Retrieved: True\n",
            "Query: Wie viele Zeugen jehovas leben in Russland?, Correct Retrieved: True\n",
            "Query: Welche Staaten galten nach dem zweiten Weltkrieg als Weltmacht?, Correct Retrieved: True\n",
            "Query: Welche Einrichtungen des Technischen Hilfswerks sind in Hannover angesiedelt?, Correct Retrieved: True\n",
            "Query: Seit wann veröffentlichte Kanye West eigene Musik als rapper?, Correct Retrieved: True\n",
            "Query: Für welche Bereiche werden Hydraulikaufzüge eingesetzt?, Correct Retrieved: True\n",
            "Query: Wie wirkte sich die Gletscherbildung während der Kaltzeiten auf die Nordseeregion aus?, Correct Retrieved: True\n",
            "Query: Wer kann die liberische Staatsbürgerschaft erhalten?, Correct Retrieved: True\n",
            "Query: Was sind frühere Vorläufer von Non-Profit-Organisationen?, Correct Retrieved: True\n",
            "Query: Welches ist der zweitgrößte Telefonanbieter in den USA?, Correct Retrieved: True\n",
            "Query: Welchen Urbanisierungsgrad hatte Israel bei Staatsgründung?, Correct Retrieved: True\n",
            "Query: In welchem Wirtschaftsbereich sind in Palermo die meisten Menschen beschäftigt?, Correct Retrieved: True\n",
            "Query: Welches sind die am dichtesten besiedelten Gebiete im Iran?, Correct Retrieved: True\n",
            "Query: In welchem Jahr besuchte Helmut Kohl Namibia?, Correct Retrieved: True\n",
            "Query: Was ist das besondere am Lykurgosbecher?, Correct Retrieved: True\n",
            "Query: Durch was die Transaktionsliste bei einer USB-Schnittstelle verwaltet?, Correct Retrieved: True\n",
            "Query: Wessen Häuser waren in der römischen Gesellschaft meist mit Mosaiken verziert?, Correct Retrieved: True\n",
            "Query: Von wo nach wo wandern Zugvögel?, Correct Retrieved: True\n",
            "Query: Welche Auswirkungen hatte die Steuerforderungen der Ostindien-Kompanie in Bengalen im 18. Jhd.?, Correct Retrieved: True\n",
            "Query: Wie können Hunde Geschmacksstoffe nur wahrnehmen?, Correct Retrieved: True\n",
            "Query: Welcher Vertrag wurde zum Ende des Ersten Weltkriegs geschlossen?, Correct Retrieved: True\n",
            "Query: Wieso werden Priester im Elsass teilweise vom Staat bezahlt?, Correct Retrieved: True\n",
            "Query: Wie kann der R.O.B. von Nintendo informationen aus der Umwelt wahrnehmen?, Correct Retrieved: True\n",
            "Query: Welchen Status hat Moses im jüdischen Glauben?, Correct Retrieved: True\n",
            "Query: Wann wurden Teile des heutigen Namibia zur Deutschen Kolonie?, Correct Retrieved: True\n",
            "Query: Wie hoch ist das BIP pro Kopf in Guinea-Bissau?, Correct Retrieved: True\n",
            "Query: Wozu dient der Alaska Permanent Fund?, Correct Retrieved: True\n",
            "Query: In welcher Stadt ist Kanye West geboren?, Correct Retrieved: True\n",
            "Query: Warum wird moderne Popularmusik manchmal als klassisch benannt?, Correct Retrieved: True\n",
            "Query: Durch welche Städte verläuft der 15. östliche Längengrad?, Correct Retrieved: True\n",
            "Query: Bei welchen Parameter von Beleuchtungsmitteln wird eine Optimierung angestrebt?, Correct Retrieved: True\n",
            "Query: Welche Firma steht hinter der Entwicklung von WMA?, Correct Retrieved: True\n",
            "Query: Truppen aus welchen britischen Überseegebieten nahmen an der Schlacht von Gallipoli teil?, Correct Retrieved: True\n",
            "Query: Wie wirkt sich eine Temperaturänderung bei Keramikkondensatoren aus?, Correct Retrieved: True\n",
            "Query: Seit wann unterstützt der WLAN-Adapter der XBox auch WPA2-Verschlüsselung?, Correct Retrieved: True\n",
            "Query: Wie wird die Westeuropäische Sommerzeit international bezeichnet?, Correct Retrieved: True\n",
            "Query: Wann versuchten die Alliierten im Krimkrieg erstmals Petropawlowsk einzunehmen?, Correct Retrieved: True\n",
            "Query: Was sind Teilzieher bei den Zugvögeln?, Correct Retrieved: True\n",
            "Query: Welche Minderheiten gibt es in Tadschikistan?, Correct Retrieved: True\n",
            "Query: Wie wurde John Kerry im Vergleich  mit den anderen Kandidat:innen in den Vorwahlen 2004 wahrgenommen?, Correct Retrieved: True\n",
            "Query: Mit vielen Schiffen griffen die Alliierten im Krimkrieg Petropawlowsk an ?, Correct Retrieved: True\n",
            "Query: Wieso wanderten um 1900 viele aschkenasische Juden aus Russland aus?, Correct Retrieved: True\n",
            "Query: In welcher Branche sind die meisten Menschen in Myanmar beschäftigt?, Correct Retrieved: True\n",
            "Query: Wie hieß die Armee der amerikanischen Kolonien im Unabhängigkeitskrieg?, Correct Retrieved: True\n",
            "Query: Welches Gebiet wollte die Ostindien-Kompanie 1620 einnehmen?, Correct Retrieved: True\n",
            "Query: Wie lange muss man nach einer Organtransplantation Immunsuppressiva nehmen?, Correct Retrieved: True\n",
            "Query: Welches Gremium hat in Nigeria die Aufsicht über den Rundfunk?, Correct Retrieved: True\n",
            "Query: Wo in Nigeria ist die Situation für freie Medien besonders schwierig?, Correct Retrieved: True\n",
            "Query: Welches Arrondissment bildet das Zentrum der Stadtgliederung von Paris?, Correct Retrieved: True\n",
            "Query: Welcher Tag ist eritreischer Nationalfeiertag?, Correct Retrieved: True\n",
            "Query: nach welchen Kriterien wurde die Zucht von Hunden betrieben?, Correct Retrieved: True\n",
            "Query: Was wird bei einem Kondensator durch die Zeitkonstante der Selbstentladung beschrieben?, Correct Retrieved: True\n",
            "Query: Seit wann sind Todeszahlen und Neuinfektionen für Tuberkulosepatienten weltweit rückläufig?, Correct Retrieved: True\n",
            "Query: Wie viele Legislaturperioden kann der Präsident in Namibia maximal regieren?, Correct Retrieved: True\n",
            "Query: Welcher Anteil stimmte 2017 im Referendum in Puerto Rico für die Aufnahme in die USA?, Correct Retrieved: True\n",
            "Query: Um was geht es in dem Buch, das John Kerrys Vater geschrieben hat?, Correct Retrieved: True\n",
            "Query: Wodurch entsteht genetische Variabilität in einer Population?, Correct Retrieved: True\n",
            "Query: Welche Juden wanderten in der zweiten Hälfte des 20. Jhd. in das Elsass ein?, Correct Retrieved: True\n",
            "Query: Wie sieht Zink aus?, Correct Retrieved: True\n",
            "Query: Aus wie vielen Inseln bestehen die Marshallinseln?, Correct Retrieved: True\n",
            "Query: Welche Gruppen in Mali stehen unter dem Vorwurf, Kindersoldaten eingesetzt zu haben?, Correct Retrieved: True\n",
            "Query: Wieso wurde John Kerry in den 1970ern durch das FBI überwacht?, Correct Retrieved: True\n",
            "Query: Wann wurde Eritrea Teil der italienischen Kolonie in Ostafrika?, Correct Retrieved: True\n",
            "Query: welcher Anteil der israelischen Bevölkerung lebt in der Stadt?, Correct Retrieved: True\n",
            "Query: Wie lange hatten die Chicago White Sox bis 2015 keinen Titel geholt?, Correct Retrieved: True\n",
            "Query: Wer schrieb die Musik für die Hymne der US-Army?, Correct Retrieved: True\n",
            "Query: Welche Unterbereiche gibt es in der biologischen Anthropologie?, Correct Retrieved: True\n",
            "Query: Wie lange verbleiben Tuberkuloseerreger nach einer akuten Infektion im Körper?, Correct Retrieved: True\n",
            "Query: Woher stammt die Musikerin Jewel?, Correct Retrieved: True\n",
            "Query: Was wird bei Frauen durch männliche Pheromone angeregt?, Correct Retrieved: True\n",
            "Query: Die Sommerzeit welcher Zeitzone ist der UTC um eine Stunde voraus?, Correct Retrieved: True\n",
            "Query: Wie viele Einwohner:innen hat die Metropolregion von Valencia?, Correct Retrieved: True\n",
            "Query: wie viele amerikanische Soldaten kamen im Unabhängigkeitskrieg ums Leben?, Correct Retrieved: True\n",
            "Query: Wen bestimmte Johann Ohneland als Nachfolger von Wilhelm I.?, Correct Retrieved: True\n",
            "Query: In welchem Wirtschaftssektor arbeiten ca. ein Fünftel der Arbeitnehmner:innen in Estland?, Correct Retrieved: True\n",
            "Query: Wo auf den Marshallinseln leben die meisten Menschen?, Correct Retrieved: True\n",
            "Query: Welche Auflage haben die überregionalen Tageszeitungen in Nigeria zusammen?, Correct Retrieved: True\n",
            "Query: Welche Dimensionen umfasst der Eigenwert von Biodiversität?, Correct Retrieved: True\n",
            "Query: Was ist der höchste Berg von Namibia?, Correct Retrieved: True\n",
            "Query: Wie unterscheidet sich Canadian Football von American Football inbezug auf die Taktik des Spiels?, Correct Retrieved: True\n",
            "Query: Als was kommt Uran bei Panzern verwendet?, Correct Retrieved: True\n",
            "Query: Was erließ der Mogulkaiser der Ostindien-Kompanie 1718?, Correct Retrieved: True\n",
            "Query: Von welchen Frauen wird in Mali westliche Kleidung getragen?, Correct Retrieved: True\n",
            "Query: Wie viele Schriftzeichen der chinesischen Schrift gab es vermutlich 1400 v. Chr?, Correct Retrieved: True\n",
            "Query: Wie heißt das Bussystem, das zwischen Raleigh und Cary verkehrt?, Correct Retrieved: True\n",
            "Query: Wie wollte der schottische König Wilhelm I. ein Bündnis mit Frankreich schließen?, Correct Retrieved: True\n",
            "Query: In welchem Jahr entstand die Melodie der Hymne der US-Army?, Correct Retrieved: True\n",
            "Query: Welches international renomierte Musik-Label stammt aus Detroit?, Correct Retrieved: True\n",
            "Query: Wie groß ist die Fläche des Iran verglichen mit Deutschland?, Correct Retrieved: True\n",
            "Query: Wie sind die Postleitzahlen der Arrondissments von Paris angeordnet?, Correct Retrieved: True\n",
            "Query: In welcher Branche ist die Comcast Corporation führend?, Correct Retrieved: True\n",
            "Query: Wieso wurde MacArthur als Befehlshaber im Koreakrieg abgezogen?, Correct Retrieved: True\n",
            "Query: Welchen Rang belegt die Schweiz 2019 auf dem Demokratieindex?, Correct Retrieved: True\n",
            "Query: Welche Elemente können in normalen Sternen entstehen?, Correct Retrieved: True\n",
            "Query: Welcher Unternehmer besitzt den Großteil der Aktien des FC Arsenal?, Correct Retrieved: True\n",
            "Query: Wie hieß die erste elektrische Straßenbahn in Richmond im volksmund?, Correct Retrieved: True\n",
            "Query: Wo kam es erneut zu Kampfhandlungen zwischen Österreich un Preußen nach der Schlacht von Prag?, Correct Retrieved: True\n",
            "Query: Wann entwickelte sich Canadian Football?, Correct Retrieved: True\n",
            "Query: An welcher islamischen Schule orientierte sich  Abd al-Wahhab?, Correct Retrieved: True\n",
            "Query: Wer war der ursprüngliche deutsche Synchronsprecher von Schwarzenegger in seinem ersten Film?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen lebten zu Beginn des 20. Jhd. in Santa Monica?, Correct Retrieved: True\n",
            "Query: In welchem Land lebt die größte Gruppe von Esten im Ausland?, Correct Retrieved: True\n",
            "Query: Von welcher Art von Waren wird der Transport per Flugzeug organisiert?, Correct Retrieved: True\n",
            "Query: Welches Amt hatte Tiberius Sempronius Gracchus in Rom?, Correct Retrieved: True\n",
            "Query: Wie viel Prozent der Möbelindustrie von North Carolina  ist im Piedmont Triad angesiedelt?, Correct Retrieved: True\n",
            "Query: Welches Modell lässt Volkswagen im seinem Standort in Tennessee fertigen?, Correct Retrieved: True\n",
            "Query: Wieso ist das KaDeWe ein Warenhaus?, Correct Retrieved: True\n",
            "Query: Wo war die Sammlung der Galleria d’Arte Moderna in Palermo vor 2006 untergebracht?, Correct Retrieved: True\n",
            "Query: Welche Rolle hat der Kanzler einer Universität?, Correct Retrieved: True\n",
            "Query: Was hatte Warren Buffett im Interview mit Fortune in Bezug auf sein Vermögen angekündigt?, Correct Retrieved: True\n",
            "Query: Wann erlangte Eritrea seine Unabhängigkeit?, Correct Retrieved: True\n",
            "Query: Welches Hindernis gibt es für die russischsprachige Minderheit in Estland bei der Einbürgerung?, Correct Retrieved: True\n",
            "Query: Wie wird der R.O.B. von Nintendo betrieben?, Correct Retrieved: True\n",
            "Query: Was gilt als Vorgänger von Kaufhäusern?, Correct Retrieved: True\n",
            "Query: Wie verhielten sich die Elementarteilchen mit der Abkühlung nach dem Urknall?, Correct Retrieved: True\n",
            "Query: Wann formten sich viele neue Vogelarten und -gruppen?, Correct Retrieved: True\n",
            "Query: Zu welcher Nebengruppe gehört Zink?, Correct Retrieved: True\n",
            "Query: Wie viele alliierte Soldaten gerieten im Pazifikkrieg in Corregidor in japanische Gefangenschaft?, Correct Retrieved: True\n",
            "Query: Welchen Rang erreicht die Comcast Corporation nach dem Forbes-Global-Index?, Correct Retrieved: True\n",
            "Query: Unter was leiden die großen Städte im ehemaligen Manufacturing Belt in den USA?, Correct Retrieved: True\n",
            "Query: wie wurde Myanmar zu seiner wirtschaftlichen Blütezeit in der Vergangenheit bezeichnet?, Correct Retrieved: True\n",
            "Query: Welche Musiksparten hat Motown geprägt?, Correct Retrieved: True\n",
            "Query: Wie viele Soldaten hatten die Südstaaten im Amerikanischen Bürgerkrieg?, Correct Retrieved: True\n",
            "Query: In welchem Land werden Madrasa-Absolventen als Mullah bezeichnet?, Correct Retrieved: True\n",
            "Query: Wo liegt der höchste Berg von Namibia?, Correct Retrieved: True\n",
            "Query: Welches Prinzip dominierte die Außenpolitk der USA in der Nachkriegszeit?, Correct Retrieved: True\n",
            "Query: Wer war der Nachfolger von MacArthur als Kommandant im Koreakrieg?, Correct Retrieved: True\n",
            "Query: In welchem Jahr wurde eine elektrische betriebene Straßenbahn in Richmond in Betrieb genommen?, Correct Retrieved: True\n",
            "Query: Auf was konzentrierte sich die Historiographie im 17. Jahrhundert?, Correct Retrieved: True\n",
            "Query: welcher Anteil der Bevölkerung der Republik Zypern spricht Türkisch als Muttersprache?, Correct Retrieved: True\n",
            "Query: Durch welche Sportarten ist Canadian Football beeinflusst?, Correct Retrieved: True\n",
            "Query: in welchem militärischen Konflikten der jüngsten Vergangenheit wurde Uranmunition verwendet?, Correct Retrieved: True\n",
            "Query: Auf was bezieht sich das Prinzip der grundsätzlichen Übersetzbarkeit?, Correct Retrieved: True\n",
            "Query: Wann migrierten die Vorfahren väterlicherseits von John Kerry nach Amerika?, Correct Retrieved: True\n",
            "Query: Seit wann gibt es das studentische Radio an der Univeristy of Kansas?, Correct Retrieved: True\n",
            "Query: Über wie viele Geschütze verfügte die Stadt Petropawlowsk im Krimkrieg?, Correct Retrieved: True\n",
            "Query: wie lautet der Fachbegriff für das Kopfsegment von Ringelwürmern?, Correct Retrieved: True\n",
            "Query: Welche Dokumente im US-Naitonalarchiv unterliegen nicht dem Urheberrecht?, Correct Retrieved: True\n",
            "Query: Was ist der Text im britischen Königswappen?, Correct Retrieved: True\n",
            "Query: Was ist eine Graft- versus-Host-Reaktion?, Correct Retrieved: True\n",
            "Query: Wo liegt Valenica in Relation zu Madrid?, Correct Retrieved: True\n",
            "Query: Wodurch können Flughäfen regional als wirtschaftlicher Motor wirken?, Correct Retrieved: True\n",
            "Query: Welcher Bereich der Zunge beim Hund spricht auf die Geschmacksrichtung bitter an?, Correct Retrieved: True\n",
            "Query: Durch was wurde die britische Ostindien-Kompanie 1718 von Zollzahlungen befreit?, Correct Retrieved: True\n",
            "Query: Als was verstand sich der osmanische Herrscher in bezug auf die islamische Pilgerfahrt?, Correct Retrieved: True\n",
            "Query: Wann wurden die Zeugen Jehovas in Russland offiziell akzeptiert?, Correct Retrieved: True\n",
            "Query: Wie viel des weltweiten Frachtaufkommens werden durch Flugzeuge transportiert? , Correct Retrieved: True\n",
            "Query: In welchem Jahr fand die islamische Revolution in Iran statt?, Correct Retrieved: True\n",
            "Query: Welchem Staat wurde Eritrea nach dem Zweiten Weltkrieg zugeordnet?, Correct Retrieved: True\n",
            "Query: Welche Bedeutung hat die Tora für die jüdische Religion?, Correct Retrieved: True\n",
            "Query: Wo kann man Aktien von FC Arsenal kaufen?, Correct Retrieved: True\n",
            "Query: Wie wurde Paris unter den Römern genannt?, Correct Retrieved: True\n",
            "Query: Wie verändert sich Zeit für Intervalle der Planck-Zeit?, Correct Retrieved: True\n",
            "Query: Von wann bis wann lebte Albert Bloch in Deutschland?, Correct Retrieved: True\n",
            "Query: Welche Klasse der römischen Gesellschaft diente als Pool für die römische Berufsarmee?, Correct Retrieved: True\n",
            "Query: Welches quelloffene, patentfreie mp3-ähnliche Audioformat gibt es?, Correct Retrieved: True\n",
            "Query: Wann wurde die Erweiterung der Avenida de Blasco Ibanez in Valencia endgültig gestoppt?, Correct Retrieved: True\n",
            "Query: Welche Funktion hat Zink für den Körper?, Correct Retrieved: True\n",
            "Query: Was sind Immunsuppressiva?, Correct Retrieved: True\n",
            "Query: Welchen Rang hat Guniea-Bissau auf dem Korruptionsindex?, Correct Retrieved: True\n",
            "Query: Wo erstrecken sich die Ostalpen nach der in Italien üblichen Einteilung?, Correct Retrieved: True\n",
            "Query: Wann wurde Richmond Hauptstadt der Südstaaten?, Correct Retrieved: True\n",
            "Query: Wie kann der Gouverneur von Louisiana auf Todesurteile einwirken?, Correct Retrieved: True\n",
            "Query: welches sind die größten Pub-Ketten in Großbritannien?, Correct Retrieved: True\n",
            "Query: wie kann man die alten XBox-Spiele auf der neuen Konsole spielen?, Correct Retrieved: True\n",
            "Query: Was strebte Großbritannien an in anbetracht der antikolonialen Bewegungen?, Correct Retrieved: True\n",
            "Query: Was war Eritrea bevor es von den Italiener eingenommen wurde?, Correct Retrieved: True\n",
            "Query: In welcher Stadt in North Carolina hat die Daimler-Tochter Setra ihren Sitz?, Correct Retrieved: True\n",
            "Query: Wieso strebt man laut dem Hinayana-Buddhismus nach Erwachen?, Correct Retrieved: True\n",
            "Query: Welche Summe geht durch den Länderfinanzausgleich pro Jahr an Thüringen?, Correct Retrieved: True\n",
            "Query: Wie bezeichnete eine Rezension in The Craftsman Picasso nach einer Ausstellung 1911 in New York?, Correct Retrieved: True\n",
            "Query: durch was entsteht das große Handelsdefizit von Guinea-Bissau?, Correct Retrieved: True\n",
            "Query: Welcher Herrscher befreite die Juden aus der Gefangenschaft in Babylon?, Correct Retrieved: True\n",
            "Query: Welche Herangehensweise an sexuelle Orientierung wollte Sell 1996 durch eine neue Messkala ersetzen?, Correct Retrieved: True\n",
            "Query: Wann hat die Bevölkerung von Detroit stark abgenommen?, Correct Retrieved: True\n",
            "Query: Unter welchem Namen sollte der R.O.B. von nintendo  eigentlich auf den Markt kommen?, Correct Retrieved: True\n",
            "Query: Welcher Anführer versuchte mit der deutschen Kolonialmacht unter Theodor Leutwein zu verhandeln?, Correct Retrieved: True\n",
            "Query: Welche Auswirkung hat das Theorem der Planck-Zeit für die Physik?, Correct Retrieved: True\n",
            "Query: In welchem Museum wird der Lykurgosbecher ausgestellt?, Correct Retrieved: True\n",
            "Query: Wie heißt der Teil des Thorax bei Insekten, an dem die Flügel sitzen?, Correct Retrieved: True\n",
            "Query: Gegen wen suchte König Arama Hilfe beim Staat Bit Agusi?, Correct Retrieved: True\n",
            "Query: Für wie lange schloss Johann Ohneland mit dem französischen König Frieden?, Correct Retrieved: True\n",
            "Query: Wann fand in Louisiana die letzte Exekution statt?, Correct Retrieved: True\n",
            "Query: welche Bedingungen musste Wilhelm I. im Vertrag von Norham erfüllen?, Correct Retrieved: True\n",
            "Query: Zu was rief Polizeichef Johnson die Menschen bei \"Call to Action\" auf?, Correct Retrieved: True\n",
            "Query: Welche Art der Savanne macht den größten Teil der Fläche der Zentralafrikanischen Republik aus?, Correct Retrieved: True\n",
            "Query: Um wie viele Stunden ist die MESZ von der UTC verschoben?, Correct Retrieved: True\n",
            "Query: Welcher Zusammenhang besteht zwischen der Größe und der Lebenserwartung von Säugetieren?, Correct Retrieved: True\n",
            "Query: Bei welchen internationalen Organisationen ist Guinea-Bissau Mitglied?, Correct Retrieved: True\n",
            "Query: Welches Land war am Bau des Hafen in Monrovia beteiligt?, Correct Retrieved: True\n",
            "Query: Wer eroberte Anfang des 19. Jhds Medina und Mekka?, Correct Retrieved: True\n",
            "Query: Bei welchen Kondensatoren tritt Selbstentladung auf?, Correct Retrieved: True\n",
            "Query: Wer war während der Präsidentschaft Eisenhowers Speaker of the House?, Correct Retrieved: True\n",
            "Query: Welches ist die zweitgrößte Stadt in Spanien?, Correct Retrieved: True\n",
            "Query: Welche biologische Wirkung zeigt künstliche Beleuchtung bei Menschen?, Correct Retrieved: True\n",
            "Query: Welche Art von Reisen werden über den Teterboro Airport vorwiegend abgewickelt?, Correct Retrieved: True\n",
            "Query: Welche Positionierung nahm Eisenhower innerhalb der republikanischen Partei ein?, Correct Retrieved: True\n",
            "Query: Mit welcher Partei trat Ellen Johnson-Sirleaf 2005 zur Wahl an?, Correct Retrieved: True\n",
            "Query: Welches sind die am wenigsten eng besiedelten Gebiete im Iran?, Correct Retrieved: True\n",
            "Query: Welches sind die größten Städte in Israel?, Correct Retrieved: True\n",
            "Query: Mit welchem Land hat Namibia den meisten Warenaustausch?, Correct Retrieved: True\n",
            "Query: Wie heißt die Mutter von John Kerry?, Correct Retrieved: True\n",
            "Query: zu was gehörte Eritrea in den 1950ern?, Correct Retrieved: True\n",
            "Query: Welcher Staat ist das Hauptziel des iranischen Raketenprogramms?, Correct Retrieved: True\n",
            "Query: Wie hoch ist die Arbeitslosenquote unter Jugendlichen in Estland?, Correct Retrieved: True\n",
            "Query: Von was wird Musik durch die Bezeichnung \"klassisch\" unterschieden?, Correct Retrieved: True\n",
            "Query: Aus welcher Zeit stammen die ersten Schriften zu einer wissenschaftlichen Untersuchung von Pflanzen?, Correct Retrieved: True\n",
            "Query: Nach welchem Krieg wurde die Powell-Doktrin zur Maxime in der US-Politik?, Correct Retrieved: True\n",
            "Query: Wer war der Widersacher von Tiberus Gracchus?, Correct Retrieved: True\n",
            "Query: Unter welchen Umständen ist nach der Weinberger-Powell-Doktrin der Einsatz von Soldaten ein legitimes Mittel?, Correct Retrieved: True\n",
            "Query: Auf was geht der Name Eritrea zurück?, Correct Retrieved: True\n",
            "Query: wie lange wurden mit dem Moratorium von 2014 keine Hinrichtungen in Ohio durchgeführt?, Correct Retrieved: True\n",
            "Query: Welcher deutsche Politiker nahm für Deutschland am Unabhängigkeitsjubiläum 2015 in Namibia teil?, Correct Retrieved: True\n",
            "Query: Wie verhält sich die Bevölkerungsdichte in Israel zu der der anderen Länder der Region?, Correct Retrieved: True\n",
            "Query: In welchem Museum ist Antonello da Messinas Annunziata ausgestellt?, Correct Retrieved: True\n",
            "Query: Welches Schutzgebiet liegt in den Tropenregionen der Zentralafrikanischen Republik?, Correct Retrieved: True\n",
            "Query: Als was gilt Zaynab von Muhammed Haykal?, Correct Retrieved: True\n",
            "Query: Wann starb die Mutter von Edgar Allan Poe?, Correct Retrieved: True\n",
            "Query: Wieso folgte Susan Rice nicht als Außenministerin nach Hillary Clinton?, Correct Retrieved: True\n",
            "Query: Wie viel Prozent stimmten bei der Stichwahl 2011 in Liberia für Johnson-Sirleaf?, Correct Retrieved: True\n",
            "Query: Welcher Teil eines Zahnstangenaufzuges ist Träger des Antriebmotors?, Correct Retrieved: True\n",
            "Query: Bei welcher Variante des Nintendo Entertainment System ist der R.O.B. enthalten?, Correct Retrieved: True\n",
            "Query: Wie viele Frauen wurden in Iowa hingerichtet?, Correct Retrieved: True\n",
            "Query: Was war normalerweise der Träger einer islamischen Madrasa?, Correct Retrieved: True\n",
            "Query: Welches Ereignis führte vor ca 2000 Jahren zur Vereinheitlichung der chinesischen Schrift?, Correct Retrieved: True\n",
            "Query: Welche Städte in North Carolina setzen in den letzten Jahren auf den Ausbau des öffentlichen Nahverkehrs?, Correct Retrieved: True\n",
            "Query: Wem wird der Kauf von Gebieten im heutigen Namibia von der lokalen Bevölkerung Ende des 19. Jahrhunderts zugeschrieben?, Correct Retrieved: True\n",
            "Query: welches Flugzeug stürzte im Februar 2008 über Guam ab?, Correct Retrieved: True\n",
            "Query: Um wie viel war das Meeresniveau tiefer während der Eiszeiten?, Correct Retrieved: False\n",
            "Query: Welcher ägyptische Autor erhielt als erster den Literaturnobelpreis?, Correct Retrieved: True\n",
            "Query: Wie lange regierte Sam Nujoma in Namibia?, Correct Retrieved: True\n",
            "Query: Welche Selbstentladungszeitkonstante haben Kunststoff-Folien-Kondensatoren?, Correct Retrieved: True\n",
            "Query: Was kennzeichnet den jüdischen Friedhof in Hamburg?, Correct Retrieved: True\n",
            "Query: An was erinnert der Name Jayhawk?, Correct Retrieved: True\n",
            "Query: Welchen international bekannten Literaturpreis erhielt Nagib Mahfuz?, Correct Retrieved: True\n",
            "Query: Durch was kann die dauerhafte Beleuchtung eines unbenutzten Aufzugs verhindert werden?, Correct Retrieved: True\n",
            "Query: Wie starb König Rusa I. von Urartu?, Correct Retrieved: True\n",
            "Query: Scheine in welchem Wert wurden als Hawaii-Dollar gedruckt?, Correct Retrieved: True\n",
            "Query: Was ist eine Lungenobstruktion?, Correct Retrieved: True\n",
            "Query: Unter welchen Umständen kann eine katholisch geschlossene Ehe annulliert werden?, Correct Retrieved: True\n",
            "Query: Was sind die Paranota bei Insekten?, Correct Retrieved: True\n",
            "Query: Wieso bildete sich der 38. Breitengrad als Front im Koreakrieg?, Correct Retrieved: True\n",
            "Query: Zu welchem Konzern gehörte Eastman Chemical früher?, Correct Retrieved: True\n",
            "Query: In welche Gruppen werden Säugetiere bezüglich ihrer Ernährung eingeteilt?, Correct Retrieved: True\n",
            "Query: In welchem Museum in Palermo werden die Sizilianischen Zwergelefanten ausgestellt?, Correct Retrieved: True\n",
            "Query: In welchem Zeitraum führte die deutsche Kolonialmacht in Namibia Krieg gegen die einheimische Bevölkerung?, Correct Retrieved: True\n",
            "Query: welche Möglichkeiten zum unerkannten Surfen im Internet gibt es?, Correct Retrieved: True\n",
            "Query: Was ist das älteste Gebäude in der Second Street in Santa Monica?, Correct Retrieved: True\n",
            "Query: Wovon wird klassische Musik im Bezug auf die verwendeten Instrumente abgegerenzt?, Correct Retrieved: True\n",
            "Query: Was war der Inhalt der von Gracchus angestrebten Landreform 133.v.Chr.?, Correct Retrieved: True\n",
            "Query: Welcher Vogel hat eine  symbolische Bedeutung im Christentum?, Correct Retrieved: True\n",
            "Query: In welcher Stadt hat die Regal Entertainment Group ihren Sitz?, Correct Retrieved: True\n",
            "Query: Mit was steht die öffentliche Förderung der Bildung in den USA in Zusammenhang?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen leben in Windsor, Ontario?, Correct Retrieved: True\n",
            "Query: Wann wurde das aktuelle britische Thronwappen festgelegt?, Correct Retrieved: False\n",
            "Query: Wozu sollte das Dorf El Cabanyal bei Valencia abgerissen werden?, Correct Retrieved: True\n",
            "Query: Wieso ließ König Menua einen Kanal nach Tuspa bauen?, Correct Retrieved: True\n",
            "Query: In welchem Stadtbezirk liegen die beiden Airport von New York?, Correct Retrieved: True\n",
            "Query: Was sind die Ursachen für den Anstieg der Tuberkulosezahlen in osteuropäischen Ländern?, Correct Retrieved: True\n",
            "Query: Wieso ist der Grad des Wohlstandes in der Republik Kongo trotz hohem BIP nicht sehr hoch?, Correct Retrieved: True\n",
            "Query: Welches Elternteil ist laut dem orthodoxen Judentum relevant für die Bestimmung eines Kindes als jüdisch?, Correct Retrieved: True\n",
            "Query: Wie heißt die Insel in Detroit im gleichnamigen Fluss?, Correct Retrieved: True\n",
            "Query: welches Amt hatte Susan Rice unter Obama?, Correct Retrieved: True\n",
            "Query: Wieso ist in manchen Pubs das Tragen von Fußball-Fanartikeln verboten?, Correct Retrieved: True\n",
            "Query: Wieso kann man bei Ringelwürmern nicht das übliche Strickleiternervensystem erkennen?, Correct Retrieved: True\n",
            "Query: Welches Flugzeug stürzte im August 1997 über Guam ab?, Correct Retrieved: True\n",
            "Query: Für welche Bitraten ist Vorbis besser als mp3?, Correct Retrieved: True\n",
            "Query: Wie hoch ist die Arbeitslosigkeit in Estland?, Correct Retrieved: True\n",
            "Query: Welche Gruppen werden vom Iran in der militärischen Auseinandersetzung mit Israel unterstützt?, Correct Retrieved: True\n",
            "Query: Wer war der erste Präsident im unabhängigen Mali?, Correct Retrieved: True\n",
            "Query: Wie koopertiert der Honiganzeiger mit Menschen?, Correct Retrieved: True\n",
            "Query: Wer versuchte Anfang der 1990er die Todesstrafe in Iowa wieder einzuführen?, Correct Retrieved: True\n",
            "Query: Was sind Antituberkulotika?, Correct Retrieved: True\n",
            "Query: Was ist die höchste Leistung, die ein USB-Anschluss haben kann?, Correct Retrieved: True\n",
            "Query: Welche Art von Geschichtswissenschaft wurde gegen Ende des 17. Jahrhunderts gefordert?, Correct Retrieved: True\n",
            "Query: Wie unterscheidet sie das Feld beim Canadian Football vom American Football?, Correct Retrieved: True\n",
            "Query: Welcher König ist der Gründer der Vorläuferstadt von Van?, Correct Retrieved: True\n",
            "Query: Was sind die Hauptverwendungsbereiche von Zink?, Correct Retrieved: True\n",
            "Query: Wieso dient Empirie laut der frühgriechischen Philosophen nicht zur Bildung allgemeiner Theorien?, Correct Retrieved: True\n",
            "Query: Welche Arten von Sensorik gibt es bei Elektromotoren?, Correct Retrieved: True\n",
            "Query: Welcher zweisprachige Fernsehsender ist in Straßburg angesiedelt?, Correct Retrieved: True\n",
            "Query: Wann wurde die deutsche Ausgabe der Dernieres Nouvelle d'Alsace eingestellt?, Correct Retrieved: True\n",
            "Query: Seit wann steigt der Anteil der ländlichen Bevölkerung in Israel wieder?, Correct Retrieved: True\n",
            "Query: Wieso bezeichneten einige Republikaner Schwarzenegger als Mogelkandidat?, Correct Retrieved: True\n",
            "Query: Bei welchen Säugetieren gilt die sonst übliche Tendenz zwischen Größe und Lebenserwartung nicht?, Correct Retrieved: True\n",
            "Query: Welcher Text ist auf der schottischen variante des britischen Königswappen abgebildet?, Correct Retrieved: True\n",
            "Query: Wie alt sind die meisten Wrestlingfans?, Correct Retrieved: True\n",
            "Query: Wer war der erste demokratisch gewählte Präsident von Mali?, Correct Retrieved: True\n",
            "Query: Welche der großen Buddhismushauptströmungen reicht zeitlich weiter zurück?, Correct Retrieved: True\n",
            "Query: Was sind die beiden Hauptindustriebranchen in North Carolina?, Correct Retrieved: True\n",
            "Query: Wie ist der Wohlstand in Guinea-Bissau verteilt?, Correct Retrieved: True\n",
            "Query: In welche Gruppe wird die Schweiz nach dem Demokratieindex eingeordnet?, Correct Retrieved: True\n",
            "Query: Wie bezeichnet man Zugvögel, die in Gebiete ziehen, die in den selben Breitengraden liegen?, Correct Retrieved: True\n",
            "Query: Wer veranlasste die Einrichtung der United States Military Academy?, Correct Retrieved: True\n",
            "Query: Wo sind die meisten Firmen, die VPN oder Proxy anbieten, ansässig?, Correct Retrieved: True\n",
            "Query: Wo hatte die East India Company ihre Zentrale?, Correct Retrieved: True\n",
            "Query: Wie viel Geld hat Kanye West laut Forbes?, Correct Retrieved: True\n",
            "Query: In welchem Zeitraum gehörte Santa Monica zu Mexiko?, Correct Retrieved: True\n",
            "Query: welche Währung war vor dem Euro in Portugal gültig?, Correct Retrieved: True\n",
            "Query: Wann gewannen die Chicago Cubs nach über hundert Jahren erstmals wieder eine Meisterschaft?, Correct Retrieved: True\n",
            "Query: Welche Metalle werden in Alaska geschürft?, Correct Retrieved: True\n",
            "Query: Wie viele Abgeordnete im Repräsentantenhaus der USA würde Puerto Rico als Bundesstaat bekommen?, Correct Retrieved: True\n",
            "Query: In welchen Landessprachen neben Englisch erscheinen Zeitungen in Nigeria?, Correct Retrieved: True\n",
            "Query: Welche Volksgruppe auf Zypern spricht Arabisch?, Correct Retrieved: True\n",
            "Query: Welche kanadische Stadt liegt Detroit am Detroit River gegenüber?, Correct Retrieved: True\n",
            "Query: wer war vor John Kerry US-Außenministerin?, Correct Retrieved: True\n",
            "Query: Wer wurde nach der Unabhängigkeit namibischer Präsident?, Correct Retrieved: True\n",
            "Query: Wann wurden die Zeugen Jehovas in Russland als extremistisch verurteilt?, Correct Retrieved: True\n",
            "Query: Wo hat FedEx seine Zentrale?, Correct Retrieved: True\n",
            "Query: Durch was unterscheidet sich Zink von den anderen Übergangsmetallen?, Correct Retrieved: True\n",
            "Query: Woher stammten die Elamer?, Correct Retrieved: True\n",
            "Query: Was ist das Pipau aus Mali?, Correct Retrieved: True\n",
            "Query: Welcher Begriff etabliert sich heutzutage für Phytologie?, Correct Retrieved: True\n",
            "Query: Bei welchem Propheten liegt der Ursprung des Judentums?, Correct Retrieved: True\n",
            "Query: Was sind urtümliche Hunde?, Correct Retrieved: True\n",
            "Query: In was für einen wirtschaftlichen System enstehen Non-Profit-Organisationen?, Correct Retrieved: True\n",
            "Query: Was ist Uranmunition?, Correct Retrieved: True\n",
            "Query: Wie wird der Isolationswiderstand bei Kondensatoren mit Elektrolyt bestimmt?, Correct Retrieved: True\n",
            "Query: Welchen Einfluss hat der Mensch auf die Verbreitungsgebiete von Säugetieren?, Correct Retrieved: True\n",
            "Query: Unter welchem Präsidenten wurde der New Deal umgesetzt?, Correct Retrieved: True\n",
            "Query: Wen sah Truman als eigentlichen Feind im Koreakrieg?, Correct Retrieved: True\n",
            "Query: Welche ISO Norm entspricht dem unicode ?, Correct Retrieved: True\n",
            "Query: Wer förderte die Gates Foundation 2006 mit Aktien im Wert von mehreren Milliarden Dolalr?, Correct Retrieved: True\n",
            "Query: Der Sonnenzeit welches Längengrades entspricht die europäische Sommerzeit?, Correct Retrieved: True\n",
            "Query: Was sind die Nuchalorgane bei Ringelwürmern?, Correct Retrieved: True\n",
            "Query: Welche Vorteile bietet künstliche Beleuchtung?, Correct Retrieved: True\n",
            "Query: An was orientiert sich die in Frankreich übliche Dreiteilung der Alpen?, Correct Retrieved: True\n",
            "Query: Welcher Hafen in Liberia hat das größte Handelsvolumen?, Correct Retrieved: True\n",
            "Query: Wie viele Sternwarten hat der Jaipur-Fürst Jai Singh II. erbauen lassen?, Correct Retrieved: True\n",
            "Query: Was versteht man unter Modern Republicanism?, Correct Retrieved: True\n",
            "Query: in welchem Jahr entstand der Neoklassizismus in den USA?, Correct Retrieved: True\n",
            "Query: wie kann man die Sixaxis-Controller laden?, Correct Retrieved: True\n",
            "Query: Wo grenzt namibia an Botswana?, Correct Retrieved: True\n",
            "Query: In welchem Teil der Zentralafrikanischen Republik gibt es Regenwald?, Correct Retrieved: True\n",
            "Query: Wo liegt der Ursprung des Techno in Detroit?, Correct Retrieved: True\n",
            "Query: Wer wurde 2005 zur Präsidentin von Liberia gewählt?, Correct Retrieved: True\n",
            "Query: Wofür werden Ausländer:innen in Mali gekidnappt?, Correct Retrieved: True\n",
            "Query: Welche Probleme der britischen Armee trugen zu deren Niederlage im amerikanischen Unabhängigkeitskrieg bei?, Correct Retrieved: True\n",
            "Query: In welcher Branche ist Eastman Chemical tätig?, Correct Retrieved: True\n",
            "Query: Welche Art der Savanne ist im Norden der Zentralafrikanischen Republik zu finden?, Correct Retrieved: False\n",
            "Query: Kontingente von was für Truppen kämpften im Unabhängigkeitskrieg für  die britische Armee?, Correct Retrieved: True\n",
            "Query: Wie verhalten sich die Werte der Selbstentladung eines Kondensator mit der Temperatur?, Correct Retrieved: True\n",
            "Query: Welche Wüste liegt im Westen von Namibia?, Correct Retrieved: True\n",
            "Query: Seit wann wird die aktuelle Bezeichnung für Paris verwendet?, Correct Retrieved: True\n",
            "Query: Welche Atomnummer hat Zink?, Correct Retrieved: True\n",
            "Query: In welcher Zeitschrift wurde die Bezeichnung als erstes verwendet?, Correct Retrieved: True\n",
            "Query: Was gilt als Anfänge der Botanik?, Correct Retrieved: True\n",
            "Query: Welche Menschenrechtsverletzungen werden den Rebellen- und Islamistenmilizen in Mali vorgeworfen?, Correct Retrieved: True\n",
            "Query: Welcher Wirtschaftsbereich beschäftigt in Estland die meisten Arbeitnehmer:innen?, Correct Retrieved: True\n",
            "Query: Welche anderen Größen werden wie die Zeit über Messverfahren definiert?, Correct Retrieved: True\n",
            "Query: Was versteht man unter grundsätzlicher Übersetzbarkeit?, Correct Retrieved: True\n",
            "Query: Für welche Schiffe kommen Uran-getriebenene Treibwerke zum Einsatz?, Correct Retrieved: True\n",
            "Query: Welche Schreibrichtung hat Avesta?, Correct Retrieved: True\n",
            "Query: Von wem stammen die \"Polenlieder\"?, Correct Retrieved: True\n",
            "Query: welche Art von Unternehmen will North Carolina in den letzten jahren verstärkt in den Staat locken?, Correct Retrieved: True\n",
            "Query: In die Tradition welches Künstlers stellt Michael Puy den Kubismus?, Correct Retrieved: True\n",
            "Query: Wie viele Legislaturperioden regierte Konare in Mali?, Correct Retrieved: True\n",
            "Query: Welcher Anteil der in der Schweiz lebenden Menschen hat nicht die schweizer Staatsangehörigkeit?, Correct Retrieved: True\n",
            "Query: Wie lange existiert die chinesische Schrift schon?, Correct Retrieved: True\n",
            "Query: Wie viele Arrondissements gibt es in Paris?, Correct Retrieved: True\n",
            "Query: Wann war die Regeleinführung, die American Football und Canadian Football deutlich voneinander trennte?, Correct Retrieved: True\n",
            "Query: Durch was unterscheidet sich Pappe von Papier?, Correct Retrieved: True\n",
            "Query: Welches Amt hatte Albert Bloch an der University of Kansas?, Correct Retrieved: True\n",
            "Query: Was hat Mose nach orthodoxen Glauben geschrieben?, Correct Retrieved: True\n",
            "Query: Welches Sprache wird auf Zypern neben den Amtssprachen auch häufig verwendet?, Correct Retrieved: True\n",
            "Query: welches Gebiet wollte Wilhelm I. von Johann Ohneland zurückbekommen?, Correct Retrieved: True\n",
            "Query: Wann war die Amtseinführung von Schwarzenegger als Gouverneur von Kalifornien?, Correct Retrieved: True\n",
            "Query: Mit welcher Methode werden Hinrichtungen in Louisiana durchgeführt?, Correct Retrieved: True\n",
            "Query: welche Gesetzesvorhaben wollte Gaius Sempronius Gracchus als Volkstribun durchsetzen?, Correct Retrieved: True\n",
            "Query: Wer unterlag in der Schlacht von Kolin?, Correct Retrieved: True\n",
            "Query: In welchem Gebiet in North Carlolina ist die Möbelindustrie vor allem angsiedelt?, Correct Retrieved: True\n",
            "Query: Bis wann war die Todesstrafe in den USA-weit ausgesetzt?, Correct Retrieved: True\n",
            "Query: Was umfasst der Unicode, was in der ISO-Norm nicht enthalten ist?, Correct Retrieved: True\n",
            "Query: Welche Tageszeitung in Straßburg hat die höchste Auflage?, Correct Retrieved: True\n",
            "Query: Wie viele Überlebende gab es bei dem Flugzeugabsturz auf Guam im August 1997?, Correct Retrieved: True\n",
            "Query: Wie lange dauerte der Unabhängigkeitskampf in Eritrea?, Correct Retrieved: True\n",
            "Query: Zu welchem Wissenschaftszweig gehört die biologische Anthropologie?, Correct Retrieved: True\n",
            "Query: Auf welchem US-Luftwaffenstützpunkt stürzte 2016 auf Guam ein Flugzeug ab?, Correct Retrieved: True\n",
            "Query: Der Sonnenzeit welches Längengrades entspricht die Standardzeit in Mitteleuropa?, Correct Retrieved: True\n",
            "Query: Was ist die Ausdehnung der Westalpen nach der in Frankreich üblichen Einteilung?, Correct Retrieved: True\n",
            "Query: Wie viele Zugvögel gibt es auf der Welt?, Correct Retrieved: True\n",
            "Query: Welche Veränderung erlebte North Carolina nach dem Sezessionskrieg?, Correct Retrieved: True\n",
            "Query: Um wie viel würde das Meeresniveau durch Abschmelzen der Polarkappen und Gletscher ansteigen?, Correct Retrieved: True\n",
            "Query: Was sind die wichtigsten Bestandteile des nationalen Selbstverständnis der Schweiz?, Correct Retrieved: True\n",
            "Query: Welches Uran-Isotop kommt in der Natur am häufigsten vor?, Correct Retrieved: True\n",
            "Query: welche Parteien waren an der Koalition nach der Wahl 2005 in Galizien beteiligt?, Correct Retrieved: True\n",
            "Query: Welcher Anteil der russischen Minderheit in Estland sind keine Bürger:innen von Estland?, Correct Retrieved: True\n",
            "Query: Wieso ist Tuberkulose bei vorhandener HIV-Infektion schwieriger festzustellen?, Correct Retrieved: True\n",
            "Query: Wann verzeichnete Portugal nach der Weltwirtschaftskrise 2008 wieder ein Wirtschaftswachstum?, Correct Retrieved: True\n",
            "Query: Wann wurde Griechenland vom Osmanischen Reich unabhängig?, Correct Retrieved: True\n",
            "Query: zu was entwickelten sich die USA und die Sowjetunion nach dem 2. Weltkrieg?, Correct Retrieved: True\n",
            "Query: Von welchen Staaten wurde das griechische Streben nach Unabhängigkeit vom Osmanischen Reich gefördert?, Correct Retrieved: True\n",
            "Query: Welches Land hatte Kolonien in Guinea-Bissau?, Correct Retrieved: True\n",
            "Query: Wie alt werden Elefanten?, Correct Retrieved: True\n",
            "Query: Wer wurde nach der Wahl 2005 Regierungschef in Galizien?, Correct Retrieved: True\n",
            "Query: Mit was verdiente Arnold Schwarzenegger in den 1960ern viel Geld?, Correct Retrieved: True\n",
            "Query: Was sind die Folgen einer fehlenden Immunsuppression bei Organtransplantation?, Correct Retrieved: True\n",
            "Query: Welche Länder sind neben Namibia in der Southern African Customs Union?, Correct Retrieved: True\n",
            "Query: In welchem US-Bundesstaat liegt der Newark Liberty Airport?, Correct Retrieved: True\n",
            "Query: Welcher Vogel wurde oft in Wappen verwendet?, Correct Retrieved: True\n",
            "Query: Welche Industriezweige sind in North Carolina seit der Jahrtausendwende stark gewachsen?, Correct Retrieved: True\n",
            "Query: Wo wurden im Osmanischen Reich besonders Griechen als Übersetzer eingesetzt?, Correct Retrieved: True\n",
            "Query: Als was galt das Arcadia Hotel in Santa Monica nach seiner Eröffnung?, Correct Retrieved: True\n",
            "Query: Wann trat Mali der FIFA bei?, Correct Retrieved: True\n",
            "Query: wer gewann die Schlacht von Prag Mitte des 18. Jahrhunderts?, Correct Retrieved: True\n",
            "Query: Was ist ein Feynmann-Diagramm?, Correct Retrieved: True\n",
            "Query: Welche Auswirkungen hatte die deutsche Besiedelung von Namibia auf die wirtschaftliche Situation der einheimischen Herero?, Correct Retrieved: True\n",
            "Query: Wie viel Geld soll Kroenke für die Aktien des FC Arsenal aus Katar geboten worden sein?, Correct Retrieved: True\n",
            "Query: Was sind die Aufgabenbereiche der Tfl in London?, Correct Retrieved: True\n",
            "Query: Welchen Anteil des BIP in Portugal macht der Dienstleistungssektor aus?, Correct Retrieved: True\n",
            "Query: Ab wann war ISO 10646 quasi mit Unicode austauschbar?, Correct Retrieved: True\n",
            "Query: Mit welchem Instrumentarium lässt sich die von Sell 1996 vorgeschlagene  Skala zur Erfassung der sexuellen Orientierung koordinieren?, Correct Retrieved: True\n",
            "Query: zu welcher Gruppe im Periodensystem gehört Uran?, Correct Retrieved: True\n",
            "Query: Wie war John Kerrys Haltung zum Putsch 2013 in Ägypten?, Correct Retrieved: True\n",
            "Query: Bei welchen Probandengruppen wurde in Studien eine verstärkte Hypothalamus-Aktivität durch Gabe von männlichen Pheromonen beobachtet?, Correct Retrieved: True\n",
            "Query: Wer konstruierte im 18. Jhd. die Montgolfiere?, Correct Retrieved: False\n",
            "Query: Wann regierte Menua in Urartu?, Correct Retrieved: True\n",
            "Query: Welche Fischarten werden in Alaska hauptsächlich gefangen?, Correct Retrieved: True\n",
            "Query: welche Hunde entsprechen der ersten Stufe der Domestikation?, Correct Retrieved: True\n",
            "Query: Welche Flagge stellte vermutlich die Inspiration für die US-Flagge dar?, Correct Retrieved: True\n",
            "Query: Was sind Ganglien bei Würmern?, Correct Retrieved: True\n",
            "Query: Welcher assyrische König führte ca. 850 v.Chr. Krieg gegen Arzaskun?, Correct Retrieved: True\n",
            "Query: Welchen Titel erhalten Personen in Südasien, die eine islamische Madrasa absolvieren?, Correct Retrieved: True\n",
            "Query: In welchem Temperaturbereich ist zink leicht formbar?, Correct Retrieved: True\n",
            "Query: Welchen Anteil an der Bevölkerung Liberias machen Menschen mit Vorfahren aus Amerika aus?, Correct Retrieved: True\n",
            "Query: Wo in Israel konzentriert sich der Hauptteil der Bevölkerung?, Correct Retrieved: True\n",
            "Query: Von was hängen die Körpermaße eines Bodybuilders ab?, Correct Retrieved: True\n",
            "Query: Welcher Industriezweig ist nach der Ölindustrie in Alaska besonders wichtig?, Correct Retrieved: True\n",
            "Query: Wie hoch war die Wahlbeteiligung bei der Stichwahl 2011 in Liberia?, Correct Retrieved: True\n",
            "Query: Welcher Producer ist für den Erfolg von Motown mit verantwortlich?, Correct Retrieved: True\n",
            "Query: Wer befehligte die österreichischen Truppen, die nach der Schlacht von Prag gegen Preußen kämpften?, Correct Retrieved: True\n",
            "Query: Welche Aufgabe hat die Federation Cynologique Internationale?, Correct Retrieved: True\n",
            "Query: in welche drei Regionen werden die Alpen in Italien üblicherweise gegliedert?, Correct Retrieved: True\n",
            "Query: Welche Spielgeräte werden in Pubs bereitgestellt?, Correct Retrieved: True\n",
            "Query: Gegen wen kämpfte England bei der Schlacht von Gallipoli?, Correct Retrieved: True\n",
            "Query: In welcher Sprache werden viele Zeitungen in Nigeria geschrieben?, Correct Retrieved: True\n",
            "Query: Welche Städte in North Carolina sind Teil des Research Triangles?, Correct Retrieved: True\n",
            "Query: Wieso war die Wahlbeteiligung bei der Stichwahl 2011 in Liberia eher gering?, Correct Retrieved: True\n",
            "Query: Wann wurde der Handelshafen in Monrovia gebaut?, Correct Retrieved: True\n",
            "Query: Wo wird Uran als Energiequelle eingesetzt?, Correct Retrieved: True\n",
            "Query: Ab wann etablierten sich in Prosa verfasste Bühnenstücke?, Correct Retrieved: True\n",
            "Query: Wer folgte auf Sam Nujoma als Präsident von Namibia?, Correct Retrieved: True\n",
            "Query: Aus wie vielen Teilen besteht die Ratak-Kette der Marshallinseln?, Correct Retrieved: True\n",
            "Query: Seit wann ist das Nationalarchiv in den USA eine eigenständige Einrichtung?, Correct Retrieved: True\n",
            "Query: mit welchem Land hatte Mali unter Traore kriegerische Auseinandersetzungen?, Correct Retrieved: True\n",
            "Query: Wer ist Präsident der University of Kansas?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen leben im Durchschnitt auf einem Quadratkilometer im Iran?, Correct Retrieved: True\n",
            "Query: Wieso können sich bei einem Befall mit Tuberkuloseerregern leicht Resistenzen bilden?, Correct Retrieved: True\n",
            "Query: Was wurde im Amerikanischen Bürgerkrieg eingeführt, um große Armeen aufstellen zu können?, Correct Retrieved: True\n",
            "Query: Was bezeichnete Feynmann als Cargo Cult Science?, Correct Retrieved: True\n",
            "Query: Wie groß ist Namibia?, Correct Retrieved: True\n",
            "Query: Wann wurde Namibia unabhängig?, Correct Retrieved: True\n",
            "Query: In welchem Jahr war die Gründung der  University of Kansas?, Correct Retrieved: True\n",
            "Query: Welche Zinkverbindung wird bei der Herstellung von Porzellan und Keramik eingesetzt?, Correct Retrieved: True\n",
            "Query: Was war John Kerrys Vater von Beruf?, Correct Retrieved: True\n",
            "Query: Anlässlich welches Jubiläums stürzte im Juli 2008 auf Guam ein Flugzeug ab?, Correct Retrieved: True\n",
            "Query: Was wird als Hominiden bezeichnet?, Correct Retrieved: True\n",
            "Query: An welche Währung ist der Wert des namibischen Dollar gebunden?, Correct Retrieved: True\n",
            "Query: Welchen Anteil hat landwirtschaftliche Produktion  am Bruttoinlandsprodukt von Myanmar?, Correct Retrieved: True\n",
            "Query: Welche Geschmacksrichtungen nehmen die seitlichen Bereiche der Zunge beim Hund wahr?, Correct Retrieved: True\n",
            "Query: Wie versuchten die Kelten Lutetia gegen die Römer zu verteidigen?, Correct Retrieved: True\n",
            "Query: Welche Veränderung prägte Kanye West in der Hip-Hop-Musik mit?, Correct Retrieved: True\n",
            "Query: Wie wurde die Koordinierte Weltzeit früher genannt?, Correct Retrieved: True\n",
            "Query: Wann wurde die Nord-Süd-Verbindung des innerstädtischen Zugverkehrs in Houston eröffnet?, Correct Retrieved: True\n",
            "Query: Was beeinflusste den traditionellen Kleidungsstil in Mali in den letzten Jahrhunderten?, Correct Retrieved: True\n",
            "Query: Von was wird eine Atemwegsobstruktion ausgelöst?, Correct Retrieved: True\n",
            "Query: Was wurde an einer klassischen islamischen Madrass unterrichtet?, Correct Retrieved: True\n",
            "Query: Welches Gesetz wurde Ende 2014 in Ohio im Zusammenhang mit der Todesstrafe beschlossen?, Correct Retrieved: True\n",
            "Query: Mit welcher anderen physikalischen Größe hängt die Zeit eng zusammen?, Correct Retrieved: True\n",
            "Query: An was orientierte sich der amerikanische Neoklassizismus?, Correct Retrieved: True\n",
            "Query: Welche Funktion hat der akademische Senat an einer Uni?, Correct Retrieved: True\n",
            "Query: Was ist das südliche Nachbarland von Eritrea?, Correct Retrieved: True\n",
            "Query: Wann wurde die Sternwarte Jantar Mantar in Neu-Delhi errichtet?, Correct Retrieved: True\n",
            "Query: Durch was ging die 3. Dynastie von Ur unter?, Correct Retrieved: True\n",
            "Query: Welcher Teil der Bibel entspricht der Tora?, Correct Retrieved: True\n",
            "Query: In welcher Beziehung stehen The Funk Brothers zu Motown?, Correct Retrieved: True\n",
            "Query: WElcher Behörde unterstand das US-Nationalarchiv bis in die 1980er?, Correct Retrieved: True\n",
            "Query: Welche Rassen gehören zu den urtümlichen Hunden?, Correct Retrieved: True\n",
            "Query: Was ist Ornithologie?, Correct Retrieved: True\n",
            "Query: Wo soll Abraham gelebt haben?, Correct Retrieved: True\n",
            "Query: Wieso verfügen Hunde über zwei verschiedene Arten von Speichel?, Correct Retrieved: True\n",
            "Query: Wer ist der Nachfolger von Pohamba als Präsident von Namibia?, Correct Retrieved: True\n",
            "Query: Welchen Auftrag gab die Ostindien-Kompanie William Kidd?, Correct Retrieved: True\n",
            "Query: Für wen war Kanye West zu Beginn seiner Karriere als Produzent tätig?, Correct Retrieved: True\n",
            "Query: Was gilt für Objekte, auf die ein physikalisches Gesetz im Bereich der Planck-Zeit wirkt?, Correct Retrieved: True\n",
            "Query: Wann entstand der Neoklassizismus in Deutschland?, Correct Retrieved: True\n",
            "Query: Welches war die Hauptstadt des Medri Bahri- Königreichs?, Correct Retrieved: True\n",
            "Query: Was ist die frühste Funktion von Säugetieren für den Menschen?, Correct Retrieved: True\n",
            "Query: Wie viele Soldaten der Unionstruppen starben im Sezessionskrieg?, Correct Retrieved: True\n",
            "Query: Welche Nachricht aus der Kolonie Südwest-Afrika verursachte im deutschen Kaiserreich einen Goldrausch?, Correct Retrieved: True\n",
            "Query: Was ist Primärtuberkulose?, Correct Retrieved: True\n",
            "Query: Durch was wird Tubrekulose ausgelöst?, Correct Retrieved: True\n",
            "Query: in welchen europäischen Ländern ist Guinea-Bissau diplomatisch mit einem Botschafter vertreten?, Correct Retrieved: True\n",
            "Query: Was war der Zweck der Einrichtung eines Nationalarchives in den USA?, Correct Retrieved: True\n",
            "Query: Wer verwendete die Bezeichnung Kubismus als erster?, Correct Retrieved: True\n",
            "Query: Welches sind die offiziellen Sprachen auf Zypern?, Correct Retrieved: True\n",
            "Query: Was ist die Hauptstadt der MArshallinseln?, Correct Retrieved: True\n",
            "Query: Als was werden Aufzüge mit eigenem Antrieb an der Kabine eingesetzt?, Correct Retrieved: True\n",
            "Query: Was war der Grund für den Absturz des B2-Tarnkappenbombers über Guam 2008?, Correct Retrieved: True\n",
            "Query: Wie wurden die griechischstämmigen Bewohner:innen Istanbuls im Osmanischen Reich genannt?, Correct Retrieved: True\n",
            "Query: Der wie vielte Gouverneur war Schwarzenegger in Kalifornien?, Correct Retrieved: True\n",
            "Query: Welche Funktion hatte Baron Robert Clive in den britischen Gebieten in Indien?, Correct Retrieved: True\n",
            "Query: Für was stehen die drei Raubkatzen im britischen Königswappen?, Correct Retrieved: True\n",
            "Query: Was sind die Gründe dafür, dass in der Schweiz viele Menschen ohne Schweizer Bürgerrecht leben?, Correct Retrieved: True\n",
            "Query: Was sind die häufigsten Verfahren, die vor Kirchlichen Gerichten verhandelt werden?, Correct Retrieved: True\n",
            "Query: Welche Selbstentladungszeitkonstante ist für Kondensatoren in Klasse 2 aus Keramik vorgeschrieben?, Correct Retrieved: True\n",
            "Query: An welchen Thoraxsegmenten befinden sich die Flügel bei Insekten?, Correct Retrieved: True\n",
            "Query: Welche Stoffe haben während der Embryonalentwicklung Einfluss auf die sexuelle Orientierung eines Menschen?, Correct Retrieved: True\n",
            "Query: Welches Gebiet Namibias wurde 1884 zur deutschen Kolonie ausgerufen?, Correct Retrieved: True\n",
            "Query: Wie lang sind die Endzonen beim American Football?, Correct Retrieved: True\n",
            "Query: An welchem Teil von Ringelwürmern befindet sich die Mundöffnung?, Correct Retrieved: True\n",
            "Query: Mit welchem Land hat Eritrea im Norden eine gemeinsame Grenze?, Correct Retrieved: True\n",
            "Query: Wie viele Inseln gehören zur Ralik-Kette der Marshallinseln?, Correct Retrieved: True\n",
            "Query: In welchen Städten in der Schweiz ist der Anteil an Ausländer:innen höher als der landesweite Durchschnitt?, Correct Retrieved: True\n",
            "Query: Wieso unterschied sich die Kriegsführung im Amerikanischen Bürgerkrieg von früheren Kriegen?, Correct Retrieved: True\n",
            "Query: Was ist der Hauptbereich der Wirtschaft in North Carolina?, Correct Retrieved: True\n",
            "Query: Welche bedrohten Tierarten sind in den Tropengebieten der Zentralafrikanischen Republik zu finden?, Correct Retrieved: True\n",
            "Query: Welcher Schauspieler wurde ebenfalls von Schwarzeneggers deutschem Synchronsprecher synchronisiert?, Correct Retrieved: True\n",
            "Query: Durch welche Technik wird der Stator eines Elektromotors im Gehäuse verbaut?, Correct Retrieved: True\n",
            "Query: Welche Größe brauchen die aktuellen Theorien in der Kosmologie?, Correct Retrieved: True\n",
            "Query: In welchem Bereich in aac besser als mp3?, Correct Retrieved: True\n",
            "Query: Wann brach Johann Ohneland mit seinem Heer nach Schottland auf?, Correct Retrieved: True\n",
            "Query: In welchem Jahr brachte Nintendo den R.O.B. auf den Markt?, Correct Retrieved: True\n",
            "Query: Warum wird Zeit über Messverfahren definiert?, Correct Retrieved: True\n",
            "Query: Von welchen landwirtschaftlichen Erzeugnissen lebt die Landwirtschaft in Palermo hauptsächlich?, Correct Retrieved: True\n",
            "Query: Wann entstand Paris?, Correct Retrieved: True\n",
            "Query: Welches Gebiet in Israel hat die geringste Bevölkerungsdichte?, Correct Retrieved: True\n",
            "Query: Welche Werke von Picasso wurden 1911 in der Ausstellung in der Galerie 291 in New York ausgestellt?, Correct Retrieved: True\n",
            "Query: Wie viel Aktienanteile am FC Arsenal besitzt Kroenke?, Correct Retrieved: True\n",
            "Query: Wieso wurde ab 1942 der Hawaii-Dollar eingeführt?, Correct Retrieved: True\n",
            "Query: In welchem Jahr besuchte Klaus Mann die University of Kansas?, Correct Retrieved: True\n",
            "Query: Wer war der Vorgänger von Schwarzenegger als Gouverneur?, Correct Retrieved: True\n",
            "Query: Wie viele Subunternehmen vereint die Arsenal Holdings plc?, Correct Retrieved: True\n",
            "Query: Welche Insel kontrollierte die britische Ostindien-Kompanie zeitweise?, Correct Retrieved: True\n",
            "Query: Auf welche Art von Flügen konzentriert sich der LaGuardia-Flughafen in New York?, Correct Retrieved: True\n",
            "Query: In welchem Jahr wurde das Nationalarchiv gegründet?, Correct Retrieved: True\n",
            "Query: An welchem Teil der Körpers befinden sich die Augen von Ringelwürmern?, Correct Retrieved: True\n",
            "Query: Was ist der aktuelle Status von Puerto Rico?, Correct Retrieved: True\n",
            "Query: Wie wird der Sixaxis-Conroller an die Playstation angeschlossen?, Correct Retrieved: True\n",
            "Query: Wer besetzte am 16. Oktober 1757 Berlin?, Correct Retrieved: True\n",
            "Query: Welches Uranisotop wird für Atomwaffen verwendet?, Correct Retrieved: True\n",
            "Query: Wie wird in der Loop-Quantengravitationstheorie die Raumzeit repräsentiert?, Correct Retrieved: True\n",
            "Query: Was sind die Haupteinflüsse der Musik in Alaska?, Correct Retrieved: True\n",
            "Query: Was forderte MacArthur als Reaktion auf die chinesische und nordkoreanische Offensive im Januar 1951? , Correct Retrieved: True\n",
            "Query: Welchem Bereich widmet sich das Museo Etnografico in Palermo?, Correct Retrieved: True\n",
            "Query: Wann wird die Zeit in Europa auf Winterzeit zurückgestellt?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen starben bei der Verteidigung von Petropawlowsk im Krimkrieg?, Correct Retrieved: True\n",
            "Query: Wie hoch ist das BIP von Portugal?, Correct Retrieved: True\n",
            "Query: Wieso sind haben Namibia und Deutschland ein besonderes bilaterales Verhältnis?, Correct Retrieved: True\n",
            "Query: Mit welchem Antrieb werden Zahnstangenaufzüge betrieben?, Correct Retrieved: True\n",
            "Query: Was kann den Verschleiß des seillosen Aufzuges minimieren?, Correct Retrieved: True\n",
            "Query: In welcher deutschen Stadt wird der seillose Aufzug getestet?, Correct Retrieved: True\n",
            "Query: Wo wurde ein seilloser Aufzug entwickelt?, Correct Retrieved: True\n",
            "Query: Wie funktioniert ein seilloser Aufzug?, Correct Retrieved: True\n",
            "Query: Wann muss man die Zieletage in seillosen Aufzügen auswählen? , Correct Retrieved: True\n",
            "Query: Was wird in Sichuan angebaut?, Correct Retrieved: True\n",
            "Query: Welches für den Export bestimmte Produkt wird in Sichuan produziert?, Correct Retrieved: True\n",
            "Query: Was wird in den Gebirgen von Sichuan gezüchtet?, Correct Retrieved: True\n",
            "Query: Welche tierische Produkte werden in Sichuan produziert?, Correct Retrieved: True\n",
            "Query: Was passiert, wenn die Polarisation einer Empfangs- und Sendeantenne nicht übereinstimmen?, Correct Retrieved: True\n",
            "Query: Was wird von Antennen abgestrahlt?, Correct Retrieved: True\n",
            "Query: Wie bewegt sich der elektrische Feldvektor einer Antenne?, Correct Retrieved: True\n",
            "Query: Was ist eine Wendelantenne?, Correct Retrieved: True\n",
            "Query: Was ist das Hauptziel von Softwaretest?, Correct Retrieved: False\n",
            "Query: Wozu tragen die Ergebnisse von Softwaretests bei?, Correct Retrieved: False\n",
            "Query: Warum konnte man die Tuberkulose bis zum 19. Jahrhundert von anderen ähnlichen Krankheiten nicht unterscheiden?, Correct Retrieved: True\n",
            "Query: Wer hat erfahren, dass die Tuberkulose nicht nur Lungen beschädigen kann, sondern auch andere Organe?, Correct Retrieved: True\n",
            "Query: Wie war die Tuberkulose im 19. Jahrhundert behandelt?, Correct Retrieved: True\n",
            "Query: Wann wurde das erste Tuberkulose- Sanatorium gegründet?, Correct Retrieved: True\n",
            "Query: Wie hat man am Ende des 19. Jahrhundert in Großbritannien versucht, die Tuberkulose zu bekämpfen?, Correct Retrieved: True\n",
            "Query: Was bedeutet die Pneumothorax-Technik bzw. Pneumolyse?, Correct Retrieved: True\n",
            "Query: Wer hat zuerst die Resektion der Lungenabschnitte bei Tuberkulose ausgeführt?, Correct Retrieved: True\n",
            "Query: Wer hat das Bakterium, das die Tuberkulose auslöst, zuerst beschrieben?, Correct Retrieved: True\n",
            "Query: Welchen Preis gewann Robert Koch für die Entdeckung des Erregers von Tuberkulose?, Correct Retrieved: True\n",
            "Query: Was führte zur Entwicklung des ersten Tuberkulose-Testes?, Correct Retrieved: True\n",
            "Query: Welche Diät kann bei der Behandlung der Hauttuberkulose helfen?, Correct Retrieved: True\n",
            "Query: Wo spielte der FC Barcelona bei dessen Gründung?, Correct Retrieved: True\n",
            "Query: Was war das erste Stadion des FC Barcelona?, Correct Retrieved: True\n",
            "Query: Wo fand das erste Spiel des FC Barcelona statt?, Correct Retrieved: True\n",
            "Query: Was war die erste Spielstätte des FC Barcelona?, Correct Retrieved: True\n",
            "Query: Wie viele Fans passten in das erste Stadion des FC Bareclona?, Correct Retrieved: True\n",
            "Query: Wie lange dauerte der Bau des Camp de Les Corts, Correct Retrieved: True\n",
            "Query: In welchem weiteren Museums Haus hat Frida Kahlo abgesehen Vom Museo Frida Kahlo gewohnt?, Correct Retrieved: True\n",
            "Query: Wo in Mexiko-Stadt ist das Museo Frida Kahlo?, Correct Retrieved: True\n",
            "Query: Welche Farbe hat das Museo Frida Kahlo?, Correct Retrieved: True\n",
            "Query: In welchem Stil ist das Museo Frida Kahlo gebaut?, Correct Retrieved: True\n",
            "Query: Mit wem war Frida Kahlo verheiratet?, Correct Retrieved: True\n",
            "Query: Was waren die Hauptprobleme der Aggregat-4 Rakete?, Correct Retrieved: True\n",
            "Query: Was waren die Hauptmotive für den Wettlauf ins All?, Correct Retrieved: True\n",
            "Query: Wer ist der größte Rosinen Exporteur der Welt?, Correct Retrieved: True\n",
            "Query: Welches Land ist der größte Safran Exporteur?, Correct Retrieved: True\n",
            "Query: Wie viel Prozent des Irans werden für die Landwirtschaft benutzt?, Correct Retrieved: True\n",
            "Query: Was tauschen Bakterien mit Sexpili untereinander aus?, Correct Retrieved: True\n",
            "Query: Wie können Bakterien auch ohne Sexpili DNA untereinander austauschen?, Correct Retrieved: True\n",
            "Query: Wie viele schwarze Menschen leben in Frankreich?, Correct Retrieved: True\n",
            "Query: Woher kommen die meisten Schwarzen Frankreichs?, Correct Retrieved: True\n",
            "Query: Warum gab es in der französischen Regierung oft schwarze Minister?, Correct Retrieved: True\n",
            "Query: Wo leben die meisten schwarzen in Frankreich?, Correct Retrieved: True\n",
            "Query: Warum sind Schwarze aus Überseegebieten in Frankreich tendenziell besser integriert als Schwarze aus Schwarzafrika?, Correct Retrieved: True\n",
            "Query: Wie viele Schwarze waren in der Fußballnationalmannschaft Frankreichs bei der WM 2006?, Correct Retrieved: True\n",
            "Query: Wer wurde 2005 als schwarze Frau Ministerin in Frankreich?, Correct Retrieved: True\n",
            "Query: Was ist die beste Schweizer Fußball Liga?, Correct Retrieved: True\n",
            "Query: Was ist der größte Leichtathletik Verein der Schweiz?, Correct Retrieved: True\n",
            "Query: In welcher Eritreischen Stadt Produziert Tesinma Busse?, Correct Retrieved: True\n",
            "Query: Welche Voraussetzung muss der Staatspräsident von Zypern erfüllen?, Correct Retrieved: True\n",
            "Query: Wer ist das Staatsoberhaupt von Zypern?, Correct Retrieved: True\n",
            "Query: Wie lange ist die Amtsperiode des zypriotischen Staatspräsidenten?, Correct Retrieved: False\n",
            "Query: Seit wann die ist das Amt des stellvertretenden Staatspräsidenten unbesetzt?, Correct Retrieved: False\n",
            "Query: Als was bezeichnete der Demokratieindex Zypern 2019?, Correct Retrieved: True\n",
            "Query: Wie heißt die große kommunistische Partei in Zypern?, Correct Retrieved: True\n",
            "Query: Wie viele Sitze gibt es im Parlament von zypern?, Correct Retrieved: True\n",
            "Query: In welchen Ländern gibt es die Sommerzeit?, Correct Retrieved: True\n",
            "Query: In welcher Jahreszeit wird auf die Sommerzeit umgestellt?, Correct Retrieved: True\n",
            "Query: Wann beginnt die Sommerzeit?, Correct Retrieved: True\n",
            "Query: Woher kommt der Begriff Pestizid?, Correct Retrieved: True\n",
            "Query: Von welchem Land ist die Kultur der Tristan da Cunha Inseln stark beeinflusst?, Correct Retrieved: True\n",
            "Query: Wie viel Alkohol trinken die Bewohner der Inseln Tristan da Cunhas?, Correct Retrieved: True\n",
            "Query: Wie viele polnische Spielfilme über Chopin gibt es?, Correct Retrieved: True\n",
            "Query: Was sind die wichtigsten Abschnitt Maßeinheits Größen des Korans?, Correct Retrieved: True\n",
            "Query: Wofür ist die Einteilung des Korans in den Dschuz besonders praktisch?, Correct Retrieved: True\n",
            "Query: Wofür wird die Einteilung des Korans in 30 Teile beim Ramadan benutzt?, Correct Retrieved: True\n",
            "Query: An was erkennt man die einzelnen Unterteilungen des Korans?, Correct Retrieved: True\n",
            "Query: Was wird für die MP3 Kompression benutzt?, Correct Retrieved: True\n",
            "Query: Welches Verfahren zur Daten Kompression von Musik an Computern wird am häufigsten benutzt?, Correct Retrieved: True\n",
            "Query: Wo wurde das MP3 Verfahren entwickelt?, Correct Retrieved: True\n",
            "Query: Wann liefen die letzten Patente für das MP3 Format aus?, Correct Retrieved: True\n",
            "Query: Welches Land hatte die größte freiwillige Armee im zweiten Weltkrieg?, Correct Retrieved: True\n",
            "Query: Wo wurde die indische Armee am Anfang des zweiten Weltkriegs eingesetzt?, Correct Retrieved: True\n",
            "Query: Wer gründete die Indische Legion in Europa?, Correct Retrieved: True\n",
            "Query: Wo hat Subhash Chandra Bose die Indische Nationale Armee gegründet?, Correct Retrieved: True\n",
            "Query: Wie viele Soldaten in Indien wurden während des Zweiten Weltkriegs getötet?, Correct Retrieved: True\n",
            "Query: Warum wollte Indien in den zweiten Weltkrieg eintreten?, Correct Retrieved: True\n",
            "Query: Wie viel Mann hatte die indische Armee zu Beginn des zweiten Weltkrieges?, Correct Retrieved: True\n",
            "Query: Was kann die Lebensdauer einer Glühbirne verlängern?, Correct Retrieved: True\n",
            "Query: Welche Lampen sind schwierig zu wechseln?, Correct Retrieved: True\n",
            "Query: Wie kann die USA einen neuen Bundesstaat aufnehmen? , Correct Retrieved: False\n",
            "Query: Warum ist öffentliche Verkehrsmittel so beliebt in New York?, Correct Retrieved: True\n",
            "Query: In welche Teile ist das Straßennetz in Manhattan unterteilt?, Correct Retrieved: True\n",
            "Query: Welches Transportmittel benutzen die meisten Einwohner in New York?, Correct Retrieved: True\n",
            "Query: Welches Transportmittel ist typisch für New York?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen leben im südlichen Teil von Zypern?, Correct Retrieved: True\n",
            "Query: Wie hoch ist der Migrantenanteil in Zypern?, Correct Retrieved: True\n",
            "Query: Wie viele Deutschen wohnen in Südzypern?, Correct Retrieved: False\n",
            "Query: Aus welchen Ländern kommen die meisten Migranten in Zypern?, Correct Retrieved: True\n",
            "Query: Wie hängen Frequenz und Kapazität bei Kondensatoren zusammen?, Correct Retrieved: True\n",
            "Query: Wo wird ein Kondensator vorwiegend induktiv wirksam?, Correct Retrieved: True\n",
            "Query: Als was wirkt der Kondensator bei höheren Frequenzen?, Correct Retrieved: True\n",
            "Query: Welche Kondensatoren werden für Frequenzen um 100 MHz eingesetzt?, Correct Retrieved: True\n",
            "Query: Für welchen Frequenzbereich sind Aluminium-Elektrolytkondensatoren wirksam?, Correct Retrieved: True\n",
            "Query: Wieso werden verschiedene Arten von Kondensatoren kombiniert?, Correct Retrieved: True\n",
            "Query: Was ist der Fachbegriff für die Gleichgewichtslinie beim Gletscher?, Correct Retrieved: True\n",
            "Query: Was wird als Gleichgewichtslinie eines Gletschers bezeichnet?, Correct Retrieved: True\n",
            "Query: Wie ist das Zehrgebiet des Gletschers definiert?, Correct Retrieved: True\n",
            "Query: Wie heißt der Bereich oberhalb der Gleichgewichtslinie des Gletschers?, Correct Retrieved: True\n",
            "Query: Wie heißt der Bereich unterhalb der Gleichgewichtslinie des Gletschers?, Correct Retrieved: True\n",
            "Query: Wie ist das Akkumulationsgebiet des Gletschers definiert?, Correct Retrieved: True\n",
            "Query: In welchem Edikt wurde im osmanischen Reich die Gleichheit aller Bürger formal festgeschrieben?, Correct Retrieved: True\n",
            "Query: Wann wurde das Edikt von Gülhane erlassen?, Correct Retrieved: True\n",
            "Query: Wann wurde der Hatt-i Hümayun erlassen?, Correct Retrieved: True\n",
            "Query: Wann wurde die griechische Bevölkerung aus dem Osmanischen Reich vertrieben?, Correct Retrieved: True\n",
            "Query: Welches Gesetz war Grundlage für den Genozid an den Armeniern im Osmanischen Reich?, Correct Retrieved: True\n",
            "Query: Welche Volksgruppe wurde 1915 im Osmanischen Reich Opfer eines Völkermordes?, Correct Retrieved: True\n",
            "Query: Welche Gruppe mit nationalistischen Ideen erlangte in der Endphase des Osmanischen Reichs die Macht?, Correct Retrieved: True\n",
            "Query: Wie viele Kasus gibt es im Tschechischen?, Correct Retrieved: True\n",
            "Query: Wie viele grammatische Geschlechter gibt es im Tschechischen?, Correct Retrieved: True\n",
            "Query: Welche Genera gibt es im Tschechischen?, Correct Retrieved: True\n",
            "Query: Zwischen was wird im Tschechischen beim männlichen Genus unterschieden?, Correct Retrieved: True\n",
            "Query: Welche Artikel gibt es im Tschechischen?, Correct Retrieved: True\n",
            "Query: Wozu dient die Kurzform von Adjektiven im Tschechischen?, Correct Retrieved: True\n",
            "Query: Wann wurde ASCII eingeführt?, Correct Retrieved: True\n",
            "Query: Wie viele Zeichen umfasst ASCII?, Correct Retrieved: True\n",
            "Query: Welche Buchstaben umfasst ASCII?, Correct Retrieved: True\n",
            "Query: Wie viele Steuerzeichen gibt es im ASCII-Code?, Correct Retrieved: True\n",
            "Query: Für wie viel Geld wurde Neymar zu Paris Saint Germain transferiert?, Correct Retrieved: True\n",
            "Query: In welcher Mannschaft spielte Ousman Dembélé, bevor er zu FC Barcelona gekommen ist?, Correct Retrieved: True\n",
            "Query: Welche Art von Kondensatoren wurden mit \"cm\" gemessen?, Correct Retrieved: True\n",
            "Query: In welchem Jahr wurde die US-Army aufgestellt?, Correct Retrieved: True\n",
            "Query: Was sind die Aufgaben der US-Army?, Correct Retrieved: True\n",
            "Query: Welche Armeen der Welt haben mehr Mann als die US-Army?, Correct Retrieved: True\n",
            "Query: In welchem Teil von China liegt Zhejiang?, Correct Retrieved: True\n",
            "Query: Woran grenzt Zhejiang im Norden?, Correct Retrieved: True\n",
            "Query: Woran grenzt Zhejiang im Osten?, Correct Retrieved: True\n",
            "Query: Was liegt südlich von Zhejiang?, Correct Retrieved: True\n",
            "Query: In welche Zonen wird Zhejiang gegliedert?, Correct Retrieved: True\n",
            "Query: Wie viel Prozent der Fläche von Zhejiang bilden Gebirge?, Correct Retrieved: True\n",
            "Query: Wie viele Bergketen hat Zhejiang?, Correct Retrieved: True\n",
            "Query: Wie hoch ist der höchste Punkt in Zhejiang?, Correct Retrieved: True\n",
            "Query: Was ist der höchste Punkt in Zhejiang?, Correct Retrieved: True\n",
            "Query: Welche Flüsse verlaufen in Zhejiang?, Correct Retrieved: True\n",
            "Query: Welche natürliche Seen gibt es in Zhejiang?, Correct Retrieved: True\n",
            "Query: Wie viele Inseln gibt es in Zhejiang?, Correct Retrieved: True\n",
            "Query: Wie sieht die molekulare Struktur von Eis aus?, Correct Retrieved: True\n",
            "Query: In welchem Fall bewegt sich die obere Gletscherschicht schneller als die darunterliegende?, Correct Retrieved: True\n",
            "Query: Warum ist die Fließgeschwindigkeit verschiedener Teile eines Gletschers nicht gleichmäßig?, Correct Retrieved: True\n",
            "Query: In welchem Bundesstaat liegt Houston?, Correct Retrieved: True\n",
            "Query: Wo liegt Houston?, Correct Retrieved: True\n",
            "Query: Wie viel der Fläche von Houston besteht aus Wasser?, Correct Retrieved: True\n",
            "Query: In welchem County liegt Houston?, Correct Retrieved: True\n",
            "Query: Wie heißt der Schifffahrtskanal in Houston?, Correct Retrieved: True\n",
            "Query: Wie heißt der Fluss, der durch Houston fließt?, Correct Retrieved: True\n",
            "Query: Wo mündet der Buffalo Bayou?, Correct Retrieved: True\n",
            "Query: Wie heißt die Methode des Regenwassersammelns in Rajasthan?, Correct Retrieved: True\n",
            "Query: Was versteht man unter dem \"Johad\"?, Correct Retrieved: True\n",
            "Query: Welches Ergebnis hat der Bau von Johads in Rajasthan?, Correct Retrieved: True\n",
            "Query: Was versuchen die Umweltorganisationen wie CSE in Indien zu verbessern?, Correct Retrieved: True\n",
            "Query: Seit wann gibt es eine quelloffene Variante von Poseidon für AROS?, Correct Retrieved: True\n",
            "Query: Ist USB mit Atari MINT benutzbar?, Correct Retrieved: True\n",
            "Query: Welche USB-Versionen unterstützt Windows 10?, Correct Retrieved: True\n",
            "Query: Kann man USB-Anschlüsse mit DOS benutzen?, Correct Retrieved: True\n",
            "Query: Wann fand die Premier League erstmals statt?, Correct Retrieved: True\n",
            "Query: Wie viele Vereine spielten beim ersten Turnier der Premier League teil?, Correct Retrieved: True\n",
            "Query: Welcher Verein erzielte das erste Tor in der Premier League?, Correct Retrieved: True\n",
            "Query: Seit wann spielten in der Premier League nur noch 20 Vereine?, Correct Retrieved: True\n",
            "Query: Was forderte die FIFA in Bezug auf die Anzahl der Vereine in der Premier League?, Correct Retrieved: True\n",
            "Query: Welcher war der erste nicht-englische Verein in der Premier League?, Correct Retrieved: True\n",
            "Query: Wie hieß die Premier League vor 2007 offiziell?, Correct Retrieved: True\n",
            "Query: Welches Audioformat wird beim HDTV hauptsächlich verwendet?, Correct Retrieved: True\n",
            "Query: Welche Filme verfügen bei HDTV nicht über Mehrkanalton?, Correct Retrieved: True\n",
            "Query: Wie schwer ist ein Schlachtreifer Strauß?, Correct Retrieved: True\n",
            "Query: Welchem anderen Fleisch ist das Straußenfleisch ähnlich?, Correct Retrieved: True\n",
            "Query: Wer benutzt den deutschen Fußballjargon hauptsächlich?, Correct Retrieved: True\n",
            "Query: Welche Art von Sprache ist der Fußballjargon?, Correct Retrieved: True\n",
            "Query: Was ist das \"Sommermärchen\", Correct Retrieved: True\n",
            "Query: Welche Länder nutzen den Begriff Soccer?, Correct Retrieved: True\n",
            "Query: Wie viele Touristen schlafen jährlich in Bern?, Correct Retrieved: True\n",
            "Query: Wie viele Touristen in Bern kommen aus dem Ausland?, Correct Retrieved: True\n",
            "Query: Woher kommen die meisten ausländischen Touristen Berns?, Correct Retrieved: False\n",
            "Query: Wann kommen die meisten Touristen nach Bern?, Correct Retrieved: True\n",
            "Query: Wer bewertete die Leistung von England im ersten Weltkrieg?, Correct Retrieved: True\n",
            "Query: Wer war 1921 britischer Premierminister?, Correct Retrieved: False\n",
            "Query: Seit wann hat England einen Generalstab?, Correct Retrieved: True\n",
            "Query: Warum hat Lord Chatfield als \"Minister for Coordination of Defence\" keinen Erfolg?, Correct Retrieved: True\n",
            "Query: Wer führte in England das Amt des Verteidigungsministers ein?, Correct Retrieved: True\n",
            "Query: Welche britischen Ministerien wurden zum heutigen Verteidigungsministerium zusammengefasst?, Correct Retrieved: True\n",
            "Query: In welcher Klimazone liegt Oklahoma City?, Correct Retrieved: True\n",
            "Query: Wann war der heißeste Tag in Oklahoma City?, Correct Retrieved: True\n",
            "Query: In welchem Monat regnet es in Oklahoma City im Schnitt am meisten?, Correct Retrieved: True\n",
            "Query: Was war die kälteste gemessene Temperatur in Oklahoma City?, Correct Retrieved: True\n",
            "Query: Wie oft treten in Oklahoma City Tornados auf?, Correct Retrieved: True\n",
            "Query: Seit wann ist Zypern EU-Mitglied?, Correct Retrieved: True\n",
            "Query: Welches Land erkennt Zypern nicht offiziell an?, Correct Retrieved: True\n",
            "Query: Seit wann gibt es den Euro in Zypern?, Correct Retrieved: True\n",
            "Query: Welche Maßnahmen unternimmt die Türkei gegen Zypern?, Correct Retrieved: True\n",
            "Query: Wann war Zypern kurz vor dem Staatsbankrott?, Correct Retrieved: True\n",
            "Query: Wie viel Geld bekam Zypern von der EU um ein Staatsbankrott zu verhindern?, Correct Retrieved: True\n",
            "Query: Wie wurde der Zusammenschluss mehrerer Sippen bei den Slawen genannt?, Correct Retrieved: True\n",
            "Query: Wie war das Zusammenleben in der lokalen Gemeinschaft bei den Slawen organisiert?, Correct Retrieved: False\n",
            "Query: Welchen Stellenwert hatte die Ehe bei den Slawen?, Correct Retrieved: True\n",
            "Query: Wo würde das frühere Baktrien heutzutage liegen?, Correct Retrieved: True\n",
            "Query: Wo herrschten die Shunga um 100 v. Chr.?, Correct Retrieved: True\n",
            "Query: Welche Religion favorisierten die Shunga um 100  v. Chr.?, Correct Retrieved: True\n",
            "Query: Wer darf wie viele Vertreter in den Inselrat von St. Helena schicken?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen leben in Eritrea?, Correct Retrieved: True\n",
            "Query: Warum ist in Eritrea ein starkes Bevölkerungswachstum zu beobachten?, Correct Retrieved: True\n",
            "Query: Wie soll nach Einschätzungen die Bevölkerung in Eritrea bis 2050 anwachsen?, Correct Retrieved: True\n",
            "Query: Wie viele Tonnen Bomben wurden von den USA während des Koreakrieges abgeworfen?, Correct Retrieved: True\n",
            "Query: Seit wann hat in Griechenland das Fernsehen nicht mehr die meisten Werbeeinnahmen? , Correct Retrieved: True\n",
            "Query: Wie ist die Pressefreiheit in Griechenland im Vergleich zu anderen Ländern?, Correct Retrieved: True\n",
            "Query: Was ist ein Güteraufzug?, Correct Retrieved: True\n",
            "Query: Warum dürfen die Güteraufzüge nur von außen bedient werden?, Correct Retrieved: True\n",
            "Query: Was ist eine Sonderform von Güteraufzügen?, Correct Retrieved: False\n",
            "Query: Wozu werden Kleinlastenaufzüge genutzt?, Correct Retrieved: True\n",
            "Query: Wofür werden Möbellifte benutzt?, Correct Retrieved: True\n",
            "Query: Wie heißen die vier Konservatorien in London?, Correct Retrieved: True\n",
            "Query: Wann starb der Mann von Queen Victoria?, Correct Retrieved: True\n",
            "Query: Wie viele Kinder hatte Queen Victoria?, Correct Retrieved: True\n",
            "Query: Welche Krankheit wurde vor seinem Tod bei Queen Victorias Ehemann festgestellt?, Correct Retrieved: True\n",
            "Query: Welche Krankheiten werden heutzutage als Ursache für den Tod von Queen Victorias Mann vermutet?, Correct Retrieved: True\n",
            "Query: Wann starb die Mutter von Queen Victoria?, Correct Retrieved: True\n",
            "Query: Was war die schwierigste Krise in Queen Victorias Privatleben?, Correct Retrieved: True\n",
            "Query: Mit wem hatte der älteste Sohn von Queen Victoria eine Affäre in der Zeit, als sein Vater starb?, Correct Retrieved: True\n",
            "Query: Wieso reiste Queen Victorias Mann kurz vor seinem Tod nach Cambridge?, Correct Retrieved: True\n",
            "Query: Welche Kleidung pflegte Queen Victoria nach dem Tod ihres Mannes zu tragen?, Correct Retrieved: True\n",
            "Query: Wo wurde Queen Victorias Mann beerdigt?, Correct Retrieved: False\n",
            "Query: Als was bezeichnete Queen Victoria die Krone in ihrer Witwenzeit?, Correct Retrieved: True\n",
            "Query: Wieso nahm Queen Victorias Beliebtheit unter der Bevölkerung ab?, Correct Retrieved: False\n",
            "Query: Was ist das Besondere an niederländischen Schimpfwörtern?, Correct Retrieved: True\n",
            "Query: Mit welcher Erweiterung werden auf Krankheiten basierende Schimpfwörter im Niederländischen häufig verwendet?, Correct Retrieved: True\n",
            "Query: Welche Themenfelder werden im Niederländischen vor allem für Schimpfwörter benutzt?, Correct Retrieved: True\n",
            "Query: Durch was wird das Hochskalieren bei neueren HDTV-Auflösungen begünstigt?, Correct Retrieved: True\n",
            "Query: Wo wurde der Prototyp von HDTV mit vierfacher Pixelzahl präsentiert?, Correct Retrieved: True\n",
            "Query: Wo soll HDTV mit vierfacher Pixelzahl eingesetzt werden?, Correct Retrieved: True\n",
            "Query: Welche Auswirkungen kann USB 3.0 auf Bluetooth haben?, Correct Retrieved: True\n",
            "Query: Welche Linux-Versionen erlauben USB 3.0?, Correct Retrieved: True\n",
            "Query: Sind USB 3.0.Stecker mit älteren Typen kompatibel?, Correct Retrieved: True\n",
            "Query: Wann wurde USB 3.0 präsentiert?, Correct Retrieved: True\n",
            "Query: Welche großen Firmen gehören zum USB Implementers Forum?, Correct Retrieved: True\n",
            "Query: Was ist die Übertragungsrate von USB 3.0?, Correct Retrieved: True\n",
            "Query: Welcher USB-Typ hat blaue Stecker?, Correct Retrieved: True\n",
            "Query: Wann wurde in England erstmals eine Sperrstunde eingeführt?, Correct Retrieved: True\n",
            "Query: Wieso wurde 1915 in Großbritannien eine Sperrstunde eingeführt?, Correct Retrieved: True\n",
            "Query: Ab wann war in englischen Pubs nach 1915 Sperrstunde?, Correct Retrieved: True\n",
            "Query: wie wird die Forderung nach der Wiedereinführung der Sperrstunde in ENgland begründet?, Correct Retrieved: True\n",
            "Query: Mit was wird in englischen Pubs zur letzten Runde aufgerufen?, Correct Retrieved: True\n",
            "Query: Wer war zur Zeit von Queen Victorias diamantenem Thronjubiläum Premierminister?, Correct Retrieved: True\n",
            "Query: Welche Position hatte Joseph Chamberlain unter Queen Victoria 1897?, Correct Retrieved: True\n",
            "Query: Als was sollte das 60. Thronjubiläum von Queen Victoria gefeiert nach Vorschlag von Lord Salisbury werden ?, Correct Retrieved: True\n",
            "Query: Wie alt war Queen Victoria an ihrem 60. Thronjubiläum?, Correct Retrieved: True\n",
            "Query: An welcher Krankheit litt Queen Victoria zur Zeit ihres 60. Regierunsjubiläums?, Correct Retrieved: True\n",
            "Query: An welchem Tag wurden die Feierlichkeiten anlässlich von Queen Victorias 60. Thronjubiläum in London durchgeführt?, Correct Retrieved: True\n",
            "Query: Wann war der Burenkrieg in Südafrika?, Correct Retrieved: False\n",
            "Query: Wie wurde Queen Victorias ältester Sohn genannt?, Correct Retrieved: True\n",
            "Query: Wann hatte Queen Victoria ihr 60. Thronjubiläum?, Correct Retrieved: True\n",
            "Query: Was ist der \"Trail of Tears\"?, Correct Retrieved: True\n",
            "Query: Was verbot die Regierung 1880 in Oklahoma zum Schutz der indianischen Bevölkerung?, Correct Retrieved: True\n",
            "Query: Wovon profitierte die Wirtschaft in Oklahoma Anfang des 20. Jhd?, Correct Retrieved: True\n",
            "Query: Wer wird als \"Vater der Route 66\" bezeichnet?, Correct Retrieved: True\n",
            "Query: Wann trat Oklahoma offiziell den Vereinigten Staaten bei?, Correct Retrieved: True\n",
            "Query: Als was wurde Oklahoma Ende des 19. Jahrhunderts  bezeichnet?, Correct Retrieved: True\n",
            "Query: Wie heißt die große Besiedlungswelle in Oklahoma Ende des 19. Jahrhunderts?, Correct Retrieved: True\n",
            "Query: Welches Gebäude in Oklahoma wurde 1995 durch einen Bombenanschlag zerstört?, Correct Retrieved: True\n",
            "Query: Welches Verbot galt in Oklahoma bis 1967?, Correct Retrieved: True\n",
            "Query: Was strebte die indianische Bevölkerung in Oklahoma Anfang des 20. Jhd. an?, Correct Retrieved: True\n",
            "Query: Was brachte Oklahoma den Namen \"Dust Bowl\" ein?, Correct Retrieved: True\n",
            "Query: Wer repräsentiert die Großregion Melbourne?, Correct Retrieved: True\n",
            "Query: Liegt Bildung im Aufgabenbereich der Verwaltungsbezirke von Melbourne oder beim Bundesstaat?, Correct Retrieved: True\n",
            "Query: In welchem Bundesstaat liegt Melbourne?, Correct Retrieved: True\n",
            "Query: Für welche Regionen ist dsa deutsche Generalkonsulat in Melbourne zuständig?, Correct Retrieved: True\n",
            "Query: In was ist die Metropolregion im Melbourne gegliedert?, Correct Retrieved: True\n",
            "Query: Wann war der Terroranschlag, der das World Trade Center zerstörte?, Correct Retrieved: True\n",
            "Query: Wann wurde der Bombenanschlag in der Tiefgarage des WTC verübt?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen starben bei dem Anschlag 1993 auf das World Trade Center?, Correct Retrieved: True\n",
            "Query: Was ist der Ground Zero?, Correct Retrieved: True\n",
            "Query: Was ist das höchste Gebäude in den USA?, Correct Retrieved: True\n",
            "Query: Wann wurde das One World Trade Center fertiggestellt?, Correct Retrieved: True\n",
            "Query: Wo fand der Parteitag der Repubilkaner 2004 statt?, Correct Retrieved: True\n",
            "Query: Wer entwarf die Gedenkstätte für die Opfer des 11. September?, Correct Retrieved: True\n",
            "Query: Wie ist das Memorial am Ground Zero gestaltet?, Correct Retrieved: True\n",
            "Query: Wann traf Hurrikan Sandy New York?, Correct Retrieved: True\n",
            "Query: Wann war die Börse in New York vor 2012 das letzte Mal wegen Unwetter geschlossen worden?, Correct Retrieved: True\n",
            "Query: Weswegen war die New York Stock Exchange 1888 geschlossen?, Correct Retrieved: True\n",
            "Query: Zu welcher Literauturströmung gehört Novalis?, Correct Retrieved: False\n",
            "Query: Wann fand der Wiener Kongress statt?, Correct Retrieved: True\n",
            "Query: Wo wurde die Sozialdemokratische Arbeiterpartei gegründet?, Correct Retrieved: True\n",
            "Query: Was war ein Spitzname für Herzog Ernst II. von Sachsen-Coburg?, Correct Retrieved: True\n",
            "Query: Wie hieß der Vorgänger von Hertie?, Correct Retrieved: True\n",
            "Query: Aus welchen Gruppierungen entstand die SPD?, Correct Retrieved: False\n",
            "Query: Welches politische Konzept wurde um 1850 in den deutschen Fürstentümern diskutiert?, Correct Retrieved: True\n",
            "Query: Wer verhinderte, dass Sachsen-Meiningen nach dem Krieg von 1866 von Preußen annektiert wurde?, Correct Retrieved: True\n",
            "Query: Wieso forderte Bismarck die Annexion von Sachsen-Meiningen und Reuß nach dem Krieg von 1866?, Correct Retrieved: True\n",
            "Query: Wer lud zum sogenannten Wartburgfest ein?, Correct Retrieved: False\n",
            "Query: Wer prägte die Weimarer Klassik?, Correct Retrieved: True\n",
            "Query: Ab wann gab es die erste Zugstrecke in Thüringen?, Correct Retrieved: True\n",
            "Query: Für welchen Industriezweig ist Jena bekannt?, Correct Retrieved: True\n",
            "Query: Wer gründete den ersten Kindergarten in Deutschland?, Correct Retrieved: True\n",
            "Query: Als was wird das Wiederaufleben des kulturellen Lebens in Weimar im 19. Jhd bezeichnet?, Correct Retrieved: True\n",
            "Query: Wen schlug Napoleon 1806 auf dem Gebiet des heutigen Thüringen?, Correct Retrieved: True\n",
            "Query: Welches Nachschlagewerk gibt das Bibliographische Institut heraus?, Correct Retrieved: True\n",
            "Query: In welchen Disziplinen spielt der Begriff Emotion eine Rolle?, Correct Retrieved: True\n",
            "Query: Wie ist der zeitliche Verlauf von Emotionen verglichen mit Stimmungen?, Correct Retrieved: True\n",
            "Query: Sind Emotionen oder Stimmungen eher durch einen bestimmten Reiz ausgelöst?, Correct Retrieved: True\n",
            "Query: Was unterscheidet Emotionen von Gefühlen?, Correct Retrieved: True\n",
            "Query: Mit was beschäftigt sich die Neurowissenschaft in Bezug auf Emotionen?, Correct Retrieved: True\n",
            "Query: Zu welcher Art von Metall gehört Kupfer?, Correct Retrieved: True\n",
            "Query: Ist Kupfer gesundheitsschädlich?, Correct Retrieved: True\n",
            "Query: Wie wird die antibakterielle Wirkung von Kupfer bezeichnet?, Correct Retrieved: True\n",
            "Query: Wann wirkt Kupfer antibakteriell?, Correct Retrieved: True\n",
            "Query: Gilt Leinenpflicht für Hunde deutschlandweit, Correct Retrieved: False\n",
            "Query: Müssen Hunde gegen Tollwut geimpft werden?, Correct Retrieved: True\n",
            "Query: Wo kann man Rettungshundeprüfungen machen?, Correct Retrieved: True\n",
            "Query: Wo muss man Hundehaufen entfernen?, Correct Retrieved: False\n",
            "Query: Welche öffentlichen Radiosender gibt es in der Schweiz auf deutsch?, Correct Retrieved: True\n",
            "Query: Wie wird das staatliche Radio in der Schweiz finanziert?, Correct Retrieved: True\n",
            "Query: Seit wann gibt es in der Schweiz private Radiostationen?, Correct Retrieved: True\n",
            "Query: Was ist die UNIKOM in der Schweiz?, Correct Retrieved: False\n",
            "Query: Auf welcher Frequenz senden die Radiosender in der Schweiz?, Correct Retrieved: False\n",
            "Query: Was ist Preisniveaustabilität?, Correct Retrieved: True\n",
            "Query: Welche Inflationsrate will die EZB erreichen?, Correct Retrieved: True\n",
            "Query: Für welchen Anschlag beschuldigte Reagan Gaddafi?, Correct Retrieved: True\n",
            "Query: Wie viele Personen starben beim Lockerbie-Anschlag?, Correct Retrieved: True\n",
            "Query: Wie viel Entschädigung wurde von Libyen für den Lockerbie-Anschlag gezahlt?, Correct Retrieved: True\n",
            "Query: Wie unterstütze Gaddafi die IRA?, Correct Retrieved: True\n",
            "Query: Warum unterstütze al-Gaddafi die IRA?, Correct Retrieved: True\n",
            "Query: Welches Land soll am La Belle-Anschlag auch beteiligt gewesen sein?, Correct Retrieved: True\n",
            "Query: Wieso soll Libyen anstelle von Iran und Syrien für den Lockerbie-Anschlag verantwortlich gemacht worden sein?, Correct Retrieved: True\n",
            "Query: Von wo hatte die Abu Nidal-Gruppe hauptsächlich operiert?, Correct Retrieved: True\n",
            "Query: Was sind Verbrechen gegen die Menschlichkeit?, Correct Retrieved: True\n",
            "Query: Was sind Kriegsverbrechen?, Correct Retrieved: True\n",
            "Query: Wie heißt der Völkermord an den Juden durch die Nationalsozialisten?, Correct Retrieved: True\n",
            "Query: In welchem Abkommen werden Regeln zu Verbrechen während eines Krieges oder Konflikts festgelegt?, Correct Retrieved: True\n",
            "Query: Was ist emotionale Intelligenz?, Correct Retrieved: True\n",
            "Query: Welche Theorie liegt der emotionale Intelligenz zugrunde?, Correct Retrieved: True\n",
            "Query: Wer hat die Theorie der mutliplen Intelligenzen aufgestellt?, Correct Retrieved: True\n",
            "Query: Welche Komponenten haben Emotionen?, Correct Retrieved: True\n",
            "Query: Wo hatten die meisten Stücke von Max Frisch ihre Uraufführung?, Correct Retrieved: True\n",
            "Query: Welche Auszeichnung erhielt das Schauspielhaus Zürich 2002 und 2003?, Correct Retrieved: True\n",
            "Query: Wann wurde das Schauspielhaus Zürich von \"Theater heute\" zum Theater des Jahres gewählt?, Correct Retrieved: True\n",
            "Query: Wann wurde das Opernhaus in Zürich eröffnet?, Correct Retrieved: True\n",
            "Query: Welche Art von Stücken wird im Opernhaus Zürich gespielt?, Correct Retrieved: True\n",
            "Query: In welcher Kultureinrichtung in der Schweiz ist der Dadaismus entstanden?, Correct Retrieved: True\n",
            "Query: Was ist der Hans-Reinhart-Ring?, Correct Retrieved: True\n",
            "Query: Welches Tier ist im Wappen von Bern zu sehen?, Correct Retrieved: True\n",
            "Query: Wie weit zurück reichen Belege für einen Bär im Wappen von Bern?, Correct Retrieved: True\n",
            "Query: Wie sah das erste Wappen von Bern aus?, Correct Retrieved: True\n",
            "Query: Welche Stadt trägt das gleiche Wappen wie Bern in der Schweiz?, Correct Retrieved: True\n",
            "Query: Wie unterscheiden sich die Wappen von Bern und New Bern?, Correct Retrieved: True\n",
            "Query: Was ist die Stadtmarke von Bern?, Correct Retrieved: True\n",
            "Query: Wann wurden Bern und der umliegende Kanton getrennt?, Correct Retrieved: True\n",
            "Query: Wer benutzte den Begriff Energie zuerst in seiner naturwissenschaftlichen Bedeutung?, Correct Retrieved: True\n",
            "Query: Seit wann wird Energie als Begriff in der Physik benutzt?, Correct Retrieved: True\n",
            "Query: Bei welchen Körpern zeigen sich unterschiedliche WIrkungen bei gleichem Impuls?, Correct Retrieved: True\n",
            "Query: Welche physikalische Größe wurde durch die Energie ergänzt?, Correct Retrieved: True\n",
            "Query: Wie bezeichnete Leibniz die Größe Energie?, Correct Retrieved: True\n",
            "Query: Zu welchem Phänomen in der Mechanik forschte Leonhard Euler?, Correct Retrieved: True\n",
            "Query: Welche physikalische Definition von Arbeit wurde 1829 vorgeschlagen?, Correct Retrieved: True\n",
            "Query: Wer führte den Begriff kinetische Energie ein?, Correct Retrieved: True\n",
            "Query: Was behandelt eine bekannte Veröffentlichung von Carnot von 1824?, Correct Retrieved: True\n",
            "Query: Wer formalisierte Carnots Ergebnisse zur Dampfmaschine?, Correct Retrieved: True\n",
            "Query: Welche Eigenschaft von Energie beschrieb Julius Robert Mayer 1841?, Correct Retrieved: True\n",
            "Query: Welcher Hauptsatz der Thermodynamik beschreibt das Prinzip der Energieerhaltung?, Correct Retrieved: True\n",
            "Query: In wiefern erweiterte Rudolf Clausius das Verständnis von Energie und Wärme?, Correct Retrieved: True\n",
            "Query: Was beschreibt der Zweite Hauptsatz der Thermodynamik?, Correct Retrieved: True\n",
            "Query: Welchen physikalischen Begriff prägte Clausius?, Correct Retrieved: True\n",
            "Query: Wer verfasste den zweiten Hauptsatz der Thermodynamik?, Correct Retrieved: True\n",
            "Query: Wer schrieb 1847, dass es nicht möglich sei, ein Perpetuum Mobile zu konstruieren?, Correct Retrieved: True\n",
            "Query: Wieso trafen Helmholtz und Mayer unter etablierten Physikern in Deutschland auf Ablehnung?, Correct Retrieved: True\n",
            "Query: Wo hat der Trans Canada Highway seinen Anfangspunkt?, Correct Retrieved: True\n",
            "Query: Welches Gebäude steht für den Anfang des Trans Canada Highway?, Correct Retrieved: True\n",
            "Query: Welche Straße ist die drittlängste der Welt?, Correct Retrieved: True\n",
            "Query: Welchen Rang nimmt der Trans Canada Highway unter den längsten Straßen der Welt ein?, Correct Retrieved: True\n",
            "Query: In welcher Stadt startet der Trans Canada Highway?, Correct Retrieved: True\n",
            "Query: Aus welchen Quellen ist das heutige Recht in Israel beeinflusst?, Correct Retrieved: True\n",
            "Query: Wann wurde Israel gegründet?, Correct Retrieved: False\n",
            "Query: in welchem Rechtsbereich ist in Israel die englische Rechtstradition noch deutlich zu sehen?, Correct Retrieved: True\n",
            "Query: Seit wann ist englische Rechtssprechung in Israel nicht mehr gültig?, Correct Retrieved: True\n",
            "Query: Wann lebte Willliam Apes?, Correct Retrieved: True\n",
            "Query: Zu welchem Stamm gehörte William Apes?, Correct Retrieved: True\n",
            "Query: Welche Einschränkungen gibt es bei der Weitergabe von manchen Geschichten der indianischen mündlichen Tradition?, Correct Retrieved: True\n",
            "Query: Wer übersetzte das Markus-Evangelium ins Mohawk?, Correct Retrieved: True\n",
            "Query: Wie war der bürgerliche Name von Thayendanegea?, Correct Retrieved: True\n",
            "Query: Welcher Amerikaner indianischer Abstammung erhielt 1969 den Pulitzer-Preis?, Correct Retrieved: True\n",
            "Query: Wer schrieb \"The rebirth of Canada's Indians\"?, Correct Retrieved: True\n",
            "Query: In welcher Klimazone liegt Mexiko-Stadt?, Correct Retrieved: False\n",
            "Query: Wann ist in Mexiko City Regenzeit?, Correct Retrieved: True\n",
            "Query: Welche Niedeschlagsphase ist in Mexiko-Stadt im Winter und Frühjahr?, Correct Retrieved: True\n",
            "Query: Was ist die Durchschnittstemperatur in Mexiko-Stadt?, Correct Retrieved: False\n",
            "Query: In welchem Monat gibt es in Mexico City durchschnittlich die höchsten Temperaturen?, Correct Retrieved: True\n",
            "Query: in welchem Monat regnet es in Mexico-Stadt am meisten?, Correct Retrieved: True\n",
            "Query: Welche Gruppe verlor im Zuge der Teilungen Polens ihre Adelstitel?, Correct Retrieved: True\n",
            "Query: Was ist das deutsche Äquivalent der polnischen Endungen -ski, -cki und -icz?, Correct Retrieved: True\n",
            "Query: Wer regierte Preußen zur Zeit der ersten Teilung Polens 1772?, Correct Retrieved: True\n",
            "Query: In welchem Jahr war der Novemberaufstand gegen die russische Herrschaft in Polen?, Correct Retrieved: True\n",
            "Query: Welcher Auftstand fand 1863 in Polen statt?, Correct Retrieved: False\n",
            "Query: Wohin floh die Fürstin Isabella Czartoryska im Zuge der gescheiterten polnischen Aufstände im 19. Jhd?, Correct Retrieved: True\n",
            "Query: Seit wann dürfen Menschen in Nordirland der Labour Party beitreten?, Correct Retrieved: True\n",
            "Query: In welchem Zeitraum ist der Roman \"Wer die Nachtigall stört\" verordnet?, Correct Retrieved: True\n",
            "Query: Wo spielt \"Wer die Nachtigall stört\"?, Correct Retrieved: True\n",
            "Query: Wer ist die Erzählerin von \"Wer die Nachtigall stört\"?, Correct Retrieved: True\n",
            "Query: Wie heißt Scouts Vater in Wer die Nachtigall stört?, Correct Retrieved: True\n",
            "Query: Welchen Beruf hat Scouts Vater in Wer die Nachtigall stört?, Correct Retrieved: True\n",
            "Query: Wie heißt der Nachbar von Scout in Wer die Nachtigall stört?, Correct Retrieved: True\n",
            "Query: Was wird Tom Robinson in Wer die Nachtigall stört vorgeworfen?, Correct Retrieved: True\n",
            "Query: Welche Idee folgt die Jury in Wer die Nachtigall stört bei der Verurteilung von Robinson?, Correct Retrieved: True\n",
            "Query: Was geschieht am Ende des Romans Wer die Nachtigall stört mit Robinson?, Correct Retrieved: True\n",
            "Query: Wer greift Scout und ihren Bruder am Ende des Romans Wer die Nachtigall stört an?, Correct Retrieved: True\n",
            "Query: Wer rettet Scout und ihren Bruder vor Ewells Angriff in Wer die Nachtigall stört?, Correct Retrieved: True\n",
            "Query: Welche Staats- und Regierungsform befürwortete Locke?, Correct Retrieved: True\n",
            "Query: Wann hat Montesquieu die Persischen Briefe veröffentlicht?, Correct Retrieved: True\n",
            "Query: Mit welcher Aufgabe war Montesquieu am Gericht von Bordeaux betraut?, Correct Retrieved: True\n",
            "Query: Worin besteht für Montesquieu politische Freiheit?, Correct Retrieved: True\n",
            "Query: Wie heißt das Buch von Montesquieu zur Staatstheorie?, Correct Retrieved: True\n",
            "Query: Welche Airlines fliegen von dem St. John’s International Airport aus? , Correct Retrieved: True\n",
            "Query: Welche Städte innerhalb Kanada kann man von dem St. John's International Airport erreichen?, Correct Retrieved: True\n",
            "Query: Welche Städte außerhalb Kanada sind von dem St. John's International Airport erreichbar?, Correct Retrieved: True\n",
            "Query: Was bedeutet Luxuspapiere?, Correct Retrieved: True\n",
            "Query: Welche Methoden wurden zur Veredelung der Luxuspapiere eingesetzt?, Correct Retrieved: True\n",
            "Query: In welchen Ländern wird das Papier in Innenräumen als Einrichtung verwendet?, Correct Retrieved: True\n",
            "Query: Wie viel Prozent der Stimmen hat Miguel Angel Mancera bei den Wahlen bekommen?, Correct Retrieved: True\n",
            "Query: Wie viel Prozent der Stimmen hat der Vorgänger von Miguel Angel Mancera bei den Wahlen bekommen?, Correct Retrieved: True\n",
            "Query: Wer war der Vorgänger von Marcelo Ebrard?, Correct Retrieved: True\n",
            "Query: Seit wann gibt es einen Regierungschef in Mexiko-Stadt?, Correct Retrieved: True\n",
            "Query: Wer hat die Mexiko-Stadt vorher regiert, bevor es einen Stadtoberhaupt gab? , Correct Retrieved: True\n",
            "Query: Wie viele Bezirken gibt es heutzutage im Bundesbezirk neben Mexiko-Stadt?, Correct Retrieved: True\n",
            "Query: Wer regiert in den einzelnen Bezirken in Mexiko-Stadt?, Correct Retrieved: True\n",
            "Query: Was war das Ziel der Verwaltungsreform 1982 in Mexiko-Stadt?, Correct Retrieved: True\n",
            "Query: Wer war der erste frei gewählte Regierungschef der Mexiko-Stadt?, Correct Retrieved: True\n",
            "Query: Wer war der Vorgänger des ersten frei gewählten Regierungschefs von Mexiko-Stadt?, Correct Retrieved: True\n",
            "Query: Was ist die regierende Partei von Mexiko-Stadt?, Correct Retrieved: True\n",
            "Query: Wann hat Andrés Manuel López Obrador in den Präsidentschaftswahlen teilgenommen?, Correct Retrieved: True\n",
            "Query: Welche Outdoorsportarten sind populär in North Carolina?, Correct Retrieved: True\n",
            "Query: Wie wird der Breitensport in North Carolina gefördert?, Correct Retrieved: True\n",
            "Query: Welche Sportveranstaltungen finden in North Carolina jährlich statt?, Correct Retrieved: True\n",
            "Query: Wofür stellt der North Carolina Amateur Sports Mittel zur Verfügung?, Correct Retrieved: True\n",
            "Query: Warum hat der Fürst Menschikow den Militär nach Konstantinopel entsandt? , Correct Retrieved: True\n",
            "Query: Was forderte Fürst Menschikow vom Sultan des Osmanischen Reiches 1853?, Correct Retrieved: True\n",
            "Query: Wann reiste Menschikow aus dem Osmanischen Reich ab, nachdem seine Mission gescheitert ist?, Correct Retrieved: True\n",
            "Query: Wer hat versucht russische Häfen 1854 in der Ostsee zu blockieren?, Correct Retrieved: True\n",
            "Query: Wer war der wichtigste militärische Berater vom Fürst Menschikow?, Correct Retrieved: True\n",
            "Query: Warum war die Raumfahrt in den 60ern so populär?\n",
            ", Correct Retrieved: True\n",
            "Query: Welches Recht befasst sich mit der Jagd?, Correct Retrieved: True\n",
            "Query: Auf was basiert das objektive Jagdrecht meistens?, Correct Retrieved: True\n",
            "Query: Was kommt meistens zum Fundament des objektiven Jagdrechts hinzu?, Correct Retrieved: True\n",
            "Query: Seit wann nimmt Guam an allen Olympischen Sommerspielen teil?, Correct Retrieved: True\n",
            "Query: In welchen Vereinen ist die Guams Fußballnationalmannschaft ein Mitglied?, Correct Retrieved: True\n",
            "Query: Wann hat Guam zum ersten Mal versucht in der Fußballweltmeisterschaft teilzunehmen?, Correct Retrieved: True\n",
            "Query: Wann hat Guam in einem Spiel gegen Turkmenistan gewonnen?, Correct Retrieved: True\n",
            "Query: Was ist der Föderalismus im engeren Sinne?, Correct Retrieved: True\n",
            "Query: Was bedeutet \"nachhaltiger Föderalismus\"?, Correct Retrieved: True\n",
            "Query: Wie unterscheiden sich Gehirne von Männern und Frauen?, Correct Retrieved: True\n",
            "Query: Wie viel wiegt das Gehirn eines Mannes durchschnittlich?, Correct Retrieved: True\n",
            "Query: Wie groß ist der Unterschied zwischen dem Gewicht des Gehirnes eines Mannes und einer Frau?, Correct Retrieved: True\n",
            "Query: Wie schwer ist das Gehirn eines Blauwalles?, Correct Retrieved: True\n",
            "Query: Welchem Tier ähnelt sich der Hippocampus?, Correct Retrieved: True\n",
            "Query: Wofür ist der Hippocampus zuständig?, Correct Retrieved: True\n",
            "Query: Was ist der Unterschied zwischen dem Hippocampus eines Mannes und einer Frau?, Correct Retrieved: True\n",
            "Query: Wofür ist die Amygdala zuständig?, Correct Retrieved: True\n",
            "Query: Was ist der Unterschied zwischen einer Amygdala eines Mannes und einer Frau?, Correct Retrieved: True\n",
            "Query: Wie unterscheiden sich die beiden Hirnhemisphären im Bezug auf Sprache und Raumvorstellung bei Männern und Frauen?, Correct Retrieved: True\n",
            "Query: Wie kann man den Unterschied in den beiden Hirnhemisphären von Männern und Frauen erklären?, Correct Retrieved: True\n",
            "Query: Wie können die Geschlechtschromosomen die Entwicklung beeinflussen?, Correct Retrieved: True\n",
            "Query: Wer ließ 1702 San Agustin zerstören?, Correct Retrieved: True\n",
            "Query: Wann nahmen Franzosen die spanische Siedlung in Pensacola im Westen Floridas ein?, Correct Retrieved: True\n",
            "Query: Wann wurde San Agustin angegriffen und ausgeräubert?, Correct Retrieved: True\n",
            "Query: Wo liegt Guinea-Bissau?, Correct Retrieved: True\n",
            "Query: Welches Land grenzt an Guinea-Bissau im Norden?, Correct Retrieved: True\n",
            "Query: Welches Land grenzt an Guinea-Bissau im Osten?, Correct Retrieved: True\n",
            "Query: Wie groß ist Guinea-Bissau?, Correct Retrieved: True\n",
            "Query: Was ist die Hauptstadt von Guinea- Bissau?, Correct Retrieved: True\n",
            "Query: Wie wird die Northwestern University auch gennant?, Correct Retrieved: True\n",
            "Query: In welchem Bundesstaat ist die Northwestern University angesiedelt?, Correct Retrieved: True\n",
            "Query: In welcher Stadt ist die Northwestern University?, Correct Retrieved: True\n",
            "Query: Wie heißt das U-Bahnsystem in Chicago?, Correct Retrieved: True\n",
            "Query: An welchem See liegt die Northwestern University?, Correct Retrieved: True\n",
            "Query: In welcher Stadt ist der zentrale Campus der Northwestern University?, Correct Retrieved: True\n",
            "Query: Wie groß ist der Hauptcampus der Northwestern University?, Correct Retrieved: True\n",
            "Query: Seit wann gibt es die Kellogg School of Management an der NU?, Correct Retrieved: True\n",
            "Query: Wie viele Studierende gibt es an der Northwestern University?, Correct Retrieved: True\n",
            "Query: Ist die Northwestern eine private oder staatliche Universität?, Correct Retrieved: True\n",
            "Query: Wie heißt die studentische Zeitung an der Northwestern University?, Correct Retrieved: True\n",
            "Query: Wann wurde die Association of American Universities gegründet?, Correct Retrieved: True\n",
            "Query: In welchem Land gab es die meisten Toten im Pazifikkrieg?, Correct Retrieved: True\n",
            "Query: Wie viele Soldaten in China starben im Pazifikkrieg?, Correct Retrieved: True\n",
            "Query: Wie viele japanische Soldaten fielen im Pazifikkrieg?, Correct Retrieved: True\n",
            "Query: Was versteht man unter der Lesbarkeit in der Architektur?, Correct Retrieved: True\n",
            "Query: Welche Themen sind seit den zunehmenden Debatten um die globale Erwarmung in der Architektur wichtig geworden?, Correct Retrieved: True\n",
            "Query: Was versteht man unter dem Begriff \"Solararchitektur\"?, Correct Retrieved: True\n",
            "Query: Was macht der Rettungsdienst als erstes, wenn ein Patient den Herzinfarkt hat?, Correct Retrieved: False\n",
            "Query: Wozu dient eine medikamentöse Therapie beim Herzinfarkt in der Akutphase?, Correct Retrieved: True\n",
            "Query: Welche Medikamente werden beim Herzinfarkt eingesetzt?, Correct Retrieved: False\n",
            "Query: Warum wird die Therapie mit Sauerstoff beim Herzinfarkt nicht mehr durchgeführt?, Correct Retrieved: True\n",
            "Query: Welche Medikamente können beim Herzinfarkt manchmal erforderlich sein?, Correct Retrieved: True\n",
            "Query: Wie wurde Gaddafi getötet?, Correct Retrieved: True\n",
            "Query: Welche Organisation hat geholfen Gaddafi 2011 zu finden, als er geflohen ist?, Correct Retrieved: True\n",
            "Query: Wo wurde die Leihe von Gaddafi bestattet?, Correct Retrieved: True\n",
            "Query: Wann ist die Literatur in Tibet sehr religiös geprägt geworden?, Correct Retrieved: True\n",
            "Query: Wie hat sich die Literatur in Tibet mit der Annexion des Landes durch China verändert? , Correct Retrieved: True\n",
            "Query: Was wird unter der tibetischen Literatur verstanden?, Correct Retrieved: True\n",
            "Query: Wer hat das Famicon entworfen?, Correct Retrieved: False\n",
            "Query: In welchem Land hat man das Famicon verkauft?, Correct Retrieved: False\n",
            "Query: Wie hieß die erste Nintendo-Konsole?, Correct Retrieved: True\n",
            "Query: Welches Zubehör hatte die erste Nintendo?, Correct Retrieved: True\n",
            "Query: In welchen Paketen konnte man das Nintendo Entertainment System 1985 kaufen?, Correct Retrieved: True\n",
            "Query: Wann reagiert das Immunsystem übermäßig auf bestimmte körperfremde Strukturen?, Correct Retrieved: True\n",
            "Query: Was ist der Grund von Autoimmunerkrankungen?, Correct Retrieved: True\n",
            "Query: Was sind die Beispiele für Autoimmunerkrankungen?, Correct Retrieved: True\n",
            "Query: Was ist ein Erfordernis für die Entstehung einer Allergie?, Correct Retrieved: True\n",
            "Query: Welche Allergien treten am häufigsten auf?, Correct Retrieved: True\n",
            "Query: Bei welchen Softwaretests wird die Automatisierung empfohlen?, Correct Retrieved: True\n",
            "Query: Wozu dienen Regressionstests beim Testen von Software?, Correct Retrieved: True\n",
            "Query: Welcher Wert ist extrem wichtig bei der Papierherstellung?, Correct Retrieved: True\n",
            "Query: Wovon hängt die Zugfestigkeit von Papier ab?, Correct Retrieved: True\n",
            "Query: Wie wird die Zugfestigkeit von Papier gemessen?, Correct Retrieved: True\n",
            "Query: Was bestimmt der spezifische Weiterreißwiderstand von Papier?, Correct Retrieved: True\n",
            "Query: Wie wird der spezifische Weiterreißwiderstand von Papier gemessen?, Correct Retrieved: True\n",
            "Query: Was macht der Berstwiderstand beim Papier?, Correct Retrieved: True\n",
            "Query: Wie wird der Berstwiderstand beim Papier gemessen?, Correct Retrieved: True\n",
            "Query: Was ist unter dem Spaltwiderstand beim Papier gemeint?, Correct Retrieved: True\n",
            "Query: Wie werden intensive Grüntöne bezeichnet?, Correct Retrieved: True\n",
            "Query: Wie viel Prozent der Bevölkerung sprechen Deutsch als Muttersprache?, Correct Retrieved: True\n",
            "Query: Was ist die gesprochene Umgangssprache in Bern?, Correct Retrieved: True\n",
            "Query: Was ist eine der Besonderheiten des Berndeutsches?, Correct Retrieved: True\n",
            "Query: Wodurch zeichnen sich Chloroplasten und Mitochondrien aus?, Correct Retrieved: True\n",
            "Query: Wo liegt San Diego?, Correct Retrieved: True\n",
            "Query: Was grenzt an Westen von San Diego?, Correct Retrieved: True\n",
            "Query: Was grenzt an Osten von San Diego?, Correct Retrieved: True\n",
            "Query: In wie viele Teile wird San Diego geteilt?, Correct Retrieved: True\n",
            "Query: Was ist der höchste Punkt San Diegos?, Correct Retrieved: True\n",
            "Query: Welchen Fluss gibt es in San Diego?, Correct Retrieved: True\n",
            "Query: Was ist das Hauptwerk von Charles Darwin?, Correct Retrieved: True\n",
            "Query: Wann wurde \"Über die Entstehung der Arten\" veröffentlicht?, Correct Retrieved: True\n",
            "Query: Was hat Charles Darwin in seinem Hauptwerk bewiesen?, Correct Retrieved: True\n",
            "Query: Wo hat Charles Darwin Belege für seine Theorie gesammelt?, Correct Retrieved: True\n",
            "Query: Was war die ursprüngliche Religion der Slawen?, Correct Retrieved: True\n",
            "Query: Mit welchem Namen haben die Slawen den Gott genannt?, Correct Retrieved: True\n",
            "Query: Welche mythische Wesen wurden von den Slawen verehrt?, Correct Retrieved: True\n",
            "Query: Was brachten die Slawen den Göttern zum Opfer?, Correct Retrieved: True\n",
            "Query: Was passiert mit der Seele nach dem Tod laut Slawen?, Correct Retrieved: True\n",
            "Query: Wer hat Tristan da Cunha in seinem Roman im Jahr 1838 ausführlich beschrieben?, Correct Retrieved: True\n",
            "Query: Wer hat einen Roman über Tristan da Cunha geschrieben, der denselben Namen wie diese Inselgruppe trägt?, Correct Retrieved: True\n",
            "Query: In welchem Werk hat Jule Verne Tristan da Cunha dargestellt?, Correct Retrieved: True\n",
            "Query: Wann hat der Österreichische Erbfolgekrieg stattgefunden?, Correct Retrieved: True\n",
            "Query: Was beendete den Österreichischen Erbfolgekrieg?, Correct Retrieved: True\n",
            "Query: Was hat Österreich versucht, um Schlesien zurückzugewinnen?, Correct Retrieved: True\n",
            "Query: In welchem Jahr verschlechterte sich der britisch- französische Konflikt in Nordamerika?, Correct Retrieved: True\n",
            "Query: Wer wollte das Bündnis von Frankreich und Preußen  Mitte des 18.Jahrhundert vermeiden? , Correct Retrieved: True\n",
            "Query: Worum ging es im Vertrag von Sankt Petersburg zwischen Großbritannien und Russland?, Correct Retrieved: True\n",
            "Query: Wann hat Großbritannien die Westminister-Konvention mit Preußen geschlossen?, Correct Retrieved: True\n",
            "Query: Was hat die Westminister-Konvention von 1756 garantiert?, Correct Retrieved: True\n",
            "Query: An welchem Tag hat Großbritannien Frankreich 1756 den Krieg erklärt?, Correct Retrieved: True\n",
            "Query: Warum glühen erhitzte Körper zunächst rot?, Correct Retrieved: True\n",
            "Query: Welche Sinneszellen im menschlichen Auge sind für das Rotsehen verantwortlich?, Correct Retrieved: True\n",
            "Query: Mit welcher Geschwindigkeit kann man Daten mithilfe eines USB-Sticks übertragen?, Correct Retrieved: True\n",
            "Query: Welcher im 14.Jahrhundert angelegte künstliche See in Jaisalmer wurde von der Bevölkerung gepflegt? , Correct Retrieved: True\n",
            "Query: Was war die Quelle des Trinkwassers in Jaisalmer?, Correct Retrieved: True\n",
            "Query: Wie nennt man religiöse Stiftungen in Iran?, Correct Retrieved: True\n",
            "Query: Warum werden religiöse Stiftungen in Iran kritisiert?, Correct Retrieved: True\n",
            "Query: In welchen Bereichen der Wirtschaft haben religiöse Stiftungen in Iran herrschende Stellung?, Correct Retrieved: True\n",
            "Query: Was sind die zwei größten religiösen Stiftungen in Iran?, Correct Retrieved: True\n",
            "Query: Wie ist der Achtfache Pfad im Buddhismus geteilt?, Correct Retrieved: True\n",
            "Query: Was ist das Kern der Lehre des Buddha?, Correct Retrieved: True\n",
            "Query: Welche Wirkung können manche für die Munitionsproduktion eingesetzte Metalle haben?, Correct Retrieved: True\n",
            "Query: Wie kann das Geschossmaterial der Natur schaden? , Correct Retrieved: True\n",
            "Query: Warum wird die Verwendung von Blei in der Munition kritisiert?, Correct Retrieved: True\n",
            "Query: Wo finden Vakuumkondensatoren ihre Anwendung?, Correct Retrieved: False\n",
            "Query: Wann werden Vakuumkondensatoren eingesetzt?, Correct Retrieved: True\n",
            "Query: Warum werden Glimmerkondensatoren für hohe Anforderungen eingesetzt?, Correct Retrieved: True\n",
            "Query: Warum werden Schutzringkondensatoren gebaut?, Correct Retrieved: True\n",
            "Query: Wie viele Schichten haben mehrlagige Leiterplatten?, Correct Retrieved: True\n",
            "Query: Was ist ein Kurzschluss?, Correct Retrieved: True\n",
            "Query: Wie entsteht ein Kurzschluss?, Correct Retrieved: True\n",
            "Query: Wie funktionieren Kurzschlusstests?, Correct Retrieved: False\n",
            "Query: Als was bezeichnen die Demokraten bei Wahlen die im Ausland lebenden Wähler?, Correct Retrieved: True\n",
            "Query: Wie viele US-Amerikaner leben im Ausland?, Correct Retrieved: True\n",
            "Query: Was war das Grundprinzip von Alfred North Whiteheads Schaffen?, Correct Retrieved: True\n",
            "Query: Wie heißt das erste Werk von Whitehead im Bereich Naturphilosophie?, Correct Retrieved: True\n",
            "Query: Wo ist die Yale University?, Correct Retrieved: True\n",
            "Query: Welche ist die drittälteste Uni der USA?, Correct Retrieved: True\n",
            "Query: Wessen Namen trägt die Yale University?, Correct Retrieved: True\n",
            "Query: Welche Universität verfügt weltweit über das meiste Kapital?, Correct Retrieved: True\n",
            "Query: Was ist die Ivy League?, Correct Retrieved: True\n",
            "Query: Seit wann gibt es die Association of American Universities?, Correct Retrieved: True\n",
            "Query: Welches sind die drei wichtigsten Universitäten der USA?, Correct Retrieved: True\n",
            "Query: Wie viele bücher hab es 2009 in den Bibliotheken von Yale?, Correct Retrieved: True\n",
            "Query: Wie viele US-Präsidenten haben in Yale studiert?, Correct Retrieved: True\n",
            "Query: Was ist armenische Kunst?, Correct Retrieved: True\n",
            "Query: Wie sind Daten auf Laserdiscs gespeichert?, Correct Retrieved: True\n",
            "Query: Kann man eine Laserdisc als CD benutzen?, Correct Retrieved: True\n",
            "Query: Was bedeutet CAV bei Laserdiscs?, Correct Retrieved: True\n",
            "Query: Welche Form der Erkenntnis steht dem Empirismus gegenüber?, Correct Retrieved: True\n",
            "Query: Wieso lehnt Leibniz empirisches WIssen ab?, Correct Retrieved: True\n",
            "Query: Wie wird nach Descartes Erkenntnis generiert?, Correct Retrieved: True\n",
            "Query: Wie ist das VErhältnis von Zonenzeit und Sonnenzeit?, Correct Retrieved: True\n",
            "Query: Was ist die MEZ?, Correct Retrieved: True\n",
            "Query: Was ist die Sommerzeit?, Correct Retrieved: True\n",
            "Query: Was waren die Gründe für die Einführung der Sommerzeit?, Correct Retrieved: True\n",
            "Query: Wieso galt in der Tschechoslowakei 1946 eine Winterzeit?, Correct Retrieved: True\n",
            "Query: Was ist die Standardzeit?, Correct Retrieved: True\n",
            "Query: Was ist die Sonnenzeit?, Correct Retrieved: True\n",
            "Query: Wann wurden die globalen Zeitzonen festgelegt?, Correct Retrieved: True\n",
            "Query: Wo wurde ein weltweites Zeitsystem festgelegt?, Correct Retrieved: True\n",
            "Query: Was ist die Zonenzeit?, Correct Retrieved: True\n",
            "Query: Wie groß ist der Zeitunterschied zwischen den Zonenzeiten?, Correct Retrieved: True\n",
            "Query: Was war die erste Funktion von Hunden für den Menschen?, Correct Retrieved: True\n",
            "Query: von wem stammen Hunde ab?, Correct Retrieved: True\n",
            "Query: Welche Eigenschaft benötigen Hunde für die Treibjagd?, Correct Retrieved: True\n",
            "Query: Wozu wurden Dackel gezüchtet?, Correct Retrieved: True\n",
            "Query: Was trug bei der Kolonialisierung Amerikas durch die Europäer neben Krieg auch zur Ausschlöschung der indigenen Bevölkerung bei?, Correct Retrieved: True\n",
            "Query: Wie groß schätze Alfred Kroeber die Bevölkerung  in Mittelamerika im Jahr 1492?, Correct Retrieved: True\n",
            "Query: Was wird heute in Bezug auf die Kolonisierung Amerikas als Mythos bezeichnet?, Correct Retrieved: True\n",
            "Query: Auf wie viele Einwohner wird Mittelamerika zur Zeit der Kolonisierung durch die Europäer geschätzt?, Correct Retrieved: True\n",
            "Query: Wer vernichtete die Azteken?, Correct Retrieved: True\n",
            "Query: Wie viele Soldaten hatte Hernan Cortes?, Correct Retrieved: True\n",
            "Query: Welche Hochkultur in Amerika hat Pizarro vernichtet?, Correct Retrieved: True\n",
            "Query: Was ist der Vertrag von Tordesillas?, Correct Retrieved: True\n",
            "Query: Wie wurden die Kinder indianischer Frauen mit europäsichen Kolonisatoren bezeichnet?, Correct Retrieved: True\n",
            "Query: Welche Krankheiten grassierten in Nordamerika nach der Ankunft der Europäer?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen sind in Amerika in der Kolonialzeit Schätzungen zufolgen an den Pocken gestorben?, Correct Retrieved: True\n",
            "Query: Wieso waren die Krankheiten der Europäer für die indigene Bevölkerung in Amerika besonders schwerwiegend?, Correct Retrieved: True\n",
            "Query: Wie sollen die Europäer absichtlich Pocken unter der indigenen Bevölkerung Amerikas verbreitet haben?, Correct Retrieved: True\n",
            "Query: Wann war die Schlacht von Mauvilla?, Correct Retrieved: True\n",
            "Query: Wie viele Seminolenkriege gab es?, Correct Retrieved: True\n",
            "Query: Wann waren die Biberkriege?, Correct Retrieved: True\n",
            "Query: Wer führte die Apachen bis 1886 bei den Aufständen gegen die europäischen Siedler an?, Correct Retrieved: True\n",
            "Query: Wann war der Aufstand der Sioux?, Correct Retrieved: True\n",
            "Query: Welches Massaker gegen die indianische Bevölkerung wurde 1890 begangen?, Correct Retrieved: True\n",
            "Query: Was ist das Zinkfingerprotein?, Correct Retrieved: False\n",
            "Query: Wie tritt Zink im Blutkreislauf auf?, Correct Retrieved: True\n",
            "Query: Welche Enzyme benötigen Zink?, Correct Retrieved: True\n",
            "Query: Wofür benötigt der Körper Zink?, Correct Retrieved: True\n",
            "Query: In welcher Stadt steht das Alley Theatre, Correct Retrieved: True\n",
            "Query: Was heißt Sowjet?, Correct Retrieved: True\n",
            "Query: Welche Verwaltungsebenen gab es in der Russischen Sowjetrepublik?, Correct Retrieved: True\n",
            "Query: Welche Institution sollte das Parlament in der Russischen Sowjetrepublik ersetzten?, Correct Retrieved: True\n",
            "Query: Wer durfte laut der Räteordnung der Russischen Sozialistischen Föderativen Sowjetrepulik wählen?, Correct Retrieved: True\n",
            "Query: Welches Prinzip führte Montesquieu in \"Vom Geist der Gesetze\" ein?, Correct Retrieved: True\n",
            "Query: Was ist die empfohlene Tagesdosis für Zink?, Correct Retrieved: True\n",
            "Query: Was sind die Folgen von zu viel Zink?, Correct Retrieved: True\n",
            "Query: Ab wie viel Gramm ist Zink giftig?, Correct Retrieved: True\n",
            "Query: Was ist Zinkfieber?, Correct Retrieved: True\n",
            "Query: Kann Zink Durchfall auslösen?, Correct Retrieved: True\n",
            "Query: Was ist die Epiglottis?, Correct Retrieved: True\n",
            "Query: Wozu dient der Kehldeckel?, Correct Retrieved: True\n",
            "Query: Was unterscheidet Säugetiere von andern TIeren?, Correct Retrieved: True\n",
            "Query: Was ist die Henle'sche Schleife?, Correct Retrieved: True\n",
            "Query: Welche Steuerungsmechanismen gibt es bei Aufzügen?, Correct Retrieved: False\n",
            "Query: Welche Bedienmöglichkeiten gibt es bei Aufzügen?, Correct Retrieved: False\n",
            "Query: Wo werden Gruppensammelsteuerungen von Aufzügen benutzt?, Correct Retrieved: True\n",
            "Query: Wer verwaltet die Unis in Deutschland?, Correct Retrieved: False\n",
            "Query: Wer ist Träger der Eidgenössischen Technischen Hochschule Zürich?, Correct Retrieved: True\n",
            "Query: Wem unterstehen die Universitäten in der Schweiz?, Correct Retrieved: True\n",
            "Query: Wie heißen die Lehrer an der Uni?, Correct Retrieved: False\n",
            "Query: Was kann man laut Alexander Pashos aus Funden der Kleiderlaus schließen?, Correct Retrieved: True\n",
            "Query: Welcher Zeitpunkt wurden anhand von Genanalysen für das Auftreten von Kleidung festgestellt?, Correct Retrieved: True\n",
            "Query: Was ist die Fundstelle Neumark-Nord?, Correct Retrieved: True\n",
            "Query: Was ist das Besondere an der Fundstelle Neumark-Nord?, Correct Retrieved: True\n",
            "Query: Welche Eigenschaft des Menschen wurde durch den Übergang von Fell zu Haut begünstigt?, Correct Retrieved: True\n",
            "Query: Welches Material wurde zuerst für Kleidung benutzt?, Correct Retrieved: True\n",
            "Query: Welche Bedeutung hat die Entwicklung von Nähkunst in Bezug auf Kleidung?, Correct Retrieved: True\n",
            "Query: Wann wurden erstmals Schafe als Haustiere gehalten?, Correct Retrieved: False\n",
            "Query: Welche Arten von frühen Verschlussmechanismen für Kleidung gab es?, Correct Retrieved: True\n",
            "Query: Vor wie vielen Jahren wurden erstmals Pflanzen zur Herstellung von Kleidung benutzt?, Correct Retrieved: True\n",
            "Query: Wer prägte den Begriff Wirkungsquantum?, Correct Retrieved: False\n",
            "Query: Was wird in der Physik als Wirkung bezeichnet?, Correct Retrieved: True\n",
            "Query: In welchem Jahr präsentierte Niels Bohr sein Atommodell erstmals?, Correct Retrieved: True\n",
            "Query: Wer gilt als Begründer de Quantenmechanik?, Correct Retrieved: True\n",
            "Query: Zu welchem Modell wurde Bohrs Atommodell 1917 erweitert?, Correct Retrieved: True\n",
            "Query: Was ist Spin von teilchen?, Correct Retrieved: True\n",
            "Query: Wie heißt Straßburg im lokalen Dialekt?, Correct Retrieved: True\n",
            "Query: Wo liegt Straßburg?, Correct Retrieved: True\n",
            "Query: Wo hat der Europäische Gerichtshof für Menschenrechte seinen SItz?, Correct Retrieved: True\n",
            "Query: Welches europäische Gericht hat seinen Sitz in Straßburg?, Correct Retrieved: True\n",
            "Query: Welhce Teile von Straßburg sind UNESCO-Weltkulturerbe?, Correct Retrieved: True\n",
            "Query: Wann wurde die Utrechter Union geschlossen?, Correct Retrieved: True\n",
            "Query: Welche Provinzen gehörten zur Republik der Vereinigten Niederlanden?, Correct Retrieved: True\n",
            "Query: In welchen Bereichen wurde in der Republik der Vereinigten Niederlande auf Bundesebene entschieden?, Correct Retrieved: True\n",
            "Query: War die Republik der Vereinigten Niederlande ein Zentralstaat?, Correct Retrieved: True\n",
            "Query: Wieso nahm Holland in den Vereinigten Provinzen eine Vormachtsstellung ein?, Correct Retrieved: True\n",
            "Query: Welche Provinz der Republik Vereinigten Niederlanden hatte den meisten Einfluss?, Correct Retrieved: True\n",
            "Query: Aus welcher Adelsfamilie stammte der Statthalter der Republik der Vereinigten Provinzen?, Correct Retrieved: True\n",
            "Query: Welcher Konflikt im Inland prägte die Republik der Vereinigten Provinzen?, Correct Retrieved: True\n",
            "Query: Ab wann war das Amt des Statthalters der Republik der Vereinigten Provinzen erblich?, Correct Retrieved: True\n",
            "Query: Wo wurde Chopin geboren?, Correct Retrieved: True\n",
            "Query: Wann wurde Chopin getauft?, Correct Retrieved: True\n",
            "Query: Was ist Chopins Taufname?, Correct Retrieved: True\n",
            "Query: Wann wurde Chopin geboren?, Correct Retrieved: True\n",
            "Query: Was gilt als Grund dafür, dass für Chopin zwei unterschiedliche Geburtstage bekannt sind?, Correct Retrieved: True\n",
            "Query: Wann war Kanye West Yeezus-Tour?, Correct Retrieved: True\n",
            "Query: Mit wem hat Kanye West für sein Album Yeezus kooperiert?, Correct Retrieved: True\n",
            "Query: Für welches Lied ließ Kanye West öffentlich Videos an Wände projizieren?, Correct Retrieved: True\n",
            "Query: Was heißt Yeezus?, Correct Retrieved: True\n",
            "Query: Welche Platzierung nahm West Album Yeezus auf den Billboard 200 ein?, Correct Retrieved: True\n",
            "Query: Wie heißt Kanye West 7. Album?, Correct Retrieved: True\n",
            "Query: Wann erschien \"The Life of Pablo\"?, Correct Retrieved: True\n",
            "Query: Mit was stellte The Life of Pablo einen Rekord auf?, Correct Retrieved: True\n",
            "Query: Wodurch fand Kanye West Song Famous in den Medien große Beachtung?, Correct Retrieved: True\n",
            "Query: Mit welcher Tour war Kanye West Ende 2016 unterwegs?, Correct Retrieved: True\n",
            "Query: Wieso kam Kanye West nach dem Tourabbruch 2016 ins Krankenhaus? , Correct Retrieved: True\n",
            "Query: Was hat Kanye West Psychose ausgelöst?, Correct Retrieved: True\n",
            "Query: Wo liegt Palermo?, Correct Retrieved: True\n",
            "Query: Wie hoch ist der Monte Pellegrino?, Correct Retrieved: True\n",
            "Query: Was heißt Conca d'Oro?, Correct Retrieved: True\n",
            "Query: Wieso wird die Gegend um Palermo Goldenes Becken genannt?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen leben in der Metropolregion Palermo?, Correct Retrieved: True\n",
            "Query: wie viele Bezirke gibt es in Palermo?, Correct Retrieved: True\n",
            "Query: Wie heißt die Sammlung von Hirtengedichten von Vergil?, Correct Retrieved: True\n",
            "Query: Wie werden die Eklogen von Vergil auch genannt?, Correct Retrieved: True\n",
            "Query: Wann hat Vergil die Eklogen geschrieben?, Correct Retrieved: True\n",
            "Query: Welches politische Ereignis wird in der ersten Ekloge von Vergil aufgegriffen?, Correct Retrieved: True\n",
            "Query: Wieso ist die Deutsche Bahn von der EEG-Umlage ausgenommen?, Correct Retrieved: True\n",
            "Query: Wie groß ist die EEG-Umlage, die die Deutsche Bahn bezahlt?, Correct Retrieved: True\n",
            "Query: Wozu werden in Datenbanken auch die Zugriffe der Benutzer gespeichert?, Correct Retrieved: True\n",
            "Query: Durch was werden die Bestandsdaten in Datenbanken gesichert?, Correct Retrieved: True\n",
            "Query: Wieso schränkt ein Backup die Arbeit mit einer Datenbank ein?, Correct Retrieved: False\n",
            "Query: Welche Informationen werden in Datenbanken neben den eigentlichen Einträgen auch gespeichert?, Correct Retrieved: True\n",
            "Query: Wo lag das Königreich Vijayanagar?, Correct Retrieved: True\n",
            "Query: Was heißt Vijayanagar?, Correct Retrieved: True\n",
            "Query: Bis wann bestand das Königreich Vijayanagar in Indien?, Correct Retrieved: True\n",
            "Query: Nach wem war das Königreich Vijayanagar benannt?, Correct Retrieved: True\n",
            "Query: Wer war für den Untergang von Vijayanagar verantwortlich?, Correct Retrieved: True\n",
            "Query: Wer gründete das Vijayanagar-Königreich?, Correct Retrieved: True\n",
            "Query: Wann wurde der ägyptische König Faruk abgesetzt?, Correct Retrieved: True\n",
            "Query: Wann ist der nationalfeiertag in Ägypten?, Correct Retrieved: True\n",
            "Query: Wer setzte den ägyptischen König 1952 ab?, Correct Retrieved: True\n",
            "Query: Wer prägte die Republik Ägypten in ihrer Entstehungszeit?, Correct Retrieved: True\n",
            "Query: Wer führte die Revolution in Ägypten an?, Correct Retrieved: True\n",
            "Query: Was ist die Sueskrise?, Correct Retrieved: True\n",
            "Query: Seit wann dürfen Frauen in Ägypten wählen?, Correct Retrieved: True\n",
            "Query: Welcher Unterschied im Wahlrecht bestand in Ägypten zwischen Männern und Frauen bis 1979?, Correct Retrieved: True\n",
            "Query: Welcher Vereinigung, die bis 1961 bestand, gehörte Ägypten an?, Correct Retrieved: True\n",
            "Query: Wann war der Sechstagekrieg?, Correct Retrieved: True\n",
            "Query: An welchem Krieg war Ägypten 1973 beteiligt?, Correct Retrieved: True\n",
            "Query: Wann schlossen Ägypten und Israel einen Friedensvertrag?, Correct Retrieved: True\n",
            "Query: Was kennzeichnet die boreale Zone in den USA?, Correct Retrieved: False\n",
            "Query: Was bildet sich auf sandigen Böden in Fichtenwäldern?, Correct Retrieved: True\n",
            "Query: Aus welchen Böden entsteht Braunerde?, Correct Retrieved: True\n",
            "Query: Auf welchem Boden bildet sich Parabraunerde?, Correct Retrieved: False\n",
            "Query: Bei welchen pH-Werten findet Lessivierung statt?, Correct Retrieved: True\n",
            "Query: Welche Bodentypen sind in den USA in subtropischen Wäldern zu finden?, Correct Retrieved: True\n",
            "Query: Welcher Bodentyp ist in Florida verbreitet?, Correct Retrieved: False\n",
            "Query: Welcher Bodentyp ist im Mississippi-Delta zu finden?, Correct Retrieved: False\n",
            "Query: Welcher Religion gehören in der Republik Kongo die meisten Menschen an?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen in der Republik Kongo sind katholisch?, Correct Retrieved: True\n",
            "Query: Wie viel Prozent der Menschen in der Republik Kongo gehören keiner Religion an?, Correct Retrieved: True\n",
            "Query: Welche Religion ist in der Republik Kongo mit einem Anteil von unter 2 Prozent vertreten?, Correct Retrieved: True\n",
            "Query: An welchen Gott erinnerte Diokletian mit seinem selbstgewählten Namen?, Correct Retrieved: False\n",
            "Query: Wie lautete der Name, den Diokletian für sich selbst wählte?, Correct Retrieved: True\n",
            "Query: Welche religiösen Traditionen wurden unter Diokletian gefördert?, Correct Retrieved: True\n",
            "Query: Wieso waren die frühen Christen im Römischen Reich Verfolgung ausgesetzt?, Correct Retrieved: True\n",
            "Query: Welcher römische Kaiser erließ das Toleranzedikt?, Correct Retrieved: True\n",
            "Query: Welcher Vorteil bot sich durch die Annahme des Christentums für die römischen Kaiser?, Correct Retrieved: True\n",
            "Query: Ab wann war im Römischen Reich die freie Ausübung aller Religionen erlaubt?, Correct Retrieved: True\n",
            "Query: Wann wurde die christliche Religion zur Staatsreligion im Römischen Reich?, Correct Retrieved: True\n",
            "Query: Welche Zeit gilt als Hochzeit der Auseinandersetzungen zwischen Christentum und traditionellen Götterkulten im Römischen Reich?, Correct Retrieved: True\n",
            "Query: Um den Altar welcher Göttin kam es im 4. Jhd im römischen Senat zum Streit?, Correct Retrieved: True\n",
            "Query: Welcher Papst ließ um 600 n.Chr. Sardinien missionieren?, Correct Retrieved: True\n",
            "Query: Welcher römische Kaiser befahl, dass alle Kinder getauft werden sollen?, Correct Retrieved: True\n",
            "Query: Welcher Wissenschaftler wird in Hannover im Georgengarten mit einem  Denkmal geehrt?, Correct Retrieved: True\n",
            "Query: Was ist das Besondere an dem Leibniz-Denkmal in Hannover?, Correct Retrieved: True\n",
            "Query: Wann wurde die Waterloosäule in Hannover erbaut?, Correct Retrieved: True\n",
            "Query: Zu welcher Stilrichtung gehört der Reese-Brunnen in Hannover?, Correct Retrieved: True\n",
            "Query: Wo in Hannover stehen die Skulpturen von Niki de Saint Phalle?, Correct Retrieved: True\n",
            "Query: Welche Haltestelle in Hannover wurde von Frank Gehry entworfen?, Correct Retrieved: True\n",
            "Query: An was erinnern die Göttinger Sieben in Hannover?, Correct Retrieved: True\n",
            "Query: Mit welcher japanischen Stadt hat Hannover eine Städtepartnerschaft?, Correct Retrieved: True\n",
            "Query: Wo leben die Lugbara?, Correct Retrieved: True\n",
            "Query: Was bedeutet transzendent bei Göttern?, Correct Retrieved: True\n",
            "Query: Was schrieb Ramanuja über das Verhältnis der Menschen zu Gott?, Correct Retrieved: True\n",
            "Query: Wo lebt die immanente Gottheit der Lugbara auf der Erde?, Correct Retrieved: True\n",
            "Query: Wieso lehnt Leibniz empirische Erkenntnisse ab?, Correct Retrieved: True\n",
            "Query: Was ist für Leibniz Grundlage allgemeiner Erkenntnisse, die über den Einzelfall hinausgehen?, Correct Retrieved: True\n",
            "Query: Welche philosophische Richtung stellt alle allgemein gültigen Aussagen infrage?, Correct Retrieved: False\n",
            "Query: Was ist das Induktionsproblem in der Philosophie?, Correct Retrieved: True\n",
            "Query: Welcher philosophischer Richtung ist Ernst Mach zuzuordnen?, Correct Retrieved: True\n",
            "Query: Was besagt der Radikale Konstruktivismus?, Correct Retrieved: True\n",
            "Query: Was ist ein Induktionsschluss?, Correct Retrieved: False\n",
            "Query: Was war nach sowjetischer Geschichtsschreibung das Ziel der Außenpolitik der Sowjetunion vor dem 2. Weltkrieg?, Correct Retrieved: True\n",
            "Query: Mit wem strebte Stalin laut Gerhard Weinberg vor dem 2. Weltkrieg ein Bündnis an?, Correct Retrieved: True\n",
            "Query: Was war laut Hermann Graml Stalins Ziel während eines Krieges zwischen Deutschland und den Westmächten?, Correct Retrieved: True\n",
            "Query: Welches Prinzip vertrat die Sowjetunion vor dem 2. Weltkrieg in der Außenpolitik?, Correct Retrieved: True\n",
            "Query: Als was wollte Stalin laut Sergej Slutsch die Verhandlungen mit den Westmächten nutzen?, Correct Retrieved: True\n",
            "Query: Wie wird die These bezeichnet, Stalin habe absichtlich einen Krieg zwischen Deutschland und den Westmächten provozieren wollen?, Correct Retrieved: True\n",
            "Query: Wieso wollte Stalin laut Tucker und Raack, dass es zum Krieg kam?, Correct Retrieved: True\n",
            "Query: Wann wurde der Nichtangriffspakt zwischen Deutschland und Polen geschlossen?, Correct Retrieved: True\n",
            "Query: Als was beschreibt Pietrow-Ennker Stalins außenpolitisches Handeln vor dem 2. Weltkrieg?, Correct Retrieved: True\n",
            "Query: Durch was sah Stalin laut Historikern die Sowjetunion vor dem 2. Weltkrieg  umgeben?, Correct Retrieved: True\n",
            "Query: Welchen außenpolitischen Leitsatz folgte Stalin, den er 1925 formuliert hatte?, Correct Retrieved: True\n",
            "Query: Was war laut Teddy Uldricks Stalins außenpolitisches Ziel vor dem 2. WK?, Correct Retrieved: True\n",
            "Query: Was war laut MIcheal Carley der ideologische Antrieb der Politik von England und Frankreich vor dem 2. Weltkrieg?, Correct Retrieved: False\n",
            "Query: Durch was kann Zeit in der Musik erfahrbar gemacht werden?, Correct Retrieved: True\n",
            "Query: In welcher Beziehung steht Zeit zur Musik?, Correct Retrieved: True\n",
            "Query: Als was wird Musik in Hinblick auf ihr Fortbestehen oft bezeichnet?, Correct Retrieved: True\n",
            "Query: Wann entstand der A-cappella-Stil?, Correct Retrieved: True\n",
            "Query: Was ist die ursprüngliche Bedeutung von „a cappella“ ?, Correct Retrieved: True\n",
            "Query: Wie hieß das Gebäude, das vor dem Buckingham Palace an dessen Standort stand?, Correct Retrieved: True\n",
            "Query: Wann wurde das Goring House gebaut?, Correct Retrieved: True\n",
            "Query: Wer ließ das Goring House erbauen?, Correct Retrieved: True\n",
            "Query: Wann wurde das erste Gebäude des Buckingham Palace errichtet?, Correct Retrieved: True\n",
            "Query: Wer entwarf das erste Gebäude des Buckingham Palace?, Correct Retrieved: True\n",
            "Query: Welcher Herrscher veranlasste den Neubau am Standort des Goring House?, Correct Retrieved: True\n",
            "Query: Welche Form hatte das ursprüngliche Buckingham House?, Correct Retrieved: True\n",
            "Query: Welcher König erwarb den Buckingham Palace 1761?, Correct Retrieved: True\n",
            "Query: Wann kaufte König Georg III. die Residenz von Buckingham?, Correct Retrieved: True\n",
            "Query: Was war das BIP von Montana 2016?, Correct Retrieved: True\n",
            "Query: Welche Bodenschätze gibt es in Montana?, Correct Retrieved: True\n",
            "Query: Wann wurde die Kupferproduktion in Anaconda geschlossen?, Correct Retrieved: True\n",
            "Query: Wo in Montana wird vor allem Viehwirtschaft betrieben?, Correct Retrieved: True\n",
            "Query: Wie viel Prozent der Einwohner von Liberia waren 2017 nicht in dem Land geboren?, Correct Retrieved: True\n",
            "Query: Welches Land grenzt im Norden an Liberia?, Correct Retrieved: False\n",
            "Query: Wo in Liberia lebt die Landbevölkerung vor allem?, Correct Retrieved: True\n",
            "Query: Welcher Epoche ist das Konzept Adoleszenz zuzuordnen?, Correct Retrieved: True\n",
            "Query: Nach was benannte Spielberg seine Produktionsfirma Anfang der 1980er?, Correct Retrieved: True\n",
            "Query: Mit wem gründete Spielberg Dreamworks?, Correct Retrieved: True\n",
            "Query: Wann wurde DreamWorks verkauft?, Correct Retrieved: True\n",
            "Query: Wieso verkaufte Spielberg DreamWorks?, Correct Retrieved: True\n",
            "Query: Welches Studio kaufte DreamWorks?, Correct Retrieved: True\n",
            "Query: Wie heißt Spielbergs eigene Produktionsstudio?, Correct Retrieved: False\n",
            "Query: Wann wurde Amblin Partners gegründet?, Correct Retrieved: True\n",
            "Query: Zu welcher Firma gehörte Jeff Skoll, als er mit Spielberg Amblin Partners gründete?, Correct Retrieved: True\n",
            "Query: Wer hat das Logo von Windows 8 entworfen?, Correct Retrieved: True\n",
            "Query: In welcher Schriftart ist das Windows 8-Logo gestaltet?, Correct Retrieved: True\n",
            "Query: Seit wann ist in Illinois die Todesstrafe ausgesetzt?, Correct Retrieved: True\n",
            "Query: Die Todesstrafen von wie vielen Menschen wurden von Gouverneur George Ryan 2003 zu lebenslanger Haft umgewandelt?, Correct Retrieved: True\n",
            "Query: Welche Strafe erhielten 167 Menschen in Illinois 2003 anstatt der Todesstrafe?, Correct Retrieved: True\n",
            "Query: Welche Zeitung schrieb im Vorfeld des Moratoriums der Todesstrafe in Illinois über Probleme in der Justiz?, Correct Retrieved: True\n",
            "Query: Welche Probleme des Justizsystems in Illinois wurde in einem Artikel des Chicago Tribune vor dem Todesstrafenmoratorium bemängelt?, Correct Retrieved: True\n",
            "Query: Welcher Verurteilte wurde nach Recherchen von Studierenden in Illinois 1999 aus dem Todestrakt entlassen?, Correct Retrieved: True\n",
            "Query: Wann wurde die Todesstrafe in Illinois offiziell abgeschafft?, Correct Retrieved: True\n",
            "Query: Wie viele Bundesstaaten der USA hatten 2011 mit Illinois die Todesstrafe abgeschafft?, Correct Retrieved: True\n",
            "Query: Wann begann die Heian-Epoche?, Correct Retrieved: True\n",
            "Query: Wo war der Sitz des japanischen Kaisers in der Heian-Zeit?, Correct Retrieved: True\n",
            "Query: Durch welches Ereignis wird der Beginn der Heian-Zeit markiert?, Correct Retrieved: True\n",
            "Query: Welche Bedeutung hat die Heian-Zeit für die japanische Kultur?, Correct Retrieved: True\n",
            "Query: Was sind berühmte Werke der japanischen Hofdamenliteratur aus der Heian-Zeit?, Correct Retrieved: True\n",
            "Query: Welche japanische Schrift hat ihren Ursprung in der Heian-Zeit?, Correct Retrieved: True\n",
            "Query: Wieso schufen Frauen in der Heian-Zeit eine neue Schrift?, Correct Retrieved: True\n",
            "Query: Welche Familie erlangte in der Heian-Zeit in Japan große Macht?, Correct Retrieved: True\n",
            "Query: Wodurch konnte die Familie Fujiwara in Japan in der Heian-Zeit besonders ihre Macht vergrößern?, Correct Retrieved: True\n",
            "Query: Was ist ein Sessho im japanischen Kaiserreich?, Correct Retrieved: True\n",
            "Query: Welches Amt wurde in Japan 1086 für ehemalige Monarchen eingeführt?, Correct Retrieved: True\n",
            "Query: Was wurde in Japan in der Heian-Zeit als Zahlungsmittel verwendet?, Correct Retrieved: True\n",
            "Query: Welche Klans kämpften in Gempei-Krieg?, Correct Retrieved: False\n",
            "Query: Welcher Klan verlor den Gempei-Krieg?, Correct Retrieved: True\n",
            "Query: Welches Gebiet wollte Österreich an Frankreich übergeben für die Unterstützung im Siebenjährigen Krieg?, Correct Retrieved: False\n",
            "Query: Welches war das umkämpfte Gebiet zwischen Preußen und Österreich im Siebenjährigen Krieg?, Correct Retrieved: True\n",
            "Query: Welche strategische Bedeutung hatte die Okkupation  Sachsens für Preußen?, Correct Retrieved: True\n",
            "Query: Als was wurde ein Single im Canadian Football früher bezeichnet?, Correct Retrieved: True\n",
            "Query: Was ist ein Single im Canadian Football?, Correct Retrieved: True\n",
            "Query: Was ist im Football ein Touchdown?, Correct Retrieved: True\n",
            "Query: Wie viele Punkte gibt ein Touchdown im Football?, Correct Retrieved: True\n",
            "Query: Wie viele Punkte zählte ein Touchdown im Canadian Football vor 1904?, Correct Retrieved: True\n",
            "Query: Wie heißt der Wurf, den ein Team beim Canadian Football nach erfolgreichem Touchdown erhält?, Correct Retrieved: True\n",
            "Query: Von wo wird bei erfolgreichem Touchdown beim Canadian football geworfen?, Correct Retrieved: True\n",
            "Query: Wie heißt der Punkt nach dem Touchdown beim Canadian Football?, Correct Retrieved: True\n",
            "Query: Wann wurde im Canadian Football eine feste Punktezählung eingeführt?, Correct Retrieved: True\n",
            "Query: In welcher Liga spielt Racing Straßburg?, Correct Retrieved: True\n",
            "Query: Wie heißt der Frauenfußballverein von Straßburg?, Correct Retrieved: True\n",
            "Query: Wann hat der Basketballverein aus Straßburg die Meisterschaft gewonnen?, Correct Retrieved: True\n",
            "Query: Auf wann wurde die Ausgabe des neuen 100-Dollar-Scheins verschoben, der 2011 in Umlauf gebracht werden sollte?, Correct Retrieved: True\n",
            "Query: Seit wann werden US-Dollarnoten mit Sicherheitsaufdrucken versehen?, Correct Retrieved: False\n",
            "Query: In welchem Turnus werden US-Dollarnoten neu gestaltet, um die Fälschungssicherheit zu erhöhen?, Correct Retrieved: False\n",
            "Query: Wieso ist der Sicherheitsfaden bei Banknoten fälschungssicher?, Correct Retrieved: True\n",
            "Query: Welche US-Dollarscheine enthalten einen Sicherheitsfaden?, Correct Retrieved: True\n",
            "Query: Was ist das Besondere an Mikroschriften bei Geldscheinen?, Correct Retrieved: True\n",
            "Query: Wieso sind Mikroschriften ein wirksames Mittel gegen Geldfälschungen?, Correct Retrieved: True\n",
            "Query: Wie werden Wasserzeichen erzeugt?, Correct Retrieved: True\n",
            "Query: Mit welchen Sicherheitsmerkmalen sollte der 100-Dollarschein ausgestattet sein, der 2011 in Umlauf gebracht werden sollte?, Correct Retrieved: True\n",
            "Query: Wieso wurde die Ausgabe der 100-Dollarnote von 2011 verschoben?, Correct Retrieved: True\n",
            "Query: Welche Bedeutung hatte das Jagen ab etwa 6500 v.Chr.?, Correct Retrieved: True\n",
            "Query: Wann war das Proto-Neolithikum?, Correct Retrieved: True\n",
            "Query: Wie wurden die Werkzeuge aus Feuerstein in Proto-Neolithikum bearbeitet?, Correct Retrieved: True\n",
            "Query: Aus welcher Epoche stammt das erste nachgewiesene kultivierte Getreide?, Correct Retrieved: False\n",
            "Query: Welche technische Neuerung ist für das Keramische Neolithikum prägend?, Correct Retrieved: True\n",
            "Query: Welche Behausungen wurden im Präkeramischen Neolithikum A von sesshaften Menschen erbaut?, Correct Retrieved: True\n",
            "Query: Was stellen die Kunstgegenstände aus dem PPNA mehrheitlich dar?, Correct Retrieved: False\n",
            "Query: Was sind Idole aus der Jungsteinzeit?, Correct Retrieved: True\n",
            "Query: Für welche Epoche ist erstmals Tierhaltung von Menschen nachgewiesen?, Correct Retrieved: False\n",
            "Query: An welchen Ausgrabungsorten forschten Cauvin, Kenyon und Garstang?, Correct Retrieved: True\n",
            "Query: Was bezeichnet in Mitteleuropa die Kupferzeit?, Correct Retrieved: True\n",
            "Query: Welche technische Errungenschaft wurde in der Kupfersteinzeit entwickelt?, Correct Retrieved: True\n",
            "Query: Wann entdeckte Planck das Wirkungsquantum?, Correct Retrieved: True\n",
            "Query: Was ist das Plancksche Wirkungsquantum?, Correct Retrieved: True\n",
            "Query: Welchen Zweig der Physik etablierte Planck mit der Entdeckung des Wirkungsquantums?, Correct Retrieved: True\n",
            "Query: Welches physikalische Prinzip begründet das Plancksche Wirkungsquantum?, Correct Retrieved: True\n",
            "Query: Wie nannte Planck selbst das Wirkungsquantum?, Correct Retrieved: True\n",
            "Query: Wieso nannte Planck seine Entdeckung Wirkungsquantum?, Correct Retrieved: True\n",
            "Query: In welchem Jahr fing erstmals eine Frau an bei IBM als Fachkraft zu arbeiten?, Correct Retrieved: True\n",
            "Query: wer war 1935 Direktor von IBM?, Correct Retrieved: True\n",
            "Query: Wie viele Personen hatten bis 2019 die Auszeichnung IBM Fellow erhalten?, Correct Retrieved: True\n",
            "Query: Wer hat das die IBM Fellow-Auszeichnung initiiert?, Correct Retrieved: True\n",
            "Query: Welches Merkmal hat IBM 1984 in seine Leitlinien gegen Diskriminierung aufgenommen?, Correct Retrieved: True\n",
            "Query: Welchem Leitsatz folgt IBM seit 1953 bei der Auswahl von Mitarbeitern?, Correct Retrieved: True\n",
            "Query: Was erklärte IBM am 10. Oktober 2005?, Correct Retrieved: True\n",
            "Query: Zu welchem Reich gehörte Ägypten ab 525 v. Chr?, Correct Retrieved: True\n",
            "Query: Zu dem Reich wessen Herrschers gehörte Ägypten ab 332 v. Chr?, Correct Retrieved: True\n",
            "Query: Der Herrschers welches Reiches war Alexander der Große?, Correct Retrieved: True\n",
            "Query: Wann starb Alexander der Große?, Correct Retrieved: True\n",
            "Query: Wer wurde nach Alexander dem Großen König von Ägypten?, Correct Retrieved: True\n",
            "Query: Wie lange herrschten die Nachkommen von Ptolemäus I. in Ägypten?, Correct Retrieved: True\n",
            "Query: Wann wurde Ägypten Teil des römischen Reiches?, Correct Retrieved: True\n",
            "Query: Wer war der letzte Nachfahre des ptolemäischen Herrscherfamilie, der in Ägypten regierte?, Correct Retrieved: True\n",
            "Query: Wann wurde das Römische Reich geteilt?, Correct Retrieved: True\n",
            "Query: Was war die Hauptstadt der ägyptischen Provinz im Römischen Reich?, Correct Retrieved: True\n",
            "Query: Nach welchem Konzil entstand die koptische Kirche?, Correct Retrieved: True\n",
            "Query: Wer war zur Zeit des Konzil von Chalcedon Papst?, Correct Retrieved: True\n",
            "Query: Wie viele Migrationsströme gab es aus Griechenland?, Correct Retrieved: True\n",
            "Query: Was war das Hauptzielland der griechischen Auswanderer zwischen 1850 und 1940?, Correct Retrieved: True\n",
            "Query: Wohin flohen Kaufleute und Gelehrte aus Griechenland unter osmanischer Herrschaft?, Correct Retrieved: True\n",
            "Query: Nach welchem Ereignis im 20. Jhd verstärkte sich die Migration aus Griechenland?, Correct Retrieved: True\n",
            "Query: Was war in der zweiten Hälfte des 20. Jhd Ziel der griechischen Emigranten?, Correct Retrieved: True\n",
            "Query: Als was verstehen sich viele griechisch-stämmigen Menschen im Ausland?, Correct Retrieved: False\n",
            "Query: Wer war Anfang der 1980er Herausgeber von The Sun?, Correct Retrieved: True\n",
            "Query: Mit was wurde Thatcher durch die Queen geehrt?, Correct Retrieved: True\n",
            "Query: Wofür kritisierte die Queen Thatcher 1986 gerüchteweise?, Correct Retrieved: True\n",
            "Query: Welcher Premierminister schrieb Queen Elisabeth II. eine Rolle bei der Abschaffung des Apartheid-Regimes in Südafrika zu?, Correct Retrieved: True\n",
            "Query: Wofür wurde Queen Elisabeth II. 1987 in Kanada kritisiert?, Correct Retrieved: True\n",
            "Query: Was ist der Meeck Lake Accord?, Correct Retrieved: True\n",
            "Query: In welchem Jahr kam es zu einem Putsch auf Fidschi?, Correct Retrieved: True\n",
            "Query: Welches Amt hatte Queen Elisabeth II vor dem Militärputsch von Fidschi 1987 dort?, Correct Retrieved: True\n",
            "Query: Für welchen TV-Auftritt erfuhren die Queen und ihre Familie 1987 Häme?, Correct Retrieved: True\n",
            "Query: Wann hielt Queen Elisabeth die erste Rede vor dem amerikanischen Kongress?, Correct Retrieved: True\n",
            "Query: Was ist der HLA-Komplex?, Correct Retrieved: True\n",
            "Query: Was entdeckte Astrid Fagraeus 1948?, Correct Retrieved: True\n",
            "Query: Wer entdeckte in den 1930ern H-2-Antigene?, Correct Retrieved: True\n",
            "Query: An welchen Tieren forschte Gorer in den 1930ern?, Correct Retrieved: True\n",
            "Query: Was erforschte Gorer in den 1930ern?, Correct Retrieved: True\n",
            "Query: Welche Theorie formulierte Frank Macfarlane Burnet 1957 als Beitrag zur Immunologie?, Correct Retrieved: True\n",
            "Query: Was entdeckten Isaacs und Lindenmann 1957 bei Forschungen zu Virusinfektionen?, Correct Retrieved: True\n",
            "Query: Für was erhielt Stanley Cohen 1986 den Nobelpreis?, Correct Retrieved: True\n",
            "Query: Was wurde als Lymphokine bezeichnet?, Correct Retrieved: True\n",
            "Query: Welcher Begriff ersetzte \"Lymphokine\"?, Correct Retrieved: True\n",
            "Query: Was gilt als Beginn der modernen Immunologie?, Correct Retrieved: True\n",
            "Query: Wer entschlüsselte um 1960 den Aufbau von Antikörpern?, Correct Retrieved: True\n",
            "Query: Welche Immunzellen klassifizierte Jacques Miller?, Correct Retrieved: True\n",
            "Query: Zu welcher Unterteilung der Immunreaktion führten u.a. die Ergebnisse von Jacques Miller?, Correct Retrieved: True\n",
            "Query: Wann erhielten Köhler und Milstein den Nobelpreis für Medizin?, Correct Retrieved: True\n",
            "Query: Welchen Preis erhielten Köhler und Milstein 1984?, Correct Retrieved: True\n",
            "Query: Wann wurde die European Autoimmunity Standardisation Initiative gegründet?, Correct Retrieved: True\n",
            "Query: Wie kann Zink nachgewiesen werden?, Correct Retrieved: True\n",
            "Query: Was entsteht beim Zinknachweis mit Cobaltsalzlösung?, Correct Retrieved: True\n",
            "Query: Für den Nachweis welcher Mengen von Zink wird die Graphitrohr-AAS benutzt?, Correct Retrieved: True\n",
            "Query: Welche Methode benutzt man, um kleine Spuren von Zink nachzuweisen?, Correct Retrieved: True\n",
            "Query: Welchen Kandidaten unterstütze Arnold Schwarzenegger bei den Präsidentschaftswahlen 2008?, Correct Retrieved: True\n",
            "Query: Für welche Partei kandidierte John McCain 2008 als Präsident?, Correct Retrieved: True\n",
            "Query: Wieso war es Arnold Schwarzenegger nicht möglich in den USA als Präsident zu kandidieren?, Correct Retrieved: True\n",
            "Query: Wieso wollte Schwarzenegger 2016 nicht mehr die Republikaner wählen?, Correct Retrieved: True\n",
            "Query: Wieso wollte sich Robert de Niro vor der Wahl 2016 nicht mit Schwarzenegger fotografieren lassen?, Correct Retrieved: True\n",
            "Query: Welche Staffel von The Apprentice moderierte Schwarzenegger?, Correct Retrieved: True\n",
            "Query: Welcher Sender produziert The Apprentice?, Correct Retrieved: True\n",
            "Query: Welche Fernseh-Show moderierte Schwarzenegger 2017?, Correct Retrieved: True\n",
            "Query: Wie wird Zucker für die Bierproduktion gewonnen?, Correct Retrieved: True\n",
            "Query: Wie viel Alkohol hat Bier?, Correct Retrieved: True\n",
            "Query: Wie wird alkoholfreies Bier hergestellt?, Correct Retrieved: True\n",
            "Query: Welche Stoffe werden bei der Herstellung von Bier zugesetzt?, Correct Retrieved: True\n",
            "Query: Was wird bei der Herstellung von Wein und Bier gegärt?, Correct Retrieved: True\n",
            "Query: Welcher Zucker wird bei der Weinproduktion vergoren?, Correct Retrieved: True\n",
            "Query: Wer war verunsichert wegen der Nachricht vom Abschluss des deutsch-sowjetischen Nichtangriffspaktes?, Correct Retrieved: True\n",
            "Query: Welche Folge hatte die Unterzeichnung des deutsch-sowjetischen Nichtangriffspaktes in Frankreich?, Correct Retrieved: True\n",
            "Query: Wann wurde der britisch-polnische Beistandspakt unterschrieben?, Correct Retrieved: True\n",
            "Query: Wann haben Frankreich und England dem Deutschen Reich den Krieg erklärt?, Correct Retrieved: True\n",
            "Query: Warum hat sich die Beziehung zwischen dem Deutschen Reich und der Sowjetunion 1940 verschlechtert?, Correct Retrieved: True\n",
            "Query: Was hat die Errichtung einer zusätzlichen Energiequelle für Bahnstrom in Ostösterreich erforderlich gemacht? , Correct Retrieved: True\n",
            "Query: Wo befindet sich das Umformerwerk Bergern?, Correct Retrieved: True\n",
            "Query: Wie wurde der Standort des Umformerwerkes Bergern ausgewählt?, Correct Retrieved: True\n",
            "Query: Welcher deutscher König war der Förderer verschiedener Kampfspiele und Turniere im Mittelalter?, Correct Retrieved: True\n",
            "Query: Wie viel Prozent der liberianischen Bevölkerung lebt von der Landwirtschaft?, Correct Retrieved: False\n",
            "Query: Was ist die Hauptnahrungsmittel in Liberia?, Correct Retrieved: True\n",
            "Query: Was ist der Name für Maniok in Liberia?, Correct Retrieved: True\n",
            "Query: An welchen Orten in Liberia wird Maniok angebaut?, Correct Retrieved: True\n",
            "Query: Welche in Liberia angebaute Produkte werden in die USA exportiert?, Correct Retrieved: True\n",
            "Query: Wie heißen die zehn staatlichen Forstbezirken in Liberia?, Correct Retrieved: True\n",
            "Query: Was ist eine symptomlose Infektion?, Correct Retrieved: True\n",
            "Query: Was bedeutet stille Feiung bei Infektionen?, Correct Retrieved: True\n",
            "Query: Was ist die Zeitdimension von subklinischen Infektionen?, Correct Retrieved: False\n",
            "Query: Wodurch kennzeichnen sich subklinische Infektionen?, Correct Retrieved: True\n",
            "Query: Wann brechen persistierende Infektionen wieder aus?, Correct Retrieved: True\n",
            "Query: Wie lange überdauern Erreger bei persistierenden Infektionen im Körper?, Correct Retrieved: True\n",
            "Query: Bei welcher Art von Infektion befinden sich Wirt und Erreger in einem Gleichgewicht?, Correct Retrieved: True\n",
            "Query: Wie lange besteht eine latente Infektion?, Correct Retrieved: True\n",
            "Query: Wie gelangen die Erreger tolerierter Infektionen häufig in den Körper?, Correct Retrieved: True\n",
            "Query: Was deutet auf maskierte Infektionen hin?, Correct Retrieved: True\n",
            "Query: Bei welcher Art von Infektion kann der Erreger nicht nachgewiesen werden?, Correct Retrieved: True\n",
            "Query: Welche Krankheitsanzeichen treten bei abortiven Infektionen auf?, Correct Retrieved: True\n",
            "Query: Wie werden manifeste Infektionen auch genannt?, Correct Retrieved: False\n",
            "Query: Was kennzeichnet opportunistische Infektionen?, Correct Retrieved: True\n",
            "Query: Warum hatten die Soldaten der US-Army keinen Erfolg in der Schlacht von Mogadischu?, Correct Retrieved: True\n",
            "Query: Warum wurde die US-amerikanische Einsatzbereitschaft in Somalia endgültig abgebrochen?, Correct Retrieved: True\n",
            "Query: Wann wurde die CIA gegründet?, Correct Retrieved: True\n",
            "Query: Wer war der Vorgänger der CIA?, Correct Retrieved: True\n",
            "Query: Wie wurde die CIA gegründet?, Correct Retrieved: True\n",
            "Query: Wer war der erste CIA-Direktor?, Correct Retrieved: True\n",
            "Query: Wer hat die Stelle des CIA-Direktors am längsten besetzt?, Correct Retrieved: True\n",
            "Query: Wofür war die CIA während des Koreakrieges zuständig?, Correct Retrieved: True\n",
            "Query: Wann begann die CIA mit Spionageflügen im Ausland?, Correct Retrieved: True\n",
            "Query: Wo hat die CIA geheime Operationen während des Vietnamkrieges geführt?, Correct Retrieved: True\n",
            "Query: Wer wurde als erster ehemaliger CIA-Chef zum Präsidenten der USA gewählt?, Correct Retrieved: True\n",
            "Query: Der Versuch eines Attentats 1995 im Hauptquartier der CIA hatte was als Folge? , Correct Retrieved: True\n",
            "Query: Warum ist das Attentat 1995 im Hauptquartier der CIA gescheitert?, Correct Retrieved: True\n",
            "Query: Warum trat der Direktor der CIA George Tenet zurück?, Correct Retrieved: True\n",
            "Query: Seit wann führt die CIA Operationen mit Drohnen aus?, Correct Retrieved: True\n",
            "Query: Warum musste der CIA-Direktor Porter Goss sein Amt Bush abgeben?, Correct Retrieved: True\n",
            "Query: Wer wurde 2009 als neuer CIA-Chef von Barack Obama nominiert?, Correct Retrieved: True\n",
            "Query: Warum ist David Petraeus 2012 von seinem Amt zurückgetreten? , Correct Retrieved: True\n",
            "Query: Wer wurde 2018 zum neuen Außenminister der USA ernannt? , Correct Retrieved: True\n",
            "Query: Wer ist derzeit der CIA-Chef?, Correct Retrieved: True\n",
            "Query: Wann wurde über Sicherheitsrisiken von USB-Geräten berichtet?, Correct Retrieved: True\n",
            "Query: Welche Sicherheitsrisiken kann ein USB-Gerät haben?, Correct Retrieved: True\n",
            "Query: Warum sind von einem USB-Stick ausgelöste  Virusangriffe schwer zu beheben?, Correct Retrieved: True\n",
            "Query: Wie wird macOS gegen Virusangriffe geschützt?, Correct Retrieved: False\n",
            "Query: Warum hilft die Neuinstallation des Betriebssystems bei der Beseitigung von Malware nicht?, Correct Retrieved: True\n",
            "Query: Wer hat eine Lösung zur Schadensbehebung von Virusangriffen 2014 angekündigt?, Correct Retrieved: True\n",
            "Query: Wo haben sich Denker in der Zeit der Aufklärung getroffen?, Correct Retrieved: False\n",
            "Query: Warum wurden während der Aufklärung in Deutschland Lesezirkel gebildet?, Correct Retrieved: True\n",
            "Query: Wie viele Lesegesellschaften gab es Ende des 18. Jahrhunderts in Deutschland?, Correct Retrieved: True\n",
            "Query: Welche literarische Formen zählten zu Hauptverbreitungsformen der Aufklärung?, Correct Retrieved: True\n",
            "Query: In welchen Ländern bildete sich keine Salonkultur während der Aufklärung?, Correct Retrieved: True\n",
            "Query: Welche Frauen waren aktiv während der Frühaufklärung in Deutschland?, Correct Retrieved: True\n",
            "Query: Wie unterscheiden sich Ursäuger von anderen Säugetieren?, Correct Retrieved: True\n",
            "Query: Welcher Körperteil ist typisch für Ursäuger?, Correct Retrieved: True\n",
            "Query: Wie sehen Eier von Ursäugern aus?, Correct Retrieved: True\n",
            "Query: Wie sehen neugeschlüpfte Ursäuger aus?, Correct Retrieved: True\n",
            "Query: In welcher Region lebt das Schnabeltier?, Correct Retrieved: True\n",
            "Query: Welche Gruppe aus Italien ist bekannt in der Welt von Wrestling?, Correct Retrieved: True\n",
            "Query: Was ist die bekannteste italienische Wrestling-Liga?, Correct Retrieved: True\n",
            "Query: Wo hat die WWE die Wrestling-Industrie expandiert?, Correct Retrieved: True\n",
            "Query: Was wird im Nahbereich einer Antenne erzeugt?, Correct Retrieved: True\n",
            "Query: Wann ist Wilhelm IV. gestorben?, Correct Retrieved: True\n",
            "Query: Welche Union endete mit der Thronübernahme durch Victoria?, Correct Retrieved: True\n",
            "Query: Wann hat Victoria den Thron übernommen?, Correct Retrieved: True\n",
            "Query: Wohin verlegte Victoria 1837 ihren Hofstaat?, Correct Retrieved: True\n",
            "Query: Wann ist die Krönung von Victoria stattgefunden?, Correct Retrieved: True\n",
            "Query: Wie fand die Bevölkerung die Prinzessin Victoria?, Correct Retrieved: True\n",
            "Query: Welche Krone war speziell für Victoria angefertigt?, Correct Retrieved: True\n",
            "Query: Warum ist es schwierig eine Definition von Gott aufzustellen?, Correct Retrieved: True\n",
            "Query: Von welchen Wesen wird Gott in einigen Kulturen nicht unterschieden?, Correct Retrieved: True\n",
            "Query: Wie heißen politische Parteien, die die Arbeit freiwillig machen?, Correct Retrieved: True\n",
            "Query: Was zeichnet eine Wählerpartei aus?, Correct Retrieved: True\n",
            "Query: Wie erfolgt die Finanzierung der Wählerparteien?, Correct Retrieved: True\n",
            "Query: Von wem wurden Wählerparteien gegründet?, Correct Retrieved: False\n",
            "Query: Anhänger welcher politischer Strömung waren die meisten Wählerparteien?, Correct Retrieved: False\n",
            "Query: Wer hat die ersten Arbeiterparteien gegründet?, Correct Retrieved: True\n",
            "Query: Was zeichnet eine Mitgliederpartei aus?, Correct Retrieved: True\n",
            "Query: Was sind Beispiele für Volksparteien in Deutschland?, Correct Retrieved: False\n",
            "Query: Was sind Beispiele für Volksparteien in Österreich?, Correct Retrieved: False\n",
            "Query: Aus welcher Sprache kommt Katalanisch?, Correct Retrieved: True\n",
            "Query: Wann und wo wurde die katalanische Sprache zum ersten Mal erwähnt?, Correct Retrieved: True\n",
            "Query: Aus welchem Jahrhundert stammen erste schriftliche Werke in der katalanischer Sprache?, Correct Retrieved: True\n",
            "Query: Wer hat die katalanische Sprache berühmt gemacht?, Correct Retrieved: True\n",
            "Query: Wann wurde die Sprachgrenze des Katalanischen festgelegt?, Correct Retrieved: True\n",
            "Query: Warum ist die katalanische Sprache zwischen dem 13. und 15. Jahrhundert bedeutend geworden?, Correct Retrieved: True\n",
            "Query: Wann erschien das erste katalanische Wörterbuch?, Correct Retrieved: True\n",
            "Query: Welche andere Sprache beinhaltete das erste zweisprachige katalanische Wörterbuch?, Correct Retrieved: True\n",
            "Query: Wo kann man das erste katalanische Wörterbuch im Original finden?, Correct Retrieved: True\n",
            "Query: Wer hatte das erste katalanische Wörterbuch hergestellt?, Correct Retrieved: True\n",
            "Query: Wodurch wurde die katalanische Sprache durch kastilische als Literatursprache verdrängt?, Correct Retrieved: True\n",
            "Query: Wann hat der spanische Erbfolgekrieg stattgefunden?, Correct Retrieved: True\n",
            "Query: Wann hat Katalonien seine politische Eigenständigkeit verloren?, Correct Retrieved: True\n",
            "Query: Wann ist die kastilische Sprache gesetzliche Unterrichtssprache geworden?, Correct Retrieved: True\n",
            "Query: Wie nennt man den Tiefpunkt der katalanischen Sprachgeschichte?, Correct Retrieved: True\n",
            "Query: Wann gewann das Katalanische nach seinem Tiefpunkt wieder an Bedeutung?, Correct Retrieved: True\n",
            "Query: Wie nennt man die Wiedergeburt der katalanischer Sprache?, Correct Retrieved: True\n",
            "Query: Wodurch wurde die Blüte des Katalanischen in den 1930er zerstört?, Correct Retrieved: True\n",
            "Query: Wie wurde die katalanische Sprache in den Anfangsjahren der Franco-Diktatur unterdrückt?, Correct Retrieved: True\n",
            "Query: Wann ist der Diktator Franco gestorben?, Correct Retrieved: True\n",
            "Query: Warum wird die katalanische Sprache seit den letzten 25 Jahren stark von der Regionalregierung gefördert?, Correct Retrieved: True\n",
            "Query: Wie heißt der Prozess der Wiederherstellung der Bedeutung des Katalanischen?, Correct Retrieved: True\n",
            "Query: Wie viel Prozent der in Katalonien lebenden Menschen können Spanisch schreiben?, Correct Retrieved: True\n",
            "Query: Wie viel Prozent der katalanischen Bevölkerung können Katalanisch schreiben?, Correct Retrieved: True\n",
            "Query: Was ist der Beweis dafür, dass das Katalanische sich in den meisten Bereichen der Gesellschaft  durchgesetzt hat?, Correct Retrieved: True\n",
            "Query: Wie haben die Medien das Osmanische Reich im letzten Drittel des 19. Jahrhundert bezeichnet?, Correct Retrieved: True\n",
            "Query: Welche historische Quellen von Hellenismus gibt es?, Correct Retrieved: True\n",
            "Query: Warum sind fast keine schriftliche Werke aus der Zeit des Hellenismus erhalten?, Correct Retrieved: True\n",
            "Query: Welche Autoren aus dem Hellenismus sind fragmentarisch erhalten?, Correct Retrieved: True\n",
            "Query: Wann hat das Militär in Putschen die politische Macht übernommen?, Correct Retrieved: True\n",
            "Query: Mit welchem Ereignis endete die Geschichte des Osmanischen Reiches?, Correct Retrieved: True\n",
            "Query: Wann hat das Osmanische Reich ein Heer gebildet, um die französische Armee aus Ägypten zu drängen?, Correct Retrieved: True\n",
            "Query: Ab wann war es im Osmanischen Reich möglich, das Privateigentum zu besitzen?, Correct Retrieved: True\n",
            "Query: Wann besiegte die ägyptische Armee die osmanische in der Schlacht von Nisibis?, Correct Retrieved: True\n",
            "Query: Wann wurde das Sueskanal fertiggebaut?, Correct Retrieved: True\n",
            "Query: Was wurde in Ägypten im 19.Jahrhundert angebaut, das für Europa interessant war?, Correct Retrieved: True\n",
            "Query: Was führte zu Aufständen am Ende des 19.Jahrhundert in Ägypten?, Correct Retrieved: True\n",
            "Query: In welchem Jahr ist Ägypten der britische Schutzstaat geworden?, Correct Retrieved: True\n",
            "Query: Seit wann herrschte das Osmanische Reich über Ägypten?, Correct Retrieved: True\n",
            "Query: In welche Teile wird North Carolina gegliedert?, Correct Retrieved: True\n",
            "Query: Wie sehen die Böden der atlantischen Küstenebene von North Carolina?, Correct Retrieved: True\n",
            "Query: Wofür kann man die Böden der atlantischen Küstenebene von North Carolina verwenden?, Correct Retrieved: True\n",
            "Query: Was ist \"Outer Banks\" in North Carolina?, Correct Retrieved: True\n",
            "Query: Welche Lagunen umgeben die \"Outer Banks\"?, Correct Retrieved: True\n",
            "Query: Warum gibt es keinen bedeutenden Seehafen in North Carolina?, Correct Retrieved: True\n",
            "Query: Wie heißt der einzige größere Hafen von North Carolina?, Correct Retrieved: True\n",
            "Query: Wie ist die geologische Struktur der atlantischen Küstenebene von North Carolina?, Correct Retrieved: True\n",
            "Query: Was zeichnet die Piedmont-Region von North Carolina aus?, Correct Retrieved: True\n",
            "Query: Wie sieht die Landschaft der Piedmont-Region von North Carolina aus?, Correct Retrieved: True\n",
            "Query: Was ist die geologische Struktur der Piedmont-Region von North Carolina?, Correct Retrieved: True\n",
            "Query: In welchem Teil von North Carolina werden heutzutage verschiedene Baumaterialen abgebaut?, Correct Retrieved: True\n",
            "Query: Wie sehen die Böden in der Piedmont-Region von North Carolina aus?, Correct Retrieved: True\n",
            "Query: Für welche Obstsorten ist die Piedmont-Region bekannt?, Correct Retrieved: True\n",
            "Query: Was bildet die Westgrenze von North Carolina?, Correct Retrieved: True\n",
            "Query: Wie viele Bergzüge bilden die Berge auf dem Gebiet von North Carolina?, Correct Retrieved: True\n",
            "Query: Was ist der größte Gebirgszug in North Carolina?, Correct Retrieved: True\n",
            "Query: Wie werden die Great Smoky Mountains umgangssprachlich bezeichnet?, Correct Retrieved: True\n",
            "Query: Was ist der zweithöchste Gebirgszug in North Carolina?, Correct Retrieved: True\n",
            "Query: Was ist der geologische Bestand vom \"Blue Ridge Belt\"?, Correct Retrieved: True\n",
            "Query: Was ist der älteste Gebirgszug North Carolinas?, Correct Retrieved: True\n",
            "Query: Was ist der wichtigste Wirtschaftszweig der Bergregion von North Carolina?, Correct Retrieved: True\n",
            "Query: Was sind Beispiele für Nutztiere?, Correct Retrieved: True\n",
            "Query: Wie nennt man den Verzehr von Insekten?, Correct Retrieved: True\n",
            "Query: In welchen Ländern werden Insekten verzehrt?, Correct Retrieved: True\n",
            "Query: Welche Insekten können als Haustiere gehalten werden?, Correct Retrieved: True\n",
            "Query: Mit welchen Insekten sind Ameisen verwandt?, Correct Retrieved: True\n",
            "Query: Welche Insekten können als Haustiere gehalten werden?, Correct Retrieved: True\n",
            "Query: Welche Insekten werden in der Pharmazie benutzt?, Correct Retrieved: True\n",
            "Query: Welche Insekten werden als Versuchstiere eingesetzt?, Correct Retrieved: True\n",
            "Query: Welche Insekten spielen eine große Rolle in der Kriminalistik?, Correct Retrieved: True\n",
            "Query: In welcher Produktion können Schildläuse eingesetzt werden?, Correct Retrieved: True\n",
            "Query: Welche Empfindlichkeit haben fotographische Aufnahmematerialen heutzutage? , Correct Retrieved: True\n",
            "Query: Was ermöglicht ein empfindlicherer Film?, Correct Retrieved: True\n",
            "Query: Was ist besser bei nierdigempfindlichen Filmen?, Correct Retrieved: True\n",
            "Query: Welche Zeitung in Großbritannien ist ähnlich zu BILD in Deutschland?, Correct Retrieved: True\n",
            "Query: Welche Art von Zeitung ist \"The Sun\"?, Correct Retrieved: True\n",
            "Query: Was zeichnet eine Boulevardzeitung aus?, Correct Retrieved: True\n",
            "Query: Wer gibt die Zeitung \"The Sun\" heraus?, Correct Retrieved: True\n",
            "Query: Seit wann gibt es eine Sonntagsausgabe von der Zeitung \"The Sun\"?, Correct Retrieved: True\n",
            "Query: Als was arbeitete Edmund Burke von 1765 bis 1766?, Correct Retrieved: True\n",
            "Query: In welcher Organisation war Burke ein Mitglied in London?, Correct Retrieved: True\n",
            "Query: Welche politische Werke stammen von Edmund Burke?, Correct Retrieved: True\n",
            "Query: Was ist das Hauptwerk von Edmund Burke?, Correct Retrieved: True\n",
            "Query: Was beinhaltet das Hauptwerk von Edmund Burke?, Correct Retrieved: True\n",
            "Query: Wovon ist die galicische Musik geprägt?, Correct Retrieved: True\n",
            "Query: Welche international bekannte Musikgruppen spielen traditionelle galicische Musik?, Correct Retrieved: True\n",
            "Query: Nach wem ist der Bezirk Bronx in New York benannt?, Correct Retrieved: True\n",
            "Query: In welchem Jahr ist Bronx ein eigenständiger Stadtbezirk geworden?, Correct Retrieved: True\n",
            "Query: Welche Straftaten gehörten ab den 1960er in Bronx zum Alltag?, Correct Retrieved: True\n",
            "Query: Wann hat überwiegend die Mittelschicht in Bronx gewohnt?, Correct Retrieved: True\n",
            "Query: Was ist das größte menschliche Gen?, Correct Retrieved: True\n",
            "Query: Wie viele Aminosäure hat das größte menschliche Gen?, Correct Retrieved: True\n",
            "Query: Wodurch ist die Region der Mexiko-Stadt gefährdet?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen wurden von einem Erdbeben  1985 in Mexiko-Stadt getötet?  , Correct Retrieved: True\n",
            "Query: Wie viele Gebäude waren von dem Erdbeben 1985 in Mexiko-Stadt geschadet?, Correct Retrieved: True\n",
            "Query: Warum kam es zu so vielen Toten nach dem Erdbeben 1985 in Mexiko-Stadt?, Correct Retrieved: True\n",
            "Query: Wie sieht die Landschaft der Mexiko-Stadt aus?, Correct Retrieved: True\n",
            "Query: Was wird in der Mexiko-Stadt angebaut?, Correct Retrieved: False\n",
            "Query: Welche Metalle sind in der Region der Mexiko-Stadt zu finden?, Correct Retrieved: True\n",
            "Query: Wann erschien der Soundtrack zum Film \"James Bond 007: Spectre\"?, Correct Retrieved: True\n",
            "Query: Wer singt im Soundtrack von \"James Bond 007: Spectre\"?, Correct Retrieved: True\n",
            "Query: Welchen Preis gewann Sam Smith für seinen Soundtrack bei der Oscarverleihung 2016?, Correct Retrieved: True\n",
            "Query: Wann wurde der Staat Rus am Dnepr gegründet?, Correct Retrieved: True\n",
            "Query: Auf welchem Kontinent liegen die US-Bundesstaaten?, Correct Retrieved: True\n",
            "Query: Welche US-Bundesstaaten bilden das \"Kernland\" der USA?, Correct Retrieved: True\n",
            "Query: Wie sieht die Landschaft der USA aus?, Correct Retrieved: False\n",
            "Query: Wie heißt der Vulkan auf Hawaii?, Correct Retrieved: True\n",
            "Query: Warum distanzierte sich die evangelische Kirche von der römisch-katholischen?, Correct Retrieved: True\n",
            "Query: Wie hat man die amerikanischen Anglikaner nach der Unabhängigkeitserklärung genannt?, Correct Retrieved: True\n",
            "Query: Wann sind Waldenser entstanden?, Correct Retrieved: True\n",
            "Query: Welche Gruppen der evangelischen Konfessionsfamilie sind in der Reformationszeit in deutschsprachigen Ländern entstanden?, Correct Retrieved: True\n",
            "Query: Was sind die bekanntesten Reformatoren der Evangelisch-lutherischen Kirche?, Correct Retrieved: True\n",
            "Query: Was sind die bekanntesten Reformatoren der Reformierten Kirche?, Correct Retrieved: True\n",
            "Query: Was sind die bekanntesten Reformatoren der Anglikanischen Kirche?, Correct Retrieved: True\n",
            "Query: Wie waren die deutschen evangelischen Landeskirchen organisiert?, Correct Retrieved: True\n",
            "Query: In welchen Ländern wächst die Anzahl der evangelischen Kirchen besonders stark?, Correct Retrieved: True\n",
            "Query: In welchen Ländern ist die Mehrheit der Bevölkerung evangelisch?, Correct Retrieved: True\n",
            "Query: Wer wird nach der Wiedervereinigung als \"Deutschen\" bezeichnet?, Correct Retrieved: True\n",
            "Query: Warum kann es schwierig sein eine klare Definition von \"Deutschen\" zu geben?, Correct Retrieved: True\n",
            "Query: Was passiert während der Regenzeit in Liberia?, Correct Retrieved: False\n",
            "Query: Was ist die Hauptstadt von Liberia?, Correct Retrieved: False\n",
            "Query: Wie unterschiedet sich die Menge von Niederschlägen in verschiedenen Regionen von Liberia?, Correct Retrieved: False\n",
            "Query: In welchem Bereich von Liberia ist Trockenzeit zu beobachten?, Correct Retrieved: True\n",
            "Query: Wann wurde der USB 1.0 eingeführt?, Correct Retrieved: True\n",
            "Query: Welche Unternehmen haben den USB 1.0 entwickelt?, Correct Retrieved: True\n",
            "Query: Wer hat viel zur Entwicklung vom USB 1.0 beigetragen?, Correct Retrieved: True\n",
            "Query: Welche Fortschritte wurden mit der Herstellung vom ersten USB gemacht?, Correct Retrieved: True\n",
            "Query: Wie viele Sprachen spricht man in Mali?, Correct Retrieved: True\n",
            "Query: Was ist die bedeutendste Sprache in Mali?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen sprechen in Mali Bambara als Muttersprache? , Correct Retrieved: True\n",
            "Query: Warum spricht man im Norden Malis kein Bambara?, Correct Retrieved: True\n",
            "Query: Was ist die Amtssprache Malis?, Correct Retrieved: True\n",
            "Query: Welche Sprachen werden in Mali als nationale Sprachen anerkannt?, Correct Retrieved: True\n",
            "Query: Auf welcher Sprache studiert man in Mali?, Correct Retrieved: True\n",
            "Query: Warum bleibt Französisch eine bedeutende Sprache in Mali?, Correct Retrieved: True\n",
            "Query: Wann wurden Juden in Bern zum ersten Mal erwähnt?, Correct Retrieved: True\n",
            "Query: Was war die Folge des Ritualmordes an einem Kind in Bern 1294?, Correct Retrieved: True\n",
            "Query: Seit wann gibt es in Bern wieder eine jüdische Gemeinde?, Correct Retrieved: True\n",
            "Query: Wann wurde die erste Synagoge in Bern gebaut?, Correct Retrieved: True\n",
            "Query: Wann ist das Fußballteam \"Irish\" aus der University of Notre Dame bekannt geworden?, Correct Retrieved: True\n",
            "Query: Wann gewann das Fußballteam \"Irish\" die nationale Meisterschaft?, Correct Retrieved: True\n",
            "Query: Wie heißt der Film über das Fußballteam \"Irish\"?, Correct Retrieved: True\n",
            "Query: Wie lang ist die Straßenbahnstrecke in Mexiko-Stadt heutzutage?, Correct Retrieved: True\n",
            "Query: Warum ist der Verkehr in der Mexiko-Stadt oft blockiert?, Correct Retrieved: True\n",
            "Query: Was wurde in Mexiko-Stadt unternommen, um den Straßenverkehr zu entlasten?, Correct Retrieved: True\n",
            "Query: Wie viele Linien hat die Metro in Mexiko-Stadt?, Correct Retrieved: True\n",
            "Query: Warum ist die Metro in Mexiko-Stadt heutzutage völlig überfordert?, Correct Retrieved: True\n",
            "Query: Wann wurde die Eisenbahn in Mexiko privatisiert?, Correct Retrieved: True\n",
            "Query: Wann fuhr die erste Pferdestraßenbahn in Mexiko-Stadt?, Correct Retrieved: True\n",
            "Query: Wann fuhr die erste elektrische Straßenbahn in Mexiko-Stadt?, Correct Retrieved: True\n",
            "Query: Was ist der Unterschied zwischen den Deutschstämmigen und Volksdeutschen?, Correct Retrieved: True\n",
            "Query: Wie viele Deutschen leben in der ganzen Welt?, Correct Retrieved: True\n",
            "Query: Wie heißen die ins Ausland gezogene Menschen, die eine deutsche Staatsangehörigkeit besitzen?, Correct Retrieved: True\n",
            "Query: Mithilfe welches Verfahrens kann schwefelfreies Lignin und schwefelfreie Hemicellulose gewonnen werden? , Correct Retrieved: True\n",
            "Query: Was bedeutet Kriegsverbrechen der Kategorie A?, Correct Retrieved: False\n",
            "Query: Wie heißen die beiden internationalen Flughäfen in Tennessee?, Correct Retrieved: True\n",
            "Query: Welche nationale Flughäfen gibt es in Tennessee?, Correct Retrieved: False\n",
            "Query: Welche Sportveranstaltung findet häufig in Miami statt?, Correct Retrieved: True\n",
            "Query: Wann existierte in Miami die Autorennstrecke Bayfront Park?, Correct Retrieved: True\n",
            "Query: Seit wann gibt es den Begriff des religiösen oder spirituellen Naturalismus?, Correct Retrieved: True\n",
            "Query: Was ist unter dem religiösen oder spirituellen Naturalismus zu verstehen?, Correct Retrieved: True\n",
            "Query: Was ist Gott im religiösen Naturalismus?, Correct Retrieved: True\n",
            "Query: Warum trat Vilanova 2013 zurück?, Correct Retrieved: True\n",
            "Query: Wer gewann in der Champions League 2012/13?, Correct Retrieved: True\n",
            "Query: Wie viele Punkte hat Barcelona in der Champions League 2012/13 gesammelt?, Correct Retrieved: True\n",
            "Query: Was ist der Unterschied zwischen dem traditionellen Wrestling und dem europäischen Catchen?, Correct Retrieved: True\n",
            "Query: Wann ist das amerikanische Wrestling in Deutschland populär geworden?, Correct Retrieved: True\n",
            "Query: Inwiefern unterscheidet sich das amerikanische und britische Wrestling?, Correct Retrieved: True\n",
            "Query: Warum war Wrestling 2000 nicht mehr so populär wie früher in Deutschland? , Correct Retrieved: True\n",
            "Query: Welche bekannten Wrestling-Ligen wurden in Deutschland gegründet?, Correct Retrieved: True\n",
            "Query: Welche deutsche Wrestling-Liga hat mit den amerikanischen Wrestling-Organisationen zusammengearbeitet?, Correct Retrieved: True\n",
            "Query: Welche Wrestling-Arten sind heutzutage populär in Deutschland?, Correct Retrieved: True\n",
            "Query: Wonach ist Eisenhower 1961 umgezogen?, Correct Retrieved: True\n",
            "Query: Wann ist Eisenhower in den Ruhestand gegangen?, Correct Retrieved: True\n",
            "Query: Wann ist Eisenhower gestorben?, Correct Retrieved: True\n",
            "Query: Wo fand eine Trauerfeier von Eisenhower statt?, Correct Retrieved: True\n",
            "Query: Warum hat die Bevölkerung angefangen zu wachsen im Hochmittelalter?, Correct Retrieved: True\n",
            "Query: Welches Konflikt gab es im Hochmittelalter?, Correct Retrieved: True\n",
            "Query: Welche Königreiche wurden im Zuge der Christianisierung gegründet?, Correct Retrieved: True\n",
            "Query: Was ist das größte Blasmusikfestival der Welt?, Correct Retrieved: True\n",
            "Query: Wie wird die traditionelle Schweizer Volksmusik bezeichnet?, Correct Retrieved: True\n",
            "Query: Was sind typische schweizerische Instrumente?, Correct Retrieved: True\n",
            "Query: Welche Gruppen sind bekannt für ihre Schweizer Volksmusik?, Correct Retrieved: True\n",
            "Query: Wann wurde der Eidgenössische Jodlerverband gegründet?, Correct Retrieved: True\n",
            "Query: Warum steht der Wasserstoff im Periodensystem in der ersten Hauptgruppe?, Correct Retrieved: True\n",
            "Query: Wie viele Valenzelektronen hat Wasserstoff?, Correct Retrieved: True\n",
            "Query: Wie nennt man chemische Verbindungen mit der Oxidationszahl -1?, Correct Retrieved: True\n",
            "Query: Warum ist der Wasserstoff für die erste Hauptgruppe des Periodensystems nicht typisch?, Correct Retrieved: True\n",
            "Query: Was führte zum Aufstand der Pariser Kommune?, Correct Retrieved: True\n",
            "Query: Wann hat die Revolutionsregierung angefangen in Paris zu regieren?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen wurden während der sogenannten \"blutigen Woche\" in Paris getötet?, Correct Retrieved: True\n",
            "Query: Bis wann war das Leben der Juden in Deutschland erschwert?, Correct Retrieved: True\n",
            "Query: Wer hat den klassischen Empirismus kritisiert?, Correct Retrieved: True\n",
            "Query: Welchen Einfluss hatte Hayek auf die Evolutionsökonomik?, Correct Retrieved: True\n",
            "Query: Aus welchen drei Wurzeln stammen die Werte nach Hayek?, Correct Retrieved: True\n",
            "Query: Wie viele Arten von Ordnungen unterscheidet Hayek?, Correct Retrieved: True\n",
            "Query: Welcher Papst hat als Erster eine Pilgerfahrt ins Heilige Land unternommen?, Correct Retrieved: True\n",
            "Query: Wohin führte die Pilgerfahrt von Paul_VI?, Correct Retrieved: True\n",
            "Query: Wen traf Paul_VI während seiner Pilgerfahrt in Jerusalem?, Correct Retrieved: True\n",
            "Query: Was ist mit Paul_VI während seiner letzten Auslandsreise in Manila passiert?, Correct Retrieved: True\n",
            "Query: Was ist die größte Sprache Indiens?, Correct Retrieved: True\n",
            "Query: Was ist die Hauptsprache Himachal Pradeshs?, Correct Retrieved: True\n",
            "Query: Wie viel Prozent der Bevölkerung in Himachal Pradeshs sprechen Hindi als Muttersprache?, Correct Retrieved: True\n",
            "Query: Welche Sprache verwenden die meisten Menschen in Himachal Pradeshs im Alltag?, Correct Retrieved: True\n",
            "Query: Wie viel Prozent der Bevölkerung in Himachal Pradeshs sprechen Panjabi als Muttersprache?, Correct Retrieved: True\n",
            "Query: Was ist die Hauptsprache des indischen Bundesstaates Punjab?, Correct Retrieved: True\n",
            "Query: In welchem Teil von Himachal Pradeshs beherrscht man tibetobirmanische Sprachen?, Correct Retrieved: True\n",
            "Query: Warum gibt es sehr wenig tibetobirmanische Sprecher in Himachal Pradeshs?, Correct Retrieved: True\n",
            "Query: Wie wird Englisch in Indien verwendet?, Correct Retrieved: True\n",
            "Query: Wie kann man Apps in Windows 8 herunterladen?, Correct Retrieved: True\n",
            "Query: Wer beendete die erste Republik in Nigeria?, Correct Retrieved: True\n",
            "Query: Wie sah die Wirtschaft in den 1970er Jahren in Nigeria aus?, Correct Retrieved: True\n",
            "Query: Wie wurde mit Juden während des Nationalsozialismus umgegangen?, Correct Retrieved: True\n",
            "Query: Nach welchem Gesetz konnten Juden ihre deutsche Nationalität während des Nationalsozialismus verlieren?, Correct Retrieved: True\n",
            "Query: Was bedeutet ''Network Centric Warfare''?, Correct Retrieved: True\n",
            "Query: Wofür interessiert sich Elisabeth II in ihrer Freizeit?, Correct Retrieved: True\n",
            "Query: Mit welchen Päpsten hat sich Elisabeth II getroffen?, Correct Retrieved: True\n",
            "Query: Welche Hundrasse mag Elisabeth II am meisten?, Correct Retrieved: True\n",
            "Query: Warum produzierte die BBC den Film \"Royal Family\"?, Correct Retrieved: True\n",
            "Query: Wie hieß der deutsche Schneider von Elisabeth II?, Correct Retrieved: True\n",
            "Query: In welchem Jahr ist die Prinzessin Diana gestorben?, Correct Retrieved: True\n",
            "Query: Wie viele Staatsbürgerschaften besaß Chopin?, Correct Retrieved: True\n",
            "Query: Wann hat Chopin seinen französischen Reisepass bekommen?, Correct Retrieved: True\n",
            "Query: Warum konnte Chopin eine französische Staatsbürgerschaft bekommen?, Correct Retrieved: True\n",
            "Query: Wann hat Chopin seinen ersten französischen Pass bekommen?, Correct Retrieved: True\n",
            "Query: Welche Opera und Orchestra befinden sich in Tucson?, Correct Retrieved: True\n",
            "Query: Welche Theater gibt es in Tucson?, Correct Retrieved: True\n",
            "Query: Welche Museen gibt es in Tucson?, Correct Retrieved: True\n",
            "Query: Wie viele Bauwerke und Stätte in Tucson sind im National Register of Historic Places angegeben?, Correct Retrieved: True\n",
            "Query: Wie funktioniert Joint-Stereo?, Correct Retrieved: True\n",
            "Query: Wann ist Albanien aus dem Warschauer Pakt ausgetreten? , Correct Retrieved: True\n",
            "Query: Wann sind die Warschauer-Pakt-Staaten in die Tschechoslowakische Sozialistische Republik einmarschiert?, Correct Retrieved: True\n",
            "Query: Wie hoch ist die tägliche Netzfrequenz des Bahnstromnetzes?, Correct Retrieved: True\n",
            "Query: Was bedeutet ein Umformer, der zum Leistungsausgleich eingesetzt wird?, Correct Retrieved: True\n",
            "Query: Wie hoch ist die Sollfrequenz der Bahnstromnetze in Deutschland?, Correct Retrieved: True\n",
            "Query: Welche Arten von Sperrschicht-Feldeffekttransistoren gibt es?, Correct Retrieved: True\n",
            "Query: Wo werden Sperrschicht-Feldeffekttransistoren angewandt?, Correct Retrieved: True\n",
            "Query: Welche Beziehung hat Gott im naturwissenschaftlichen Deismus?, Correct Retrieved: True\n",
            "Query: Was ist die Aufgabe von dem Director of the Central Intelligence Agency?, Correct Retrieved: True\n",
            "Query: Was sind Dialekte im Bezug zu Vögeln?, Correct Retrieved: True\n",
            "Query: Was ist das Ziel der Kommunikation?, Correct Retrieved: True\n",
            "Query: Was ist der Zweck der Kommunikation?, Correct Retrieved: True\n",
            "Query: Was bedeutet Kommunikation  im handlungstheoretischen Kontext? , Correct Retrieved: True\n",
            "Query: In welchem Jahr wurde Straußburg die Hauptstadt von Elsaß-Lothringen?, Correct Retrieved: True\n",
            "Query: Was hat die Unzufriedenheit der elsässischen Bevölkerung nach der Annexion Elsass-Lothringens durch das Deutsche Reich gezeigt?, Correct Retrieved: True\n",
            "Query: Nach wem wurde die \"Kaiser-Wilhelm- Universität\" in Straußburg benannt?, Correct Retrieved: True\n",
            "Query: Welche Architekten haben sich mit der Neugestaltung von Straußburg nach dem Deutsch-Französischen Krieg beschäftigt?, Correct Retrieved: True\n",
            "Query: Wie werden die NPOs finanziert?, Correct Retrieved: True\n",
            "Query: Wie groß ist der jährliche Umsatz von NPOs weltweit?, Correct Retrieved: True\n",
            "Query: Welche Dimensionen zählen für NPOs im Bereich der sozialen Arbeit?, Correct Retrieved: True\n",
            "Query: Wer war der neue Trainer von FC Arcenal 1986?, Correct Retrieved: True\n",
            "Query: Was waren die ersten Schritte von Graham als Trainer von FC Arcenal?, Correct Retrieved: True\n",
            "Query: Wie lange war George Graham der Trainer von FC Arcenal?, Correct Retrieved: True\n",
            "Query: Warum wurde George Graham entlassen?, Correct Retrieved: True\n",
            "Query: Was versteht man unter Verifikationismus?, Correct Retrieved: True\n",
            "Query: Wann ist ein Satz sinnvoll unter der Annahme von Verifikationismus?, Correct Retrieved: True\n",
            "Query: Wohin exportierte Tibet ein Großteil des Holzes in 50ern?, Correct Retrieved: True\n",
            "Query: Was sind die Folgen des hohen Kahlschlags der Tibeter Wälder?, Correct Retrieved: True\n",
            "Query: Wie hat sich die Bevölkerung Tibets entwickelt?, Correct Retrieved: True\n",
            "Query: Warum gab es in Tibet eine Weidenkonkurrenz?, Correct Retrieved: True\n",
            "Query: Wie soll versucht werden die Steppen in Tibet zu entlasten?, Correct Retrieved: True\n",
            "Query: Was brauchte die Südbahn in den 50ern für die Strom Versorgung?, Correct Retrieved: True\n",
            "Query: Wo lag das Umformwerk Auhof?, Correct Retrieved: True\n",
            "Query: Wie viele Umformsätze hatte das Umformwerk Auhof bei der Gründung?, Correct Retrieved: True\n",
            "Query: Wann wurde das Umformwerk Auhof Generalerneuert?, Correct Retrieved: True\n",
            "Query: Mit welcher Ländern schloss England vor den Weltkriegen eine Allianz?, Correct Retrieved: True\n",
            "Query: Welches Land schien 1902 am wahrscheinlichsten der nächste Krieg Gegner Englands zu sein?, Correct Retrieved: True\n",
            "Query: Wann wurde Germanium durch Silizium bei der Produktion von Transistoren ersetzt?, Correct Retrieved: True\n",
            "Query: Woraus wurden bipolare Transistoren zunächst hergestellt?, Correct Retrieved: True\n",
            "Query: Woraus bestehen Feldeffekttransistoren und bipolare Transistoren heutzutage?, Correct Retrieved: True\n",
            "Query: Wofür wird Siliziumgermanium bei Transistoren verwendet?, Correct Retrieved: True\n",
            "Query: Wann kommt Siliziumcarbid bei der Produktion von Transistoren zum Einsatz?, Correct Retrieved: True\n",
            "Query: Wo können Transistoren aus Siliziumcarbid eingesetzt werden?, Correct Retrieved: True\n",
            "Query: Welche Arabischen Herrscher sahen den kurdischen Unabhängigkeitskrieg als etwas gutes?, Correct Retrieved: False\n",
            "Query: Wer war 1996 Premierministier der Türkei?, Correct Retrieved: True\n",
            "Query: Wo schlief Gaddafi meistens bei Auslandsreisen?, Correct Retrieved: True\n",
            "Query: Welche Gruppe schütze Gaddafi oft bei Auslandsreisen?, Correct Retrieved: True\n",
            "Query: Wie hieß das erste Libysche Auto?, Correct Retrieved: True\n",
            "Query: Können sich Schalwellen im Vakuum ausbreiten?, Correct Retrieved: True\n",
            "Query: Wer hat 2013 überprüft wie viele der beliebtesten YouTube-Videos in Deutschland verfügbar sind?, Correct Retrieved: True\n",
            "Query: Wie konnte man in Deutschland gesperrte Videos auf YouTube schauen?, Correct Retrieved: True\n",
            "Query: Wann wurde die Sperre von manchen YouTube-Videos in Deutschland aufgehoben?, Correct Retrieved: True\n",
            "Query: Welche Elemente nahmen die Stoiker für die Substanz Gottes an?, Correct Retrieved: True\n",
            "Query: Welcher christliche Autor hielt Gott für materiell?, Correct Retrieved: True\n",
            "Query: Was spricht laut der Philosophie in der Tradition von Platon und Aristoteles für die Immaterialität Gottes?, Correct Retrieved: True\n",
            "Query: Wo fand die Operation TA der Japaner statt?, Correct Retrieved: True\n",
            "Query: Wie viele starben bei der Operation TA?, Correct Retrieved: True\n",
            "Query: Was war die Operation Desecrate One?, Correct Retrieved: True\n",
            "Query: Seit wann sind die Fürstenstaaten Indiens von dem britischen Protektorat unabhängig?, Correct Retrieved: True\n",
            "Query: In wie viele Gruppen wurden die Staaten Indiens 1950 eingeteilt?, Correct Retrieved: True\n",
            "Query: Wer herrschte über die B-Staaten ab 1950 in Indien?, Correct Retrieved: True\n",
            "Query: Seit wann sind alle indischen Staaten gleichgesetzt?, Correct Retrieved: True\n",
            "Query: Was bekamen die 1956 abgesetzten Herrscher der indischen Staaten als Ausgleich?, Correct Retrieved: True\n",
            "Query: Wie viel elektrischen Strom erzeugt Armenien?, Correct Retrieved: True\n",
            "Query: Wo in Armenien wird der meiste Strom hergestellt?, Correct Retrieved: True\n",
            "Query: Wie viel Erdgas verbraucht Armenien?, Correct Retrieved: True\n",
            "Query: Welche Ebenen von Softwaretests gibt es?, Correct Retrieved: False\n",
            "Query: Durch was ist ein Regel-Abschluss bei Softwaretests definiert?, Correct Retrieved: True\n",
            "Query: Wo ist die Starcevo-Kultur angesiedelt?, Correct Retrieved: True\n",
            "Query: Welche Kultur markiert die Jungsteinzeit in Griechenland?, Correct Retrieved: True\n",
            "Query: In welchem Gebiet wird die Bükker-Kultur verortet?, Correct Retrieved: True\n",
            "Query: Welche Phase der Jungsteinzeit markiert die Theiß-Kultur?, Correct Retrieved: True\n",
            "Query: Welche Kultur prägte die späte Jungsteinzeit in Serbien?, Correct Retrieved: True\n",
            "Query: Wie viele Wappen hat die Stadt Paris?, Correct Retrieved: True\n",
            "Query: Was ist der offizielle Leitspruch von Paris?, Correct Retrieved: True\n",
            "Query: Welche Farbe hat die Flagge von Paris?, Correct Retrieved: True\n",
            "Query: Wofür stehen die Farben in der Pariser Flagge?, Correct Retrieved: True\n",
            "Query: In welcher Sportart war Arnold Schwarzeneggers Vater erfolgreich?, Correct Retrieved: True\n",
            "Query: Welche Sportarten betätigte Arnold Schwarzenegger im Alter von 10 Jahren?, Correct Retrieved: True\n",
            "Query: Wann war Arnold Schwarzenegger das erste Mal in einem Gewichtheber Studio? , Correct Retrieved: True\n",
            "Query: Woher bekam Arnold Schwarzenegger Anfangs sein Wissen über das Bodybuilding?, Correct Retrieved: True\n",
            "Query: Wer war am Anfang seiner Bodybuilding Karriere Arnold Schwarzeneggers Vorbild?, Correct Retrieved: True\n",
            "Query: Was war Arnold Schwarzeneggers erster großer Bodybuilding Wettbewerbs Sieg?, Correct Retrieved: True\n",
            "Query: Mit wie vielen Jahren gewann Arnold Schwarzenegger den Titel Mister Universum zum ersten mal?, Correct Retrieved: True\n",
            "Query: Wann wurde Arnold Schwarzenegger zum zweiten mal \"Mister Universum\"?, Correct Retrieved: True\n",
            "Query: Welcher Bodybuildingverband wurde populärer als NABBA?, Correct Retrieved: True\n",
            "Query: Welchen Platz belegte Arnold Schwarzenegger bei seinem ersten IFBB Meisterschaft?, Correct Retrieved: True\n",
            "Query: Wann gewann Arnold Schwarzenegger zum ersten mal die IFBB Weltmeisterschaft?, Correct Retrieved: True\n",
            "Query: Was war der größte Bodybuilding Titel den man in den 60ern gewinnen konnte?, Correct Retrieved: True\n",
            "Query: Wen musste Arnold Schwarzenegger für seinen ersten Mr. Olympia Titel schlagen?, Correct Retrieved: True\n",
            "Query: Wie oft wurde Arnold Schwarzenegger Mr. Olympia?, Correct Retrieved: True\n",
            "Query: Mit was fing Arnold Schwarzenegger ab 1975 an?, Correct Retrieved: True\n",
            "Query: Wann hörte Arnold Schwarzenegger mit dem BB komplett auf?, Correct Retrieved: True\n",
            "Query: Welche Krankenhäuser zählen zu den Verbund Klinikum Region Hannover?, Correct Retrieved: True\n",
            "Query: Wer versuchte Russlands Einfluss auf Tibet während des Great Games zu hindern?, Correct Retrieved: True\n",
            "Query: Wer führte den britischen Tibetfeldzug an?, Correct Retrieved: True\n",
            "Query: Was war das Ziel des britischen Tibetfeldzugs?, Correct Retrieved: False\n",
            "Query: Was erreichten die Briten mit der Besetzung von der tibetischen Stadt Lhasa?, Correct Retrieved: True\n",
            "Query: Wann einigten sich Russland und England über ihre Interessen in Zentralasien?, Correct Retrieved: True\n",
            "Query: Warum haben die chinesischen Truppen 1911 Tibet verlassen?, Correct Retrieved: True\n",
            "Query: Was ist die Hauptreligion Liberias?, Correct Retrieved: False\n",
            "Query: Was ist Liberias zweit größte Religion?, Correct Retrieved: False\n",
            "Query: Welche Bistümer gibt es in Liberia?, Correct Retrieved: True\n",
            "Query: Wer ist die höchste Person in der Pfingstkirche Asemblies of God, Correct Retrieved: True\n",
            "Query:  Wie groß sind die Zeugen Jehovas in Liberia?, Correct Retrieved: True\n",
            "Query: Wo spielen die Detroit Red Wings heutzutage?, Correct Retrieved: True\n",
            "Query: Welche Mannschaft aus Detroit spielt in der MLB?, Correct Retrieved: True\n",
            "Query: Wer gewann 2012 die MLB?, Correct Retrieved: True\n",
            "Query: Wie heißt Detroits NBA Team?, Correct Retrieved: True\n",
            "Query: Wie viele NBA-Championships konnten die Detroit Pistons gewinnen?, Correct Retrieved: True\n",
            "Query: An welcher Stelle in der Thronfolge war Elisabeth II. bei ihrer Geburt?, Correct Retrieved: True\n",
            "Query: Wan war Elisabeth II. das erste mal im \"Time\" Magazin auf der Titelseite?, Correct Retrieved: True\n",
            "Query: Wer war nach George V. König Englands?, Correct Retrieved: True\n",
            "Query: Warum dankte König Eduard VIII. ab?, Correct Retrieved: True\n",
            "Query: Wer brachte Elisabeth II. Verfassungsgeschichte bei?, Correct Retrieved: True\n",
            "Query: Warum war Elisabeth II. in Pfadfindergruppen? , Correct Retrieved: True\n",
            "Query: Wie viel verdient der Durchschnittliche Haushalt in Seattle?, Correct Retrieved: True\n",
            "Query: Welcher Anteil der Bevölkerung Seattles ist weiß?, Correct Retrieved: True\n",
            "Query: Was sind bekannte Weinbaugebiete um Paris?, Correct Retrieved: True\n",
            "Query: Welche Bakterien können nicht ohne Sauerstoff leben?, Correct Retrieved: True\n",
            "Query: Welche Bakterien sterben von Sauerstoff?, Correct Retrieved: True\n",
            "Query: Was können Bakterien mit Dauerstadium?, Correct Retrieved: True\n",
            "Query: Können Bakterien Photosynthese betreiben?, Correct Retrieved: True\n",
            "Query: Wie ging der Britisch-Amerikanische Krieg 1812 aus?, Correct Retrieved: True\n",
            "Query: Wer war 1812 Präsident der USA?, Correct Retrieved: True\n",
            "Query: Was wollte James Madison mit dem Krieg gegen die Briten erreichen?, Correct Retrieved: True\n",
            "Query: Wo fanden die meisten Schlachten des Britisch-Amerikanischen Krieges von 1812 statt?, Correct Retrieved: True\n",
            "Query: Was ist der elementare Teil beim Coverage im Canadian Football?, Correct Retrieved: True\n",
            "Query: Welche beiden Deckungsarten gibt es beim Canadian Football?, Correct Retrieved: False\n",
            "Query: Wie wurde das Imperial College in London grgründet?, Correct Retrieved: True\n",
            "Query: Wie heißt der Haushund auf Latein?, Correct Retrieved: True\n",
            "Query: Zu welcher Tierart gehört der Haushund?, Correct Retrieved: True\n",
            "Query: Was ist ein Haushund?, Correct Retrieved: True\n",
            "Query: Wo ist der Sitz des französischen Staatspräsidenten?, Correct Retrieved: True\n",
            "Query: Wer entwarf die Pläne für den Der Élysée-Palast?, Correct Retrieved: True\n",
            "Query: Wo liegt der Der Élysée-Palast?, Correct Retrieved: True\n",
            "Query: Wo sammelt sich die Französische Nationalversammlung?, Correct Retrieved: True\n",
            "Query: Welcher Französische Herrscher lies die Bauten von Ange-Jacques Gabriel bauen?, Correct Retrieved: True\n",
            "Query: Was ist Frankreichs Ruhmeshalle?, Correct Retrieved: True\n",
            "Query: Wer ist im Panthéon in Paris bestattet?, Correct Retrieved: True\n",
            "Query: Wann wurde die Stadt Changsha von den Japanern eingenommen?, Correct Retrieved: True\n",
            "Query: Welcher Sieg öffnete den Japanern im Pazifikkrieg Zugang zu den Südostprovinzen Chinas?, Correct Retrieved: True\n",
            "Query: Wann nahm Japan die Stadt Zaoyang ein?, Correct Retrieved: True\n",
            "Query: Wer war 1939 Außenminister der USA?, Correct Retrieved: True\n",
            "Query: Mit welchen Nationen wollte Japan 1939 ein Bündnis eingehen?, Correct Retrieved: False\n",
            "Query: Wo kamen Japans Rohstoffe 1939 hauptsächlich her?, Correct Retrieved: True\n",
            "Query: In welcher Schlacht nutzen die Japaner Giftgas 1939?, Correct Retrieved: True\n",
            "Query: Wo ist Humphrey Gilbert zu Tode gekommen?, Correct Retrieved: True\n",
            "Query: Wer wurde 1603 Englischer König?, Correct Retrieved: True\n",
            "Query: Wer umsegelte als zweiter die Welt?, Correct Retrieved: False\n",
            "Query: Wer regierte 1578 über England?, Correct Retrieved: True\n",
            "Query: Was wollte Humphrey Gilbert in der Karibik erreichen?, Correct Retrieved: True\n",
            "Query: Wer war Halbbruder von Walter Raleigh?, Correct Retrieved: True\n",
            "Query: Was unterscheidet die Waldländer im Westen und Osten der USA?, Correct Retrieved: True\n",
            "Query: Welche Käufer kauften die Laserdisc am Anfang?, Correct Retrieved: True\n",
            "Query: Warum kauften User die Laserdisc?, Correct Retrieved: True\n",
            "Query: Welche deutsche Firmen machten die Laserdisc in Deutschland groß?, Correct Retrieved: True\n",
            "Query: Wo konnte man Laserdiscs in Deutschland kaufen?, Correct Retrieved: True\n",
            "Query: Was war der Gegensatz zwischen VHS Kassetten und Laserdiscs?, Correct Retrieved: True\n",
            "Query: Von was wurde die Laserdisc ersetzt?, Correct Retrieved: True\n",
            "Query: Zu was berechtigt eine Urheberrechtsverletzung?, Correct Retrieved: True\n",
            "Query: Was ist die Basis für die Berechnung des Schadenerstsatzanspruches bei unrechtmäßig verwendeten Fotos?, Correct Retrieved: True\n",
            "Query: An was soll Schadenersatz für verletzte Lizenzen gemessen werden?, Correct Retrieved: True\n",
            "Query: Seit wann darf Alaska bei den US-Präsidentschaftswahlen wählen?, Correct Retrieved: True\n",
            "Query: Welche Partei führt meistens in Alaska bei den Präsidentschaftswahlen?, Correct Retrieved: True\n",
            "Query: Wer war der erfolgreichste Parteilose Kandidat für die US-Präsident Wahl in Alaska?, Correct Retrieved: True\n",
            "Query: Welcher Tierklasse dachte man ist das Vogelgehirn ähnlich?, Correct Retrieved: True\n",
            "Query: Welche Vögel zählen zu den schlausten?, Correct Retrieved: True\n",
            "Query: Wer befasste sich zuerst mit der Theorie der Rule of Law?, Correct Retrieved: True\n",
            "Query: Was gibt es im Pub üblicherweise zu essen?, Correct Retrieved: True\n",
            "Query: Was bekommt der Sieger ein Pub-Quiz-Abends?, Correct Retrieved: True\n",
            "Query: Was ist der pub-crawl?, Correct Retrieved: True\n",
            "Query: Ist in englischen Pubs das Rauchen erlaubt?, Correct Retrieved: True\n",
            "Query: Wie wird in einem Pub miteinander umgegangen? , Correct Retrieved: True\n",
            "Query: Wie kriegt man in einem Pub Getränke?, Correct Retrieved: True\n",
            "Query: Was gibt es in Pubs zu trinken?, Correct Retrieved: True\n",
            "Query: Von welchen Ländern ist Griechenlands Energieversorgung abhängig?, Correct Retrieved: True\n",
            "Query: Wie viel der verbrauchten Energie stellte Griechenland 2010 im eigenen Land her?, Correct Retrieved: True\n",
            "Query: Wie ist Griechenlands Energiehandelsbilanz?, Correct Retrieved: True\n",
            "Query: Wo ist Griechenlands größtes WasserkraftwerK?, Correct Retrieved: True\n",
            "Query: Wie groß ist der Chapultepec-Park?, Correct Retrieved: True\n",
            "Query: In welchem Abschnitt des Chapultepec-Park befindet sich der Zoo?, Correct Retrieved: True\n",
            "Query: Was ist das Monumento a los Niños Héroes?, Correct Retrieved: True\n",
            "Query: Für wen wurde das Castillo im Chapultepec-Park gebaut?, Correct Retrieved: True\n",
            "Query: Was ist Mexiko-Stadts Haupt Zoo?, Correct Retrieved: True\n",
            "Query: Wie heißt die Parkeisenbahn des Chapultepec-Park?, Correct Retrieved: True\n",
            "Query: Wo befindet sich das Grab von Diego Rivera?, Correct Retrieved: True\n",
            "Query: Was verschlechtere 1810 die Beziehung zwischen Frankreich und Russland?, Correct Retrieved: True\n",
            "Query: Welches Land verbündete sich 1812 mit Russland?, Correct Retrieved: True\n",
            "Query: Was war Napoleons Plan für den russischen \"Vaterlänidschen Krieg\"?, Correct Retrieved: True\n",
            "Query: Wie viele Verletzte gab es bei der Schlacht von Borodino?, Correct Retrieved: True\n",
            "Query: Was zwang Napoleon aus Moskau abzuziehen?, Correct Retrieved: True\n",
            "Query: Wie viele Soldaten Napoleons kamen bei seinem Russlandfeldzug zurück?, Correct Retrieved: True\n",
            "Query: Wann wurde die wärmste Temperatur in der Schweiz gemessen?, Correct Retrieved: True\n",
            "Query: Wie oft hagelt es in den Alpen?, Correct Retrieved: True\n",
            "Query: Wie viele Nebeltage gibt es in Zürich heutzutage durchschnittlich?, Correct Retrieved: True\n",
            "Query: Warum gibt es heutzutage um Zürich weniger Nebel als noch vor 50 Jahren?, Correct Retrieved: True\n",
            "Query: Wie hoch lieg der Ort Säntis?, Correct Retrieved: True\n",
            "Query: Wie ist der Durchschnitts Niederschlagwert in der trockensten Region der Schweiz?, Correct Retrieved: True\n",
            "Query: In welcher Jahreszeit regnet es in der Schweiz am meisten?, Correct Retrieved: True\n",
            "Query: Wo schneit es in der Schweiz am wenigsten?, Correct Retrieved: True\n",
            "Query: Was sind die wärmsten Orte der Schweiz?, Correct Retrieved: True\n",
            "Query: Wo wurde die kälteste Temperatur der Schweiz gemessen?, Correct Retrieved: True\n",
            "Query: Welche Stilrichtung kam nach dem Kubismus?, Correct Retrieved: True\n",
            "Query: Wer erfand den Begriff Purismus?, Correct Retrieved: True\n",
            "Query: Wer herrschte 1956 über Ungarn?, Correct Retrieved: True\n",
            "Query: Wo wird Glas benutzt?\n",
            ", Correct Retrieved: True\n",
            "Query: Welche Rolle hatte der FC Barcelona im Straßenbahnboykott von 1951?, Correct Retrieved: True\n",
            "Query: Wer wurde 1968 Präsident des FC Barcelona?, Correct Retrieved: True\n",
            "Query: Was gab der FC Barcelona der Bevölkerung Kataloniens zur Zeit Francos?, Correct Retrieved: True\n",
            "Query: Wo kommt das Motto des FC Barcelona her?, Correct Retrieved: True\n",
            "Query: Was stärkte die liebe zum FC Barcelona als gesellschaftliche Institution für Katalonien?, Correct Retrieved: True\n",
            "Query: Wer war Josip Broz Tito?, Correct Retrieved: True\n",
            "Query: Welches Amt hatte Josip Broz Tito bis er starb?, Correct Retrieved: True\n",
            "Query: Wann trennte sich Josip Broz Tito von der Sowjetunion?, Correct Retrieved: True\n",
            "Query: Wo sind Perlhühner ursprünglich heimisch?, Correct Retrieved: True\n",
            "Query: Wie schwer ist ein Auerhahn?, Correct Retrieved: True\n",
            "Query: Wie viele Jahre trainiert man im Sport ca. um die Höchstleistung abrufen zu können?, Correct Retrieved: True\n",
            "Query: Was ist das Ziel der verlustfreien Datenkompression?, Correct Retrieved: True\n",
            "Query: Auf welcher Theorie beruht die verlustfreie Datenkompression?, Correct Retrieved: True\n",
            "Query: Wie lange ist die Schulpflicht Nigerias?, Correct Retrieved: True\n",
            "Query: Wie viele der Kinder Nigerias im Schulalter gehen zur Schule?, Correct Retrieved: True\n",
            "Query: Welche Probleme haben die Schulen in Nigeria?, Correct Retrieved: True\n",
            "Query: Wo ist ein wichtiges islamisches Bildungszentrum in  Nigeria?, Correct Retrieved: True\n",
            "Query: Wie wird die Urheberrechtsverletzung heutzutage verfoglt?, Correct Retrieved: False\n",
            "Query: Wer wird für Urheberrechts Verletzungen hauptsächlich verfolgt?, Correct Retrieved: False\n",
            "Query: Seit wann ist Iran die offizielle Bezeichnung für den Iran?, Correct Retrieved: True\n",
            "Query: Seit wann hat Russland keine Sommerzeit mehr?, Correct Retrieved: True\n",
            "Query: Wie groß ist die Zeit Verschiebung zwischen der Weltzeit und der Osteuropäischen Normalzeit?, Correct Retrieved: True\n",
            "Query: Wovon hängt die Lage des Faschings ab?, Correct Retrieved: True\n",
            "Query: Wer war im Jahr 600 Papst?, Correct Retrieved: True\n",
            "Query: Wie lange geht die christliche Fastenzeit normalerweise?, Correct Retrieved: True\n",
            "Query: Wann ist der Aschermittwoch?, Correct Retrieved: True\n",
            "Query: Was ist Humanismus?, Correct Retrieved: True\n",
            "Query: Was ist der Renaissance Humanismus?, Correct Retrieved: True\n",
            "Query: Welches Zeitalter war vor dem Humanismus?, Correct Retrieved: True\n",
            "Query: Wie wurde das Mittelalter in der Renaissance angesehen?, Correct Retrieved: True\n",
            "Query: Wodurch kamen die Schriften Griechenlands während des Humanismus in den Westen Europas?, Correct Retrieved: True\n",
            "Query: Wen nahm der Humanismus als Vorbild?, Correct Retrieved: True\n",
            "Query: Wann nannten sich die ersten Menschen Humanisten?, Correct Retrieved: True\n",
            "Query: Was bedeutete der Begriff \"humanista\" als er das erste mal aufkam?, Correct Retrieved: True\n",
            "Query: Welchen Bezug hatte Papst Pius II. zu den Humanisten?, Correct Retrieved: True\n",
            "Query: Was war ein Grund für den Niedergang des Renaissance Humanismus?, Correct Retrieved: True\n",
            "Query: Wo hat die US Army Rekrutierungsstellen?, Correct Retrieved: True\n",
            "Query: Was sind Voraussetzungen um dem dem US Army beizutreten?, Correct Retrieved: True\n",
            "Query: Wie wirbt die US-Army für neue Rekruten?, Correct Retrieved: True\n",
            "Query: Wen Rekrutiert die US-Army seit 2006 häufiger als früher?, Correct Retrieved: True\n",
            "Query: Kann man der US-Army ohne High-School-Abschluss beitreten?, Correct Retrieved: True\n",
            "Query: Welche Naturkatastrophe gibt es in Oklahoma oft?, Correct Retrieved: True\n",
            "Query: Was ist die kälteste gemessene Temperatur Oklahomas?, Correct Retrieved: True\n",
            "Query: Wann wurde die wärmste Temperatur Oklahomas gemessen?, Correct Retrieved: False\n",
            "Query: Welches große Gebirge liegt in Oklahoma?, Correct Retrieved: True\n",
            "Query: Wann regnet es in Oklahoma?, Correct Retrieved: True\n",
            "Query: Was wird benutzt um einen Herzinfarkt Verdacht zu bestätigen?, Correct Retrieved: False\n",
            "Query: An was erkennt man ein Herzinfarkt Verdacht beim EKG?, Correct Retrieved: True\n",
            "Query: Wie viele Amerikaner fühlen sich mehr als einer \"Rasse\" angehörig?, Correct Retrieved: True\n",
            "Query: Wann bekam ein Asteroid Feynmans Namen?, Correct Retrieved: True\n",
            "Query: Wieso trat Feynman aus der National Academy of Sciences aus?, Correct Retrieved: True\n",
            "Query: Welche Auszeichnung bekam Richard Feynman 1954?, Correct Retrieved: True\n",
            "Query: Welche Auszeichnung wird sei 1993 im Andenken an Feynman vergeben?, Correct Retrieved: True\n",
            "Query: Was ist der Russische Begriff für Aufklärung?, Correct Retrieved: True\n",
            "Query: Wer herrschte 1763 über Russland?, Correct Retrieved: True\n",
            "Query: Wer herrschte vor Katharina II. über Russland?, Correct Retrieved: True\n",
            "Query: Wann wurde die Moskauer Universität gegründet?, Correct Retrieved: True\n",
            "Query: In welcher Stadt verbreitete Johann Cristoph Berens die Aufklärung?, Correct Retrieved: True\n",
            "Query: Wer endete die Russische Aufklärung?, Correct Retrieved: True\n",
            "Query: Wer hatte 1647 in der Siedlung Nieuw Amsterdam für Ordnung zu sorgen?, Correct Retrieved: True\n",
            "Query: Was gab der Wall Street ihren Namen?, Correct Retrieved: True\n",
            "Query: Wie hieß die Siedlung die später zu New York City wurde ursprünglich?, Correct Retrieved: True\n",
            "Query: Wer nannte die Nieuw Amsterdam in New York um?, Correct Retrieved: True\n",
            "Query: Wann gaben die Niederländer die Rechte an New York City auf?, Correct Retrieved: True\n",
            "Query: Was handelten Niederländer Anfang des 17. Jhd. mit  Indianern auf dem heutigen Land New York Citys?, Correct Retrieved: True\n",
            "Query: Wer erhielt Anfang des 1614 ein Monopol für den Handel in dem Land des heutigen New York Citys?, Correct Retrieved: True\n",
            "Query: Wer erhielt 1621 einen Freibrief für den Handel in Amerika?, Correct Retrieved: True\n",
            "Query: Wann wurde das Land des heutigen New York Citys kolonialisiert?, Correct Retrieved: True\n",
            "Query: Für wie viel kaufte ein Niederländer den Indianer das Land Manhattans der Legende nach ab?, Correct Retrieved: True\n",
            "Query: Wann lebte Ulrich von Wilamowitz-Moellendorff?, Correct Retrieved: True\n",
            "Query: Welche Einstellung hatte Hans Blüher gegenüber der humanistischen Bildung?, Correct Retrieved: True\n",
            "Query: Wer führte gleichzeitig wie Blüher Kritik an dem neuhumanistischen Schulsystem?, Correct Retrieved: True\n",
            "Query: Wer veröffentlichte \"The Tyranny of Greece over Germany\"?, Correct Retrieved: True\n",
            "Query: Welche Länder sind Teil der insulare Südostasiens?, Correct Retrieved: True\n",
            "Query: Welche Länder sind ein Teil von Südostasien?, Correct Retrieved: True\n",
            "Query: Wer ist die zweite Mannschaft vom FC Everton?, Correct Retrieved: True\n",
            "Query: Wann waren die ersten Spiele der Zweitmannschaft vom FC Everton?, Correct Retrieved: True\n",
            "Query: Wer dominierte die Liga \"The Combination\" im Gründungsjahrzehnt?, Correct Retrieved: True\n",
            "Query: In welcher Liga spielten die Everton Reserves in den 50ern? , Correct Retrieved: True\n",
            "Query: Wie alt sind die Reserve Spieler des FC Everton heutzutage normalerweise?, Correct Retrieved: True\n",
            "Query: Wer trainiert die FC Everton Reserve Mannschaft 2019?, Correct Retrieved: True\n",
            "Query: Welche bekannten Spieler waren in der Everton Academy ausgebildet worden?, Correct Retrieved: True\n",
            "Query: Von was sind private Universitäten abhängig?, Correct Retrieved: True\n",
            "Query: Wer darf in den Deutschland den Titel Universität besitzen?, Correct Retrieved: True\n",
            "Query: Was unterscheidet Staatsphilosophie und politische Philosophie?, Correct Retrieved: True\n",
            "Query: Mit welchen Bereichen beschäftigt sich die politische Philosophie?, Correct Retrieved: True\n",
            "Query: Was muss der Mensch aus seinen natürlicher Umwelt herausziehen?, Correct Retrieved: True\n",
            "Query: Was zeigt das Kulturerzeugnisse nicht nur die Urbedürfnisse des Menschen stillen?, Correct Retrieved: True\n",
            "Query: Wann wurde der KGB in Estland verboten?, Correct Retrieved: True\n",
            "Query: Wann trat Estland der NATO bei?, Correct Retrieved: True\n",
            "Query: Seit wann gibt es in Estland den Euro?, Correct Retrieved: True\n",
            "Query: Was ist sowohl in der Bildenden Kunst als auch Comics wichtig?, Correct Retrieved: True\n",
            "Query: Wer hatte den größten Einfluss auf den Handel in feudalistischen Ständestaat Polen-Litauen?, Correct Retrieved: True\n",
            "Query: Wie schränkte Deutschland die aschkenasischen Juden im 18. Jhd. ein?, Correct Retrieved: True\n",
            "Query: Was für ein politisches System hat Tadschikistan laut Verfassung?, Correct Retrieved: True\n",
            "Query: Wann ist Tadschikistans Nationalfeiertag?, Correct Retrieved: True\n",
            "Query: Zu welchem Land gehört die Provinz Berg-Badachschan?, Correct Retrieved: True\n",
            "Query: Wann wurde Emomalij Rahmon als Präsident Tadschikistans wiedergewählt?, Correct Retrieved: True\n",
            "Query: Wann starb Gulmurod Chalimow?, Correct Retrieved: True\n",
            "Query: Auf was gab es in Tadschikistan am 4. Sept. 2015 einen bewaffneten überfall in Wachdat?, Correct Retrieved: True\n",
            "Query: Wer war Anfang 2015 Vizeverteidigungsminister Tadschikistans?, Correct Retrieved: True\n",
            "Query: Wo starb Abduchalim Nasarsoda?, Correct Retrieved: True\n",
            "Query: Wer war 2016 Generalstaatsanwalt Tadschikistans?, Correct Retrieved: True\n",
            "Query: Wer beschäftigt sich mit den Verschiedenen Emotions Arten?, Correct Retrieved: False\n",
            "Query: Was sind Paul Ekmans sieben Basisemotionen?, Correct Retrieved: True\n",
            "Query: Als was sehen sich die Zeugen Jehovas?, Correct Retrieved: True\n",
            "Query: Wer ist der treue und verständige Sklave der Zeugen Jehovas?, Correct Retrieved: True\n",
            "Query: Wer litt unter der \"Krise des 17. Jhd.\"?, Correct Retrieved: True\n",
            "Query: Wer regierte ende des 16. Jhd. im Osmanischen Reich?, Correct Retrieved: True\n",
            "Query: Was wollten die Engländer von dem Osmanischen Reich?, Correct Retrieved: True\n",
            "Query: Wie standen die Engländer zu islamischen Ländern im 17. Jhd.?, Correct Retrieved: True\n",
            "Query: Wer ist Oberbefehlshaber des Ägyptischen Militärs?, Correct Retrieved: True\n",
            "Query: Wer ernennt die Gouverneure in Ägypten?, Correct Retrieved: True\n",
            "Query: Wer war 2005 Präsident in Ägypten?, Correct Retrieved: True\n",
            "Query: Wieso hat Mohammed Mursi das Amt als Präsident Ägyptens niedergelegt?, Correct Retrieved: True\n",
            "Query: Wer ist Ägyptens Präsident?, Correct Retrieved: True\n",
            "Query: Was für einen Glühfaden nutzen die ersten patentieren Glühlampen?, Correct Retrieved: True\n",
            "Query: Gibt es immer noch Kohlenfadenlampen?, Correct Retrieved: True\n",
            "Query: Welche Farbe hat das Licht von Kohlenfadenlampen?, Correct Retrieved: True\n",
            "Query: Wie wurde aus Osmium ein Glühfaden hergestellt?, Correct Retrieved: True\n",
            "Query: Welche Glühfäden ersetzen die Kohleglühfäden?, Correct Retrieved: True\n",
            "Query: Seit wann wird Florida von Menschen bewohnt?, Correct Retrieved: True\n",
            "Query: Welcher Europäer entdeckte Florida?, Correct Retrieved: True\n",
            "Query: Wann wurde Florida entdeckt?, Correct Retrieved: True\n",
            "Query: Wer sollte die Kolonie \"La Florida\" gründen?, Correct Retrieved: True\n",
            "Query: Weshalb musste Pánfilo de Narváez mit der Erkundung Floridas aufhören?, Correct Retrieved: True\n",
            "Query: Bei was starb De Soto?, Correct Retrieved: True\n",
            "Query: Wie weit entwickelt sind Platzhocker Vögel beim schlüpfen?, Correct Retrieved: True\n",
            "Query: Wo sind Platzhocker Vögel bis sie fliegen können?, Correct Retrieved: True\n",
            "Query: Wer füttert Nesthocker Vögel so lange sie sich nicht selbstständig ernähren können?, Correct Retrieved: True\n",
            "Query: Wo ist der Genetiker Harry Ostrer angestellt?, Correct Retrieved: True\n",
            "Query: Welcher Gruppe ist die DNA von Juden ähnlich?, Correct Retrieved: True\n",
            "Query: Wie viel wollte die EZB monatlich ab März 2015 für den Ankauf von Wertpapieren ausgeben?, Correct Retrieved: True\n",
            "Query: Wie viel wollte die EZB insgesamt für das EAPP ausgeben?, Correct Retrieved: True\n",
            "Query: Wie wurden die Notwendigkeit der Ausgaben für die EAPP der EZB begründet?, Correct Retrieved: True\n",
            "Query: Was wollte die EZB mit dem EAPP erreichen?, Correct Retrieved: True\n",
            "Query: Wie viel investierten die USA in das ähnliche Prinzip, dass die EAPP abschaute, zwischen 2009 und 2014?, Correct Retrieved: True\n",
            "Query: Er war 2015 Italienischer Finanzminister?, Correct Retrieved: True\n",
            "Query: Welche Einstellung hatte der Bundesbank-Präsident gegenüber dem EAPP Programm?, Correct Retrieved: True\n",
            "Query: Was ist das BVerfG?, Correct Retrieved: True\n",
            "Query: Wie heißen Valencias Universitäten?, Correct Retrieved: True\n",
            "Query: Wie viele Studenten hat Valencia?, Correct Retrieved: True\n",
            "Query: Wie viel Geld musste Spanien aufgrund der Sparpolitik 2012 einsparen?, Correct Retrieved: True\n",
            "Query: Wo in Hannover findet man Bauten von Georg Ludwig Friedrich Laves?, Correct Retrieved: True\n",
            "Query: In welchem Gebäude ist der Sitz des Niedersächsischen Landtages?, Correct Retrieved: True\n",
            "Query: Was wird für die Bestimmung des Osterdatums verwendet?, Correct Retrieved: True\n",
            "Query: Wie groß ist der Fehler bei der Bestimmung des Osterdatums?, Correct Retrieved: True\n",
            "Query: Auf was beruhen Browserdatenstatistiken?, Correct Retrieved: False\n",
            "Query: Was übermittelt ein Browser bei jeder Anfrage an den Server womit er sich identifizieren lässt?, Correct Retrieved: True\n",
            "Query: Was ist der meist benutzte Browser laut der Statistik von Netmarketshare von 2019?, Correct Retrieved: True\n",
            "Query: Wie wird das Gewicht von Papier meistens angegeben?, Correct Retrieved: True\n",
            "Query: Wie viel wiegt ein A4 Blatt?, Correct Retrieved: True\n",
            "Query: Wie wird Papier von Pappe unterschieden?, Correct Retrieved: True\n",
            "Query: Was versteht man in den USA unter dem Basisgewicht von Papier?, Correct Retrieved: True\n",
            "Query: Zu welchem Sprachtyp gehört Russisch?, Correct Retrieved: False\n",
            "Query: Wie viele Zeit Typen hat die deutsche Sprache?, Correct Retrieved: False\n",
            "Query: Wie viele Autos werden von Ford südlich von Valencia gebaut?, Correct Retrieved: True\n",
            "Query: Wie viele Arbeitsplätze schafft das Ford Werk südlich von Valencia?, Correct Retrieved: True\n",
            "Query: Welches Regierungssystem hatte Polen ende des 18. Jahrhunderts?, Correct Retrieved: True\n",
            "Query: Was war der Hauptgegner der polnischen Aufklärung?, Correct Retrieved: True\n",
            "Query: Wie lange war Stanslaw August Poniatowskis König von Polen?, Correct Retrieved: True\n",
            "Query: Wer veröffentlichte die erste polnische Enzyklopädie?, Correct Retrieved: True\n",
            "Query: Was ist die Voraussetzung für die Weitergabe von gelernten Aktionen bei Säugetieren?, Correct Retrieved: True\n",
            "Query: Seit wann gibt es die Option eine Ausbildung in Teilzeit zu machen?, Correct Retrieved: True\n",
            "Query: Was wird gebraucht im eine Ausbildung in Teilzeit zu machen?, Correct Retrieved: True\n",
            "Query: Wie viele Stunden wöchentlich muss man in der Ausbildung arbeiten um in der Regulären Zeit fertig werden zu dürfen?, Correct Retrieved: True\n",
            "Query: Wie heißt der Entwicklungszeitraum des Menschen in dem er Geschlechtsreif wird?, Correct Retrieved: False\n",
            "Query: Was ist das bekannteste Essen der valencianischen Küche?, Correct Retrieved: True\n",
            "Query: Was ist eine \"Paellera\"?, Correct Retrieved: True\n",
            "Query: Woher kommt der Reis Bomba?, Correct Retrieved: True\n",
            "Query: Was für ein Gericht ist die Fideuà?, Correct Retrieved: True\n",
            "Query: Was ist ein typisch valencianisches Gericht aus Erdmandeln?, Correct Retrieved: True\n",
            "Query: Aus welchem Land kommt Tigran Petrosjan?, Correct Retrieved: True\n",
            "Query: Wie oft hat die Armenische Fußballmannschaft in der WM Endrunde mitgespielt?, Correct Retrieved: True\n",
            "Query: Was ist Khoren Gevor größter Titel?, Correct Retrieved: True\n",
            "Query: Welche Staatsbürgerschaft verlor Arthur Abraham?, Correct Retrieved: True\n",
            "Query: Was erschwerte die Entwicklung der Zentralafrikanischen Republik bis zur Unabhängigkeit hauptsächlich?, Correct Retrieved: True\n",
            "Query: Welche großen Probleme entstanden in der Zentralafrikanischen Republik seit der Unabhängigkeit?, Correct Retrieved: False\n",
            "Query: Wie viel der Einwohner der Zentralafrikanischen Republik leben auf dem Land?, Correct Retrieved: True\n",
            "Query: Was ist größte Wirtschaftszweig in der Zentralafrikanischen Republik?, Correct Retrieved: True\n",
            "Query: Wie sieht die Handelsbilanz der Zentralafrikanischen Republik aus?, Correct Retrieved: False\n",
            "Query: Wie viele Touristen gab es in der Zentralafrikanischen Republik 2005?, Correct Retrieved: True\n",
            "Query: Zu wem gehört Uramin?, Correct Retrieved: True\n",
            "Query: Was brauch man seit 2004 beim EU-Grenzübertritt für seinen Hund?, Correct Retrieved: True\n",
            "Query: Seit wann wurde in Pennsylvania niemand mehr hingerichtet?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen sind in Pennsylvania in einer Todeszelle und warten auf die Hinrichtung?, Correct Retrieved: True\n",
            "Query: Wer war 2007 Gouverneur von Pennsylvania?, Correct Retrieved: True\n",
            "Query: Wer wurde nach Ed Rendell Gouverneur Pennsylvanias?, Correct Retrieved: True\n",
            "Query: Wer wurde nach Tom Corbett Gouverneur Pennsylvanias?, Correct Retrieved: True\n",
            "Query: Welche Haltung zur Todesstrafe hatte Tom Corbett während seiner Amtszeit als Gouverneur?, Correct Retrieved: True\n",
            "Query: Welcher US-Bundestaat hat im Verhältnis zu den Einwohner am wenigsten Hinrichtungen?, Correct Retrieved: True\n",
            "Query: Welche Universität war maßgebend beteiligt bei der ersten Unabhängigkeit Estlands?, Correct Retrieved: True\n",
            "Query: Wann wurde Estland das erste mal Unabhängig?, Correct Retrieved: True\n",
            "Query: Wann trat Estland dem Völkerbund bei?, Correct Retrieved: True\n",
            "Query: Welche Kapazität hat eine Leidener Flasche, Correct Retrieved: True\n",
            "Query: Aus was wird eine Leidener Flasche gebaut?, Correct Retrieved: True\n",
            "Query: Was ist der Isolator bei einer Leidener Flasche?, Correct Retrieved: True\n",
            "Query: Wie wurde das Prinzip der Leidener Flasche entdeckt?, Correct Retrieved: True\n",
            "Query: Was schaffte Benjamin Franklin mit der Leidener Flasche und einem Drachen?, Correct Retrieved: True\n",
            "Query: Wie viele Einwohner hat die Metropolregion Greater Boston?, Correct Retrieved: True\n",
            "Query: Zu welcher Metropolregion gehört Brookline?, Correct Retrieved: True\n",
            "Query: Wer ergänzte das Modell eines Kurzzeitgedächtnis?, Correct Retrieved: True\n",
            "Query: Haben Tiere im Vergleich zu Menschen oft einen Herzinfakt?, Correct Retrieved: False\n",
            "Query: Welche Währungen sind Teil des Vergleich Korbes des USDX, Correct Retrieved: True\n",
            "Query: Mit wie vielen Währungen wird der US-Dollar beim USDX verglichen?, Correct Retrieved: True\n",
            "Query: Wann war die Glorious Revolution in England?, Correct Retrieved: True\n",
            "Query: Wofür setzte sich John Milton während der Aufklärung ein?, Correct Retrieved: True\n",
            "Query: War die Glorious Revolution gewaltsam?, Correct Retrieved: True\n",
            "Query: Woher kam König Wilhelm III.?, Correct Retrieved: True\n",
            "Query: Wer wurde 1689 König Englands?, Correct Retrieved: True\n",
            "Query: Wann war Howard Kendall Trainer vom FC Everton?, Correct Retrieved: True\n",
            "Query: In welcher Position spielte Howard Kendall beim FC Everton?, Correct Retrieved: True\n",
            "Query: In welcher Liga spielten die Blackburn Rovers als Howard Kendall Trainer wurde?, Correct Retrieved: True\n",
            "Query: Wie ging das Fünftrunden Pokalspiel Rückspiel gegen Oxford United aus?, Correct Retrieved: True\n",
            "Query: Wie lange war der FC Everton ungeschlagen nach dem Sieg gegen Oxford United im fünftrunden Pokalspiel?, Correct Retrieved: True\n",
            "Query: Wer gewann 1984 den FA Cup?, Correct Retrieved: True\n",
            "Query: Wer schoss die Tore im FA Cup Pokalfinale 1984?, Correct Retrieved: True\n",
            "Query: Gegen wen spielte der FC Everton 1984 im FA Cup Pokalfinale?, Correct Retrieved: True\n",
            "Query: Wer wurde in der Saison 1984/85 von der PFA zu Englands Fußballer des Jahres gewählt?, Correct Retrieved: True\n",
            "Query: Wer war beim FC Everton Kapitän in der Saison 1984/85, Correct Retrieved: True\n",
            "Query: Von welchem Verein wechselte Pat Van Den Hauwe zum FC Everton, Correct Retrieved: True\n",
            "Query: Wer gewann die englische Fußball Meisterschaft in der Saison 1984/85, Correct Retrieved: True\n",
            "Query: Wer gewann 1985 den FA Cup?, Correct Retrieved: True\n",
            "Query: Zu welchem Verein wechselte Gary Lineker 1986?, Correct Retrieved: True\n",
            "Query: zum wievielten mal hintereinander stand der FC Everton 1986 im FA Cup Finale?, Correct Retrieved: True\n",
            "Query: Für welche Positionen wurde 1986 beim FC Everton hauptsächlich Spieler verplfichtet?, Correct Retrieved: True\n",
            "Query: Die wievielte Meisterschaft gewann der FC Everton 1987, Correct Retrieved: True\n",
            "Query: Welchen Verein trainierte Howard Kendall nach dem FC Everton?, Correct Retrieved: True\n",
            "Query: wann gab es in der Antarktis die ersten Eisflächen?, Correct Retrieved: True\n",
            "Query: welche Erdepoche war vor Miozän?, Correct Retrieved: True\n",
            "Query: Wann ging es zur Erdepoche Miozän über?, Correct Retrieved: True\n",
            "Query: Wann trennte sich die Antarktis von Südamerika?, Correct Retrieved: True\n",
            "Query: Was war vor dem Eis in der Antarktis?, Correct Retrieved: True\n",
            "Query: Weshalb gibt es kaum Pflanzen in der Antarktis?, Correct Retrieved: True\n",
            "Query: Was ist das Gegenteil von Glaziale?, Correct Retrieved: True\n",
            "Query: Haben wir im Moment eine Warm- oder Kaltzeit?, Correct Retrieved: False\n",
            "Query: Wann wurde Fantastic Four #176 veröffentlicht?, Correct Retrieved: True\n",
            "Query: Wo konnte man den Namen Marvel Comics in den Comics von Marvel Comics wieder finden?, Correct Retrieved: True\n",
            "Query: Wo steht der Schiedsrichter beim Canadian Football vor dem Snap?, Correct Retrieved: True\n",
            "Query: Wer zählt mit dem Schiedsrichter vor dem Snap das Down beim Kanadischen Football?, Correct Retrieved: True\n",
            "Query: Wer überwacht vor dem Snap die Bewegungen der Offensive-Line-Spieler auf seiner Seite beim Kanadischen Football?, Correct Retrieved: True\n",
            "Query: Welcher Teil des Schiedsrichter Teams überwacht beim Kanadischen Football die Auswechslungen?, Correct Retrieved: True\n",
            "Query: Wer ist beim Kanadischen Football für die Kontrolle der 20-Sekunden-Uhr zuständig?, Correct Retrieved: True\n",
            "Query: Wo steht in dem Österreichischem Gesetz wie man Haushunde halten darf?, Correct Retrieved: False\n",
            "Query: Wie oft muss ein Haushund in Österreich täglich mindestens ausgeführt werden?, Correct Retrieved: True\n",
            "Query: Ab wann darf man in Österreich Welpen von der Mutter entfernen?, Correct Retrieved: True\n",
            "Query: Wie hoch ist die Strafe wenn man den Kot seines Hundes in Wien nicht entfernt?, Correct Retrieved: True\n",
            "Query: Was machten die USA gegen die Piraten der  Barbareskenstaaten?, Correct Retrieved: True\n",
            "Query: Warum brauchten die Amerikaner eine eigene See Armee?, Correct Retrieved: False\n",
            "Query: Wer war 1785 der US-Botschafter in Frankreich?, Correct Retrieved: True\n",
            "Query: Auf welche Art wollten die Amerikaner die Piraterie der Barbareskenstaaten anfangs verhindern?, Correct Retrieved: True\n",
            "Query: Wie viel kosteten die Tribut- und Lösegeldzahlungen die USA 1800?, Correct Retrieved: True\n",
            "Query: Wer wurde 1801 Präsident der USA?, Correct Retrieved: True\n",
            "Query: Über welche Schiffe hatte Edward Prieble den Oberbefehl im ersten Barbareskenkrieg?, Correct Retrieved: True\n",
            "Query: Wann war die Schlacht von Derna?, Correct Retrieved: True\n",
            "Query: Wann endete der Amerikanisch-Tripolitanische-Krieg?, Correct Retrieved: True\n",
            "Query: Ab wann herrschte in Myanmar ein Militärdiktatur?, Correct Retrieved: True\n",
            "Query: Wie nannte sich die Militärdiktatur in Myanmar?, Correct Retrieved: True\n",
            "Query: Aus wie vielen Ministern bestand das Kabinett während der Militärdiktatur in Myanmar?, Correct Retrieved: True\n",
            "Query: Wie viele Provinzen hat Galicien?, Correct Retrieved: True\n",
            "Query: Wie viel Prozent der Fläche Spaniens hat Galicien?, Correct Retrieved: True\n",
            "Query: Wie viel Prozent der Ortschaften Spaniens liegen in Galicien?, Correct Retrieved: True\n",
            "Query: Wie viele Flugstunden überlebte die Hündin Laika in der Erdumlaufbahn?, Correct Retrieved: True\n",
            "Query: Woran starb die Hündin Laika?, Correct Retrieved: True\n",
            "Query: Was war das \"Hilton Assignment\"?, Correct Retrieved: True\n",
            "Query: Wann wurde das \"Hilton Assignment\" ausgeführt?, Correct Retrieved: True\n",
            "Query: Wer opferte 1988 sein Leben um Gaddafi vor einem Anschlag zu retten?, Correct Retrieved: True\n",
            "Query: Was hat Die Sowjetunion 1943 mit der Tschechoslowakei geschlossen?, Correct Retrieved: True\n",
            "Query: Wie lange waren das Abkommen der Sowjetunion und der DDR vom 12. März 1957 gültig?, Correct Retrieved: True\n",
            "Query: Wer wollte 1963 dem Warschauer Pakt beitreten?, Correct Retrieved: True\n",
            "Query: Warum wäre für den beitritt der Mongolischen Volksrepublik zum Warschauer Pakt ein Sonderprotokoll nötig gewesen?, Correct Retrieved: True\n",
            "Query: Warum ist die Mongolische Volksrepublik nicht dem Warschauer Pakt beigetreten?, Correct Retrieved: True\n",
            "Query: Was hat die Mongolische Volksrepublik anstatt eines Beitritts in den Warschauer Pakt bekommen?, Correct Retrieved: True\n",
            "Query: Wofür steht KSZE?, Correct Retrieved: True\n",
            "Query: Womit kann man bei der \"Xbox Live Arcade\" spiele kaufen?, Correct Retrieved: True\n",
            "Query: Wie lange kann ein aus dem \"Xbox Live Arcade\" gekauftes Spiel gespielt werden?, Correct Retrieved: True\n",
            "Query: Welches Spiel ist bei manchen Xbox Versionen bereits vorinstalliert?, Correct Retrieved: True\n",
            "Query: Welches Spiel ist im \"Xbox Live Arcade\" bis jetzt Bestseller?, Correct Retrieved: True\n",
            "Query: Welche Sportart wird in der Minor League gespielt?\n",
            ", Correct Retrieved: True\n",
            "Query: Wie viele Skigebiete hat Montana?, Correct Retrieved: True\n",
            "Query: Warum tragen Menschen Kleidung?, Correct Retrieved: True\n",
            "Query: Welches Kleidungsstück schütz bei der Handhabung einer Motorsäge?, Correct Retrieved: True\n",
            "Query: Was ist das Problem mit zu eng anliegender Kleidung?, Correct Retrieved: True\n",
            "Query: Wer führte das Deutsche Militär während der Deutsch Französischen Kriege an?, Correct Retrieved: True\n",
            "Query: Wie viele der deutschen Pferde starben während des Deutsch Französischen Krieges?, Correct Retrieved: True\n",
            "Query: Wie viele Truppen hatten die Deutschen insgesamt im Deutsch Französischen Krieg?, Correct Retrieved: True\n",
            "Query: Wer wollte seinen Patriotismus Deutschland gegenüber durch die Teilnahme am Deutsch-Französischen-Krieg zeigen?, Correct Retrieved: True\n",
            "Query: Wie viele jüdische Soldaten hatte Deutschland im Deutsch-Französischen-Krieg?, Correct Retrieved: True\n",
            "Query: Was war der eigentliche Plan der Franzosen im Deutsch-Französischen-Krieg?, Correct Retrieved: True\n",
            "Query: Ist Frankreich offensiv, oder defensiv an den Deutsch-Französischen-Krieg herangegangen?, Correct Retrieved: True\n",
            "Query: Wie viele Truppen hatten die Franzosen am Anfang des Deutsch-Französischen-Krieges?, Correct Retrieved: True\n",
            "Query: Wo war der Vorteil der Französischen Ausrüstung im Deutsch-Französischen-Krieg?, Correct Retrieved: True\n",
            "Query: Ab wann führte der preußische Generalstab eine eigene Eisenbahnsektion?, Correct Retrieved: True\n",
            "Query: Wie lange brauchten die Franzosen um für den Deutsch-Französischen-Krieg Kriegsbereit zu sein?, Correct Retrieved: True\n",
            "Query: Wie viele Kilometer hat das Straßennetz Portugals 2008?, Correct Retrieved: True\n",
            "Query: Wer unterhält die kostenpflichtigen Straßen Portugals größtenteils?, Correct Retrieved: True\n",
            "Query: Was ist Exergie?, Correct Retrieved: True\n",
            "Query: Wie kann der exergetische Anteil bei einer konstant liegenden Wärmequelle berechnet werden?, Correct Retrieved: True\n",
            "Query: Was wird für die Berechnung der Carnot-Wirkungsgrad Methode benötigt?, Correct Retrieved: True\n",
            "Query: Wie viele Regionen hatte Eritrea vor der Verwaltungsreform von 1996?\n",
            ", Correct Retrieved: True\n",
            "Query: Welches Land kolonialisierte Eritrea?, Correct Retrieved: True\n",
            "Query: Was ist die Hauptsatd großbritanniens, Correct Retrieved: True\n",
            "Query: Wie sieht die geologische Beschaffenheit Südostenglands aus?, Correct Retrieved: True\n",
            "Query: In welchem Teil von Großbritannien liegt London?, Correct Retrieved: True\n",
            "Query: Welche Völker haben versucht, England zu erobern?, Correct Retrieved: False\n",
            "Query: Wann wurde die erste Person in Alabama hingerichtet?, Correct Retrieved: True\n",
            "Query: Was war ab 1927 die beliebteste Hinrichtungsmethode in Alabama?, Correct Retrieved: True\n",
            "Query: Welcher US-Staat ist der einzige bei dem der Richter Die Todesstrafe trotz anderem Urteil der Jury aussprechen kann?, Correct Retrieved: True\n",
            "Query: Wofür steht Grün als Signalfarbe?, Correct Retrieved: True\n",
            "Query: Welche Farbe wird benutzt um Vorgänge zu zeigen, die erlaubt sind?, Correct Retrieved: True\n",
            "Query: Was ist eine Grünewelle?, Correct Retrieved: False\n",
            "Query: Welche Hierarchiestufe hat Grün in deutschen Ämtern bei deren Farbcode?, Correct Retrieved: True\n",
            "Query: Wann wurde die Leitlinie der AWMF zu Begutachtung von Schmerz zuletzt aktualisiert?, Correct Retrieved: True\n",
            "Query: Wofür ist die Leitlinie der AWMF wie Ärzte Schmerz begutachten sollen?, Correct Retrieved: True\n",
            "Query: Wo leben deutschstämmige in Tadschikistan heutzutage größteils?, Correct Retrieved: True\n",
            "Query: Wer bewohnt heute die von Deutschen gegründete Stadt Taboschar in Tadschikistan?, Correct Retrieved: True\n",
            "Query: In welcher Stadt ist die deutsche Botschaft in Tadschikistan?, Correct Retrieved: True\n",
            "Query: Wie werden die Alpen in Österreich, Südtirol und Deutschland unterteilt?, Correct Retrieved: True\n",
            "Query: Warum werden die Alpen in \"West-\" und \"Ostalpen\" unterteilt?, Correct Retrieved: True\n",
            "Query: Was ist Programmiersprachen ähnlich?, Correct Retrieved: True\n",
            "Query: Wie heißt die Legislative von Rajasthan?\n",
            ", Correct Retrieved: True\n",
            "Query: Wie lange ist die Amtszeit Abgeordneter der Legislative Rajasthans?, Correct Retrieved: True\n",
            "Query: Wo ist der Sitz der Legislative Rajasthans?, Correct Retrieved: True\n",
            "Query: Wer wählt den Regierungschefs Rajasthans?, Correct Retrieved: True\n",
            "Query: Wer steht über dem Regierungschefs Rajasthans in Rajasthans?, Correct Retrieved: True\n",
            "Query: Wovon ist Malis Literatur stark beeinflusst?, Correct Retrieved: True\n",
            "Query: Mali war Kolonie von welchem Land?, Correct Retrieved: False\n",
            "Query: In welche Sprache ist die meiste moderne Literatur Malis geschrieben?, Correct Retrieved: True\n",
            "Query: Wer ist der Vater frankophoner malischer Literatur?, Correct Retrieved: True\n",
            "Query: Welches Parteisystem hat Mali heutzutage?, Correct Retrieved: False\n",
            "Query: Was ist der Unterschied zwischen der CIA und einem Nachrichtendienst?, Correct Retrieved: True\n",
            "Query: Inwiefern unterscheiden sich die CIA und NSA?, Correct Retrieved: True\n",
            "Query: In welchen Jahren fand in Hannover der Evangelische Kirchentag statt?, Correct Retrieved: True\n",
            "Query: Was gehört zum Stadtkirchenverband Hannover?, Correct Retrieved: True\n",
            "Query: Was sind Lon Fullers acht Prinzipien einer Rule of Law?, Correct Retrieved: True\n",
            "Query: Was sind Orphan-Gene?, Correct Retrieved: True\n",
            "Query: Was unterscheidet Orphangene von anderen Genen?, Correct Retrieved: True\n",
            "Query: Wie viele Gene haben Menschen, die bei Schimpansen nicht vorkommen?, Correct Retrieved: True\n",
            "Query: Wie viele Gene haben Schimpansen, die bei Menschen nicht vorkommen?, Correct Retrieved: True\n",
            "Query: Seit wann gibt es in Hannover einen Oberbürgermeister, der direkt gewählt wird?, Correct Retrieved: True\n",
            "Query: Wie lange sollte die Amtszeit von Stefan Schostok dauern?, Correct Retrieved: True\n",
            "Query: Warum hat Stefan Schostok sein Amt früher verlassen?, Correct Retrieved: True\n",
            "Query: Wer wurde als neuer Oberbürgermeister Hannovers 2019 ausgewählt?, Correct Retrieved: True\n",
            "Query: Was ist die Aufgabe des Oberbürgermeisters in Hannover?, Correct Retrieved: True\n",
            "Query: Wie viele Einwohner hat Thüringen?, Correct Retrieved: True\n",
            "Query: Wie viele Bewohner Thüringens kommen aus dem Ausland?, Correct Retrieved: True\n",
            "Query: In welchem Land liegt das Zentrum des alten Persiens heutzutage?, Correct Retrieved: True\n",
            "Query: Welches Gebirge ist nördlich des Irans?, Correct Retrieved: True\n",
            "Query: Welche Länder liegen östlich des Irans?, Correct Retrieved: True\n",
            "Query: Wie viele iranischstämmige Menschen leben derzeit außerhalb des Iran?, Correct Retrieved: True\n",
            "Query: Wohin wandert die iranische Bevölkerung aus?, Correct Retrieved: True\n",
            "Query: Was ist das Ergebnis der Auswanderung junger Menschen aus Iran? , Correct Retrieved: True\n",
            "Query: Wie viele Ausländer lebten 2011 in Iran?, Correct Retrieved: True\n",
            "Query: Woher kommen die meisten Ausländer in Iran?, Correct Retrieved: True\n",
            "Query: Warum können sich Afghanen leicht im Iran integrieren?, Correct Retrieved: True\n",
            "Query: Welche andere Nationen außer Afghanen leben im Iran?, Correct Retrieved: True\n",
            "Query: Wer wanderte nach North Carolina Anfang des 20. Jahrhundert ein?, Correct Retrieved: True\n",
            "Query: Welche Gebiete in North Carolina wurden von den schottisch-irischen und nord-englischen Einwanderern besiedelt?, Correct Retrieved: True\n",
            "Query: Wer siedelte östlich des heutigen Fayetteville im 18. Jahrhundert? , Correct Retrieved: True\n",
            "Query: An welchem Ort von North Carolina haben sich die Hugenotten und Deutschschweizer niedergelassen?, Correct Retrieved: True\n",
            "Query: Was ist der Unterschied zwischen elektrischen und reziprok- magnetischen Antennen?, Correct Retrieved: True\n",
            "Query: Wie hoch ist der Feldwellenwiderstand im freien Raum?, Correct Retrieved: True\n",
            "Query: Wann begann Frankreich Mali zu erobern?, Correct Retrieved: True\n",
            "Query: Warum wollte Frankreich Mali erobern?, Correct Retrieved: True\n",
            "Query: Wer war der erste Gouverneur der Kolonie Französisch- Sudan?, Correct Retrieved: True\n",
            "Query: Was war die Hauptstadt der Kolonie Französisch- Sudan?, Correct Retrieved: True\n",
            "Query: Wann wurde die Bahnlinie nach Dakar in Mali fertig gestellt?, Correct Retrieved: True\n",
            "Query: Was garantierte das aktive und passive allgemeine Wahlrecht im kolonisierten Mali?, Correct Retrieved: True\n",
            "Query: Wann wurde das Frauenwahlrecht im kolonisierten Mali eingeführt?, Correct Retrieved: True\n",
            "Query: Wann haben die Kolonien Senegal und Französisch- Sudan ihre Unabhängigkeit als Mali- Föderation bekommen?, Correct Retrieved: True\n",
            "Query: Wann haben sich die Kolonien Senegal und Französisch- Sudan vereinigt?, Correct Retrieved: True\n",
            "Query: Warum zerbrach die Mali- Föderation 1960?, Correct Retrieved: True\n",
            "Query: Wann erklärte die frühere Kolonie Französisch- Sudan endgültig ihre Unabhängigkeit?, Correct Retrieved: True\n",
            "Query: Woran arbeitete von Neumann ab 1943?, Correct Retrieved: True\n",
            "Query: Was war ein der Hauptarbeitsgebiete von Neumann bei der Army und Navy?, Correct Retrieved: True\n",
            "Query: Wie war von Neumann am Zweiten Weltkrieg beteiligt?, Correct Retrieved: True\n",
            "Query: Welche Verfahren hat John von Neumann entwickelt?, Correct Retrieved: True\n",
            "Query: Warum hatten andere Menschen Angst vor von Neumann?, Correct Retrieved: True\n",
            "Query: Inwiefern hat von Neumann bei dem Abwurf der Atombomben auf Japan mitgemacht?, Correct Retrieved: True\n",
            "Query: Was spielt eine große Rolle in der Wirtschaft von Mali?, Correct Retrieved: False\n",
            "Query: Wie viele Menschen in Mali sind im Bereich der Landwirtschaft beschäftigt?, Correct Retrieved: True\n",
            "Query: Wie viele Fläche kann für die Landwirtschaft im Mali genutzt werden?, Correct Retrieved: True\n",
            "Query: In welchem Teil von Mali sind regelmäßig Dürren zu beobachten?, Correct Retrieved: False\n",
            "Query: Warum gibt es in der Region Gao keine regelmäßige Ernte mehr?, Correct Retrieved: True\n",
            "Query: Was wird im Mali hauptsächlich angebaut?, Correct Retrieved: False\n",
            "Query: Was hat man vor, mit dem Office du Niger im Mali zu machen?, Correct Retrieved: True\n",
            "Query: Wie stark ist die Zahl der Angler seit 1967 im Mali gestiegen?, Correct Retrieved: True\n",
            "Query: In welchen Gebieten von Deutschland wird der Karneval primär gefeiert?, Correct Retrieved: True\n",
            "Query: Wie wird der Karneval in Sachsen und Brandenburg genannt?, Correct Retrieved: True\n",
            "Query: Wann ist der Begriff \"Karneval\" in Deutschland entstanden?, Correct Retrieved: True\n",
            "Query: Woher kommt das Wort \"Karneval\"?, Correct Retrieved: True\n",
            "Query: Was ist die Hauptaufgabe von Thermal Vias?\n",
            ", Correct Retrieved: True\n",
            "Query: Welchen Wärmeleitwert hat Kupfer?\n",
            ", Correct Retrieved: True\n",
            "Query: Was wird bei Wassergekühlten Leiterplatten vor dem Zusammenbau getan?, Correct Retrieved: True\n",
            "Query: Was ist ein neues Prinzip um Leiterkarten besser zu kühlen?, Correct Retrieved: True\n",
            "Query: Wer herrschte zur Zeit der Luxemburgkrise in Preußen?, Correct Retrieved: True\n",
            "Query: Bis wann war Luxemburg ein Teil deutschlands?, Correct Retrieved: True\n",
            "Query: Was verlangte Frankreich von Preußen nach französisch- preußischen Verhandlungen 1866? , Correct Retrieved: True\n",
            "Query: Für was war Wilhelm III. bereit Frankreich Luxemburg abzugeben, Correct Retrieved: True\n",
            "Query: Welches Gebiet beanspruchte Frankreich 1866?, Correct Retrieved: True\n",
            "Query: Wessen Unterstützung wollte Frankreich bei den Bestrebungen, Luxemburg in französischen Besitz zu bringen?, Correct Retrieved: True\n",
            "Query: Durch welches Zusammentreffen wurde die Luxemburgkrise  beendet?, Correct Retrieved: True\n",
            "Query: Unter wessen Herrschaft stand Luxemburg vor der Luxemburgkrise?, Correct Retrieved: True\n",
            "Query: In welchem Jahr kam es zur Luxemburgkrise?, Correct Retrieved: True\n",
            "Query: Wie verhinderte Bismarck den Verkauf von Luxemburg an Frankreich?, Correct Retrieved: True\n",
            "Query: Was für einen Krieg führte Israel 1948?, Correct Retrieved: True\n",
            "Query: Wer erklärte Israel bei der Gründung den Krieg?, Correct Retrieved: True\n",
            "Query: Wie lange ging der Israelische Unabhängigkeitskrieg?, Correct Retrieved: True\n",
            "Query: Wo machte Israel große Ländergewinne währen des Unabhängigkeitskrieges 1948, Correct Retrieved: True\n",
            "Query: Wie viele Araber flohen während des Unabhängigkeitskrieges 1948 aus Palästina?, Correct Retrieved: True\n",
            "Query: Der Großteil der Israelischen Bevölkerung war ab 1949 teil welcher Religion?, Correct Retrieved: True\n",
            "Query: Aus welchem Grund gab es ab 1949 mehr Juden als Araber in Israel?, Correct Retrieved: True\n",
            "Query: Welche Partei gewann die Wahl zur Verfassungsgebenden Versammlung 1949 in Israel?, Correct Retrieved: True\n",
            "Query: Welche Staaten führten die Suez-Kampagne?, Correct Retrieved: True\n",
            "Query: Was war der Plan der Suez-Kampagne?, Correct Retrieved: True\n",
            "Query: Warum wurde die Suez-Kampagne beendet?, Correct Retrieved: True\n",
            "Query: Wer sorgt dafür, dass Israel Zugang zu Internationalen Wasserwegen hat?, Correct Retrieved: True\n",
            "Query: Was umfasst die HDTV-Norm?, Correct Retrieved: True\n",
            "Query: Wie wird die Bildwiederholungsrate angegeben?, Correct Retrieved: True\n",
            "Query: Wofür steht \"i\" bei HDTV-Kennzeichnungen?, Correct Retrieved: True\n",
            "Query: Was sind Pixel?, Correct Retrieved: True\n",
            "Query: Welche Möglichkeiten des Bildaufbaus gibt es bei HDTV?, Correct Retrieved: True\n",
            "Query: Was ist Materie in der klassischen Pyhsik?, Correct Retrieved: True\n",
            "Query: Was hat die Definition von Materie in der modernen Physik stark beeinflusst?, Correct Retrieved: True\n",
            "Query: Was ist alles Materie?, Correct Retrieved: True\n",
            "Query: Wie oft muss eine Uhr im Jahr wegen der Sommerzeit umgestellt werden?, Correct Retrieved: True\n",
            "Query: Wann wurde Mexiko-Stadt in zwei Teile aufgeteilt?, Correct Retrieved: True\n",
            "Query: Wie groß war der um Mexiko-Stadt liegende Bezirk bei dessen Abtrennung von der Stadt?, Correct Retrieved: True\n",
            "Query: Wie heißt der Bezirk um Mexiko-Stadt bei der Abtrennung?, Correct Retrieved: True\n",
            "Query: Wo siedeln die Menschen der Oberschicht in Mexiko-Stadt hauptsächlich?, Correct Retrieved: True\n",
            "Query: Wer machte den Westen Mexiko-Stadts zu einem beliebten Wohnviertel?, Correct Retrieved: True\n",
            "Query: Was ist im Norden Mexiko-Stadts?, Correct Retrieved: True\n",
            "Query: Wie viele Einwohner hat die Stadt Naucalpán?, Correct Retrieved: True\n",
            "Query: Welche Metalle wurden in der Antarktika bis jetzt entdeckt?, Correct Retrieved: True\n",
            "Query: Wie viel Kohle wird unter dem Eis in der Antarktis erwartet?, Correct Retrieved: True\n",
            "Query: Wie wurden die Schätzungen der Bodenschätze in der Antarktis getroffen?, Correct Retrieved: True\n",
            "Query: Wie viele von den Erdöl Lagerstätten in der Antarktis wurden bis jetzt gefunden?, Correct Retrieved: True\n",
            "Query: Welche Ziele verfolgt die iranische Außenpolitik seit der islamischen Revolution?, Correct Retrieved: True\n",
            "Query: Wie ist das Verhältnis Irans zur westlichen Welt?, Correct Retrieved: True\n",
            "Query: Welcher Bereich der Irans Politik wird international stark kritisiert?, Correct Retrieved: False\n",
            "Query: Wer ist seit 2005 Die Exekutive Österreichs?, Correct Retrieved: True\n",
            "Query: Wem ist die österreichische Justizwache unterstellt?, Correct Retrieved: True\n",
            "Query: Wann wurde die Xbox 360 das erste mal öffentlich vorgestellt?, Correct Retrieved: True\n",
            "Query: Auf welchem Sender wurde die offizielle Präsentation der Xbox 360 im Mai im Fernsehen übertragen?, Correct Retrieved: True\n",
            "Query: Wer stellte die Xbox 360 im Mai 2005 im Fernsehen vor?, Correct Retrieved: True\n",
            "Query: Wie viel später wurde die offizielle Präsentation der Xbox 360 in Europa ausgestrahlt?, Correct Retrieved: True\n",
            "Query: Wer schrieb \"Von den Umdrehungen der Himmelskörper\"?, Correct Retrieved: True\n",
            "Query: Unter welchem Kardinal arbeitete Aloisius Lilius, Correct Retrieved: True\n",
            "Query: Wer wurde mit der mathematischen Seite der Erfindung des Gregorianischen Kalender beauftragt?, Correct Retrieved: True\n",
            "Query: Im Bezug auf Dauer kann Schmerz in welche Klassen aufgeteilt werden?, Correct Retrieved: True\n",
            "Query: Welche Art von Schmerz ist zeitlich begrenzt?, Correct Retrieved: True\n",
            "Query: Welcher Zeitraum zählt als Chronischer Schmerz?, Correct Retrieved: True\n",
            "Query: Welche Funktion hat der Akute Schmerz?, Correct Retrieved: True\n",
            "Query: Welche Art von Schmerzen ist multikausal?, Correct Retrieved: True\n",
            "Query: Zu welcher Schmerzensgruppe gehören Phantomschmerzen?, Correct Retrieved: True\n",
            "Query: Wie lange war Rebekah Wade wegen Körperverletzung verhaftet?, Correct Retrieved: True\n",
            "Query: Wer ist 2005 die Ehefrau von Ross Kemp?, Correct Retrieved: True\n",
            "Query: Wie sieht die Flamme von Wasserstoff aus?, Correct Retrieved: True\n",
            "Query: Welchen MAK-Wert hat Wasserstoff?, Correct Retrieved: True\n",
            "Query: Wie heiß muss es sein um Wasserstoff in der Luft zu zünden?, Correct Retrieved: True\n",
            "Query: Warum kann Wasserstoff durch manche Feststoffe durch?, Correct Retrieved: True\n",
            "Query: Wie darf man mit Wasserstofffahrzeugen in Tiefgaragen parken?, Correct Retrieved: True\n",
            "Query: Welche Gleichrichter werden bei Gleichstrombahnen heute benutzt?, Correct Retrieved: True\n",
            "Query: Welche Gleichrichter werden bei Gleichstrombahnen früher benutzt?, Correct Retrieved: True\n",
            "Query: Wie verglich Prokopios die Slawen und Anten?, Correct Retrieved: True\n",
            "Query: Woher kommen die meisten Jagdtouristen?, Correct Retrieved: True\n",
            "Query: Welche Sprache wurde ursprünglich für die Schriften  des Mahayana-Buddhismus verwendet?, Correct Retrieved: True\n",
            "Query: Wie werden die religiösen Schriften im Buddhismus bezeichnet?, Correct Retrieved: True\n",
            "Query: Was ist ein Bodhisattva?, Correct Retrieved: True\n",
            "Query: Was sind die großen Strömungen im Mahayana-Buddhismus?, Correct Retrieved: True\n",
            "Query: Was bedeutet Mahayana?, Correct Retrieved: True\n",
            "Query: Auf was geht der Mahayana-Buddhismus zurück?, Correct Retrieved: True\n",
            "Query: Wie wird die Aktivität eines Gens kontrolliert?, Correct Retrieved: True\n",
            "Query: Wer herrschte über Liberia nach dem Zweiten Weltkrieg?, Correct Retrieved: True\n",
            "Query: Aus welchem Grund wurde das Wirtschaftliche Wachstums Liberias nach dem Zweiten Weltkrieg zerstört?, Correct Retrieved: True\n",
            "Query: Wer ist Präsident Liberias?, Correct Retrieved: False\n",
            "Query: Welchen Platz belegt Liberia im Index für wirtschaftliche Freiheit?, Correct Retrieved: True\n",
            "Query: Was steht in Artikel vier des Warschauer Pakts?, Correct Retrieved: True\n",
            "Query: Wem Unterstanden die Truppen Des Warschauer Pakts letztendlich?, Correct Retrieved: True\n",
            "Query: Wie unterscheiden sich die Größen der Unterschiedlichen US-Dollar Scheine?, Correct Retrieved: True\n",
            "Query: Wie dick ist ein US-Dollar Schein?, Correct Retrieved: True\n",
            "Query: Auf welche Währung bezieht sich das US-Dollar Gesetz von 1965?, Correct Retrieved: True\n",
            "Query: Wie viel kostet die Herstellung eines US-Dollar Scheins?, Correct Retrieved: True\n",
            "Query: Aus was wird der US-Dollar hauptsächlich hergestellt?, Correct Retrieved: True\n",
            "Query: Was ist der wertvollste US-Dollar Schein?, Correct Retrieved: True\n",
            "Query: Wie heißt das Gebäude der Zentrale des FBIs?, Correct Retrieved: True\n",
            "Query: In welcher Stadt liegt die Zentrale des FBI?, Correct Retrieved: True\n",
            "Query: Wer ernennt den FBI-Direktor?, Correct Retrieved: True\n",
            "Query: Wem ist der FBI-Direktor direkt untergestellt?, Correct Retrieved: True\n",
            "Query: Wie viele Auslandsvertretungen hat das FBI?, Correct Retrieved: True\n",
            "Query: Wo ist das HRT Team des FBI stationiert?, Correct Retrieved: True\n",
            "Query: Über welches Budget verfügt das FBI?, Correct Retrieved: True\n",
            "Query: Was erscheint auf dem Bildschirm nach dem Start der Xbox 360?, Correct Retrieved: True\n",
            "Query: In welchem Blade der Xbox 360 Benutzeroberfläche lassen sich die Einstellungen ändern?, Correct Retrieved: True\n",
            "Query: Wie kann man ein Update für Xbox 360 herunterladen?, Correct Retrieved: True\n",
            "Query: Was ist die Genfer Konvention?, Correct Retrieved: True\n",
            "Query: Seit wann gibt es in der Schweiz keine Todesstrafe mehr?, Correct Retrieved: True\n",
            "Query: Wann wurde die Genfer Konvention erstmlas beschlossen?, Correct Retrieved: True\n",
            "Query: Welche staatlichen Einrichtungen der Schweiz sind mit dem Schutz der Menschenrechte befasst?, Correct Retrieved: True\n",
            "Query: Für was wurde die Schweiz mehrfach von Amnesty International gerügt?, Correct Retrieved: True\n",
            "Query: Was ist das Non-Refoulement-Gebot?, Correct Retrieved: True\n",
            "Query: In welchem Jahr heirateten Prinz Charles und Lady Diana Spencer?, Correct Retrieved: True\n",
            "Query: Wer schoss auf die Queen im Juni 1981?, Correct Retrieved: True\n",
            "Query: Wer war 1982 Präsident der USA?, Correct Retrieved: True\n",
            "Query: An was starb Gamal Abdel Nasser?, Correct Retrieved: True\n",
            "Query: Wer war Gamal Abdel Nasser Nachfolger als Präsident?, Correct Retrieved: True\n",
            "Query: Wie viele Menschen machten am Trauerzug von Gamal Abdel Nasser mit?, Correct Retrieved: True\n",
            "Query: Wo ist Gamal Abdel Nasser bestattet?, Correct Retrieved: True\n",
            "Query: Wie viele Kinder hatte Gamal Abdel Nasser?, Correct Retrieved: True\n",
            "Query: Warum wurde ein Sohn Gamal Abdel Nasser zu Tode verurteilt?, Correct Retrieved: True\n",
            "Query: Wer gab Israel Informationen über den Überraschungsangriff geplanten Jom-Kippur-Krieg?, Correct Retrieved: True\n",
            "Query: Wer herrscht laut den Zeugen Jehovas über alle nicht Mitglieder dieser?, Correct Retrieved: True\n",
            "Query: Wann ist Jesus laut den Zeugen Jehovas unsichtbar zur Erde wiedergekommen?, Correct Retrieved: True\n",
            "Query: Was soll in der Endschlacht von Harmagedon passieren?, Correct Retrieved: True\n",
            "Query: Wie heißt Beyoncés drittes Album?, Correct Retrieved: True\n",
            "Query: Welcher Beyoncé Song, ihres dritten Albums, schaffte in den US Charts auf Platz eins?, Correct Retrieved: True\n",
            "Query: Welchen Namen hatte Beyoncé dritte Welttour?, Correct Retrieved: True\n",
            "Query: Wie viele Grammys gewann Beyoncé 2010?, Correct Retrieved: True\n",
            "Query: Von welchen Künstlern ist der Song Telephone?, Correct Retrieved: True\n",
            "Query: Wo liegen Griechenlands meisten großen Flüsse?, Correct Retrieved: True\n",
            "Query: Welche Tiefe hat der Trichonida-See?, Correct Retrieved: True\n",
            "Query: Wie stark wächst Estlands BIP seit dem Jahr 2000?, Correct Retrieved: True\n",
            "Query: Welches Land hatte 2006 das größte Wirtschaftswachstum der EU?, Correct Retrieved: True\n",
            "Query: Wie war 2008 der BIP Estlands?, Correct Retrieved: True\n",
            "Query: Wie kam es zu dem Namen \"Baltische Tiger\"?, Correct Retrieved: True\n",
            "Query: An was für Götter glaubten die Römer?, Correct Retrieved: True\n",
            "Query: Wie interagierten die Götter der Römer mit der Welt?, Correct Retrieved: True\n",
            "Query: Als was zeigte sich Jupiter den Römern?, Correct Retrieved: True\n",
            "Query: Wo hat Amylin Pharmaceuticals seinen Hauptsitz?, Correct Retrieved: True\n",
            "Query: Was war die Arbeitslosenquote von San Diego 2003?, Correct Retrieved: True\n",
            "Query: Was sind die größten Industriebranchen in San Diego?, Correct Retrieved: True\n",
            "Query: Wer ist der Gründer von Qualcomm?, Correct Retrieved: True\n",
            "Query: Wo werden in San Diego Flugzeuge produziert?, Correct Retrieved: True\n",
            "Query: Wem gehört das Ryan Aeronautical Center?, Correct Retrieved: True\n",
            "Query: Was ist das BIP von San Diego?, Correct Retrieved: True\n",
            "Query: Welcher Konflikt besteht zwischen Armenien und Aserbaidschan?, Correct Retrieved: True\n",
            "Query: Was ist Berg Karabach?, Correct Retrieved: False\n",
            "Query: Wie viele Todesopfer gibt es in dem Konflikt um Berg Karabach?, Correct Retrieved: True\n",
            "Query: Wie sind die Beziehungen zwischen Armenien und Aserbaidschan?, Correct Retrieved: True\n",
            "Query: Was ist die Republik Arzach?, Correct Retrieved: True\n",
            "Query: In welchem Land erfolgt aktuell keine Zeitumstellung auf Sommerzeit?, Correct Retrieved: True\n",
            "Query: Was sind die Folgen einer fehlenden Zeitumstellung?, Correct Retrieved: True\n",
            "Query: Wozu dient die Zeitumstellung?, Correct Retrieved: True\n",
            "Query: Wonach richten sich die meisten Menschen in ihrem Tagesablauf?, Correct Retrieved: True\n",
            "Query: Wofür ist der isochrone Transfer geeignet? , Correct Retrieved: True\n",
            "Query: Für welche Geräte ist der isochrone Transfer verfügbar?, Correct Retrieved: True\n",
            "Query: Was passiert, wenn beim isochronen Transfer keine Datenrate zur Verfügung steht?, Correct Retrieved: True\n",
            "Query: Wie viele Daten können Full-Speed-Geräte pro Sekunde übertragen?, Correct Retrieved: True\n",
            "Query: Wie viele Daten können Hi-Speed-Geräte pro Sekunde übertragen?, Correct Retrieved: True\n",
            "Query: Was passiert, wenn in einem Gerät mehrere isochrone Endpunkte verfügbar sind?, Correct Retrieved: True\n",
            "Query: Wo finden isochrone Übertragungen ihre Anwendung?, Correct Retrieved: True\n",
            "Query: Wo leben Säugetiere?, Correct Retrieved: True\n",
            "Query: Was ist die Heimat von Ursäugern?, Correct Retrieved: False\n",
            "Query: Wo leben Beutelsäuger?, Correct Retrieved: True\n",
            "Query: Wer gehörte zu den Höheren Säugetieren bis zur Ankunft des Menschen in Australien?, Correct Retrieved: True\n",
            "Query: In welchen Lebensräumen leben Säugertiere?, Correct Retrieved: True\n",
            "Query: Wo kann man keine Säugetiere finden?, Correct Retrieved: True\n",
            "Query: Welche Gruppe von Säugetieren lebt im Meer?, Correct Retrieved: True\n",
            "Query: Wer schlug die erste einheitliche Rechtschreibung für das Niederländische vor?, Correct Retrieved: True\n",
            "Query: Wie heißt der von Hendrik Laurenszoon veröffentlichte Orthografieleitfaden?, Correct Retrieved: True\n",
            "Query: Wie heißt die niederländische Bibelübersetzung von 1618?, Correct Retrieved: True\n",
            "Query: Was war ein Problem in Bezug auf die Rechtschreibung der Statenvertaling-Bibelübersetzung?, Correct Retrieved: True\n",
            "Query: Wann veröffentlichte Hendrik Laurenszoon Texte als Rechtschreibehilfe?, Correct Retrieved: True\n",
            "Query: Wie werden ja oder nein Fragen im Estnischen gebildet?, Correct Retrieved: True\n",
            "Query: Wie werden Entscheidungsfragen im Estnischen gebildet?, Correct Retrieved: True\n",
            "Query: Was ist der Fragepartikel für verneinte Fragen im Estnischen?, Correct Retrieved: True\n",
            "Query: Wann wird im Estnischen bei der Fragenbildung kein Fragepartikel verwendet?, Correct Retrieved: True\n",
            "Query: Was wird im Estnischen statt \"ega\" für Fragen verwendet?, Correct Retrieved: True\n",
            "Query: Was sind Inhaltsfragen?, Correct Retrieved: True\n",
            "Query: Wie werden die Gruppierungen bei FA Cup festgelegt?, Correct Retrieved: True\n",
            "Query: Wann wird beim FA Cup ein Rückspiel gespielt?, Correct Retrieved: True\n",
            "Query: Was passiert beim FA Cup, wenn das Rückspiel unentschieden ist?, Correct Retrieved: True\n",
            "Query: Wo wird das Finale des FA Cups gespielt?, Correct Retrieved: True\n",
            "Query: Was war das Besondere an dem FA Cup Finale von 2001?, Correct Retrieved: True\n",
            "Query: Was sind die Bedingungen, damit ein Team am FA Cup teilnehmen kann?, Correct Retrieved: True\n",
            "Query: Welche Runden gibt es im FA Cup?, Correct Retrieved: True\n",
            "Query: Welche Teams dürfen am FA CUp teilnehmen?, Correct Retrieved: True\n",
            "Query: Wann fängt der FA Cup an?, Correct Retrieved: True\n",
            "Query: Wieso spielen manche Teams im FA Cup nicht in allen Runden?, Correct Retrieved: True\n",
            "Query: Ab welcher Runde spielen die Teams der Premier Leauge im FA Cup?, Correct Retrieved: True\n",
            "Query: Wann ist dsa FInale des FA Cups?, Correct Retrieved: True\n",
            "Query: Was behauptet Tottenham Hotspur in Bezug auf ihren Sieg im FA Cup 1901?, Correct Retrieved: True\n",
            "Query: An welchem europäischen Wettbewerb kann der Sieger des FA Cup teilnehmen?, Correct Retrieved: True\n",
            "Query: Was hat WikiLeaks über Beyonce veröffentlicht?, Correct Retrieved: True\n",
            "Query: Was hat Beyonce mit dem Geld, das sie von Gadaffi bekommen hat, gemacht?, Correct Retrieved: True\n",
            "Query: Wer war nach ihrem Vater Beyoncés Manager?, Correct Retrieved: True\n",
            "Query: Welche Auszeichnung hat Beyonce 2013 bei den MTV Europe Music Awards bekommen?, Correct Retrieved: True\n",
            "Query: Weswegen hat sich Beyonce von ihrem Vater als Manager getrennt?, Correct Retrieved: True\n",
            "Query: Wann wurde Beyonces viertes Album veröffenlicht?, Correct Retrieved: True\n",
            "Query: Welche Platzierung erreichte Beyonces Album \"4\" in den Billboard 200?, Correct Retrieved: True\n",
            "Query: Welche Single hat Beyoncé veröffentlicht, als sie mit ihrem ersten Kind schwanger war?, Correct Retrieved: True\n",
            "Query: Was sind die Perspektiven der menschlichen Kommunikation?, Correct Retrieved: True\n",
            "Query: Was soll in einem Kommunikationsprozess erreicht werden?, Correct Retrieved: True\n",
            "Query: Welche Gebiete der USA liegen außerhalb des Hauptlandes?, Correct Retrieved: True\n",
            "Query: Wie lang ist die US - Kanadische Grenze?, Correct Retrieved: True\n",
            "Query: Was sind die Nachbarländer der USA?, Correct Retrieved: False\n",
            "Query: Aus wie vielen Bundesstaaten besteht das USA Kernland?, Correct Retrieved: True\n",
            "Query: An welche Ozeane grenzt die USA?, Correct Retrieved: False\n",
            "Query: Wo liegt Hawaii?, Correct Retrieved: True\n",
            "Query: Was trennt die USA und Russland geographisch?, Correct Retrieved: True\n",
            "Query: Wer nahm in der Neuzeit Palermo ein?, Correct Retrieved: True\n",
            "Query: Welche Stadt wurde vor Palermo in der Neuzeit oft bevorzugt?, Correct Retrieved: True\n",
            "Query: Wann wurde Palermo Hauptstadt von der Region Sizilien?, Correct Retrieved: True\n",
            "Query: Wie war Palermo vom zweiten Weltkrieg betroffen?, Correct Retrieved: True\n",
            "Query: Wer \"befreite\" Palermo von der Mafia?, Correct Retrieved: True\n",
            "Query: Welcher Britische Monarch herrschte am zweit längsten?, Correct Retrieved: False\n",
            "Query: Wann waren Elisabeths II. besondere Fernsehansprachen?, Correct Retrieved: True\n",
            "Query: Wo kommt ein drittel des deutschen Bahnstroms 2018 her?, Correct Retrieved: True\n",
            "Query: Welche Spannung hat das Stromnetz der Deutschen Bahn?, Correct Retrieved: False\n",
            "Query: Wie wird die Wissenschaft durch Alfred Whitehead untersucht?, Correct Retrieved: True\n",
            "Query: Wer kommt zu ähnlichen wissenschaftlichen Ergebnissen wie Whitehead?, Correct Retrieved: True\n",
            "Query: Was bedeutet der Obskurantismus für Whitehead?, Correct Retrieved: True\n",
            "Query: Was bedeutet das Konzept der \"Blackness\" in den USA?, Correct Retrieved: True\n",
            "Query: Was bedeutet das Konzept \"acting white\"?, Correct Retrieved: True\n",
            "Query: Wer wurde als erster schwarze Präsident der USA genannt, obwohl er keine dunkle Haut hatte?, Correct Retrieved: True\n",
            "Query: Was halten mache schwarze Aktivisten von Bill Clinton?, Correct Retrieved: True\n",
            "Query: Warum wurde Barack Obama während der Präsidentschaftswahlen 2008 politisch kritisiert?, Correct Retrieved: True\n",
            "Query: Wo liegt die Antarktis?, Correct Retrieved: False\n",
            "Query: Welche Territorien gehören zur Antarktis?, Correct Retrieved: False\n",
            "Query: Was ist der nördlichste Punkt der Antarktis?, Correct Retrieved: True\n",
            "Query: Was ist der südlichste Punkt der Antarktis?, Correct Retrieved: True\n",
            "Query: Was sind die größeren nächstgelegenen Landmassen zur Antarktis?, Correct Retrieved: True\n",
            "Query: Wo liegt der nördlichste Punkt der Antarktis?, Correct Retrieved: True\n",
            "Query: Welche Währung nutzen die Norfolkinsel?, Correct Retrieved: True\n",
            "Query: Wie hoch ist die Arbeitslosigkeit auf den Norfolkinsel?, Correct Retrieved: True\n",
            "Query: Was ist die wichtigste Wirtschaft der Norfolkinsel?, Correct Retrieved: True\n",
            "Query: Was sind die beliebtesten Touristenattraktionen der Norforkinsel?, Correct Retrieved: False\n",
            "Query: Wie kommt man auf die Norfolkinsel?, Correct Retrieved: True\n",
            "Query: Wann starb Athanasius der Große?, Correct Retrieved: True\n",
            "Query: Welche hohen Ämter hatte Athanasius der Große?, Correct Retrieved: True\n",
            "Query: Wann wurde der alexandrinische Presbyter Arius schuldig gesprochen?, Correct Retrieved: True\n",
            "Query: Wann wurde Alfred Whitehead geboren?, Correct Retrieved: True\n",
            "Query: Wo ist Alfred Whitehead gestorben?, Correct Retrieved: True\n",
            "Query: Für welches Werk ist Whitehead bekannt?, Correct Retrieved: True\n",
            "Query: Mit wem arbeitete Alfred Whitehead an seinem bekannten Werk über Logik?, Correct Retrieved: True\n",
            "Query: Worum geht es im Werk \"Principia Mathematica\"?, Correct Retrieved: True\n",
            "Query: Wann hat Alfred Whitehead in London gewohnt?, Correct Retrieved: True\n",
            "Query: Als was war Alfred Whitehead in London bekannt?, Correct Retrieved: True\n",
            "Query: Wann hat Whitehead angefangen an der Harvard University zu arbeiten?, Correct Retrieved: True\n",
            "Query: Wie heißt das philosophische Hauptwerk von Whitehead?, Correct Retrieved: True\n",
            "Query: Worüber schreibt Whitehead in seinem philosophischen Hauptwerk?, Correct Retrieved: True\n",
            "Query: Welchen anderen Namen haben Feldeffekttransistoren?, Correct Retrieved: True\n",
            "Query: Was ist für Feldeffekttransistoren typisch?, Correct Retrieved: True\n",
            "Query: Wie heißen die drei Anschlüsse eines Feldeffekttransistors?, Correct Retrieved: True\n",
            "Query: Wie wird der Widerstand eines Feldeffekttransistors gesteuert?, Correct Retrieved: True\n",
            "Query: Welche Arten von Feldeffekttransistoren gibt es?, Correct Retrieved: True\n",
            "Query: Was bedeutet die unbefleckte Empfängnis Mariens?, Correct Retrieved: True\n",
            "Query: Welches religiöses Fest wird am 8.Dezember gefeiert?, Correct Retrieved: True\n",
            "Query: Was ist das bedeutende Herkunftsland der Direktinvestitionen in Estland?, Correct Retrieved: True\n",
            "Query: Wie viele Investitionen in Estland stammen aus Deutschland?, Correct Retrieved: True\n",
            "Query: In welchen Bereichen wurden die Investitionen in Estland aus Schweden getätigt?, Correct Retrieved: True\n",
            "Query: Wie hieß die heutige Hauptstadt von Montenegro in Jugoslawien?, Correct Retrieved: True\n",
            "Query: Wann wurden die Städte, die nach Tito benannt worden waren, wieder umbeannt?, Correct Retrieved: True\n",
            "Query: Welcher Berg war nach Tito benannt?, Correct Retrieved: True\n",
            "Query: Welcher Tag war für die Titoverehrung besonders wichtig?, Correct Retrieved: False\n",
            "Query: Wie viele Städte wurden in Jugoslawien trugen Titos Namen?, Correct Retrieved: True\n",
            "Query: Welcher Tag wurde in Jugoslwaien als Tag der Jugend gefeiert?, Correct Retrieved: True\n",
            "Query: Wer verlor viel durch das Wachstum der Literatur als Bildungsform?, Correct Retrieved: True\n",
            "Query: Warum kam es bei dem ausbreiten der Literatur kaum auf Wiederstand?, Correct Retrieved: True\n",
            "Query: Was ist das Ziel nationalstaatlicher Bildungssysteme?, Correct Retrieved: True\n",
            "Query: Was war am Sozialen Aufstieg in westlichen Staaten im 19. Jhd. das schwerste?, Correct Retrieved: False\n",
            "Query: Wieso war die Sprachentwicklung der Serben und Kroaten für 500 Jahre stark unterschiedlich?, Correct Retrieved: True\n",
            "Query: Warum ging der Kokainhandel 2008 und 2009 in Guinea-Bissau zurück?, Correct Retrieved: True\n",
            "Query: Auf welchem Land würde die Stadt Yecheng heutzutage liegen?, Correct Retrieved: True\n",
            "Query: Wann wurde Nanjing das erste mal Hauptstadt Chinas?, Correct Retrieved: True\n",
            "Query: Wer hat die Definitionen von Ethnien beim United State Census geschrieben?, Correct Retrieved: True\n",
            "Query: In welche zwei Ethnien Gruppen werden alle Amerikaner eingeteilt?, Correct Retrieved: True\n",
            "Query: Was machen die Schüler in Griechenland die nicht am Religionsunterricht teilnehmen?, Correct Retrieved: True\n",
            "Query: Was ist der höchste Rang in der griechischen Kirche?, Correct Retrieved: True\n",
            "Query: Was ist die größte Religion Griechenlands?, Correct Retrieved: False\n",
            "Query: Welches griechische Ministerium befasst sich mit Religion?, Correct Retrieved: False\n",
            "Query: Welche europäischen Länder haben eine offizielle Staatskirche?, Correct Retrieved: True\n",
            "Query: Wem untersteht die Griechische orthodoxe Kirche zum Teil?, Correct Retrieved: True\n",
            "Query: Welches Volumen hat der Magen eines Menschen?, Correct Retrieved: True\n",
            "Query: Wie ist die Magenschleimhaut aufgebaut?, Correct Retrieved: True\n",
            "Query: Welche Arten von Drüsenzellen gibt es in der Magenschleimhaut?, Correct Retrieved: True\n",
            "Query: Welche Zellen im Magen produzieren Säure?, Correct Retrieved: True\n",
            "Query: Welche Art von Säure wird im Magen produziert?, Correct Retrieved: True\n",
            "Query: Welche FUnktion hat Pepsin im Magen?, Correct Retrieved: True\n",
            "Query: Was ist der pH-Wert im Magen?, Correct Retrieved: True\n",
            "Query: Was wird von den Nebenzellen im Magen produziert?, Correct Retrieved: True\n",
            "Query: Wozu dient der Schleim der Nebenzellen im Magen?, Correct Retrieved: True\n",
            "Query: Wie viel magensaft wird am Tag produziert?, Correct Retrieved: True\n",
            "Query: Was ist Chymus?, Correct Retrieved: True\n",
            "Query: Wann ist der Schweizer Bundesfeiertag?, Correct Retrieved: True\n",
            "Query: Welche Feiertage gibt es in der Schweiz?, Correct Retrieved: True\n",
            "Query: Wo wird in der Schweiz das Knabenschiessen gefeiert?, Correct Retrieved: True\n",
            "Query: Wo in der Schweiz wird Fronleichnam gefeiert?, Correct Retrieved: True\n",
            "Query: Wann ist der Berchtoldstag?, Correct Retrieved: True\n",
            "Query: Wann wurde der iPod 6G vorgestellt?, Correct Retrieved: True\n",
            "Query: Wo wurde der iPod 6G vorgestellt?, Correct Retrieved: True\n",
            "Query: Wie viel SPeicherplatz hat der iPod 6G?, Correct Retrieved: True\n",
            "Query: Welche iPod-Generation wird  classic genannt?, Correct Retrieved: True\n",
            "Query: Wann wurde Mahmud Ahmadineschād zum Präsidenten wiedergewählt?, Correct Retrieved: True\n",
            "Query: Was führte zu massiven Protesten 2009 in Iran?, Correct Retrieved: True\n",
            "Query: Welche Oppositioneller in Iran wurden 2011 mit dem Tod bedroht?, Correct Retrieved: False\n",
            "Query: Was war das Ergebnis der Radikalisierung in Iran 2009-2011?, Correct Retrieved: True\n",
            "Query: Wie wurde man bis 1999 in Florida hingerichtet?, Correct Retrieved: True\n",
            "Query: Welche Methode der Hinrichtung wurde in Florida nach der Abschaffung des elektrischen Stuhls praktiziert? , Correct Retrieved: True\n",
            "Query: Wann hat die bisher letzte Hinrichtung in Florida stattgefunden?, Correct Retrieved: True\n",
            "Query: Welcher US-Bundesstaat hat mehr Hinrichtungen als Florida durchgeführt?, Correct Retrieved: True\n",
            "Query: Wie viele natürliche Isotope des Wasserstoffs gibt es?, Correct Retrieved: True\n",
            "Query: Warum reagieren die Isotope des Wasserstoffs chemisch so unterschiedlich?, Correct Retrieved: True\n",
            "Query: Warum wird das einfachste Isotop des Wasserstoffs Protium genannt?, Correct Retrieved: True\n",
            "Query: Inwiefern unterscheidet sich das Isotop 1H von 2H?, Correct Retrieved: True\n",
            "Query: Wie heißt das dritte vorkommende Isotop des Wasserstoffs?, Correct Retrieved: True\n",
            "Query: Welches Isotop des Wasserstoffs ist radioaktiv?, Correct Retrieved: True\n",
            "Query: Wo kann man das dritte Isotop des Wasserstoffs finden?, Correct Retrieved: True\n",
            "Query: Wie lange leben Isotope des Wasserstoffs?, Correct Retrieved: True\n",
            "Query: Was ist der bedeutendste Fluss Afrikas?, Correct Retrieved: True\n",
            "Query: Wo hat der Fluss Niger seinen Anfang?, Correct Retrieved: True\n",
            "Query: In welche zwei andere Flüsse wird der Niger bei Mopti zerteilt?, Correct Retrieved: True\n",
            "Query: Was ist der zweite wichtige Fluss Afrikas?, Correct Retrieved: True\n",
            "Query: Was ist der größte See in Mali?, Correct Retrieved: True\n",
            "Query: Seit wann gibt es schwere Dürren in Mali?, Correct Retrieved: True\n",
            "Query: Welche Kultur lebte zuerst in Indien?, Correct Retrieved: True\n",
            "Query: Seit wann leben in Indien menschliche Kulturen?, Correct Retrieved: False\n",
            "Query: Indien war Kolonie von welchem Land?, Correct Retrieved: False\n",
            "Query: Welches Reich gründete sich im 4. Jhd. v. Chr. in Indien?, Correct Retrieved: True\n",
            "Query: In welchem Teil Indies entstand das tamilische Chola-Reich?, Correct Retrieved: True\n",
            "Query: Wie viele Dynastien regierten im 8. Jhd. über einen Großteil Indiens?, Correct Retrieved: True\n",
            "Query: Welche Persönlichkeiten führten die Unabhängigkeit Indiens an?, Correct Retrieved: True\n",
            "Query: Wann wurde Bangladesch gegründet?, Correct Retrieved: True\n",
            "Query: Was sind die Hauptprobleme Indiens?, Correct Retrieved: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_positive = 0\n",
        "false_positive = 0\n",
        "false_negative = 0\n",
        "\n",
        "for query, correct_doc_id in queries_and_doc_ids:\n",
        "    retrieved_documents = retriever.retrieve(query)\n",
        "    retrieved_doc_ids = [doc.meta['passage_id'] for doc in retrieved_documents]\n",
        "    is_correct_doc_retrieved = correct_doc_id in retrieved_doc_ids\n",
        "\n",
        "    if is_correct_doc_retrieved:\n",
        "        true_positive += 1\n",
        "    else:\n",
        "        false_negative += 1\n",
        "\n",
        "    for doc_id in retrieved_doc_ids:\n",
        "        if doc_id != correct_doc_id:\n",
        "            false_positive += 1\n",
        "\n",
        "precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
        "recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlimsvdO-1Sh",
        "outputId": "198ccfea-0f38-4ac8-8fe5-9790b2c87b2c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.10559450078268563\n",
            "Recall: 0.9609786311551564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import FARMReader\n",
        "\n",
        "# Initialize the Reader\n",
        "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", top_k=5)\n",
        "\n",
        "# Evaluate the Reader\n",
        "for query, correct_doc_id in queries_and_doc_ids:\n",
        "    retrieved_documents = retriever.retrieve(query)\n",
        "    # Use the reader to answer the question based on retrieved documents\n",
        "    predicted_answers = reader.predict(query, documents=retrieved_documents, top_k=1)\n",
        "\n",
        "    # Extract the top predicted answer\n",
        "    top_answer = predicted_answers['answers'][0].answer if predicted_answers['answers'] else \"\"\n",
        "\n",
        "    # Compare with gold standard answer and evaluate (you might need to adjust this part based on your dataset)\n",
        "    print(f\"Query: {query}, Predicted Answer: {top_answer}\")\n",
        "\n",
        "# Add your logic here for calculating metrics like F1-score, exact match, etc.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "47a3c533bd2f43b7bffbdeaeab29fd79",
            "3a0d81d9f8fa4b00b8b3f7a1f0f154be",
            "76b4ad239a564a5e96d24e41b5774b2c",
            "373d52cee79c49b4a5ca86bb01e5f092",
            "657c0859a32544a2b08233c63c8e5e4f",
            "f722d74db2494c0289f12e12a279f23a",
            "b936f9b1e3cd4848abc1d51b12337293",
            "377d0389a0d94dfea9a0bfb3992ce047",
            "ff8683515a6040c09203fb0b6c9231e0",
            "a7d416c91468481fa01458ffefaba92f",
            "15875323271a439fbdbaed7e6f4ac536",
            "d7972ad052ec4e37863de59ffc250e37",
            "1e13e17bfea144a488aef5d42f1673fa",
            "097c5bee60b448c4bf070ea18077c881",
            "31cff09ef09b477aa12286b08373fdbb",
            "9aa52ba69d704e46a45a062714217e69",
            "e28c4042c9164a33a54743568de932df",
            "ba2bd6cd26084e6996853d4b53bb7676",
            "d357432bc7b445cca486613f0c0b5e26",
            "10f7cb78239f4dc59aefc062c52ccfb4",
            "750ba90efc7f4ec896d02c7dec66823c",
            "23ea95d62ed4446ba2ff2c9d65b5fb77",
            "f78ef3f607a34007b1acfe65f2be1ae2",
            "70ac5b5230844ba1b3f7082142109df4",
            "c44b965f96e142df8df610318149b85a",
            "c81762601ed74e2e824bfc7f59ccd176",
            "6b965e73afb647b68d9416083b1a61c8",
            "197ef2c4428c4e74b541d2c94e262b9d",
            "09087bb24a5749fe8874263b6c9a57aa",
            "84b8ecf2ffc344b197c8d24a25d7ed9b",
            "788824f37aa74e3990a05b7401c06b15",
            "6c3ece08f23e47cfbd21e556d4865c88",
            "a8587acc747c4b91b11c8078086db21d",
            "7a42d6cc9be54d57ae4cce8c8e8ea63f",
            "92847244335648188392a0cc4a554c01",
            "890d22d09cf7485e983fda310cac8d45",
            "c6750e328eb548a8a6b42233bb9e7944",
            "fdd5816761a845ccbe45a22717f039b1",
            "8cc478e131534ad6bf06605812265d6e",
            "0394b08fada0413bb8d440c54e082af9",
            "96cabf15b3c246b4a63f03900b7c3412",
            "8eb46370c9204f35a62d25e1d885fce1",
            "b948fddeae1f47ad92a14ed08e3cf75f",
            "f8528ddc9fac4ad89b8009eed2595b0b",
            "7c25025d9fa04faca44972e6a795b877",
            "f7799685659d49f1ac15e6e8699bdf68",
            "ba0d0ad7df71438aa0e82026cb17a522",
            "0c3a7c84d02246cba644d6489f9d28f1",
            "076f178659d0479f8ba2aff1a449ee15",
            "9f3a82c900ca4ca190a15f14478fc7de",
            "fb7c0b2d78b2447581c96484d3bc1222",
            "935bccb69b074e78b48f90b40d5025c3",
            "72c5d85295524f58be532efcb5c59d3d",
            "0153e4bd826e4e9697b3ea8f13c41d4d",
            "db153668f5634b979af1b648425fe62b",
            "79353740df1b45c29dc23caca470fdf7",
            "e60d103749e443039c325314a0c4b174",
            "d51c8c8bdcaf477086ef0561168a465f",
            "65004dbac5214cc9b1d9d642998479d9",
            "a068e19a7b104330928b6a3063f41e96",
            "3bd690df85c044b2ac492c8c6eeb1f57",
            "8c3c88ac400641159f9d24372d907854",
            "20b533648f7b422286cd9d1c9a3a3b7b",
            "0514ae30402e4c5a8ec839119a310b3a",
            "5eb2f5e94ff94e7c8d0d376ed3429f84",
            "4e097a0efb8447b78673c8486edd7666"
          ]
        },
        "id": "OX7dJAqDABan",
        "outputId": "a3925dc6-5f86-45d8-e3ce-b4e4b1df0d07"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47a3c533bd2f43b7bffbdeaeab29fd79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7972ad052ec4e37863de59ffc250e37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f78ef3f607a34007b1acfe65f2be1ae2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a42d6cc9be54d57ae4cce8c8e8ea63f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c25025d9fa04faca44972e6a795b877"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79353740df1b45c29dc23caca470fdf7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:02<00:00,  1.17s/ Batches]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches ist die zweitgrößte Stadt in den Alpen?, Predicted Answer: Wien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.94 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hoch ist die Staatsverschuldung von Thüringen?, Predicted Answer: im zweiten Fall\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was beeinflusst das Abarbeiten von USB-Transaktionslisten?, Predicted Answer: nicht mehr vorhanden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Zinkverbindung wird bei der Vulkanisation von Kautschuk eingesetzt?, Predicted Answer: Mittel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welche Drittstaaten waren mit der Überwachung des Abkommens zwischen Nord- und Südkorea nach dem Koreakrieg betraut?, Predicted Answer: die Blütezeit des Rittertums, des Lehnswesens und des Minnesangs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.17 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welcher übergeordneten Klasse gehören Vögel?, Predicted Answer: die Vertreter bestimmter Großgruppen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.59 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche vereinheitlichen Gesetze gibt es in den USA für alle Bundesstaaten?, Predicted Answer: weitere Mittel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer stürzte 1968 Keita in Mali durch einen Putsch?, Predicted Answer: Moussa Traoré\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.12 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit wem setzte Kerry Assad gleich?, Predicted Answer: Adolf Hitler und Saddam Hussein\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Institution organisiert den öffentlichen Verkehr in London?, Predicted Answer: Transport for London\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf die Siedlung welchen Stammes geht Paris zurück?, Predicted Answer: ''Rive Droite'', ''Rive Gauche'' und „Inseln\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchen Fällen kann im orthodoxen Judentum ein Säugling zum Judentum kovnertiert werden?, Predicted Answer: bestimmten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem US-Bundesstaat liegt Detroit?, Predicted Answer: Detroit Techno\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: gegen wen gingen die Jayhawker in Kansas während des Amerikanischen Bürgerkrieges vor?, Predicted Answer: 31:20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Gegenstand der Phytologie?, Predicted Answer: ein Gebiet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das malische Dloki-Ba?, Predicted Answer: Trail of Tears\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Film spricht Charles Elkins die deutsche Stimme von Arnold Schwarzenegger?, Predicted Answer: Mr. Universum\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welches Verbrechen urteilte der Supreme Court die Todesstrafe in Louisiana nicht als verfassungskonform?, Predicted Answer: Kennedy v. Louisiana\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hatte das britische Reich seine größte Ausdehnung?, Predicted Answer: erreicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Datenübertragungsrate hatte der  kabellose Netzwerkadapter der XBox vor 2009?, Predicted Answer: SG:PART\n",
            "                   'Liebst du mich?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.96 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Montgolfiere?, Predicted Answer: eine Sonntag-bis-Montag-Furore über die Royals. Sorgt euch nicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie werden Wörter in phonetischer Schreibung in der chinesischen Schrift dargestellt?, Predicted Answer: Lautzeichen benutzt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann erschien „Zaynab“ von Muhammed Husayn Haykal erstmals?, Predicted Answer: 1913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird Uranmunition eingesetzt?, Predicted Answer: kaum\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.10 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch was wird Nordirland im britischen Königswappen symbolisiert?, Predicted Answer: die britische Kultur geprägt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.11 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr erhielt Mali die Berechtigung zur Teilnahme an den Olympischen Spielen?, Predicted Answer: 2008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die Bezeichnung Kubismus das erste mal geschrieben verwendet?, Predicted Answer: ebenfalls nicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.95 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wie viele Juden leben in Tadschikistan?, Predicted Answer: deutschstämmige Menschen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Bereich des Physik arbeitete Feynmann hauptsächlich?, Predicted Answer: Mechanik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sieht die Handelsbilanz von Guinea-Bissau aus?, Predicted Answer: ein sehr hohes Außenhandelsdefizit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.92 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bei wem suchte sich der osmanische Sultan Hilfe während des griechischen Unabhängigkeitskrieges?, Predicted Answer: Muhammad Ali\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.61 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der tiefste Punkt der Antarktis?, Predicted Answer: 2496 m unter dem Meeresspiegel liegende Bentley-Subglazialgraben in Westantarktika\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus welchen Ländern stammen die meisten der in der Schweiz lebenden Ausländer?, Predicted Answer: 167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war das Ziel hinter der geplanten Eroberung von Prag durch Friedrich II.?, Predicted Answer: gebildet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.60 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welche Musikrichtung war Detroit in der ersten Hälfte des 20. Jhd. bekannt?, Predicted Answer: Olympischen Sommerspiele\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist Mary Youngblood?, Predicted Answer: Flötistin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.14 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo befinden sich beim Hund die Geschmacksknospen?, Predicted Answer: Rezeptoren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Der wie vielte Bundesstaat der USA wäre Puerto Rico nach offiziellem Beitritt in die USA?, Predicted Answer: Puerto Ricos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Art der Politik betrieb Keita in Mali?, Predicted Answer: sozialistisch orientierte Politik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher erdgeschichtlichen Epoche sind die Dinosaurier ausgestorben?, Predicted Answer: Oligozän und Miozän\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Behörden des Bundes sind in Hannover angesiedelt?, Predicted Answer: zwei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Zustand ist der Energiebedarf von  Aufzüge höher?, Predicted Answer: leeren Raums\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange hatten die Republikaner während Eisenhowers Präsidentschaft die Mehrheit im Parlament?, Predicted Answer: unumgänglich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Partei erhielt bei den Wahlen in Galizien 2005 die meisten Stimmen?, Predicted Answer: Partido Popular\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr befürwortete die Mehrheit im Referendum in Puerto Rico die Aufnahme in die USA?, Predicted Answer: 2012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.11 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was veranstaltete die US-Army, um eine Hymne zu finden?, Predicted Answer: Wettbewerb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist neben Hinayana die andere Hauptströmung des Buddhismus?, Predicted Answer: Mahayana\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wozu wird ein Daysimeter benutzt?, Predicted Answer: zirkadianes Messgerät\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurden Hinrichtungen in Iowa nach der ersten Abschaffung wieder etabliert?, Predicted Answer: 46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hoch ist BIP in North Carolina?, Predicted Answer: traditionell\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Partei kam nach dem Militärputsch 1968 an die Macht?, Predicted Answer: Moussa Traoré\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  2.13 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch was unterscheidet sich die Historiographie des 19. Jahrhunderts von der vorhergehenden?, Predicted Answer: Franco\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Menschenrechtsverletzungen erreigneten sich in Mali infolge des Putsches 2012?, Predicted Answer: 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wer wurde zu Beginn des amerikanischen Unabhängigkeitskrieges zum obersten Kommandanten bestimmt?, Predicted Answer: Beyoncé\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.92 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hoch ist das Pro-Kopf-BIP von Portugal?, Predicted Answer: sehr unterschiedlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie groß ist das Intervall der Planck-Zeit?, Predicted Answer: eine halbe Stunde\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ab wann wurde Glasproduktion im Römischen Reich in größerem Umfang möglich?, Predicted Answer: erschwinglich wurde. Eine umfangreiche Produktion von Trinkgefäßen, Krügen, Schalen und Tellern setzte ein, anfangs meist manuell geformt oder abgesenkt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.15 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann ist Paris eigenständiges Departement?, Predicted Answer: 1968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Art von Mosaiken wurden im Römischen Reich im ersten Jahrhundert nach Christus verwendet?, Predicted Answer: Viele Fußböden und seltener auch die Wände in Wohnbauten der gehobenen sozialen Schichten wurden mit Mosaiken dekoriert. Im ersten nachchristlichen Jahrhundert bevorzugte man vor allem schwarz-weiße Mosaiken\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ist die estnische Arbeitslosenquote im Vergleich mit anderen EU-Ländern?, Predicted Answer: nötig\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.12 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann verbreitete sich das Christentum im Elsass aus?, Predicted Answer: Die Mehrheit der Gesamtbevölkerung der Republik Kongo gehört\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo kann man nachschauen, welche alten Spiele auf den neuen XBox-Modelle spielbar sind?, Predicted Answer: ''Xbox Live\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Krieg lieferte Israel Waffen an den Iran?, Predicted Answer: Golfkrieg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Zeit entspricht die westeuropäische Normalzeit?, Predicted Answer: null Stunden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Sexualhormon spielt bei der Entwicklung der sexuellen Orientierung eine besondere Rolle?, Predicted Answer: Pelikan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.96 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was gilt seit der Revolution im Iran als Basis für Gesetze?, Predicted Answer: Voraussetzungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann gibt es in Iowa keine Todesstrafe mehr?, Predicted Answer: 1872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.12 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wurde unter Eisenhower als Dynamic Conservatism bezeichnet?, Predicted Answer: Am 2. April wurde Eisenhower in Abilene (Kansas) beigesetzt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.11 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann war die Entdeckung von Lutetium?, Predicted Answer: 1905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Reisende fliegen jährlich von den Airports um New York?, Predicted Answer: Queens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Länder wären durch einen Anstieg des Meeresspiegels besonders betroffen?, Predicted Answer: Gliedstaaten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.15 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Gliedmaße sind bei Insekten am Thorax verankert?, Predicted Answer: Flügelpaare\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.69 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Transportmittel wurde im Sezessionskrieg erstmals im großen Stil eingesetzt?, Predicted Answer: Software\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurde das Dionysos-Mosaik in Köln wieder entdeckt?, Predicted Answer: 1941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Anteil der Arbeitnehmer in estland ist weiblich?, Predicted Answer: der Tourismus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Schlacht entschied den Feldzug von Johann Ohneland nach Frankreich?, Predicted Answer: Barone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Seoul nach der nordkoreanischen Offensive wieder zurückerobert?, Predicted Answer: geräumt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange dauerte der Bau der Bahnverbindung zwischen LA und Santa Monica?, Predicted Answer: 27 Kilometer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Hat Mose wirklich gelebt?, Predicted Answer: unklar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welche Bedeutung hat Kanye West als Musiker?, Predicted Answer: Vielzahl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bei welchem Verein spielte Seydou Keita?, Predicted Answer: AS Rom\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Einfluss zeigt sich bei den christlichen Mosaiken in Ravenna?, Predicted Answer: Beispiel Blauwal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.69 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer regiert in Eritrea?, Predicted Answer: Parlaments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Status erhielt Richmond 1861?, Predicted Answer: Hauptstadt der Konföderation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann gelten Vögel als Zugvögel?, Predicted Answer: „einen Vogel zeigen“\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bezeichnet der Begriff \"Avifauna\"?, Predicted Answer: Vogelwelt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welcher Künstlervereinigung gehörte Albert Bloch?, Predicted Answer: bekanntesten deutschstämmigen Professoren an KU war der Maler Albert Bloch, seit einem langjährigen Deutschlandaufenthalt (1908–1921) Mitglied der deutschen Malergruppe Blauer Reiter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Rang im Index von Reporter ohne Grenzen belegt Nigeria?, Predicted Answer: Platz 122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was forderte Kerry als Konsequenz für den russischen Einsatz auf der Krim?, Predicted Answer: Bei einem Besuch in Israel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt das Buch, das die Weltreise von Erika und Klaus Mann erzählt?, Predicted Answer: University of Kansas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Aufgabe wurde dem NNSC durch das Abkommen zwischen Nord- und Südkorea nach dem Koreakrieg zugeteilt?, Predicted Answer: schwer lösbare\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt das Hauptgebäude von Comcast Corporation?, Predicted Answer: Kabelnetzbetreiber\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mittels was werden Urankerne gespalten?, Predicted Answer: Der Penis der Männchen ist ausschließlich samenführend und an der Spitze\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Ordnungszahl hat Uran?, Predicted Answer: 92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Zeit sollen Abraham und seine Nachkommen gelebt haben?, Predicted Answer: einiger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißen die drei Teile des Insektenthorax?, Predicted Answer: Débo, Fati, Teli, Korientze, Tanda, Do, Garou und Aougoundou\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird die diplomatische Vertretung des Vatikans bezeichnet?, Predicted Answer: ausgewogene diplomatische Beziehungen zu haben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche lokalen Volksgruppen lebten in der deutschen Kolonie Südwest-Afrika?, Predicted Answer: Wahlrecht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.17 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf was hofften die römischen Legionäre nach dem Ende ihrer Dienstzeit?, Predicted Answer: besondere Privilegien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.10 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Informationen wird in den Properties der Unicode-Zeichen festgehalten?, Predicted Answer: Sortierreihenfolge, Leserichtung und Regeln\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was waren die Räumlichkeiten der Galleria d’Arte Moderna in Palermo früher?, Predicted Answer: unabsehbar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie starb Tiberius Gracchus?, Predicted Answer: weiterreichende Ziele\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Materialien sind in der DIN 6730 festgelegt?, Predicted Answer: Papier und Pappe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welche Geräte  konnte USB 1.0 auch als Stromzufuhr eingesetzt werden?, Predicted Answer: USB-Kabelverbindungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In Abgrenzung zu was entstand der Neoklassizismus in Deutschland hautpsächlich?, Predicted Answer: nach außen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was zählt das Research Triangle in North Carolina?, Predicted Answer: Raleigh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Städte verbindet die Sunset Limited-Zuglinie?, Predicted Answer: Houston\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Gebiete erhielt Großbritannien durch den Vertrag von Versailles?, Predicted Answer: Diese Ereignisse\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Unter welchem Namen war eine frühere Version der US-Army-Hymne bekannt?, Predicted Answer: Praxis\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von welchen Flüssen wird der Caprivizipfel in Namibia eingeschlossen?, Predicted Answer: Grenzflüssen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Hauptaussage der Powell-Doktrin?, Predicted Answer: entwickelt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was lösen transplantierte Organe im Körper des Empfängers aus?, Predicted Answer: erkannt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann hat Hage Geingob das Präsidentenamt in Namibia inne?, Predicted Answer: drei Amtsperioden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer entwickelte Platons Metaphysik weiter?, Predicted Answer: Attac\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Beruf hatte Edgar Allan Poes Mutter?, Predicted Answer: Maria\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher deutsche Synchronsprecher synchronisiert die aktuellen Filme von Arnold Schwarzenegger?, Predicted Answer: Ralph Schicha\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen arbeiten bei den drei größten Biotechnologie-Unternehmen in North Carolina?, Predicted Answer: Inner Banks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Verhältnis stand  Gaius Sempronius Gracchus zu Tiberius Gracchus?, Predicted Answer: Verfassungsumsturz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.27 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wo wird der Mensch in der Zoologie eingeordnet?, Predicted Answer: 0,04 Gramm Kupfer zu sich nehmen, ohne Schaden an seiner Gesundheit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bezeichnet man als genetische Variabilität?, Predicted Answer: Sinn bezeichnet man als Haushund die Hunde\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel liegt der Bentley-Subglazialgraben unter dem Meer?, Predicted Answer: daran\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso schrumpfte die Wirtschaft der Republik Kongo im Jahr 2017?, Predicted Answer: 4,6 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wohin flüchteten die Juden während und nach der Shoa?, Predicted Answer: zahlreiche Menschen starben und viele Familien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.69 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Personen sitzen im akademischen Senat?, Predicted Answer: Studenten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso wurde der Text von Gruber Caission Song für die Übernahme als Army-Hymne geändert?, Predicted Answer: Kanye West erneut mit einer Vielzahl anderer Musiker zusammen, darunter Daft Punk, Frank Ocean, Arca und Rick Rubin. Letzterer wurde erst kurz vor der Deadline in die Produktion miteinbezogen, um den Minimalismus in Wests Stücken noch konsequenter zu gestalten. Ein Video für den Song ''New Slaves\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie groß war Warren Buffets Vermögen, bevor er Geld an Stiftungen spendete?, Predicted Answer: 45 Mrd. US-Dollar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.82 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Aufgabe hat die biologische Anthropologie?, Predicted Answer: Ursachenanalyse und evolutionsbiologische Interpretation der Verschiedenheit biologischer Merkmale der Hominiden (Familie der Primaten, die fossile und rezente Menschen einschließt). Ihre Methoden sind sowohl beschreibend als auch analytisch.\n",
            "Institutionen im deutschsprachigen Raum gibt es an Universitäten und an Museen in Tübingen, Kiel, Hamburg, Berlin, Göttingen, Jena, Gießen, Mainz, Ulm, Freiburg im Breisgau, München, Zürich und Wien. Meist ist dort die Bezeichnung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In der Regierungszeit welches Königs hatte das Königreich Urartu die maximale Ausdehnung?, Predicted Answer: Unter Sarduri II\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wie viele Kinder werden pro Frau in Tadschikistan geboren?, Predicted Answer: 2,7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Stadt ist die Zentrale der Comcast Corporation?, Predicted Answer: 39 Bundesstaaten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Materialeigenschaft eines Kondensators beeinflusst die maximale Ladungsmenge?, Predicted Answer: temperaturabhängig\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.16 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was stellte Remafedi 1991 bezüglich der sexuellen Orientierung und Selbstmord unter Jugendlichen fest?, Predicted Answer: Studie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Teil welches Departements war Paris im 18. Jhd.?, Predicted Answer: sechs regionale Departements\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf welchen Platz kam die malische U20-Mannschaft bei der WM 2015?, Predicted Answer: 3. Platz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Temperatur wird für den Urknall angenommen?, Predicted Answer: 15 °\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Flüsse bilden die Grenze zwischen Namibia und Südafrika?, Predicted Answer: zahlreiche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo errichteten die Römer in Paris ihre Stadt?, Predicted Answer: geografischen Gliederung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Übertragungsgeschwindigkeit hat der neuere WLAN-Adapter N der XBox?, Predicted Answer: 54 Mbit/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: was prangerte August von Platen in den Polenliedern an?, Predicted Answer: Der Ausdruck ''Völkermord'' taucht zum ersten Mal bei dem deutschen Lyriker August Graf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus welchem Jahrhundert stammt das erste Zeichenlexikon der chinesischen Schriftzeichen?, Predicted Answer: Shuowen Jiezi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.60 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welcher Industrieregion in den USA gehört Detroit?, Predicted Answer: Detroit Techno\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wegen welchen Verbrechens wurden in Iowa die meisten Menschen hingerichtet?, Predicted Answer: 43 wegen Mord und drei wegen Vergewaltigung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Umfang hat das BIP der Republik Kongo?, Predicted Answer: fast zehnmal höher\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sind katholische Religionslehrer von dem Scheidungsverbot betroffen?, Predicted Answer: Pauls VI\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Menschenrechtsverletzungen wird den staatlichen Organen und Vertretern in Mali vorgeworfen?, Predicted Answer: grobe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf wie viele Kilometer wurde das von Militär befreite Gebiet im Waffenstillstand 1953 zwischen Nord- und Südkorea festgelegt? , Predicted Answer: Breitengrad\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Woher stammt der Name Uran?, Predicted Answer: früher\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Jahresumsatz hatte Comcast Corporation 2015?, Predicted Answer: 51,8 Mrd. US-Dollar Platz 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch welche Struktur ist die Gesellschaft in Liberia gekennzeichnet?, Predicted Answer: große Gegensätze\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind Allele?, Predicted Answer: genetischen Varianten (Allele, Gene oder Genotypen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher deutsche Synchrosprecher synchronisierte die meisten von Schwarzeneggers Filmen?, Predicted Answer: Ernst II.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen in den USA sind jüdischen Glaubens?, Predicted Answer: sehr viele gut ausgebildete junge Menschen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hieß die deutsche Ausgabe der Dernieres Nouvelle d'Alsace?, Predicted Answer: „Jedes im Ausland geborene Kind eines Franzosen ist Franzose\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Um wie viel ist die Anzahl der Beschäftigen in der Textilindustrie in North Carolina seit 1990 gefallen?, Predicted Answer: traditionell\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Service wird in Fachgeschäften bereitgestellt?, Predicted Answer: Entwicklungshilfe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Möglichkeit bietet der Ersatzausweis für Nichtbürger in Estland?, Predicted Answer: ausweises\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.14 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Stadt war vor Richmond Hauptstadt der Südstaaten?, Predicted Answer: Lutetia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann hat Portugal den Euro als Währung?, Predicted Answer: unterschiedlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch welche Gebiete wurde Eritrea als italienische Kolonie erweitert?, Predicted Answer: Parlaments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Jahre mussten die Chicago Cubs nach ihrem Meisterschaftssieg von 1908 auf einen weiteren Titel warten?, Predicted Answer: 80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war das Hauptmerkmal der Heeresreform von Gaius Marius im Römischen Reich?, Predicted Answer: Feldherr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war der Grund für den Absturz der Boeing 747-300 über Guam 1997?, Predicted Answer: Korean-Air-Flug 801 von Seoul nach Agana (Guam) bei heftigem Regen gegen einen Hügel 5 km vor dem Flughafen Hagåtña geflogen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was nimmt die Kosmologie als Ursprung der Entstehung von Materie an?, Predicted Answer: Raum einnimmt ''und'' eine Masse besitzt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wurde 1888 in Richmond eingeführt?, Predicted Answer: Einrichtung der ersten elektrischen Straßenbahn\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.13 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann galt die doppelte Sommerzeit?, Predicted Answer: genannt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.95 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches politische System gab es in Mali nach der Unabhängigkeit?, Predicted Answer: ein Einparteienstaat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: was ist einer der Hauptfaktoren, die Kinderarbeit begünstigen?, Predicted Answer: Architektur\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt die Hauptstadt von Eritrea?, Predicted Answer: Eritrea\n",
            "Eritrea (; , ) ist ein Staat im nordöstlichen Afrika\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zwischen welchen Werten liegt die  untere Grenze für das Flächengewicht für Pappe?, Predicted Answer: Nord- und Südkorea\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Teil von Zypern ist als Staat anerkannt?, Predicted Answer: Staatspräsident\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch welche Maßnahmen begründete Esra das Brauchtum des Judentum?, Predicted Answer: eigentlicher\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Fluss bildet in der Gegend von Detroit die Grenze zu Kanada?, Predicted Answer: Detroit Techno\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange ist die Amtszeit des liberianischen Präsidenten?, Predicted Answer: reibungslos und friedlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie unterscheidet sich das Intervall zwischen zwei Spielzügen beim Canadian Football vom American Football?, Predicted Answer: Arsenal Holdings plc“ als Limited company, wobei sich die Eigentumsverhältnisse enorm von denen anderer Fußballvereine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Folgen hatte die japanische Eroberung von Lasio für die allierten Mächte?, Predicted Answer: noch zwei Nachschubwege\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Die Hauptstadt welchen Landes ist Vaduz?, Predicted Answer: Liechtensteins\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist ein Jayhawk?, Predicted Answer: Maskottchen der Universität ist der Jayhawk, ein nicht real existierender Vogel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Airports gibt es in New York City?, Predicted Answer: Newark Liberty International Airport\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann sind die Dinosaurier ausgestorben?, Predicted Answer: Beim Massenaussterben vor 65,5 Millionen Jahren (Kreide-Tertiär-Grenze) starben die Nicht-Vogel-Dinosaurier aus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die durchschnittliche Höhe über dem Meeresspiegel der Marshallinseln?, Predicted Answer: High Rock Mountain\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Auswirkung für die Gesellschaft hatte die Etablierung eines einheitlichen Schriftsystems in China 200 v. Chr?, Predicted Answer: Fundorte:'' Mureybet I B, II, III, Tell es-Sultan (Jericho), Göbekli Tepe III\n",
            "* 8200 bis 6800/6500 v.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde das Ende der Kämpfe zwischen Vereinten Nationen und Norkorea im Koreakrieg beschlossen?, Predicted Answer: Die meisten Kämpfe zwischen den Streitkräften beider Nationen fanden an der Grenze zwischen den Vereinigten Staaten und dem heutigen Kanada sowie in der Gegend der Chesapeake Bay statt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele täglich erscheinende, landesweite Zeitungen gibt es in Nigeria?, Predicted Answer: Yoruba, Hausa und Igbo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sieht die Oberfläche des Sixaxis-Controllers aus?, Predicted Answer: Deutlich besser\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.12 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen waren 1990 in der Textilindustrie in North Carolina beschäftigt?, Predicted Answer: 60 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Gruppe gehören die meisten US-amerikanischen Juden an?, Predicted Answer: Bevölkerungsgruppe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Gebiet von Paris war als erstes besiedelt?, Predicted Answer: Nationalgarde\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wer führte die englischen Truppen in der Schlacht bei Damme 1213?, Predicted Answer: Johanns Halbbruder William Longespée\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele verschiedene Arten von Vögeln gibt es ?, Predicted Answer: 158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Prozent der Menschen in Puerto Rico stimmten im Referendum 2012 für einen eigenständigen Staat?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird durch den Hamiltonoperator festgelegt?, Predicted Answer: eine Unterbrechung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann trat Portugal der EU bei?, Predicted Answer: Durchschnitt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie groß ist die Fläche der Belle Isle in Detroit?, Predicted Answer: km lange und 3,9 km2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: was war die Todesursache von Papst Paul VI.?, Predicted Answer: In dieser Form eine Neuheit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche militärischen Konflikte waren Anlass für eine Heeresreform im Römischen Reich um 100 v. Chr.?, Predicted Answer: Früheste Kupferverarbeitung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was beeinträchtigt das Spielen alter XBox-Spiele per Emulator?, Predicted Answer: Einige dieser älteren Spiele werden im Rahmen der Emulation in einer Grafik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche französischen Gebiete gab es nach dem Krieg Mitte des 18. Jhd. mit Großbritannien noch in Indien?, Predicted Answer: Straßburg im neu gegründeten Deutschen Reich Hauptstadt des Reichslandes Elsaß-Lothringen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.16 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welcher Flussmündung liegt Valencia?, Predicted Answer: Turia ins Mittelmeer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Unterschied ergibt sich durch die Quantisierung von Schwingungsenergie in Bezug auf die Wärmeenergie von festen Körpern?, Predicted Answer: Albert Einstein\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Ereignis im Syrien-Krieg führte zu Kerrys Forderung nach einem militärischen Einsatz?, Predicted Answer: Der wachsende wirtschaftliche und politische Einfluss europäischer Staaten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer veranlasste den Bau einer Zugstrecke zwischen LA und Santa Monica?, Predicted Answer: Robert Baker\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war die höchste Platzierung, die Mali in der Afrikameisterschaft erreichte?, Predicted Answer: der dritte Platz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für was steht die Bezeichnung UTC?, Predicted Answer: ein deutsches Wesen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war der Grund, dass im Sezessionskrieg vergleichsweise mehr Menschen starben als bei früheren Kriegen?, Predicted Answer: Die Schlacht von Shiloh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird der Chef oder die Chefin einer Universität genannt?, Predicted Answer: Rektor oder Präsidenten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Einwohner:innen hat Iran im Vergleich mit der BRD?, Predicted Answer: Anlagen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bis wann wurde der Sixaxis-Controller produziert?, Predicted Answer: zu sieben solcher Controller können für eine Konsole\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch welches Phänomen konnte Einstein den Wärmeverlust von Körpern bei tiefen Temperaturen erklären?, Predicted Answer: Abnahme\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus wie vielen Teilen besteht der Thorax von Insekten?, Predicted Answer: drei Segmenten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wann wurde in Frankreich der Laizismus eingeführt?, Predicted Answer: schleppender verlief\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welches neue Verständnis von Poesie etablierte sich Mitte des 18. Jahrhudnerts?, Predicted Answer: Drama\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Anteil aller Menschen hat sich mit Tuberkulose angesteckt?, Predicted Answer: Armen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird die Hymne des US-Army im umgangssprachlich meist genannt?, Predicted Answer: Army Song\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Auswirkung hatte die Teilnahme an der Schlacht von Gallipoli auf die britischen Dominions Australien und Neuseeland?, Predicted Answer: tiefgreifende\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In Zusammenhang mit welchem Reformpaket wurde in den USA das Sozialstaatskonzept umgesetzt?, Predicted Answer: wom\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann endete der Kampf um die Unabhängigkeit Eritreas von Äthiopien?, Predicted Answer: 1991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Papst versuchte die Entführung von Aldo Moro zu beenden?, Predicted Answer: Paul VI.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Unter welchem Namen wurde die Stadt Van gegründet?, Predicted Answer: Sarduri I.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch was unterscheidet sich ein Warenhaus von einen Kaufhaus?, Predicted Answer: ungeachtet seines Namens ein Vollsortiment mit großer Lebensmittelabteilung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Juden lebten vor dem Fall Der Sowjetunion in Tadschikistan?, Predicted Answer: ausweises\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Durchschnittshöhe hat das Hochland von Namibia?, Predicted Answer: 1700 Meter hohe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie haben sich die Bedienelemente des Sixaxis-Controllers im Vergleich zum DualShock verändert?, Predicted Answer: PS3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.14 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie groß ist das gebiet, in dem die Inseln der Marshallinseln verteilt sind?, Predicted Answer: Besonders groß ist diese in den Monaten April bis Juni\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer führte die Truppen der Konföderation im Sezessionskrieg?, Predicted Answer: weniger genau Buch über ihre Verluste\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher römische Feldherr reformierte um 100 v. Chr. das Herr des römischen Reiches?, Predicted Answer: Gaius Marius\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.59 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was entstand die Stadt Kolmannskuppe in Namibia?, Predicted Answer: Staatspräsident\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welcher Gruppe von Ballsportarten gehört Canadian Football?, Predicted Answer: Gridiron Football bezeichneten Spielen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wurde 2009 galizischer Regierungschef?, Predicted Answer: Mussawi und Karrubi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf was haben Pheromone beim Menschen Einfluss?, Predicted Answer: keine Reaktion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso gibt es unterschiedliche Werte für die Grenze zwischen Pappe und Papier?, Predicted Answer: Flugdrachen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.16 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was findet in der Cobo Hall in Detroit vor allem statt?, Predicted Answer: Detroit International Jazz Festival\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird die Zeit nach dem internationalen Einheitensystem angegeben?, Predicted Answer: nicht einheitlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hoch ist das BIP pro Kopf in Myanmar?, Predicted Answer: äußerst ungleichmäßig verteilt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Tag ist besonders wichtig für die anti-israelische Propaganda im Iran?, Predicted Answer: al-Quds-Tag\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch was werden Vögel biologisch gekennzeichnet?, Predicted Answer: einen massiven Ölboom\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.61 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann startete die Aktion \"Call  to Action\" des Polizeichefs von Philadelphia?, Predicted Answer: 10,000 Men, It’s a New Day\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welche negativen witschaftlichen Folgen entstehen durch Kinderarbeit?, Predicted Answer: Ursachen und Folgen der Kinderarbeit ==\n",
            "Die wichtigste Ursache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Shoiwen Jiezi?, Predicted Answer: Trail of Tears\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird durch die genetische Variabilität einer Population beeinflusst?, Predicted Answer: wesentlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo liegen die Marshallinseln?, Predicted Answer: China\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Institution veranlasste die Gründung des Nationalarchivs?, Predicted Answer: Nanchang\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.95 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bei welchen Xbox-Modellen ist der WLAN-Empfänger bereits fest verbaut?, Predicted Answer: Xbox 360 S und E\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.22 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bei welchen Nintendo-Spielen wurde der R.O.B. eingebunden?, Predicted Answer: Retro-Spielern\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von wem wurde Arnold Schwarzenegger bei seiner Kandidatur in Kalifornien als Mogelkandidat bezeichnet?, Predicted Answer: Wahlkampfes wurde Schwarzenegger von einigen seiner republikanischen Parteifreunde\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo in Neu-Delhi liegt das Observatorium Jantar Mantar?, Predicted Answer: Jai Singh II.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Auswirkungen hatte die Niederlage von Kolin für das preußische Heer?, Predicted Answer: tiefgreifende\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wurde neben religiösen Fächern an den Nizamiya-Madrasas unterrichtet?, Predicted Answer: Naturwissenschaften sowie Logik und Mathematik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war designierter Vize-Präsident Im Wahlkampf von John Kerry?, Predicted Answer: John Edwards\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen leben in Israel pro Quadratkilometer?, Predicted Answer: 3000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Bereiche der Physik soll die Quantengravitation theoretische zusammenführen?, Predicted Answer: Zeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Bedeutung hat die Schlacht von Plassey für die Ostindien-Kompanie?, Predicted Answer: entscheidender Sieg durch Sir Robert Clive, 1. Baron Clive in der Schlacht bei Plassey 1757 ließ die Britische Ostindien-Kompanie auch zu einem militärischen Machtfaktor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welcher Klasse von Metallen gehört Zink?, Predicted Answer: Übergangsmetallen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird am ANZAC Day gedacht?, Predicted Answer: Beide Länder\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war König von Frankreich während Johann Ohnelands Feldzug nach Frankreich?, Predicted Answer: Barone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.60 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für was kandidierte Arnold Schwarzenegger 2003?, Predicted Answer: das Amt des Gouverneurs von Kalifornien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird in der Transaktionsliste eines USB-Anschlusses verwaltet?, Predicted Answer: Symbolrate von 5 Gbit/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war das Ziel von Sylvester Johnsons Aktion \" Call to Action\" in Philadelphia?, Predicted Answer: 10,000 Men, It’s a New Day\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.96 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso verweigerten einige englische Fürsten Johann Ohneland die Gefolgschaft, als er gegen Frankreich ziehen wollte?, Predicted Answer: Stalin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.27 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Anforderung stellt die Powell-Doktrin an das Ende eines militärischen Konflikts?, Predicted Answer: Mens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer führte den Putsch gegen Traore in Mali an?, Predicted Answer: Frankreich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.93 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Amt bekleidete der Feldherr Gaius Marius in Rom?, Predicted Answer: ein Amt, das er bis zu seinem Tod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr annektierte Haile Selassie Eritrea?, Predicted Answer: 1961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.60 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche der nigerianischen Tageszeitungen werden auf Englisch publiziert?, Predicted Answer: Die meisten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Beleuchtung zählt als Außenbeleuchtung?, Predicted Answer: Begriff\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo wurde der Waffenstillstand für den Koreakrieg beschlossen?, Predicted Answer: 1784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.95 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welches Phänomen tritt bei elektromagnetischer Strahlungsenergie auf?, Predicted Answer: Die Quantelung der Energie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Funktionen sind mit dem Hypothalamus verknüpft?, Predicted Answer: Instinktverhalten und Sexualfunktionen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso ist Thüringen auch in Zukunft auf Finanzhilfen vom Bund  oder EU angewiesen?, Predicted Answer: 19. März 2013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wurde durch das Abkommen zur Beendigung des Koreakrieges als Grenzlinie zwischen den beiden Teilen Koreas festgelegt?, Predicted Answer: Weiterhin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Funktion fällt bei dem SIXAXIS-Controller im Vergleich mit dem Vorgängermodell weg?, Predicted Answer: Rüttel“-Funktion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie entsteht außer durch Mutation noch Genvariationen und Allele?, Predicted Answer: Gene\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.94 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ist Paris verwaltungstechnisch gegliedert?, Predicted Answer: Commune de Paris\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Prozent erhielt Schwarzenegger bei der Wahl zum Gouverneur 2003?, Predicted Answer: ''Laureus World Sports Award\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Anteil hat die Ölförderung am Staatshaushalt von Alaska?, Predicted Answer: Alaska Permanent Fund\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche von Schwarzeneggers Büchern waren Bestseller?, Predicted Answer: ''The Encyclopedia of Modern Bodybuilding'', ''Arnold: The Education of a Bodybuilder'' und ''Arnold’s Bodybuilding for Men\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Nach welcher Einteilung sind Zink und Quecksilber in Gruppe 12?, Predicted Answer: IUPAC-Nomenklatur\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die größte Stadt in der Umgebung der Alpen?, Predicted Answer: Wien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Unter welchem chinesischen Kaiser wurde das Schriftsystem vereinheitlicht?, Predicted Answer: Minamoto no Yoritomo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.12 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hieß Paris vor der römischen Eroberung?, Predicted Answer: spiralförmig von innen nach außen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Organ ist meist von Tuberkulose betroffen?, Predicted Answer: Schulwesen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche an Land lebenden Säugetiere werden nach dem Menschen am ältesten?, Predicted Answer: Oberschicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der größte Internet- und Telefonanbieter in den USA?, Predicted Answer: AT&T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann spalteten sich die Südstaaten vom Rest der USA ab?, Predicted Answer: wieder deutlich erhöht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Partei bestimmt die politische Landschaft in Eritrea?, Predicted Answer: Kaiser Haile Selassie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Geschmacksknospen haben Menschen?, Predicted Answer: 9000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welche Art von Nahrung ist der flüssigere Speichel bei Hunden gedacht?, Predicted Answer: Gemüsenahrung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Position übernahm Schwarzenegger im März 2013?, Predicted Answer: Group Executive Editor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Woran liegt es, dass viele Redereien ihre Schiffe in Liberia anmelden?, Predicted Answer: Verschwiegenheit der Behörden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Tiere sind mit dem Gott Wotan unterwegs?, Predicted Answer: die anderen Götter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird der R.O.B. von Nintendo in Spiele eingebunden?, Predicted Answer: siehe unten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Selbstwert einer Sache?, Predicted Answer: Die Regelung aller anderen Feiertage ist allein Sache der Kantone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist John Kerrys älteste Schwester geboren?, Predicted Answer: Italienisch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.69 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Wert eines Kondensators wird durch die Temperatur beeinflusst?, Predicted Answer: typische\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Alter sind Kinder im Judentum religionsmündig?, Predicted Answer: Ritualmord\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Vertreter welcher iranischen MInderheit ist Ciamak Moresadegh?, Predicted Answer: Abgeordneter der jüdischen Minderheit im iranischen Parlament\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.12 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Position hatte Chalkali im iranischen Staat nach der Revolution?, Predicted Answer: Tätigkeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welche Zeitspanne fällt für Volker Reinhardt der Humanismus?, Predicted Answer: Die Ansicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.13 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wie viele Menschen lebte um 1850 in Richmond, Virginia?, Predicted Answer: ganz Virginia Jahrzehnte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Spieler hat ein Team beim American Football?, Predicted Answer: vier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie würden die Küsten von Westantarktika sich verändern, wenn die Eisdecke verschwindet?, Predicted Answer: völlig anders aussehen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ab wann war Kerry offiziell Kandidat für die Präsidentenwahl 2004?, Predicted Answer: gemäßigter Kandidat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Bevölkerungsgruppe macht den größten Teil der Bevölkerung in Tadschikistan aus?, Predicted Answer: wom\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.92 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welcher Literaturgattung wurde der Roman ab der Mitte des 18. Jhd gezählt?, Predicted Answer: War der Roman bis dahin eher Teil der dubiosen Historien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die außenpolitische Maxime von Hage Geingob?, Predicted Answer: Staatspräsident\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche farbe haben die Bruchkanten von Zink?, Predicted Answer: nicht jedoch die Türken\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Auszeichnung erhielt Ellen Johnson-Sirleaf 2018?, Predicted Answer: Anerkennung ihrer erfolgreichen Regierungsführung und ihrer Verdienste um die Demokratisierung Liberias wurde Ellen Johnson-Sirleaf 2018 mit dem Mo-Ibrahim-Preis\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo wird der Begriff \"Völkermord\" das erste Mal schriftlich verwendet?, Predicted Answer: Synonyme\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches ist die bevölkerungsreichste Stadt in den Alpen?, Predicted Answer: Davos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt das Zentrum der neuronalen Zellen bei Ringelwürmern? , Predicted Answer: gegenwärtigen Palastes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie entstehen Elemente höher als Eisen?, Predicted Answer: an der Sohle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Opfer verursachte der Krieg in der deutschen Kolonie Südwest-Afrika unter der lokalen Bevölkerung?, Predicted Answer: wom\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.59 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher controller ist Standard für die Playstation?, Predicted Answer: DualShock 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Wirkstoff wurde bei Hinrichtungen in Ohio bis 2011 benutzt?, Predicted Answer: Thiopental\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Aufgabe hat die Hochschulrektorenkonferenz?, Predicted Answer: Petrus Stuyvesant übernehmen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ab wann war Eritrea italienisches Territorium?, Predicted Answer: politisch umstritten und gefährlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso haben Säugetiere einen höheren Energiebedarf als andere Arten?, Predicted Answer: Generell leben kleinere Arten weniger lang als größere Arten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welcher Region in Frankreich gehört Paris?, Predicted Answer: Île-de-France\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welcher Maßnahme könnten Urheberrechtsverstöße auf Servern aus dem Ausland in Deutschland verhindert werden?, Predicted Answer: technische Kopierschutzmaßnahmen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was gilt Ellen Johnson-Sirleaf in Afrika?, Predicted Answer: Siegerin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Bereich sind die Kru in Liberia vor allem tätig?, Predicted Answer: Bürgerkrieges die deutlichste Verbesserung im sogenannten ''Index gescheiterter Staaten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit wem erhielt Richard Feynmann den Nobelpreis?, Predicted Answer: Shin’ichirō Tomonaga und Julian Schwinger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Gruppe will die WWE in letzter Zeit als Wrestling-Fans gewinnen?, Predicted Answer: Über die letzten Jahre schaffte die NWE den Sprung an die italienische Spitze\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Spitznamen hat Arnold Schwarzenegger in den USA?, Predicted Answer: geboren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Isotop von Uran wird bei der Kernspaltung verwendet?, Predicted Answer: Plutonium-Isotop 239Pu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso ist die Entstehung des Universums nicht unmittelbar mit dem Urknall beschreibbar?, Predicted Answer: zwingend ist diese Verbindung philosophischer Positionen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch welche Prüfschritte wird ein Elektromotor abschließend geprüft?, Predicted Answer: Banknote\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie versuchte Papst Paul VI. die Entführung von Also Moro zu beenden?, Predicted Answer: Benjamín Mendoza y Amor Flores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie werden Vögel bezeichnet, die keine Zugvögel sind?, Predicted Answer: intelligenter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer strebte 1211 nach der schottischen Königswürde?, Predicted Answer: Guthred Macwilliam\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Last konnten die Ballonbomben aus Papier, die Japan im 2. Weltkrieg einsetzte, tragen?, Predicted Answer: nicht einnehmen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie unterschied sich der Hawaii-Dollar von den regulären Dollar-Scheinen?, Predicted Answer: == Hawaii-Dollar ==\n",
            "Um zu verhindern, dass bei einer möglichen Eroberung von Hawaii größere Dollar-Bestände in feindliche Hände fallen, wurden ab Juni 1942 eigene Banknoten auf Hawaii ausgegeben. Diese waren motivgleich zu den normalen Dollarnoten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.96 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welche ist die größte indigene Gruppe in LIberia?, Predicted Answer: Pfingstkirche Assemblies of God\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Auswirkung auf die Umfragen hatte die Fernsehdebatte zwischen Bush und Kerry im Wahlkampf?, Predicted Answer: geringe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche öffentlichen Nahverkehrsmittel gibt es in Raleigh, North Carolina?, Predicted Answer: Amerikaner schottisch-irischer und englischer Abstammung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann eroberten die Alliierten Eritrea von Italien?, Predicted Answer: 1961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Staaten herrschten im 19. Jahrhundert jeweils über Teile des heutigen Polen?, Predicted Answer: die vollständige politische Kontrolle über alle indischen Territorien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele aschkenasische Juden gibt es weltweit?, Predicted Answer: 500.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.92 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie unterscheidet sich die Innenausstattung von Pubs von anderen Schankwirtschaften?, Predicted Answer: in der Größe und im Aufbau\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.82 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Zeitraum war Namibia deutsche Kolonie?, Predicted Answer: Republik Mali\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welche Auflagen gelten für Sharehoster in Bezug auf das Verhalten der User:innen?, Predicted Answer: Sichtbezüge, Raumabfolgen und Wegeführungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Stadt ist die elsässische Handelskammer angesiedelt?, Predicted Answer: North Carolina\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde der malische Präsident Traoré abgesetzt?, Predicted Answer: durch einen Staatsstreich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen lebten vor 1945 im Britischen Empire?, Predicted Answer: 1965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Titel wurden früher für die Amtsträger an Universitäten verwendet?, Predicted Answer: Schrift\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ist laut Einstein Wärmeenergie in Festkörpern gespeichert?, Predicted Answer: Abnahme\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was gilt als Ursprung des Neoklassizmus in den USA?, Predicted Answer: Trail of Tears\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche besonderen Vögel gibt es in Mythen weltweit?, Predicted Answer: intelligenter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Grenze zwischen Pappe und Papier in der DI-Norm?, Predicted Answer: Die Masse\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Downs gibt es beim Canadian Football in einem Angriff?, Predicted Answer: drei Versuche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Rezeptoren befinden sich im Kopfbereich von Ringelwürmern?, Predicted Answer: ebenfalls\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war die Ursache für das Hinrichtungsmoratorium in Ohio 2014?, Predicted Answer: „Trail of Tears\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Ziel von am Selbstwert der Biodiversität orientierten Einstellungen?, Predicted Answer: Unterstützung der allgemeinen Wirtschaftspolitik der EU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welche Städte sind an das Netz der Triangle Transit Authority in North Carolina angeschlossen?, Predicted Answer: Chapel Hill\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Zentrum der britischen Infrastruktur?, Predicted Answer: aufgeklärten Denkens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann fängt die Sommerzeit an?, Predicted Answer: gleich der Zonenzeit der östlich benachbarten Zeitzone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.10 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Fluss bildet die Grenze zwischen Namibia und Südafrika?, Predicted Answer: wichtigen Wirtschaftszweig\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was setzen die Copyright-Inhaber zur Vermeidung von illegalen Kopien ein?, Predicted Answer: im großen Stil\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wie wird die doppelte Stunde am Ende der Sommerzeit unterschieden?, Predicted Answer: Bei beruflichen Tätigkeiten, die draußen stattfinden, ist es zudem morgens z. B. an heißen Sommertagen noch eine Stunde länger kühl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ist das Einkommen in Palermo im Vergleich mit ganz Italien?, Predicted Answer: Italian Championship Wrestling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurde die UTC früher bezeichnet?, Predicted Answer: UTC+1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Amt hatte Hifikepunye Pohamba inne, bevor er namibischer Präsident wurde?, Predicted Answer: Windhoek\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was kann man an der Kopfbedeckung einer Frau in Mali erkennen?, Predicted Answer: verheiratet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für was wird das Musepack-Audiformat vor allem eingesetzt?, Predicted Answer: praktisch nicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.11 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Bakterium löst Tuberkulose aus?, Predicted Answer: Liechtenstein\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso steht es um die Wirtschaft in Guinea-Bissau trotz Investitionen nach der Unabhängigkeit schlecht?, Predicted Answer: Rolle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Bereich der Alpen wird nach der in Italien und Frankreich verwendeten Gliederung als Zentralalpen bezeichnet?, Predicted Answer: die Blütezeit des Rittertums, des Lehnswesens und des Minnesangs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Konfession gehören die meisten Menschen im Elsass an?, Predicted Answer: christlichen Konfessionen im Elsass haben sich bis heute ihre historisch bedingte Bindung an den Staat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso war Schwarzenegger als Gouverneur zur Zusammenarbeit mit den Demokraten gezwungen?, Predicted Answer: „\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches sind die renomiertesten Universitäten in Detroit?, Predicted Answer: University of Detroit Mercy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welche Regionen ist die in Hannover ansässige Bundesbank zuständig?, Predicted Answer: Genf und Basel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ging die Schlacht bei Roche-aux-Moines aus?, Predicted Answer: Johann\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Fach wurde am 1890 an  der University of Kansas gelehrt?, Predicted Answer: Fachrichtung Soziologie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.69 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was geschah mit den russischen Zeugen Jehovas in der Operation Nord?, Predicted Answer: lose\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.94 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann entstand der Lykurgosbecher?, Predicted Answer: im Besitz des Britischen Museums\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war die Essenz von Abd al-Wahhabs Lehren?, Predicted Answer: „Trail of Tears\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war der Pflegevater von Edgar Allan Poe?, Predicted Answer: John Allan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer folgte auf Johnson-Sirleaf als Präsident von Liberia?, Predicted Answer: George Weah\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird als Karton bezeichnet?, Predicted Answer: Papier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird bei der Endmontage eines Elektromotors nach dem Fertigstellen des Stators eingebaut?, Predicted Answer: der Antrieb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bedeutet der Eigenwert der Biodiversität?, Predicted Answer: dass die Biodiversität wegen des ihr von Menschen beigemessenen Wertes an sich geschätzt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was wird Zinkchlorid beim Aufbereiten von Wasser eingesetzt?, Predicted Answer: Exergieverlust\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die meisten chinesischen Schriftzeichen?, Predicted Answer: noch zwei Nachschubwege\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ersetzt das Restatements of the Law in den USA?, Predicted Answer: Intelligence Reform and Terrorism Prevention Act\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Summe gab der FC Arsenal 2012 für die Gehälter von Spielern und Angestellten aus?, Predicted Answer: 62.217 Aktienanteile\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Woher stammte John Kerrys Großvater väterlicherseits?, Predicted Answer: Aufgrund des Berufes seines Vaters verbrachte John Kerry einen Großteil seiner Jugend in Europa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Tiere halten den Schild im Wappen der englischen Krone?, Predicted Answer: Afrikanische Völker\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welchen Krankheiten sterben auf dem afrikanischen Kontinent die meisten Menschen?, Predicted Answer: entzündlich-rheumatischen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.11 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann hat der Iran keine Beziehungen zu Israel mehr?, Predicted Answer: 1979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Summe erhielten die Einwohner:innen Alaskas pro Kopf aus dem Öl-Fond 2011?, Predicted Answer: zusätzliche Einkünfte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Wüste liegt im östlichen Namibia?, Predicted Answer: Hage Geingob\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ab wann verstärkte Mali die Beziehungen zu den westlichen Ländern?, Predicted Answer: Mitte der 1970er Jahre\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann nach Chr. wurden im Römischen Reich zunehmend bildliche Darstellungen in Mosaiken verwendet? , Predicted Answer: wobei christliche Kirchen zerstört wurden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann drohte Großbritannien in der Nachkriegszeit bankrott zu gehen?, Predicted Answer: das Konfliktpotenzial zwischen den Großmächten zu beseitigen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist nominal für die Ordnung des Verkehrs in London zuständig?, Predicted Answer: TfL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Unter welcher Bedingung ist  nach der Powell-Doktrin im Verteidigungsfall der Streitkräfteeinsatz legitim?, Predicted Answer: die nach Powell und Weinberger benannte Weinberger-Powell-Doktrin oder Powell-Doktrin entwickelt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange dauerte der Krieg zwischem dem Osmanischen Reich und den Anhängern al-Wahhabs?, Predicted Answer: Muhammad Ali\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo befindet sich das Internat, das John Kerry in Europa besuchte?, Predicted Answer: Israel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr wurde erstmals eine Kernspaltung durchgeführt?, Predicted Answer: 1897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was galt als Ideal in der Literatur für die Anhänger Gottscheds?, Predicted Answer: Ziel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welchen Status hat Armenisch auf Zypern?, Predicted Answer: Westarmenisch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.61 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt das traditionelle Kleidungsstück für Frauen in Mali?, Predicted Answer: Frankreich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso ist der Verdauungstrakt bei Karnivoren vergleichsweise kurz?, Predicted Answer: R.O.B.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Anführer welcher politischen Gruppe in der Römischen Republik war Gaius Marius?, Predicted Answer: Popularen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie groß ist die Landmasse der Marshallinseln?, Predicted Answer: Besonders groß ist diese in den Monaten April bis Juni\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde das Dionysos-Mosaik in Köln wieder entdeckt?, Predicted Answer: im Jahr 1941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Vogel ist Symbol der University of Kansas?, Predicted Answer: Jayhawk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie kann eine katholisch geschlossene Ehe annulliert werden?, Predicted Answer: Recht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was steht beim Hinayana-Buddhismus im Zentrum des Strebens nach Erwachen?, Predicted Answer: ein Mensch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Stunden weicht die Westeuropäische Normalzeit von der Koordinierten Weltzeit ab?, Predicted Answer: UTC±0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche These wird in der Sprachphilosophie in Bezug auf Übersetzung vertreten?, Predicted Answer: Hören\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.22 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Schweizer Städte gehören zur Alpenregion?, Predicted Answer: traditionelle Schweizer Volksmusik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer gründete nach der Zerstörung der Dynastie von Ur durch die Elamer ein Reich auf dem Gebiet von Sumer?, Predicted Answer: Wilhelm I.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Gemeinden in Thüringen leiden besonders an Schulden?, Predicted Answer: Viele Kommunen in Thüringen sind überschuldet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür wird bei Modellflugzeugen Papier als Material eingesetzt?, Predicted Answer: Masse\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.92 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welchem Meer liegt Eritrea?, Predicted Answer: Rote Meer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo leben urtümliche Hunde?, Predicted Answer: wild\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo bekommt man die Emulator-Software für alte XBox-Spiele?, Predicted Answer: Grafik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.10 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bedeutet Energiequantelung bei elektromagnetischen Wellen?, Predicted Answer: entscheidender Bedeutung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Museum in Palermo beherbergt eine Ausstellung über die historische Entwicklung der Stadt?, Predicted Answer: Museo Frida Kahlo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hat sich die Funktionalität der Schultertasten beim Sixaxis-Contoller im Vergleich mit dem Vorgänger verändert?, Predicted Answer: Die Gehirne von Männern und Frauen unterscheiden sich in der Größe und im Aufbau\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Bauteil wird bei der endgültigen Montage von Elektromotoren als erstes verbaut?, Predicted Answer: Antrieb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo befindet sich die diplomatische Vertretung des Vatikans in Guinea-Bissau?, Predicted Answer: Folgende Staaten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was erklärte Einstein 1907 durch die Quantelung von  Schwingungsenergie?, Predicted Answer: der Schlüssel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann gibt es das für Unicode verantwortliche Konsortium?, Predicted Answer: 1991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was versuchte das Absinken des Meeresniveaus während der Eiszeiten?, Predicted Answer: die Initiative\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war die Grundform des ursprünglichen Santa Monica?, Predicted Answer: Santa Monica Pier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Personen spielen beim Canadian Football für ein Team?, Predicted Answer: weniger Verzögerungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ordnet Forbes den Marktwert des FC Arsenal ein?, Predicted Answer: taxierte den Mannschaftswert des FC Arsenal im April 2013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie werden Tuberkuloseinfektionen oder Verdachtsfälle darauf behandelt?, Predicted Answer: Antibiotika\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso wird Botanik heute eher als Pflanzenwissenschaft bezeichnet?, Predicted Answer: einen Teil der Natur\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf wen geht die Philosophie der Metaphysik zurück?, Predicted Answer: im Kern\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche vogelartigen Kreaturen gibt es in der griechischen Mythologie?, Predicted Answer: eine Rolle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.21 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von wem wurde Aldo Moro als Geisel genommen?, Predicted Answer: Roten Brigaden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Elemente entstanden nach dem Urknall als erstes?, Predicted Answer: 35 v. Chr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Konfliktpartei im amerikanischen Bürgerkrieg wird Ohio zugeordnet?, Predicted Answer: Eriesee\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Epoche umfassen die Ausstellungstücke des archäologischen Museums in Palermo?, Predicted Answer: Niedergangs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wird einer Infektion mit Tuberkuloseerregern als latent bezeichnet?, Predicted Answer: 30 Prozent\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welche Eismasse sagen Forscher:innen ein durch den Klimawandel bedingtes Abschmelzen voraus?, Predicted Answer: Gletschers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer verbündete sich mit Johann Ohneland in Flandern?, Predicted Answer: William Longespée\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welche Whiskey-Marken werden in Tennessee produziert?, Predicted Answer: Jack Daniel’s und George Dickel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ging des langjährige Synchronsprecher von Arnold Schwarzenegger in Ruhestand?, Predicted Answer: wiederum gewann\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Funktionen im Staat erfüllt der Präsident in Liberia?, Predicted Answer: Index gescheiterter Staaten'' vollbracht; dieser bewertet die politische, soziale und wirtschaftliche Lage des jeweiligen Staates.\n",
            "Präsidentin Johnson-Sirleaf hat erste Schritte zur Bekämpfung der Korruption, Anreize für private Investitionen und eine Werbeinitiative zur Unterstützung von internationalen Gebern unternommen. Die Inflationsrate stieg weiter an und lag 2008 bei 11,2 Prozent.\n",
            "Im Global Competitiveness Index\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war die Ursache für den Brand, durch den Richmond im Bürgerkrieg zerstört wurde?, Predicted Answer: vollständig\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf welcher Messe hat Nintendo den R.O.B. erstmals präsentiert?, Predicted Answer: Summer Consumer Electronics Show\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurden die Gebiete des heutigen Namibia unter deutscher Herrschaft genannt?, Predicted Answer: ''Orange River\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem County liegt Detroit?, Predicted Answer: Wayne\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde in Louisiana die Hinrichtung als Strafe nach Aussetzung in den 1970 wieder eingeführt?, Predicted Answer: Vergewaltigung von Kindern mit dem Tode bedroht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Nach welchen Kriterien sind die chinesischen Schriftzeichen im Shuowen Jiezi geordnet?, Predicted Answer: sechs Kategorien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was kann eine Begleiterscheinung von Implantaten sein?, Predicted Answer: acht Polizisten und neun Angreifer ums Leben gekommen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was waren die landwirtschaftlichen Haupterzeugnisse von North Carolina vor dem Sezessionskrieg?, Predicted Answer: die Küstenebene am Atlantik, das Piedmont-Plateau im Hinterland und die Bergregion der Appalachen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Rolle hat der Hohepriester Esra für die jüdische Religionsgemeinschaft?, Predicted Answer: wichtige\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wird ein Fahrstuhl als indirekt hydraulisch bezeichnet?, Predicted Answer: angeordnet werden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo befindet sich das Nervensystem bei Ringelwürmern?, Predicted Answer: Am westlichen Seeufer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Stadt eroberten die Japaner Ende April 1942 im Pazifikkrieg?, Predicted Answer: Burma konnten die Japaner am 30. April die Stadt Lasio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches war der erste Kinofilm, in dem Schwarzenegger mitmachte?, Predicted Answer: Idol Reg Park\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher bedeutende Reformator stammt aus dem Elsass?, Predicted Answer: Martin Bucer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist ein Schleimhautödem?, Predicted Answer: „ein gängiges Thema der üblichen Oberlehrerpädagogik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die These von der Unbestimmtheit von Übersetzung?, Predicted Answer: besagt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer gilt als die Urahnen des jüdischen Volkes?, Predicted Answer: Jude\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wohin führte die Emigration der aschkenasischen Juden aus Europa um 1900?, Predicted Answer: Allgemeine Handbuch der Freimaurerei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Branche ist innerhalb des Dienstleistungssektors in Palermo besonders wichtig?, Predicted Answer: Vitamin-B12-Resorption\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Film wurde eine Meisterschaftssieg der Chicago Cubs für 2015 vorausgesagt?, Predicted Answer: ''Zurück in die Zukunft II\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: zu welcher Art von Geschossen gehört Uranmunition?, Predicted Answer: Übergruppe der Wuchtgeschosse\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Problemen musste die malische Regierung unter Keita begegnen?, Predicted Answer: Mali in der Folge als gelungenes Beispiel für die Demokratisierung in Afrika\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen stecken sich jährlich mit Tuberkulose an?, Predicted Answer: freien Luft\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche grundlegende Neuerung wurde bei den Contollern ab Sixaxis eingeführt?, Predicted Answer: 1878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch wen wurde der Abriss des Dorfes el Cabanyal bei valencia 2010 vorübergehend gestoppt?, Predicted Answer: Polizeikräfte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Hochseehäfen gibt es in Liberia?, Predicted Answer: fünf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Funktionen erfüllen Säugetiere heute für den Menschen?, Predicted Answer: Höhere Säugetiere haben eine weltweite Verbreitung, waren aber bis zur Ankunft des Menschen in Australien nur durch relativ wenige Arten vertreten, namentlich Fledertiere und Echte Mäuse\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Keita in Mali abgesetzt?, Predicted Answer: aufgrund schlechter wirtschaftlicher Lage und wachsender Unzufriedenheit der Bevölkerung immer repressiver\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird der WLAN-Adapter an die XBox 360 angeschlossen?, Predicted Answer: nicht mehr zwingend erforderlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Bereich der Hundezunge nimmt süße Stoffe war?, Predicted Answer: Flotte Liberias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wodurch werden Warenhäuser und Kaufhäuser unterschieden?, Predicted Answer: In der Handelsbetriebslehre\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Soldaten hatten die Nordstaaten im Amerikanischen Bürgerkrieg?, Predicted Answer: 4.000.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was für ein politisches System entwickelte sich nach Ende der Dekolonialisierung in Tansania?, Predicted Answer: Patronage-System\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Zeitraum war Albert Bloch Department Chair an der University of Kansas?, Predicted Answer: Dekan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Zeugen jehovas leben in Russland?, Predicted Answer: 40.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Staaten galten nach dem zweiten Weltkrieg als Weltmacht?, Predicted Answer: Frankreich oder Portugal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Einrichtungen des Technischen Hilfswerks sind in Hannover angesiedelt?, Predicted Answer: Öffentliche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann veröffentlichte Kanye West eigene Musik als rapper?, Predicted Answer: 2003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welche Bereiche werden Hydraulikaufzüge eingesetzt?, Predicted Answer: verschiedene Insekten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wirkte sich die Gletscherbildung während der Kaltzeiten auf die Nordseeregion aus?, Predicted Answer: unterscheiden sich in der Größe und im Aufbau\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer kann die liberische Staatsbürgerschaft erhalten?, Predicted Answer: Personen afrikanischer Abstammung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind frühere Vorläufer von Non-Profit-Organisationen?, Predicted Answer: verlorene Vorlagen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches ist der zweitgrößte Telefonanbieter in den USA?, Predicted Answer: AutoZone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Urbanisierungsgrad hatte Israel bei Staatsgründung?, Predicted Answer: Mit der Reise\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Wirtschaftsbereich sind in Palermo die meisten Menschen beschäftigt?, Predicted Answer: Zweiten Weltkriegs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches sind die am dichtesten besiedelten Gebiete im Iran?, Predicted Answer: Islam, Antiimperialismus und Führerschaft\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr besuchte Helmut Kohl Namibia?, Predicted Answer: 1995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das besondere am Lykurgosbecher?, Predicted Answer: befindliche ''Lykurgosbecher''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch was die Transaktionsliste bei einer USB-Schnittstelle verwaltet?, Predicted Answer: angegeben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wessen Häuser waren in der römischen Gesellschaft meist mit Mosaiken verziert?, Predicted Answer: betroffen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von wo nach wo wandern Zugvögel?, Predicted Answer: Pennsylvania\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Auswirkungen hatte die Steuerforderungen der Ostindien-Kompanie in Bengalen im 18. Jhd.?, Predicted Answer: tiefgreifende\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie können Hunde Geschmacksstoffe nur wahrnehmen?, Predicted Answer: Geschmack\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Vertrag wurde zum Ende des Ersten Weltkriegs geschlossen?, Predicted Answer: Fürst Menschikow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso werden Priester im Elsass teilweise vom Staat bezahlt?, Predicted Answer: über 200 Millionen Euro\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie kann der R.O.B. von Nintendo informationen aus der Umwelt wahrnehmen?, Predicted Answer: siehe unten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Status hat Moses im jüdischen Glauben?, Predicted Answer: höchste Prophet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurden Teile des heutigen Namibia zur Deutschen Kolonie?, Predicted Answer: die Rechte an Suriname zugesichert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hoch ist das BIP pro Kopf in Guinea-Bissau?, Predicted Answer: 12.000 Euro\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wozu dient der Alaska Permanent Fund?, Predicted Answer: Einmalig in den USA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Stadt ist Kanye West geboren?, Predicted Answer: USA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum wird moderne Popularmusik manchmal als klassisch benannt?, Predicted Answer: modern\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch welche Städte verläuft der 15. östliche Längengrad?, Predicted Answer: mittleren Sonnenzeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bei welchen Parameter von Beleuchtungsmitteln wird eine Optimierung angestrebt?, Predicted Answer: Energieverbrauch, Wirkungsgrad und Lebensdauer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Firma steht hinter der Entwicklung von WMA?, Predicted Answer: Michigan Wolverines\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Truppen aus welchen britischen Überseegebieten nahmen an der Schlacht von Gallipoli teil?, Predicted Answer: Dominions\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wirkt sich eine Temperaturänderung bei Keramikkondensatoren aus?, Predicted Answer: ferroelektrischer Keramik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.16 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann unterstützt der WLAN-Adapter der XBox auch WPA2-Verschlüsselung?, Predicted Answer: Mit der Dashboard-Aktualisierung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird die Westeuropäische Sommerzeit international bezeichnet?, Predicted Answer: ''Western European Summer Time''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann versuchten die Alliierten im Krimkrieg erstmals Petropawlowsk einzunehmen?, Predicted Answer: konnten die Stadt aber nicht einnehmen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind Teilzieher bei den Zugvögeln?, Predicted Answer: Vogelarten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Minderheiten gibt es in Tadschikistan?, Predicted Answer: eine kleine Minderheit von Deutschstämmigen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurde John Kerry im Vergleich  mit den anderen Kandidat:innen in den Vorwahlen 2004 wahrgenommen?, Predicted Answer: Howard Dean\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit vielen Schiffen griffen die Alliierten im Krimkrieg Petropawlowsk an ?, Predicted Answer: konkrete Opferzahlen anzugeben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso wanderten um 1900 viele aschkenasische Juden aus Russland aus?, Predicted Answer: ausweises\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.14 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Branche sind die meisten Menschen in Myanmar beschäftigt?, Predicted Answer: ausweises\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hieß die Armee der amerikanischen Kolonien im Unabhängigkeitskrieg?, Predicted Answer: Napoleon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Gebiet wollte die Ostindien-Kompanie 1620 einnehmen?, Predicted Answer: die Gegend um den Tafelberg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange muss man nach einer Organtransplantation Immunsuppressiva nehmen?, Predicted Answer: Wege in Kauf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Gremium hat in Nigeria die Aufsicht über den Rundfunk?, Predicted Answer: Zahl privater Bildungseinrichtungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo in Nigeria ist die Situation für freie Medien besonders schwierig?, Predicted Answer: Ilorin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Arrondissment bildet das Zentrum der Stadtgliederung von Paris?, Predicted Answer: Stadtbezirke\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Tag ist eritreischer Nationalfeiertag?, Predicted Answer: 9. September (Tag der Unabhängigkeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: nach welchen Kriterien wurde die Zucht von Hunden betrieben?, Predicted Answer: Verhalten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird bei einem Kondensator durch die Zeitkonstante der Selbstentladung beschrieben?, Predicted Answer: Frequenz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann sind Todeszahlen und Neuinfektionen für Tuberkulosepatienten weltweit rückläufig?, Predicted Answer: 1990 stetig\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Legislaturperioden kann der Präsident in Namibia maximal regieren?, Predicted Answer: drei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.69 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Anteil stimmte 2017 im Referendum in Puerto Rico für die Aufnahme in die USA?, Predicted Answer: 97,2 % der Teilnehmer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Um was geht es in dem Buch, das John Kerrys Vater geschrieben hat?, Predicted Answer: Trail of Tears\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wodurch entsteht genetische Variabilität in einer Population?, Predicted Answer: eine konstante Lichtqualität\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Juden wanderten in der zweiten Hälfte des 20. Jhd. in das Elsass ein?, Predicted Answer: heutige Juden viele Gene von einer ursprünglichen jüdischen Bevölkerungsgruppe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sieht Zink aus?, Predicted Answer: leicht flüchtiges Element\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus wie vielen Inseln bestehen die Marshallinseln?, Predicted Answer: zwei fast parallel verlaufenden Insel- und Atollketten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Gruppen in Mali stehen unter dem Vorwurf, Kindersoldaten eingesetzt zu haben?, Predicted Answer: Die Rebellen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso wurde John Kerry in den 1970ern durch das FBI überwacht?, Predicted Answer: 1943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Eritrea Teil der italienischen Kolonie in Ostafrika?, Predicted Answer: 1890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welcher Anteil der israelischen Bevölkerung lebt in der Stadt?, Predicted Answer: größte Teil\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange hatten die Chicago White Sox bis 2015 keinen Titel geholt?, Predicted Answer: 1908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer schrieb die Musik für die Hymne der US-Army?, Predicted Answer: einen Wettbewerb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Unterbereiche gibt es in der biologischen Anthropologie?, Predicted Answer: Zusätze wie „biologisch“ wurden in jüngerer Zeit notwendig\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.16 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange verbleiben Tuberkuloseerreger nach einer akuten Infektion im Körper?, Predicted Answer: nicht zur Erkrankung führenden Erstinfektion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Woher stammt die Musikerin Jewel?, Predicted Answer: der größte Teil aus Bamako\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird bei Frauen durch männliche Pheromone angeregt?, Predicted Answer: Reaktion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Die Sommerzeit welcher Zeitzone ist der UTC um eine Stunde voraus?, Predicted Answer: UTC+2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Einwohner:innen hat die Metropolregion von Valencia?, Predicted Answer: Vögeln und Insekten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wie viele amerikanische Soldaten kamen im Unabhängigkeitskrieg ums Leben?, Predicted Answer: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wen bestimmte Johann Ohneland als Nachfolger von Wilhelm I.?, Predicted Answer: Im November 1200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Wirtschaftssektor arbeiten ca. ein Fünftel der Arbeitnehmner:innen in Estland?, Predicted Answer: wom\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo auf den Marshallinseln leben die meisten Menschen?, Predicted Answer: Stadt Nezahualcóyotl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Auflage haben die überregionalen Tageszeitungen in Nigeria zusammen?, Predicted Answer: 1,7 Millionen Stück\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Dimensionen umfasst der Eigenwert von Biodiversität?, Predicted Answer: Menschen beigemessenen Wertes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der höchste Berg von Namibia?, Predicted Answer: Südafrika\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie unterscheidet sich Canadian Football von American Football inbezug auf die Taktik des Spiels?, Predicted Answer: Canadian Football, der unter anderem in der Canadian Football League (CFL) professionell gespielt wird, unterscheidet sich von seinem US-Gegenpart\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was kommt Uran bei Panzern verwendet?, Predicted Answer: Panzerung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was erließ der Mogulkaiser der Ostindien-Kompanie 1718?, Predicted Answer: ein kaiserliches Dekret\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von welchen Frauen wird in Mali westliche Kleidung getragen?, Predicted Answer: Mitgliedern der gebildeten, städtischen Elite\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Schriftzeichen der chinesischen Schrift gab es vermutlich 1400 v. Chr?, Predicted Answer: 8200 bis 6800/6500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt das Bussystem, das zwischen Raleigh und Cary verkehrt?, Predicted Answer: Research Triangle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wollte der schottische König Wilhelm I. ein Bündnis mit Frankreich schließen?, Predicted Answer: Krieg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.17 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr entstand die Melodie der Hymne der US-Army?, Predicted Answer: 1775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.82 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches international renomierte Musik-Label stammt aus Detroit?, Predicted Answer: Detroit Techno\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie groß ist die Fläche des Iran verglichen mit Deutschland?, Predicted Answer: weitgehend isoliert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sind die Postleitzahlen der Arrondissments von Paris angeordnet?, Predicted Answer: Wappen und Wahlspruch sind an vielen Bauwerken\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Branche ist die Comcast Corporation führend?, Predicted Answer: Kabelnetzbetreiber\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso wurde MacArthur als Befehlshaber im Koreakrieg abgezogen?, Predicted Answer: rationale\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Rang belegt die Schweiz 2019 auf dem Demokratieindex?, Predicted Answer: The Economist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Elemente können in normalen Sternen entstehen?, Predicted Answer: nicht voneinander zu trennen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Unternehmer besitzt den Großteil der Aktien des FC Arsenal?, Predicted Answer: Stan Kroenke\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.60 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hieß die erste elektrische Straßenbahn in Richmond im volksmund?, Predicted Answer: 1888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo kam es erneut zu Kampfhandlungen zwischen Österreich un Preußen nach der Schlacht von Prag?, Predicted Answer: Krieg gegen Friedrich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann entwickelte sich Canadian Football?, Predicted Answer: unterscheidet sich von seinem US-Gegenpart\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welcher islamischen Schule orientierte sich  Abd al-Wahhab?, Predicted Answer: Hedschas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war der ursprüngliche deutsche Synchronsprecher von Schwarzenegger in seinem ersten Film?, Predicted Answer: Reg Park\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen lebten zu Beginn des 20. Jhd. in Santa Monica?, Predicted Answer: ausweises\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Land lebt die größte Gruppe von Esten im Ausland?, Predicted Answer: Deutschland\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von welcher Art von Waren wird der Transport per Flugzeug organisiert?, Predicted Answer: Pazifik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Amt hatte Tiberius Sempronius Gracchus in Rom?, Predicted Answer: weiterreichende Ziele\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Prozent der Möbelindustrie von North Carolina  ist im Piedmont Triad angesiedelt?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Modell lässt Volkswagen im seinem Standort in Tennessee fertigen?, Predicted Answer: VW Passat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso ist das KaDeWe ein Warenhaus?, Predicted Answer: nach der wirtschaftswissenschaftlichen Definition\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo war die Sammlung der Galleria d’Arte Moderna in Palermo vor 2006 untergebracht?, Predicted Answer: Die Galerie für moderne Kunst (Galleria d’Arte Moderna) wurde im Dezember 2006 wiedereröffnet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Rolle hat der Kanzler einer Universität?, Predicted Answer: zentrale\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was hatte Warren Buffett im Interview mit Fortune in Bezug auf sein Vermögen angekündigt?, Predicted Answer: In einem Interview mit dem US-Business-Magazin Fortune hatte der zeitweise reichste Mann der Welt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann erlangte Eritrea seine Unabhängigkeit?, Predicted Answer: Die EPRDF\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Hindernis gibt es für die russischsprachige Minderheit in Estland bei der Einbürgerung?, Predicted Answer: ausweises\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird der R.O.B. von Nintendo betrieben?, Predicted Answer: siehe unten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was gilt als Vorgänger von Kaufhäusern?, Predicted Answer: Alejandro Encinas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:02<00:00,  1.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie verhielten sich die Elementarteilchen mit der Abkühlung nach dem Urknall?, Predicted Answer: Stalin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann formten sich viele neue Vogelarten und -gruppen?, Predicted Answer: ausweises\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.11 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welcher Nebengruppe gehört Zink?, Predicted Answer: Übergangsmetallen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele alliierte Soldaten gerieten im Pazifikkrieg in Corregidor in japanische Gefangenschaft?, Predicted Answer: ausweises\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Rang erreicht die Comcast Corporation nach dem Forbes-Global-Index?, Predicted Answer: 2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Unter was leiden die großen Städte im ehemaligen Manufacturing Belt in den USA?, Predicted Answer: Boston CMSA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wie wurde Myanmar zu seiner wirtschaftlichen Blütezeit in der Vergangenheit bezeichnet?, Predicted Answer: gehört Myanmar zu den ärmeren Ländern der Welt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Musiksparten hat Motown geprägt?, Predicted Answer: Soulmusik und auch Popmusik maßgeblich beeinflusst hat. Dies geschah durch den Produzenten Berry Gordy und die Motowneigene Studio-Band The Funk Brothers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Soldaten hatten die Südstaaten im Amerikanischen Bürgerkrieg?, Predicted Answer: 27.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Land werden Madrasa-Absolventen als Mullah bezeichnet?, Predicted Answer: Iran\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo liegt der höchste Berg von Namibia?, Predicted Answer: Hage Geingob\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Prinzip dominierte die Außenpolitk der USA in der Nachkriegszeit?, Predicted Answer: FC Everton\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war der Nachfolger von MacArthur als Kommandant im Koreakrieg?, Predicted Answer: Truman\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr wurde eine elektrische betriebene Straßenbahn in Richmond in Betrieb genommen?, Predicted Answer: 1888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf was konzentrierte sich die Historiographie im 17. Jahrhundert?, Predicted Answer: Fragmente\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welcher Anteil der Bevölkerung der Republik Zypern spricht Türkisch als Muttersprache?, Predicted Answer: Bücher 1502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch welche Sportarten ist Canadian Football beeinflusst?, Predicted Answer: Ballsportart\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: in welchem militärischen Konflikten der jüngsten Vergangenheit wurde Uranmunition verwendet?, Predicted Answer: Irak\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf was bezieht sich das Prinzip der grundsätzlichen Übersetzbarkeit?, Predicted Answer: eine Person\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann migrierten die Vorfahren väterlicherseits von John Kerry nach Amerika?, Predicted Answer: Europa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann gibt es das studentische Radio an der Univeristy of Kansas?, Predicted Answer: 1952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Über wie viele Geschütze verfügte die Stadt Petropawlowsk im Krimkrieg?, Predicted Answer: ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wie lautet der Fachbegriff für das Kopfsegment von Ringelwürmern?, Predicted Answer: ''Bundespolizei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Dokumente im US-Naitonalarchiv unterliegen nicht dem Urheberrecht?, Predicted Answer: Werke der Bundesregierung und damit vom Urheberrecht befreit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Text im britischen Königswappen?, Predicted Answer: stark durch die britische Kultur geprägt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist eine Graft- versus-Host-Reaktion?, Predicted Answer: Entzündungsreaktion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo liegt Valenica in Relation zu Madrid?, Predicted Answer: Barça\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.93 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wodurch können Flughäfen regional als wirtschaftlicher Motor wirken?, Predicted Answer: modern und klassisch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Bereich der Zunge beim Hund spricht auf die Geschmacksrichtung bitter an?, Predicted Answer: Vokalmusik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch was wurde die britische Ostindien-Kompanie 1718 von Zollzahlungen befreit?, Predicted Answer: ein kaiserliches Dekret vom Mogulkaiser in Indien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was verstand sich der osmanische Herrscher in bezug auf die islamische Pilgerfahrt?, Predicted Answer: Instrument seiner Klientel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurden die Zeugen Jehovas in Russland offiziell akzeptiert?, Predicted Answer: Die Rheinbundstaaten wurden verpflichtet, ihre Kontingente zu erhöhen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel des weltweiten Frachtaufkommens werden durch Flugzeuge transportiert? , Predicted Answer: Konvoi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr fand die islamische Revolution in Iran statt?, Predicted Answer: 1935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchem Staat wurde Eritrea nach dem Zweiten Weltkrieg zugeordnet?, Predicted Answer: Israel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Bedeutung hat die Tora für die jüdische Religion?, Predicted Answer: großer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo kann man Aktien von FC Arsenal kaufen?, Predicted Answer: 62.217 Aktienanteile ausgegeben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.22 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurde Paris unter den Römern genannt?, Predicted Answer: Stadtbezirke (''Arrondissements'', abgekürzt Arrdt.) und Viertel (''Quartiers'') unterteilt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie verändert sich Zeit für Intervalle der Planck-Zeit?, Predicted Answer: Musik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.59 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von wann bis wann lebte Albert Bloch in Deutschland?, Predicted Answer: 1923 bis 1947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Klasse der römischen Gesellschaft diente als Pool für die römische Berufsarmee?, Predicted Answer: koptische Kirche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches quelloffene, patentfreie mp3-ähnliche Audioformat gibt es?, Predicted Answer: Vorbis\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die Erweiterung der Avenida de Blasco Ibanez in Valencia endgültig gestoppt?, Predicted Answer: bis zum Meer weiter zu bauen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Funktion hat Zink für den Körper?, Predicted Answer: empfohlene Tagesmenge\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind Immunsuppressiva?, Predicted Answer: so genannten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Rang hat Guniea-Bissau auf dem Korruptionsindex?, Predicted Answer: vierten Rang der weltweit lukrativsten Fußballvereine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo erstrecken sich die Ostalpen nach der in Italien üblichen Einteilung?, Predicted Answer: byzantinische Gelehrte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Richmond Hauptstadt der Südstaaten?, Predicted Answer: wichtig und wohlhabend\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie kann der Gouverneur von Louisiana auf Todesurteile einwirken?, Predicted Answer: nur mit einer positiven Empfehlung des Gnadenausschusses umwandeln\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welches sind die größten Pub-Ketten in Großbritannien?, Predicted Answer: demographische und wohl auch kulturelle Katastrophe in der Geschichte der Menschheit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wie kann man die alten XBox-Spiele auf der neuen Konsole spielen?, Predicted Answer: Überblick\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was strebte Großbritannien an in anbetracht der antikolonialen Bewegungen?, Predicted Answer: Bedeutung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war Eritrea bevor es von den Italiener eingenommen wurde?, Predicted Answer: 1936 in das neu gegründete Italienisch-Ostafrika eingegliedert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Stadt in North Carolina hat die Daimler-Tochter Setra ihren Sitz?, Predicted Answer: Greensboro\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso strebt man laut dem Hinayana-Buddhismus nach Erwachen?, Predicted Answer: Hinayana strebt ein Mensch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.27 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Summe geht durch den Länderfinanzausgleich pro Jahr an Thüringen?, Predicted Answer: Nehmerland\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie bezeichnete eine Rezension in The Craftsman Picasso nach einer Ausstellung 1911 in New York?, Predicted Answer: Kanye West\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: durch was entsteht das große Handelsdefizit von Guinea-Bissau?, Predicted Answer: Erkenntnissen des Büros der Vereinten Nationen für Drogen- und Verbrechensbekämpfung waren Guinea-Bissau und die Republik Guinea in den Jahren 2004 bis 2007 ein wichtiges Drehkreuz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Herrscher befreite die Juden aus der Gefangenschaft in Babylon?, Predicted Answer: jeweilige\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Herangehensweise an sexuelle Orientierung wollte Sell 1996 durch eine neue Messkala ersetzen?, Predicted Answer: 1996 eingeführt. Wichtige Beiträge leistete das Entwicklungsteam um Ajay Bhatt bei Intel. USB ersetzt viele bisherige PC-Schnittstellen und vereinheitlichte den Anschluss für Tastaturen und Peripheriegeräte wie Drucker, Scanner und externe Massenspeicher.\n",
            "Als einer der ersten Chipsätze unterstützte 1996 der für den Pentium Pro entwickelte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat die Bevölkerung von Detroit stark abgenommen?, Predicted Answer: Detroit Techno\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Unter welchem Namen sollte der R.O.B. von nintendo  eigentlich auf den Markt kommen?, Predicted Answer: Retro-Spielern\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Anführer versuchte mit der deutschen Kolonialmacht unter Theodor Leutwein zu verhandeln?, Predicted Answer: Grab\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Auswirkung hat das Theorem der Planck-Zeit für die Physik?, Predicted Answer: ''Energie mal Zeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Museum wird der Lykurgosbecher ausgestellt?, Predicted Answer: Britischen Museums\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt der Teil des Thorax bei Insekten, an dem die Flügel sitzen?, Predicted Answer: Epidermis\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Gegen wen suchte König Arama Hilfe beim Staat Bit Agusi?, Predicted Answer: 850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für wie lange schloss Johann Ohneland mit dem französischen König Frieden?, Predicted Answer: Brabanzonen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann fand in Louisiana die letzte Exekution statt?, Predicted Answer: Vergewaltigung von Kindern mit dem Tode bedroht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welche Bedingungen musste Wilhelm I. im Vertrag von Norham erfüllen?, Predicted Answer: erfahrbare\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.93 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu was rief Polizeichef Johnson die Menschen bei \"Call to Action\" auf?, Predicted Answer: den unproportional hohen Anteil schwarzer Mordopfer zu verringern\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Art der Savanne macht den größten Teil der Fläche der Zentralafrikanischen Republik aus?, Predicted Answer: imperative\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Um wie viele Stunden ist die MESZ von der UTC verschoben?, Predicted Answer: UTC+1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Zusammenhang besteht zwischen der Größe und der Lebenserwartung von Säugetieren?, Predicted Answer: Begriffs ''Deutschtümelei'' hängt zusammen mit einer rein abgrenzenden Haltung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bei welchen internationalen Organisationen ist Guinea-Bissau Mitglied?, Predicted Answer: Vereinten Nationen sowie bei der UNESCO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Land war am Bau des Hafen in Monrovia beteiligt?, Predicted Answer: Houston\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer eroberte Anfang des 19. Jhds Medina und Mekka?, Predicted Answer: Georg Ludwig Friedrich Laves\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bei welchen Kondensatoren tritt Selbstentladung auf?, Predicted Answer: 37 % des Anfangswertes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war während der Präsidentschaft Eisenhowers Speaker of the House?, Predicted Answer: Albert Venn Dicey\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches ist die zweitgrößte Stadt in Spanien?, Predicted Answer: Nezahualcóyotl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche biologische Wirkung zeigt künstliche Beleuchtung bei Menschen?, Predicted Answer: Rhythmus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Art von Reisen werden über den Teterboro Airport vorwiegend abgewickelt?, Predicted Answer: Pelztiere\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Positionierung nahm Eisenhower innerhalb der republikanischen Partei ein?, Predicted Answer: moderaten Flügel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welcher Partei trat Ellen Johnson-Sirleaf 2005 zur Wahl an?, Predicted Answer: Unity Party\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches sind die am wenigsten eng besiedelten Gebiete im Iran?, Predicted Answer: Islam, Antiimperialismus und Führerschaft der Dritten Welt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches sind die größten Städte in Israel?, Predicted Answer: Wohnraum\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welchem Land hat Namibia den meisten Warenaustausch?, Predicted Answer: deutlicher Mehrheit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt die Mutter von John Kerry?, Predicted Answer: „Ostküsten-Adel“ der Stadt Boston\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: zu was gehörte Eritrea in den 1950ern?, Predicted Answer: ein großer Kahlschlag\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Staat ist das Hauptziel des iranischen Raketenprogramms?, Predicted Answer: Iran\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hoch ist die Arbeitslosenquote unter Jugendlichen in Estland?, Predicted Answer: vergleichsweise\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von was wird Musik durch die Bezeichnung \"klassisch\" unterschieden?, Predicted Answer: beeinflusst\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus welcher Zeit stammen die ersten Schriften zu einer wissenschaftlichen Untersuchung von Pflanzen?, Predicted Answer: jener Zeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Nach welchem Krieg wurde die Powell-Doktrin zur Maxime in der US-Politik?, Predicted Answer: Wappinger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war der Widersacher von Tiberus Gracchus?, Predicted Answer: noch weiterreichende Ziele\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.17 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Unter welchen Umständen ist nach der Weinberger-Powell-Doktrin der Einsatz von Soldaten ein legitimes Mittel?, Predicted Answer: gewissen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf was geht der Name Eritrea zurück?, Predicted Answer: Bezeichnung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wie lange wurden mit dem Moratorium von 2014 keine Hinrichtungen in Ohio durchgeführt?, Predicted Answer: Gesetz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher deutsche Politiker nahm für Deutschland am Unabhängigkeitsjubiläum 2015 in Namibia teil?, Predicted Answer: Bundespräsident a. D. Köhler\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie verhält sich die Bevölkerungsdichte in Israel zu der der anderen Länder der Region?, Predicted Answer: ungleich verteilt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Museum ist Antonello da Messinas Annunziata ausgestellt?, Predicted Answer: Museo Frida Kahlo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Schutzgebiet liegt in den Tropenregionen der Zentralafrikanischen Republik?, Predicted Answer: Dzanga-Sangha\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was gilt Zaynab von Muhammed Haykal?, Predicted Answer: 1913 veröffentlicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.69 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann starb die Mutter von Edgar Allan Poe?, Predicted Answer: Elizabeth Poe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso folgte Susan Rice nicht als Außenministerin nach Hillary Clinton?, Predicted Answer: Druck\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Prozent stimmten bei der Stichwahl 2011 in Liberia für Johnson-Sirleaf?, Predicted Answer: 43,9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Teil eines Zahnstangenaufzuges ist Träger des Antriebmotors?, Predicted Answer: großer Teil des Rechts Israels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bei welcher Variante des Nintendo Entertainment System ist der R.O.B. enthalten?, Predicted Answer: NES Deluxe Set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Frauen wurden in Iowa hingerichtet?, Predicted Answer: Männer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war normalerweise der Träger einer islamischen Madrasa?, Predicted Answer: üblicherweise durch eine fromme Stiftung finanziert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Ereignis führte vor ca 2000 Jahren zur Vereinheitlichung der chinesischen Schrift?, Predicted Answer: re\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Städte in North Carolina setzen in den letzten Jahren auf den Ausbau des öffentlichen Nahverkehrs?, Predicted Answer: Die größeren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wem wird der Kauf von Gebieten im heutigen Namibia von der lokalen Bevölkerung Ende des 19. Jahrhunderts zugeschrieben?, Predicted Answer: wom\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welches Flugzeug stürzte im Februar 2008 über Guam ab?, Predicted Answer: B-52H\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:02<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Um wie viel war das Meeresniveau tiefer während der Eiszeiten?, Predicted Answer: immer wieder zu Übertretungen der Grenzen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher ägyptische Autor erhielt als erster den Literaturnobelpreis?, Predicted Answer: Nagib Mahfuz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange regierte Sam Nujoma in Namibia?, Predicted Answer: Nach der Unabhängigkeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.17 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Selbstentladungszeitkonstante haben Kunststoff-Folien-Kondensatoren?, Predicted Answer: 2000 bis 4000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was kennzeichnet den jüdischen Friedhof in Hamburg?, Predicted Answer: einzigartig\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An was erinnert der Name Jayhawk?, Predicted Answer: Anmarsch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen international bekannten Literaturpreis erhielt Nagib Mahfuz?, Predicted Answer: Newark Liberty International Airport\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch was kann die dauerhafte Beleuchtung eines unbenutzten Aufzugs verhindert werden?, Predicted Answer: den Kühlwasser\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie starb König Rusa I. von Urartu?, Predicted Answer: Johann Wilhelms zwölfjährigen Sohn Alexander\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Scheine in welchem Wert wurden als Hawaii-Dollar gedruckt?, Predicted Answer: Siegel des Schatzamtes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist eine Lungenobstruktion?, Predicted Answer: eine Länge von 27 Kilometern\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Unter welchen Umständen kann eine katholisch geschlossene Ehe annulliert werden?, Predicted Answer: bestimmten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die Paranota bei Insekten?, Predicted Answer: bezeichnet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso bildete sich der 38. Breitengrad als Front im Koreakrieg?, Predicted Answer: Ü\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welchem Konzern gehörte Eastman Chemical früher?, Predicted Answer: Versicherungskonzern Unum\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welche Gruppen werden Säugetiere bezüglich ihrer Ernährung eingeteilt?, Predicted Answer: Tiergruppe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.59 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Museum in Palermo werden die Sizilianischen Zwergelefanten ausgestellt?, Predicted Answer: Museo Frida Kahlo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Zeitraum führte die deutsche Kolonialmacht in Namibia Krieg gegen die einheimische Bevölkerung?, Predicted Answer: Das Kurfürstentum brauchte man jedoch als Faustpfand in einem Krieg gegen Großbritannien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welche Möglichkeiten zum unerkannten Surfen im Internet gibt es?, Predicted Answer: eklatante Mängel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das älteste Gebäude in der Second Street in Santa Monica?, Predicted Answer: der Rapp Saloon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wovon wird klassische Musik im Bezug auf die verwendeten Instrumente abgegerenzt?, Predicted Answer: Schweizer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war der Inhalt der von Gracchus angestrebten Landreform 133.v.Chr.?, Predicted Answer: schlug\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Vogel hat eine  symbolische Bedeutung im Christentum?, Predicted Answer: größere\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Stadt hat die Regal Entertainment Group ihren Sitz?, Predicted Answer: Knoxville\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit was steht die öffentliche Förderung der Bildung in den USA in Zusammenhang?, Predicted Answer: Louisiana Purchase\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen leben in Windsor, Ontario?, Predicted Answer: vor allem\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde das aktuelle britische Thronwappen festgelegt?, Predicted Answer: Weiterhin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wozu sollte das Dorf El Cabanyal bei Valencia abgerissen werden?, Predicted Answer: Gaddafi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso ließ König Menua einen Kanal nach Tuspa bauen?, Predicted Answer: Houston Ship Channel, einen seeschifftauglichen Kanal, mit der Golfküste verbunden und besitzt mit dem Hafen von Houston\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Stadtbezirk liegen die beiden Airport von New York?, Predicted Answer: Queens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die Ursachen für den Anstieg der Tuberkulosezahlen in osteuropäischen Ländern?, Predicted Answer: die Armut der Eltern\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso ist der Grad des Wohlstandes in der Republik Kongo trotz hohem BIP nicht sehr hoch?, Predicted Answer: ungleichmäßig verteilt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Elternteil ist laut dem orthodoxen Judentum relevant für die Bestimmung eines Kindes als jüdisch?, Predicted Answer: „ein Flickenteppich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt die Insel in Detroit im gleichnamigen Fluss?, Predicted Answer: Detroit Red Wings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welches Amt hatte Susan Rice unter Obama?, Predicted Answer: geltende\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso ist in manchen Pubs das Tragen von Fußball-Fanartikeln verboten?, Predicted Answer: Fußballspiele der englischen Premier League\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso kann man bei Ringelwürmern nicht das übliche Strickleiternervensystem erkennen?, Predicted Answer: Der Empfänger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Flugzeug stürzte im August 1997 über Guam ab?, Predicted Answer: Global Hawk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welche Bitraten ist Vorbis besser als mp3?, Predicted Answer: niedrigen und mittleren Bitratenbereichen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hoch ist die Arbeitslosigkeit in Estland?, Predicted Answer: 1,6 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Gruppen werden vom Iran in der militärischen Auseinandersetzung mit Israel unterstützt?, Predicted Answer: Hamas und Hisbollah\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war der erste Präsident im unabhängigen Mali?, Predicted Answer: Keïta\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie koopertiert der Honiganzeiger mit Menschen?, Predicted Answer: afrikanische Honiganzeiger beispielsweise führt Menschen zu den Nestern von Wildbienen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer versuchte Anfang der 1990er die Todesstrafe in Iowa wieder einzuführen?, Predicted Answer: 1878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.16 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind Antituberkulotika?, Predicted Answer: Antibiotika\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die höchste Leistung, die ein USB-Anschluss haben kann?, Predicted Answer: Das stellt höhere Anforderungen an die Kabel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Art von Geschichtswissenschaft wurde gegen Ende des 17. Jahrhunderts gefordert?, Predicted Answer: Konflikten politischer, religiöser und sozialer Art\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie unterscheidet sie das Feld beim Canadian Football vom American Football?, Predicted Answer: US-Gegenpart\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher König ist der Gründer der Vorläuferstadt von Van?, Predicted Answer: Wilhelm von Oranien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die Hauptverwendungsbereiche von Zink?, Predicted Answer: viele verschiedene Funktionen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso dient Empirie laut der frühgriechischen Philosophen nicht zur Bildung allgemeiner Theorien?, Predicted Answer: Kant\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Arten von Sensorik gibt es bei Elektromotoren?, Predicted Answer: kleinere Arten weniger lang als größere Arten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher zweisprachige Fernsehsender ist in Straßburg angesiedelt?, Predicted Answer: proteins\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die deutsche Ausgabe der Dernieres Nouvelle d'Alsace eingestellt?, Predicted Answer: separat abonniert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann steigt der Anteil der ländlichen Bevölkerung in Israel wieder?, Predicted Answer: ungleich verteilt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.15 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso bezeichneten einige Republikaner Schwarzenegger als Mogelkandidat?, Predicted Answer: Wahlkampfes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bei welchen Säugetieren gilt die sonst übliche Tendenz zwischen Größe und Lebenserwartung nicht?, Predicted Answer: Bahndrehimpuls\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Text ist auf der schottischen variante des britischen Königswappen abgebildet?, Predicted Answer: Wappenschild der Löwe anstatt der Leoparden doppelt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie alt sind die meisten Wrestlingfans?, Predicted Answer: 15 Jahre\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war der erste demokratisch gewählte Präsident von Mali?, Predicted Answer: Jean Tigana\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche der großen Buddhismushauptströmungen reicht zeitlich weiter zurück?, Predicted Answer: Bevölkerungszahl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die beiden Hauptindustriebranchen in North Carolina?, Predicted Answer: die Küstenebene am Atlantik, das Piedmont-Plateau im Hinterland und die Bergregion der Appalachen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ist der Wohlstand in Guinea-Bissau verteilt?, Predicted Answer: äußerst ungleichmäßig\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welche Gruppe wird die Schweiz nach dem Demokratieindex eingeordnet?, Predicted Answer: Democrats Abroad\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie bezeichnet man Zugvögel, die in Gebiete ziehen, die in den selben Breitengraden liegen?, Predicted Answer: Als Vogelzug\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer veranlasste die Einrichtung der United States Military Academy?, Predicted Answer: Thomas Jefferson\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo sind die meisten Firmen, die VPN oder Proxy anbieten, ansässig?, Predicted Answer: rund 1895 Deutsche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo hatte die East India Company ihre Zentrale?, Predicted Answer: lose\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Geld hat Kanye West laut Forbes?, Predicted Answer: ''The Life of Pablo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.95 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Zeitraum gehörte Santa Monica zu Mexiko?, Predicted Answer: Los Angeles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welche Währung war vor dem Euro in Portugal gültig?, Predicted Answer: 57,6 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann gewannen die Chicago Cubs nach über hundert Jahren erstmals wieder eine Meisterschaft?, Predicted Answer: nicht mehr erreicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.92 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Metalle werden in Alaska geschürft?, Predicted Answer: Tundra\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Abgeordnete im Repräsentantenhaus der USA würde Puerto Rico als Bundesstaat bekommen?, Predicted Answer: Wenn Puerto Rico ein Bundesstaat wäre, hätte es fünf Sitze\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchen Landessprachen neben Englisch erscheinen Zeitungen in Nigeria?, Predicted Answer: Thisday, The Guardian oder Vanguard\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Volksgruppe auf Zypern spricht Arabisch?, Predicted Answer: 1,2 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche kanadische Stadt liegt Detroit am Detroit River gegenüber?, Predicted Answer: Detroit Techno\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wer war vor John Kerry US-Außenministerin?, Predicted Answer: Bush\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wurde nach der Unabhängigkeit namibischer Präsident?, Predicted Answer: Sam Nujoma\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurden die Zeugen Jehovas in Russland als extremistisch verurteilt?, Predicted Answer: übertrieben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo hat FedEx seine Zentrale?, Predicted Answer: AutoZone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch was unterscheidet sich Zink von den anderen Übergangsmetallen?, Predicted Answer: leicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Woher stammten die Elamer?, Predicted Answer: noch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Pipau aus Mali?, Predicted Answer: Hauptstadt der Kolonie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Begriff etabliert sich heutzutage für Phytologie?, Predicted Answer: Botanik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bei welchem Propheten liegt der Ursprung des Judentums?, Predicted Answer: höchste Prophet aller Zeiten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind urtümliche Hunde?, Predicted Answer: Hunde\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In was für einen wirtschaftlichen System enstehen Non-Profit-Organisationen?, Predicted Answer: Voraussetzungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist Uranmunition?, Predicted Answer: panzerbrechende Munition\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird der Isolationswiderstand bei Kondensatoren mit Elektrolyt bestimmt?, Predicted Answer: über den Reststrom des Kondensators definiert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Einfluss hat der Mensch auf die Verbreitungsgebiete von Säugetieren?, Predicted Answer: 9000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Unter welchem Präsidenten wurde der New Deal umgesetzt?, Predicted Answer: Franklin D. Roosevelt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wen sah Truman als eigentlichen Feind im Koreakrieg?, Predicted Answer: Sowjetunion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche ISO Norm entspricht dem unicode ?, Predicted Answer: ISO 10646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer förderte die Gates Foundation 2006 mit Aktien im Wert von mehreren Milliarden Dolalr?, Predicted Answer: Berkshire Hathaway\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Der Sonnenzeit welches Längengrades entspricht die europäische Sommerzeit?, Predicted Answer: 0°, 15°, 30°\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die Nuchalorgane bei Ringelwürmern?, Predicted Answer: eine Ansammlung von Nervenfasern\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Vorteile bietet künstliche Beleuchtung?, Predicted Answer: Der Begriff\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An was orientiert sich die in Frankreich übliche Dreiteilung der Alpen?, Predicted Answer: fast allen Messstationen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Hafen in Liberia hat das größte Handelsvolumen?, Predicted Answer: Freeport Monrovia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Sternwarten hat der Jaipur-Fürst Jai Singh II. erbauen lassen?, Predicted Answer: erste von fünf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was versteht man unter Modern Republicanism?, Predicted Answer: unproblematisch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: in welchem Jahr entstand der Neoklassizismus in den USA?, Predicted Answer: 1928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wie kann man die Sixaxis-Controller laden?, Predicted Answer: Der Empfänger kann erkennen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo grenzt namibia an Botswana?, Predicted Answer: Kalahari\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.21 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Teil der Zentralafrikanischen Republik gibt es Regenwald?, Predicted Answer: größte Teil des Landes besteht aber aus Baumsavanne (Feuchtsavanne) und lichtem Wald\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo liegt der Ursprung des Techno in Detroit?, Predicted Answer: Wirtschaftsgeographisch gesehen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wurde 2005 zur Präsidentin von Liberia gewählt?, Predicted Answer: Emilio Pérez Touriño\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür werden Ausländer:innen in Mali gekidnappt?, Predicted Answer: 35 Sprachen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Probleme der britischen Armee trugen zu deren Niederlage im amerikanischen Unabhängigkeitskrieg bei?, Predicted Answer: United States Army\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Branche ist Eastman Chemical tätig?, Predicted Answer: Kingsport\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Art der Savanne ist im Norden der Zentralafrikanischen Republik zu finden?, Predicted Answer: 180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Kontingente von was für Truppen kämpften im Unabhängigkeitskrieg für  die britische Armee?, Predicted Answer: Napoleon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie verhalten sich die Werte der Selbstentladung eines Kondensator mit der Temperatur?, Predicted Answer: Zeit von selbst\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Wüste liegt im Westen von Namibia?, Predicted Answer: Wüstenstadt Jaisalmer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann wird die aktuelle Bezeichnung für Paris verwendet?, Predicted Answer: 1968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Atomnummer hat Zink?, Predicted Answer: ein bläulich weißes, unedles Metall\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Zeitschrift wurde die Bezeichnung als erstes verwendet?, Predicted Answer: Verwaltung oder literarische Zwecke\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.14 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was gilt als Anfänge der Botanik?, Predicted Answer: einen Teil der Natur, die Pflanzen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Menschenrechtsverletzungen werden den Rebellen- und Islamistenmilizen in Mali vorgeworfen?, Predicted Answer: immer wieder verletzt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.22 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Wirtschaftsbereich beschäftigt in Estland die meisten Arbeitnehmer:innen?, Predicted Answer: Einwohner\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche anderen Größen werden wie die Zeit über Messverfahren definiert?, Predicted Answer: die Zonenzeit der Zeitzone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was versteht man unter grundsätzlicher Übersetzbarkeit?, Predicted Answer: Unter Materie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welche Schiffe kommen Uran-getriebenene Treibwerke zum Einsatz?, Predicted Answer: Sandwichpanzerung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Schreibrichtung hat Avesta?, Predicted Answer: eigener Schrift geschrieben, der Avestaschrift\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von wem stammen die \"Polenlieder\"?, Predicted Answer: wom\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welche Art von Unternehmen will North Carolina in den letzten jahren verstärkt in den Staat locken?, Predicted Answer: High-Tech-Unternehmen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In die Tradition welches Künstlers stellt Michael Puy den Kubismus?, Predicted Answer: die Kulmination der Vereinfachung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Legislaturperioden regierte Konare in Mali?, Predicted Answer: zwei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Anteil der in der Schweiz lebenden Menschen hat nicht die schweizer Staatsangehörigkeit?, Predicted Answer: „andere Deutsche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.10 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange existiert die chinesische Schrift schon?, Predicted Answer: vorwiegend aus Logogrammen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Arrondissements gibt es in Paris?, Predicted Answer: Stadtbezirke\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann war die Regeleinführung, die American Football und Canadian Football deutlich voneinander trennte?, Predicted Answer: internationale Spiele und Kontakte den Anstoß gaben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch was unterscheidet sich Pappe von Papier?, Predicted Answer: DIN 6730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Amt hatte Albert Bloch an der University of Kansas?, Predicted Answer: Deutschlandaufenthalt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was hat Mose nach orthodoxen Glauben geschrieben?, Predicted Answer: nicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Sprache wird auf Zypern neben den Amtssprachen auch häufig verwendet?, Predicted Answer: Bücher 1502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welches Gebiet wollte Wilhelm I. von Johann Ohneland zurückbekommen?, Predicted Answer: französisch-schottischen Bündnis\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann war die Amtseinführung von Schwarzenegger als Gouverneur von Kalifornien?, Predicted Answer: bekannt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welcher Methode werden Hinrichtungen in Louisiana durchgeführt?, Predicted Answer: Tode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welche Gesetzesvorhaben wollte Gaius Sempronius Gracchus als Volkstribun durchsetzen?, Predicted Answer: weiterreichende Ziele\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer unterlag in der Schlacht von Kolin?, Predicted Answer: Friedrich II.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Gebiet in North Carlolina ist die Möbelindustrie vor allem angsiedelt?, Predicted Answer: Piedmont Triad\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.22 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bis wann war die Todesstrafe in den USA-weit ausgesetzt?, Predicted Answer: 1999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was umfasst der Unicode, was in der ISO-Norm nicht enthalten ist?, Predicted Answer: Regelwerk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Tageszeitung in Straßburg hat die höchste Auflage?, Predicted Answer: „Land un Sproch“\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Überlebende gab es bei dem Flugzeugabsturz auf Guam im August 1997?, Predicted Answer: eine Boeing 747-300 der Korean Airlines auf dem Korean-Air-Flug 801 von Seoul nach Agana (Guam) bei heftigem Regen gegen einen Hügel 5 km vor dem Flughafen Hagåtña geflogen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange dauerte der Unabhängigkeitskampf in Eritrea?, Predicted Answer: Gaddafi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welchem Wissenschaftszweig gehört die biologische Anthropologie?, Predicted Answer: Rhythmus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf welchem US-Luftwaffenstützpunkt stürzte 2016 auf Guam ein Flugzeug ab?, Predicted Answer: Andersen Air Force Base\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Der Sonnenzeit welches Längengrades entspricht die Standardzeit in Mitteleuropa?, Predicted Answer: 0°, 15°, 30°\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Ausdehnung der Westalpen nach der in Frankreich üblichen Einteilung?, Predicted Answer: am Mittelmeer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Zugvögel gibt es auf der Welt?, Predicted Answer: unendlich viele bewohnte Welten geben müsse: Die Welt, auf der wir leben, sei offenkundig nicht vollkommen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Veränderung erlebte North Carolina nach dem Sezessionskrieg?, Predicted Answer: West\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Um wie viel würde das Meeresniveau durch Abschmelzen der Polarkappen und Gletscher ansteigen?, Predicted Answer: weitere Umweltschäden zu vermeiden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die wichtigsten Bestandteile des nationalen Selbstverständnis der Schweiz?, Predicted Answer: Neujahr, Auffahrt und der erste Weihnachtsfeiertag\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.60 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Uran-Isotop kommt in der Natur am häufigsten vor?, Predicted Answer: am Prostomium\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welche Parteien waren an der Koalition nach der Wahl 2005 in Galizien beteiligt?, Predicted Answer: beiden großen Parteien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Anteil der russischen Minderheit in Estland sind keine Bürger:innen von Estland?, Predicted Answer: Abwanderung junger und qualifizierter Einwohner\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso ist Tuberkulose bei vorhandener HIV-Infektion schwieriger festzustellen?, Predicted Answer: AIDS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann verzeichnete Portugal nach der Weltwirtschaftskrise 2008 wieder ein Wirtschaftswachstum?, Predicted Answer: nicht mehr lebensfähig\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.10 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Griechenland vom Osmanischen Reich unabhängig?, Predicted Answer: persifliert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: zu was entwickelten sich die USA und die Sowjetunion nach dem 2. Weltkrieg?, Predicted Answer: enorm ausdehnen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von welchen Staaten wurde das griechische Streben nach Unabhängigkeit vom Osmanischen Reich gefördert?, Predicted Answer: Frankreich, Großbritannien und Russland\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Land hatte Kolonien in Guinea-Bissau?, Predicted Answer: Portugal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie alt werden Elefanten?, Predicted Answer: 15 Jahre\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wurde nach der Wahl 2005 Regierungschef in Galizien?, Predicted Answer: Partido Popular\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit was verdiente Arnold Schwarzenegger in den 1960ern viel Geld?, Predicted Answer: Fitnessartikeln und -nahrung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die Folgen einer fehlenden Immunsuppression bei Organtransplantation?, Predicted Answer: Tibet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.94 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Länder sind neben Namibia in der Southern African Customs Union?, Predicted Answer: Gliedstaaten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem US-Bundesstaat liegt der Newark Liberty Airport?, Predicted Answer: Manhattan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Vogel wurde oft in Wappen verwendet?, Predicted Answer: Schrift\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Industriezweige sind in North Carolina seit der Jahrtausendwende stark gewachsen?, Predicted Answer: Möbel- und Textilproduktion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo wurden im Osmanischen Reich besonders Griechen als Übersetzer eingesetzt?, Predicted Answer: ''„Kranker Mann am Bosporus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was galt das Arcadia Hotel in Santa Monica nach seiner Eröffnung?, Predicted Answer: 1887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann trat Mali der FIFA bei?, Predicted Answer: Premier League auf Ablehnung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wer gewann die Schlacht von Prag Mitte des 18. Jahrhunderts?, Predicted Answer: schwer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist ein Feynmann-Diagramm?, Predicted Answer: Thema der üblichen Oberlehrerpädagogik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Auswirkungen hatte die deutsche Besiedelung von Namibia auf die wirtschaftliche Situation der einheimischen Herero?, Predicted Answer: tiefgreifende\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Geld soll Kroenke für die Aktien des FC Arsenal aus Katar geboten worden sein?, Predicted Answer: anonymes Angebot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.16 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die Aufgabenbereiche der Tfl in London?, Predicted Answer: betrieblichen Belange\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Anteil des BIP in Portugal macht der Dienstleistungssektor aus?, Predicted Answer: 76,8 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ab wann war ISO 10646 quasi mit Unicode austauschbar?, Predicted Answer: Codeumfang\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.93 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welchem Instrumentarium lässt sich die von Sell 1996 vorgeschlagene  Skala zur Erfassung der sexuellen Orientierung koordinieren?, Predicted Answer: Kinsey-Skala\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: zu welcher Gruppe im Periodensystem gehört Uran?, Predicted Answer: Actinoide\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie war John Kerrys Haltung zum Putsch 2013 in Ägypten?, Predicted Answer: „Wiederherstellung der Demokratie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bei welchen Probandengruppen wurde in Studien eine verstärkte Hypothalamus-Aktivität durch Gabe von männlichen Pheromonen beobachtet?, Predicted Answer: Entwicklung der sexuellen Orientierung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer konstruierte im 18. Jhd. die Montgolfiere?, Predicted Answer: Daniel Bernoulli\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann regierte Menua in Urartu?, Predicted Answer: Bis 609 v. Chr. existierte Urartu weiter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Fischarten werden in Alaska hauptsächlich gefangen?, Predicted Answer: Kremasta-Stausee\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welche Hunde entsprechen der ersten Stufe der Domestikation?, Predicted Answer: Das Verhalten solcher Hunde\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Flagge stellte vermutlich die Inspiration für die US-Flagge dar?, Predicted Answer: liberianischer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind Ganglien bei Würmern?, Predicted Answer: sogenannte Ganglien, paarig in den einzelnen Segmenten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher assyrische König führte ca. 850 v.Chr. Krieg gegen Arzaskun?, Predicted Answer: Arama\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Titel erhalten Personen in Südasien, die eine islamische Madrasa absolvieren?, Predicted Answer: Ausbildung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.15 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Temperaturbereich ist zink leicht formbar?, Predicted Answer: gesamten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Anteil an der Bevölkerung Liberias machen Menschen mit Vorfahren aus Amerika aus?, Predicted Answer: 2–5 Prozent\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo in Israel konzentriert sich der Hauptteil der Bevölkerung?, Predicted Answer: Die USA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von was hängen die Körpermaße eines Bodybuilders ab?, Predicted Answer: unterschiedlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Industriezweig ist nach der Ölindustrie in Alaska besonders wichtig?, Predicted Answer: für die Vitamin-B12-Resorption\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hoch war die Wahlbeteiligung bei der Stichwahl 2011 in Liberia?, Predicted Answer: gering\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Producer ist für den Erfolg von Motown mit verantwortlich?, Predicted Answer: Berry Gordy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer befehligte die österreichischen Truppen, die nach der Schlacht von Prag gegen Preußen kämpften?, Predicted Answer: Napoleon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Aufgabe hat die Federation Cynologique Internationale?, Predicted Answer: unterschiedliche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: in welche drei Regionen werden die Alpen in Italien üblicherweise gegliedert?, Predicted Answer: West-, Zentral-'' und ''Ostalpen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Spielgeräte werden in Pubs bereitgestellt?, Predicted Answer: Fußballspiele der englischen Premier League\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Gegen wen kämpfte England bei der Schlacht von Gallipoli?, Predicted Answer: 1919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Sprache werden viele Zeitungen in Nigeria geschrieben?, Predicted Answer: Yoruba, Hausa und Igbo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Städte in North Carolina sind Teil des Research Triangles?, Predicted Answer: drei wesentliche Teile gliedern: die Küstenebene am Atlantik, das Piedmont-Plateau im Hinterland und die Bergregion der Appalachen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso war die Wahlbeteiligung bei der Stichwahl 2011 in Liberia eher gering?, Predicted Answer: Beyoncé\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde der Handelshafen in Monrovia gebaut?, Predicted Answer: im Zweiten Weltkrieg mit amerikanischer Unterstützung errichtet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo wird Uran als Energiequelle eingesetzt?, Predicted Answer: Munition\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ab wann etablierten sich in Prosa verfasste Bühnenstücke?, Predicted Answer: 1968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer folgte auf Sam Nujoma als Präsident von Namibia?, Predicted Answer: SWAPO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus wie vielen Teilen besteht die Ratak-Kette der Marshallinseln?, Predicted Answer: zwei fast parallel verlaufenden Insel- und Atollketten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann ist das Nationalarchiv in den USA eine eigenständige Einrichtung?, Predicted Answer: Vollendung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: mit welchem Land hatte Mali unter Traore kriegerische Auseinandersetzungen?, Predicted Answer: Burkina Faso\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist Präsident der University of Kansas?, Predicted Answer: Albert Bloch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen leben im Durchschnitt auf einem Quadratkilometer im Iran?, Predicted Answer: 1,1 Millionen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso können sich bei einem Befall mit Tuberkuloseerregern leicht Resistenzen bilden?, Predicted Answer: Thorakalbeine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wurde im Amerikanischen Bürgerkrieg eingeführt, um große Armeen aufstellen zu können?, Predicted Answer: Ein vorbildliches Reglement\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bezeichnete Feynmann als Cargo Cult Science?, Predicted Answer: Cargo-Kult-Wissenschaft\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie groß ist Namibia?, Predicted Answer: Nachbar Südafrika\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Namibia unabhängig?, Predicted Answer: vom sozialen Status\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr war die Gründung der  University of Kansas?, Predicted Answer: 1865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Zinkverbindung wird bei der Herstellung von Porzellan und Keramik eingesetzt?, Predicted Answer: Design\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.93 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war John Kerrys Vater von Beruf?, Predicted Answer: John Edwards\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Anlässlich welches Jubiläums stürzte im Juli 2008 auf Guam ein Flugzeug ab?, Predicted Answer: US-Luftwaffe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird als Hominiden bezeichnet?, Predicted Answer: analytisch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welche Währung ist der Wert des namibischen Dollar gebunden?, Predicted Answer: 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Anteil hat landwirtschaftliche Produktion  am Bruttoinlandsprodukt von Myanmar?, Predicted Answer: 40 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Geschmacksrichtungen nehmen die seitlichen Bereiche der Zunge beim Hund wahr?, Predicted Answer: 0,04 Gramm Kupfer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie versuchten die Kelten Lutetia gegen die Römer zu verteidigen?, Predicted Answer: womöglich versucht, doch waren die Risiken unabsehbar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Veränderung prägte Kanye West in der Hip-Hop-Musik mit?, Predicted Answer: Vielzahl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurde die Koordinierte Weltzeit früher genannt?, Predicted Answer: Greenwich Mean Time, GMT / Universal Time, UT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die Nord-Süd-Verbindung des innerstädtischen Zugverkehrs in Houston eröffnet?, Predicted Answer: 2004 eine von Nord nach Süd verlaufende Stadtbahn\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was beeinflusste den traditionellen Kleidungsstil in Mali in den letzten Jahrhunderten?, Predicted Answer: Ergebnis von tiefgreifenden Veränderungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.22 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von was wird eine Atemwegsobstruktion ausgelöst?, Predicted Answer: via Tastendruck\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wurde an einer klassischen islamischen Madrass unterrichtet?, Predicted Answer: Empirismus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Gesetz wurde Ende 2014 in Ohio im Zusammenhang mit der Todesstrafe beschlossen?, Predicted Answer: ein Gesetz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welcher anderen physikalischen Größe hängt die Zeit eng zusammen?, Predicted Answer: Faserverläufen und den Blutwerten von Geschlechtshormonen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An was orientierte sich der amerikanische Neoklassizismus?, Predicted Answer: US-Präsident Clinton\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Funktion hat der akademische Senat an einer Uni?, Predicted Answer: Entscheidungsgremium\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das südliche Nachbarland von Eritrea?, Predicted Answer: Nationalfeiertag Eritreas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.15 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die Sternwarte Jantar Mantar in Neu-Delhi errichtet?, Predicted Answer: 1725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch was ging die 3. Dynastie von Ur unter?, Predicted Answer: „Trail of Tears\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Teil der Bibel entspricht der Tora?, Predicted Answer: eher Teil der dubiosen Historien als Poesie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Beziehung stehen The Funk Brothers zu Motown?, Predicted Answer: Labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: WElcher Behörde unterstand das US-Nationalarchiv bis in die 1980er?, Predicted Answer: 1985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Rassen gehören zu den urtümlichen Hunden?, Predicted Answer: Paria- bzw. Schensihunde\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist Ornithologie?, Predicted Answer: Vogelkunde\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo soll Abraham gelebt haben?, Predicted Answer: armenische Staatsbürgerschaft\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso verfügen Hunde über zwei verschiedene Arten von Speichel?, Predicted Answer: weshalb Hunde über vier Paar Speicheldrüsen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist der Nachfolger von Pohamba als Präsident von Namibia?, Predicted Answer: Sam Nujoma\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.21 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Auftrag gab die Ostindien-Kompanie William Kidd?, Predicted Answer: die Piraterie vorzugehen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.13 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für wen war Kanye West zu Beginn seiner Karriere als Produzent tätig?, Predicted Answer: kontroversen Aussagen und Auftritte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was gilt für Objekte, auf die ein physikalisches Gesetz im Bereich der Planck-Zeit wirkt?, Predicted Answer: Zusätzlich gilt die Bedingung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann entstand der Neoklassizismus in Deutschland?, Predicted Answer: 1908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches war die Hauptstadt des Medri Bahri- Königreichs?, Predicted Answer: Debarwa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die frühste Funktion von Säugetieren für den Menschen?, Predicted Answer: Wasser zu stauen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.59 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Soldaten der Unionstruppen starben im Sezessionskrieg?, Predicted Answer: 360.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Nachricht aus der Kolonie Südwest-Afrika verursachte im deutschen Kaiserreich einen Goldrausch?, Predicted Answer: Die Nachricht von sagenhaften Diamantenfunden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist Primärtuberkulose?, Predicted Answer: Krankheitszeichen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch was wird Tubrekulose ausgelöst?, Predicted Answer: die Vielzahl geltender Urheberrechtsgesetze Urheberrechtsverletzungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: in welchen europäischen Ländern ist Guinea-Bissau diplomatisch mit einem Botschafter vertreten?, Predicted Answer: Myanmar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war der Zweck der Einrichtung eines Nationalarchives in den USA?, Predicted Answer: eingeteilt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer verwendete die Bezeichnung Kubismus als erster?, Predicted Answer: Herr Braque\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches sind die offiziellen Sprachen auf Zypern?, Predicted Answer: Songhai (1,5 Millionen Sprecher), Fulfulde (auch 1,5 Millionen) und Maninka\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Hauptstadt der MArshallinseln?, Predicted Answer: die Gemeinde ''(Local Government Council,'' früher ''municipality)'' Majuro\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was werden Aufzüge mit eigenem Antrieb an der Kabine eingesetzt?, Predicted Answer: Gruppensammelsteuerungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war der Grund für den Absturz des B2-Tarnkappenbombers über Guam 2008?, Predicted Answer: Denkmal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.92 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurden die griechischstämmigen Bewohner:innen Istanbuls im Osmanischen Reich genannt?, Predicted Answer: Einwohner Istanbuls, die Phanarioten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Der wie vielte Gouverneur war Schwarzenegger in Kalifornien?, Predicted Answer: Stallone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Funktion hatte Baron Robert Clive in den britischen Gebieten in Indien?, Predicted Answer: Revolution\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für was stehen die drei Raubkatzen im britischen Königswappen?, Predicted Answer: unvorstellbar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die Gründe dafür, dass in der Schweiz viele Menschen ohne Schweizer Bürgerrecht leben?, Predicted Answer: 2'126'400 Einwohner\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die häufigsten Verfahren, die vor Kirchlichen Gerichten verhandelt werden?, Predicted Answer: Hierfür bedarf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Selbstentladungszeitkonstante ist für Kondensatoren in Klasse 2 aus Keramik vorgeschrieben?, Predicted Answer: eine Selbstentladezeitkonstante von mindestens 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welchen Thoraxsegmenten befinden sich die Flügel bei Insekten?, Predicted Answer: Duplikaturen der Epidermis\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Stoffe haben während der Embryonalentwicklung Einfluss auf die sexuelle Orientierung eines Menschen?, Predicted Answer: Die Gehirne von Männern und Frauen unterscheiden sich in der Größe und im Aufbau\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Gebiet Namibias wurde 1884 zur deutschen Kolonie ausgerufen?, Predicted Answer: Schutzgebiet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lang sind die Endzonen beim American Football?, Predicted Answer: 20 statt 10 Yards\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welchem Teil von Ringelwürmern befindet sich die Mundöffnung?, Predicted Answer: Prostomium\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welchem Land hat Eritrea im Norden eine gemeinsame Grenze?, Predicted Answer: Sudan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Inseln gehören zur Ralik-Kette der Marshallinseln?, Predicted Answer: 2878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchen Städten in der Schweiz ist der Anteil an Ausländer:innen höher als der landesweite Durchschnitt?, Predicted Answer: europäischen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso unterschied sich die Kriegsführung im Amerikanischen Bürgerkrieg von früheren Kriegen?, Predicted Answer: Nordatlantikvertrages\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Hauptbereich der Wirtschaft in North Carolina?, Predicted Answer: ein stark landwirtschaftlich geprägter Staat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche bedrohten Tierarten sind in den Tropengebieten der Zentralafrikanischen Republik zu finden?, Predicted Answer: Zyperntürken, nicht jedoch die Türken\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Schauspieler wurde ebenfalls von Schwarzeneggers deutschem Synchronsprecher synchronisiert?, Predicted Answer: Schwarzenegger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.92 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch welche Technik wird der Stator eines Elektromotors im Gehäuse verbaut?, Predicted Answer: geographischen Elemente\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Größe brauchen die aktuellen Theorien in der Kosmologie?, Predicted Answer: Zeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Bereich in aac besser als mp3?, Predicted Answer: kommerziellen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann brach Johann Ohneland mit seinem Heer nach Schottland auf?, Predicted Answer: Newcastle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr brachte Nintendo den R.O.B. auf den Markt?, Predicted Answer: 1990er Jahren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum wird Zeit über Messverfahren definiert?, Predicted Answer: unterschiedlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von welchen landwirtschaftlichen Erzeugnissen lebt die Landwirtschaft in Palermo hauptsächlich?, Predicted Answer: Nahrungsmittelerzeugung, dem Tabakanbau und der Getreidewirtschaft\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann entstand Paris?, Predicted Answer: durchziehen Paris spiralförmig von innen nach außen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Gebiet in Israel hat die geringste Bevölkerungsdichte?, Predicted Answer: Lebensfeindliche Gebiete wie die Negev-Wüste\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Werke von Picasso wurden 1911 in der Ausstellung in der Galerie 291 in New York ausgestellt?, Predicted Answer: 83 Zeichnungen und Aquarellen Picassos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Aktienanteile am FC Arsenal besitzt Kroenke?, Predicted Answer: 62.217 Aktien befindet sich per März 2013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso wurde ab 1942 der Hawaii-Dollar eingeführt?, Predicted Answer: eigene Banknoten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr besuchte Klaus Mann die University of Kansas?, Predicted Answer: 1927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war der Vorgänger von Schwarzenegger als Gouverneur?, Predicted Answer: Davis\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Subunternehmen vereint die Arsenal Holdings plc?, Predicted Answer: elf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Insel kontrollierte die britische Ostindien-Kompanie zeitweise?, Predicted Answer: kleinerer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf welche Art von Flügen konzentriert sich der LaGuardia-Flughafen in New York?, Predicted Answer: überwiegend für Inlandsflüge\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr wurde das Nationalarchiv gegründet?, Predicted Answer: 1934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welchem Teil der Körpers befinden sich die Augen von Ringelwürmern?, Predicted Answer: Aufklärungsdiskurs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.10 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der aktuelle Status von Puerto Rico?, Predicted Answer: ein Bundesstaat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird der Sixaxis-Conroller an die Playstation angeschlossen?, Predicted Answer: ''SIXAXIS''-Controller der PlayStation 3 entspricht optisch zwar weitgehend dem DualShock-Controller der PlayStation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer besetzte am 16. Oktober 1757 Berlin?, Predicted Answer: SG:PART\n",
            "                   'Liebst du mich?'                                                                          (Erelt, 2009, p. 16)\n",
            "           (23) Ta       lä-k-s                       ära   või?\n",
            "                   3SG    gehen-PAST-3SG weg oder\n",
            "                   'Sie/Er ist weggegangen, oder?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Uranisotop wird für Atomwaffen verwendet?, Predicted Answer: Schrift\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird in der Loop-Quantengravitationstheorie die Raumzeit repräsentiert?, Predicted Answer: die Zeit im Bereich der Planck-Zeit möglicherweise quantisiert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die Haupteinflüsse der Musik in Alaska?, Predicted Answer: Bekannte Musiker aus Alaska sind beispielsweise die Sängerin Jewel und die aleutische Flötistin Mary Youngblood\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was forderte MacArthur als Reaktion auf die chinesische und nordkoreanische Offensive im Januar 1951? , Predicted Answer: MacArthur verlangte nun den Abwurf von 34 Atombomben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchem Bereich widmet sich das Museo Etnografico in Palermo?, Predicted Answer: Mineralogie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wird die Zeit in Europa auf Winterzeit zurückgestellt?, Predicted Answer: gesetzliche Zeit dienende Zonenzeit Normalzeit oder Standardzeit genannt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen starben bei der Verteidigung von Petropawlowsk im Krimkrieg?, Predicted Answer: Einige dieser Gruppen starben wieder aus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hoch ist das BIP von Portugal?, Predicted Answer: sehr unterschiedlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso sind haben Namibia und Deutschland ein besonderes bilaterales Verhältnis?, Predicted Answer: Verantwortung Deutschlands\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welchem Antrieb werden Zahnstangenaufzüge betrieben?, Predicted Answer: eigenen Antrieb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was kann den Verschleiß des seillosen Aufzuges minimieren?, Predicted Answer: um den Verschleiß der seillosen Aufzugsanlage bei hohem Fahrkomfort\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher deutschen Stadt wird der seillose Aufzug getestet?, Predicted Answer: RWTH Aachen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo wurde ein seilloser Aufzug entwickelt?, Predicted Answer: Microsoft\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie funktioniert ein seilloser Aufzug?, Predicted Answer: An der RWTH Aachen im Institut für Elektrische Maschinen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann muss man die Zieletage in seillosen Aufzügen auswählen? , Predicted Answer: Weltweit wird an verschiedenen Forschungseinrichtungen an seillosen Antriebslösungen für Aufzüge gearbeitet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird in Sichuan angebaut?, Predicted Answer: Getreide, Gemüse und Futterpflanzen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches für den Export bestimmte Produkt wird in Sichuan produziert?, Predicted Answer: VW Passat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.11 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird in den Gebirgen von Sichuan gezüchtet?, Predicted Answer: Jiulong-Yak\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche tierische Produkte werden in Sichuan produziert?, Predicted Answer: Schweinefleisch und Seidenkokons\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was passiert, wenn die Polarisation einer Empfangs- und Sendeantenne nicht übereinstimmen?, Predicted Answer: Sorgt euch nicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird von Antennen abgestrahlt?, Predicted Answer: Musik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.21 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie bewegt sich der elektrische Feldvektor einer Antenne?, Predicted Answer: Neben einer Übertragungsrate von bis zu 300 Mbit/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist eine Wendelantenne?, Predicted Answer: Eine verbreitete Antenne\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Hauptziel von Softwaretest?, Predicted Answer: Trail of Tears\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wozu tragen die Ergebnisse von Softwaretests bei?, Predicted Answer: 143 Millionen Pfund\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum konnte man die Tuberkulose bis zum 19. Jahrhundert von anderen ähnlichen Krankheiten nicht unterscheiden?, Predicted Answer: abgegrenzt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hat erfahren, dass die Tuberkulose nicht nur Lungen beschädigen kann, sondern auch andere Organe?, Predicted Answer: Koch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie war die Tuberkulose im 19. Jahrhundert behandelt?, Predicted Answer: die\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde das erste Tuberkulose- Sanatorium gegründet?, Predicted Answer: 1880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hat man am Ende des 19. Jahrhundert in Großbritannien versucht, die Tuberkulose zu bekämpfen?, Predicted Answer: Liechtensteiner Gemeinde Triesen verzeichneten Todesfällen der Jahre 1831 bis 1930 gingen 15 % auf das Konto der Tuberkulose.\n",
            "Das erste Tuberkulose-Sanatorium in Görbersdorf\n",
            "Im 19. Jahrhundert entwickelte sich die Luftkur\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bedeutet die Pneumothorax-Technik bzw. Pneumolyse?, Predicted Answer: verbreitete Anwendung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.27 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hat zuerst die Resektion der Lungenabschnitte bei Tuberkulose ausgeführt?, Predicted Answer: wird außerdem die ''Lungentuberkulose'' von der ''Organtuberkulose'' unterschieden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hat das Bakterium, das die Tuberkulose auslöst, zuerst beschrieben?, Predicted Answer: Robert Koch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Preis gewann Robert Koch für die Entdeckung des Erregers von Tuberkulose?, Predicted Answer: Nobelpreis für Physiologie oder Medizin''.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was führte zur Entwicklung des ersten Tuberkulose-Testes?, Predicted Answer: Die Beobachtung lokaler Hautreaktionen bei der Anwendung von Tuberkulin führte aber später\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Diät kann bei der Behandlung der Hauttuberkulose helfen?, Predicted Answer: kochsalzfreie Diät zeigte offenbar (angeblich in 448 von 450 Fällen) Erfolge\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo spielte der FC Barcelona bei dessen Gründung?, Predicted Answer: Barça-Fans\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war das erste Stadion des FC Barcelona?, Predicted Answer: Velòdrom de la Bonanova\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo fand das erste Spiel des FC Barcelona statt?, Predicted Answer: 1899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war die erste Spielstätte des FC Barcelona?, Predicted Answer: Velòdrom de la Bonanova\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Fans passten in das erste Stadion des FC Bareclona?, Predicted Answer: Die meisten zahlenden Fans fallen in diese Altersklasse\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.69 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange dauerte der Bau des Camp de Les Corts, Predicted Answer: 1978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem weiteren Museums Haus hat Frida Kahlo abgesehen Vom Museo Frida Kahlo gewohnt?, Predicted Answer: San Angel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo in Mexiko-Stadt ist das Museo Frida Kahlo?, Predicted Answer: Coyoacán\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.16 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Farbe hat das Museo Frida Kahlo?, Predicted Answer: weiter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Stil ist das Museo Frida Kahlo gebaut?, Predicted Answer: kolonialen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit wem war Frida Kahlo verheiratet?, Predicted Answer: Museo Frida Kahlo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was waren die Hauptprobleme der Aggregat-4 Rakete?, Predicted Answer: eingeschleppte Krankheiten, Strafexpeditionen, Umsiedlungen und Zwangsarbeit dezimierten die Bevölkerung in einem kaum quantifizierbaren Ausmaß\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was waren die Hauptmotive für den Wettlauf ins All?, Predicted Answer: eine bisher ungekannte Technikschlacht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist der größte Rosinen Exporteur der Welt?, Predicted Answer: der Iran\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Land ist der größte Safran Exporteur?, Predicted Answer: Iran\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Prozent des Irans werden für die Landwirtschaft benutzt?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was tauschen Bakterien mit Sexpili untereinander aus?, Predicted Answer: können Bakterien mit Hilfe sogenannter Sexpili (Proteinröhren) DNA untereinander austauschen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie können Bakterien auch ohne Sexpili DNA untereinander austauschen?, Predicted Answer: Bei einer Konjugation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele schwarze Menschen leben in Frankreich?, Predicted Answer: 2,5 bis 5 Millionen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.13 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Woher kommen die meisten Schwarzen Frankreichs?, Predicted Answer: Einwanderer oder deren Nachkommen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum gab es in der französischen Regierung oft schwarze Minister?, Predicted Answer: In der Zwischenkriegszeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo leben die meisten schwarzen in Frankreich?, Predicted Answer: Einwanderer oder deren Nachkommen aus den afrikanischen und karibischen Kolonien Frankreichs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum sind Schwarze aus Überseegebieten in Frankreich tendenziell besser integriert als Schwarze aus Schwarzafrika?, Predicted Answer: Einwanderer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Schwarze waren in der Fußballnationalmannschaft Frankreichs bei der WM 2006?, Predicted Answer: drei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.10 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wurde 2005 als schwarze Frau Ministerin in Frankreich?, Predicted Answer: Rebekah Wade\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die beste Schweizer Fußball Liga?, Predicted Answer: Angriff\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der größte Leichtathletik Verein der Schweiz?, Predicted Answer: Der STBern\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Eritreischen Stadt Produziert Tesinma Busse?, Predicted Answer: Dekemhare\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Voraussetzung muss der Staatspräsident von Zypern erfüllen?, Predicted Answer: Zeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist das Staatsoberhaupt von Zypern?, Predicted Answer: Staatspräsident\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange ist die Amtsperiode des zypriotischen Staatspräsidenten?, Predicted Answer: Der Élysée-Palast\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann die ist das Amt des stellvertretenden Staatspräsidenten unbesetzt?, Predicted Answer: ebenfalls nicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was bezeichnete der Demokratieindex Zypern 2019?, Predicted Answer: eine „unvollständige Demokratie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt die große kommunistische Partei in Zypern?, Predicted Answer: Detroit Red Wings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Sitze gibt es im Parlament von zypern?, Predicted Answer: 56 Mandate auf Zyperngriechen und 24 auf Zyperntürken\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchen Ländern gibt es die Sommerzeit?, Predicted Answer: europäischen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Jahreszeit wird auf die Sommerzeit umgestellt?, Predicted Answer: 2011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann beginnt die Sommerzeit?, Predicted Answer: doppelte Sommerzeit genannt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Woher kommt der Begriff Pestizid?, Predicted Answer: gehemm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von welchem Land ist die Kultur der Tristan da Cunha Inseln stark beeinflusst?, Predicted Answer: Südkaliforniens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.14 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Alkohol trinken die Bewohner der Inseln Tristan da Cunhas?, Predicted Answer: sehr hoch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele polnische Spielfilme über Chopin gibt es?, Predicted Answer: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die wichtigsten Abschnitt Maßeinheits Größen des Korans?, Predicted Answer: der 30. Teil des Korans, Dschuzʾ genannt (, Plural ), und der 60. Teil des Korans, Hizb genannt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür ist die Einteilung des Korans in den Dschuz besonders praktisch?, Predicted Answer: Ramadan-Monat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.69 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür wird die Einteilung des Korans in 30 Teile beim Ramadan benutzt?, Predicted Answer: wichtig\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An was erkennt man die einzelnen Unterteilungen des Korans?, Predicted Answer: den Text in gleich lange Abschnitte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird für die MP3 Kompression benutzt?, Predicted Answer: 85 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Verfahren zur Daten Kompression von Musik an Computern wird am häufigsten benutzt?, Predicted Answer: MP3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo wurde das MP3 Verfahren entwickelt?, Predicted Answer: unter der Leitung von Karlheinz Brandenburg und Hans-Georg Musmann im Wesentlichen in Deutschland\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.21 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann liefen die letzten Patente für das MP3 Format aus?, Predicted Answer: ausgelaufen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Land hatte die größte freiwillige Armee im zweiten Weltkrieg?, Predicted Answer: Liberia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo wurde die indische Armee am Anfang des zweiten Weltkriegs eingesetzt?, Predicted Answer: Napoleon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer gründete die Indische Legion in Europa?, Predicted Answer: Subhash Chandra Bose\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo hat Subhash Chandra Bose die Indische Nationale Armee gegründet?, Predicted Answer: Japan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Soldaten in Indien wurden während des Zweiten Weltkriegs getötet?, Predicted Answer: 24.338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum wollte Indien in den zweiten Weltkrieg eintreten?, Predicted Answer: nur\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Mann hatte die indische Armee zu Beginn des zweiten Weltkrieges?, Predicted Answer: 200.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was kann die Lebensdauer einer Glühbirne verlängern?, Predicted Answer: Möglichkeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Lampen sind schwierig zu wechseln?, Predicted Answer: Signallampen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie kann die USA einen neuen Bundesstaat aufnehmen? , Predicted Answer: Puerto Rico\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum ist öffentliche Verkehrsmittel so beliebt in New York?, Predicted Answer: unamerikanische Stadt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welche Teile ist das Straßennetz in Manhattan unterteilt?, Predicted Answer: Ost und West\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Transportmittel benutzen die meisten Einwohner in New York?, Predicted Answer: öffentliche Verkehrsmittel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Transportmittel ist typisch für New York?, Predicted Answer: eine erhöhte Alarmbereitschaft\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen leben im südlichen Teil von Zypern?, Predicted Answer: 1,1 Millionen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hoch ist der Migrantenanteil in Zypern?, Predicted Answer: im Winter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Deutschen wohnen in Südzypern?, Predicted Answer: drei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus welchen Ländern kommen die meisten Migranten in Zypern?, Predicted Answer: 167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hängen Frequenz und Kapazität bei Kondensatoren zusammen?, Predicted Answer: höher\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo wird ein Kondensator vorwiegend induktiv wirksam?, Predicted Answer: solcher\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was wirkt der Kondensator bei höheren Frequenzen?, Predicted Answer: verwendbar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.17 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Kondensatoren werden für Frequenzen um 100 MHz eingesetzt?, Predicted Answer: Keramik- und Folienkondensatoren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welchen Frequenzbereich sind Aluminium-Elektrolytkondensatoren wirksam?, Predicted Answer: Gewachsene Traditionen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso werden verschiedene Arten von Kondensatoren kombiniert?, Predicted Answer: weniger lang\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Fachbegriff für die Gleichgewichtslinie beim Gletscher?, Predicted Answer: der Massenverlust\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.10 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird als Gleichgewichtslinie eines Gletschers bezeichnet?, Predicted Answer: Equilibrium Line Altitude''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ist das Zehrgebiet des Gletschers definiert?, Predicted Answer: Fernfeld\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt der Bereich oberhalb der Gleichgewichtslinie des Gletschers?, Predicted Answer: der Massenverlust durch Ablation größer als der Zuwachs an Gletschereis\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt der Bereich unterhalb der Gleichgewichtslinie des Gletschers?, Predicted Answer: der Massenverlust durch Ablation größer als der Zuwachs an Gletschereis\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ist das Akkumulationsgebiet des Gletschers definiert?, Predicted Answer: Fernfeld\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.92 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Edikt wurde im osmanischen Reich die Gleichheit aller Bürger formal festgeschrieben?, Predicted Answer: Hatt-ı Hümâyû\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde das Edikt von Gülhane erlassen?, Predicted Answer: Ebenfalls wurde eine Gedenkstätte errichtet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde der Hatt-i Hümayun erlassen?, Predicted Answer: abgegrenzt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die griechische Bevölkerung aus dem Osmanischen Reich vertrieben?, Predicted Answer: Bezogen auf die Zeit des Osmanischen Reichs wird diese Idee mit dem Begriff des Osmanismus beschrieben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Gesetz war Grundlage für den Genozid an den Armeniern im Osmanischen Reich?, Predicted Answer: Umsiedlungskampagne\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Volksgruppe wurde 1915 im Osmanischen Reich Opfer eines Völkermordes?, Predicted Answer: Umsiedlungskampagne\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Gruppe mit nationalistischen Ideen erlangte in der Endphase des Osmanischen Reichs die Macht?, Predicted Answer: Moussa Traoré\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Kasus gibt es im Tschechischen?, Predicted Answer: ausweises\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele grammatische Geschlechter gibt es im Tschechischen?, Predicted Answer: ausweises\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Genera gibt es im Tschechischen?, Predicted Answer: drei Genera, nämlich männlich, weiblich und sächlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zwischen was wird im Tschechischen beim männlichen Genus unterschieden?, Predicted Answer: n- und p-FETs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Artikel gibt es im Tschechischen?, Predicted Answer: eklatante Mängel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wozu dient die Kurzform von Adjektiven im Tschechischen?, Predicted Answer: schwefelfreien und damit umweltfreundlicheren Zellstoffproduktion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde ASCII eingeführt?, Predicted Answer: Unterart des Wolfes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Zeichen umfasst ASCII?, Predicted Answer: 95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Buchstaben umfasst ASCII?, Predicted Answer: Zeichen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.22 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Steuerzeichen gibt es im ASCII-Code?, Predicted Answer: 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für wie viel Geld wurde Neymar zu Paris Saint Germain transferiert?, Predicted Answer: 222 Millionen Euro\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Mannschaft spielte Ousman Dembélé, bevor er zu FC Barcelona gekommen ist?, Predicted Answer: Borussia Dortmund\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Art von Kondensatoren wurden mit \"cm\" gemessen?, Predicted Answer: Mica-Kondensatoren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr wurde die US-Army aufgestellt?, Predicted Answer: 1775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die Aufgaben der US-Army?, Predicted Answer: Rangers und Delta Force\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Armeen der Welt haben mehr Mann als die US-Army?, Predicted Answer: Rangers und Delta Force\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Teil von China liegt Zhejiang?, Predicted Answer: Jangtsekiang-Deltas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Woran grenzt Zhejiang im Norden?, Predicted Answer: an Jiangsu und Shanghai\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Woran grenzt Zhejiang im Osten?, Predicted Answer: Ostchinesische Meer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was liegt südlich von Zhejiang?, Predicted Answer: Jangtsekiang-Deltas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.22 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welche Zonen wird Zhejiang gegliedert?, Predicted Answer: sechs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.10 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Prozent der Fläche von Zhejiang bilden Gebirge?, Predicted Answer: 74,6 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Bergketen hat Zhejiang?, Predicted Answer: Drei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hoch ist der höchste Punkt in Zhejiang?, Predicted Answer: 1929 Metern\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der höchste Punkt in Zhejiang?, Predicted Answer: Huangmaojian\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Flüsse verlaufen in Zhejiang?, Predicted Answer: Grundstück\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche natürliche Seen gibt es in Zhejiang?, Predicted Answer: vier größten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Inseln gibt es in Zhejiang?, Predicted Answer: 2878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sieht die molekulare Struktur von Eis aus?, Predicted Answer: übereinanderliegenden Molekülschichten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Fall bewegt sich die obere Gletscherschicht schneller als die darunterliegende?, Predicted Answer: zweiten Fall\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum ist die Fließgeschwindigkeit verschiedener Teile eines Gletschers nicht gleichmäßig?, Predicted Answer: höher als an der Sohle und an den Seiten niedriger als in der Mitte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Bundesstaat liegt Houston?, Predicted Answer: Texas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo liegt Houston?, Predicted Answer: an der Südküste der Vereinigten Staaten und im Osten des Bundesstaates Texas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel der Fläche von Houston besteht aus Wasser?, Predicted Answer: 58 km2 Wasserfläche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem County liegt Houston?, Predicted Answer: Downtown\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt der Schifffahrtskanal in Houston?, Predicted Answer: Houston Ship Channel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt der Fluss, der durch Houston fließt?, Predicted Answer: Amtrak\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo mündet der Buffalo Bayou?, Predicted Answer: im Golf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt die Methode des Regenwassersammelns in Rajasthan?, Predicted Answer: weitergegeben werden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was versteht man unter dem \"Johad\"?, Predicted Answer: Dieser kleine See entsteht durch Anhäufen von Erdwällen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Ergebnis hat der Bau von Johads in Rajasthan?, Predicted Answer: ein vollkommen überfordertes Metronetz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was versuchen die Umweltorganisationen wie CSE in Indien zu verbessern?, Predicted Answer: begonnen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann gibt es eine quelloffene Variante von Poseidon für AROS?, Predicted Answer: August 2009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ist USB mit Atari MINT benutzbar?, Predicted Answer: unterstützt standardmäßig kein USB, es sind jedoch für MiNT verschiedene Treiber\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche USB-Versionen unterstützt Windows 10?, Predicted Answer: 1.0, 1.1, 2.0, 3.0, 3.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Kann man USB-Anschlüsse mit DOS benutzen?, Predicted Answer: unterstützen USB standardmäßig nicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann fand die Premier League erstmals statt?, Predicted Answer: „Premier Division“ hieß\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Vereine spielten beim ersten Turnier der Premier League teil?, Predicted Answer: zwei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Verein erzielte das erste Tor in der Premier League?, Predicted Answer: Brian Deane\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann spielten in der Premier League nur noch 20 Vereine?, Predicted Answer: wenige Sekunden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was forderte die FIFA in Bezug auf die Anzahl der Vereine in der Premier League?, Predicted Answer: eine weitere Verkleinerung auf 18 Klubs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher war der erste nicht-englische Verein in der Premier League?, Predicted Answer: Gary Lineker\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hieß die Premier League vor 2007 offiziell?, Predicted Answer: auf Ablehnung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.61 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Audioformat wird beim HDTV hauptsächlich verwendet?, Predicted Answer: MPEG-2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Filme verfügen bei HDTV nicht über Mehrkanalton?, Predicted Answer: Stereo oder gar Mono\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie schwer ist ein Schlachtreifer Strauß?, Predicted Answer: ein flugunfähiger Laufvogel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchem anderen Fleisch ist das Straußenfleisch ähnlich?, Predicted Answer: sehr fettarm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer benutzt den deutschen Fußballjargon hauptsächlich?, Predicted Answer: Armee\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Art von Sprache ist der Fußballjargon?, Predicted Answer: Umgangssprache eine Sondersprache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das \"Sommermärchen\", Predicted Answer: Trail of Tears\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Länder nutzen den Begriff Soccer?, Predicted Answer: Gliedstaaten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Touristen schlafen jährlich in Bern?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Touristen in Bern kommen aus dem Ausland?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Woher kommen die meisten ausländischen Touristen Berns?, Predicted Answer: Säugetiere\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann kommen die meisten Touristen nach Bern?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer bewertete die Leistung von England im ersten Weltkrieg?, Predicted Answer: Politiker und Mitarbeiter des öffentlichen Dienstes die Leistung des britischen Staates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war 1921 britischer Premierminister?, Predicted Answer: Isayas Afewerki\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann hat England einen Generalstab?, Predicted Answer: 1923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum hat Lord Chatfield als \"Minister for Coordination of Defence\" keinen Erfolg?, Predicted Answer: Diesen nahm Lord Chatfield bis zum Ende der Regierung Chamberlain ein\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer führte in England das Amt des Verteidigungsministers ein?, Predicted Answer: Winston Churchill\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.14 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche britischen Ministerien wurden zum heutigen Verteidigungsministerium zusammengefasst?, Predicted Answer: 1964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.27 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Klimazone liegt Oklahoma City?, Predicted Answer: Tornado Alley\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann war der heißeste Tag in Oklahoma City?, Predicted Answer: einzigartig\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Monat regnet es in Oklahoma City im Schnitt am meisten?, Predicted Answer: März bis Juni\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war die kälteste gemessene Temperatur in Oklahoma City?, Predicted Answer: −27 °\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie oft treten in Oklahoma City Tornados auf?, Predicted Answer: Gefahr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann ist Zypern EU-Mitglied?, Predicted Answer: 2004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Land erkennt Zypern nicht offiziell an?, Predicted Answer: Englisch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann gibt es den Euro in Zypern?, Predicted Answer: eingeführt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Maßnahmen unternimmt die Türkei gegen Zypern?, Predicted Answer: nicht jedoch die Türken\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann war Zypern kurz vor dem Staatsbankrott?, Predicted Answer: Zuvor war ein Versuch der Vereinigung der Insel bei einer Volksabstimmung am 24. April 2004 an der Ablehnung im griechischen Teil gescheitert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Geld bekam Zypern von der EU um ein Staatsbankrott zu verhindern?, Predicted Answer: Zahlungsunfähigkeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurde der Zusammenschluss mehrerer Sippen bei den Slawen genannt?, Predicted Answer: ''bog\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie war das Zusammenleben in der lokalen Gemeinschaft bei den Slawen organisiert?, Predicted Answer: öffentlich-rechtlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.15 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Stellenwert hatte die Ehe bei den Slawen?, Predicted Answer: heilig gehalten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo würde das frühere Baktrien heutzutage liegen?, Predicted Answer: Federal Reserve Notes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo herrschten die Shunga um 100 v. Chr.?, Predicted Answer: Alexanderzüge entstand im nordwestlichen Grenzgebiet von Baktrien und Gandhara (heute: Afghanistan und Pakistan) das hellenistische Gräko-baktrische Reich. Man verzeichnete eine Entfaltung der buddhistischen Kunst und Kultur. Das Reich zerfiel mit dem Eindringen der aus Zentralasien stammenden Skythen, die von den Indern ''Shakas'' genannt werden.\n",
            "In Nordindien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Religion favorisierten die Shunga um 100  v. Chr.?, Predicted Answer: In Nordindien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer darf wie viele Vertreter in den Inselrat von St. Helena schicken?, Predicted Answer: Peter Behrens und Joseph Maria Olbrich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen leben in Eritrea?, Predicted Answer: sehr viele gut ausgebildete junge Menschen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum ist in Eritrea ein starkes Bevölkerungswachstum zu beobachten?, Predicted Answer: Nebel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie soll nach Einschätzungen die Bevölkerung in Eritrea bis 2050 anwachsen?, Predicted Answer: im Jahr 2050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Tonnen Bomben wurden von den USA während des Koreakrieges abgeworfen?, Predicted Answer: 450.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann hat in Griechenland das Fernsehen nicht mehr die meisten Werbeeinnahmen? , Predicted Answer: 1972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ist die Pressefreiheit in Griechenland im Vergleich zu anderen Ländern?, Predicted Answer: Platz 88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist ein Güteraufzug?, Predicted Answer: eine Aufzugsanlage\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum dürfen die Güteraufzüge nur von außen bedient werden?, Predicted Answer: Aus diesem Grund\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist eine Sonderform von Güteraufzügen?, Predicted Answer: Oklahoma\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wozu werden Kleinlastenaufzüge genutzt?, Predicted Answer: 2012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür werden Möbellifte benutzt?, Predicted Answer: im Niederländischen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißen die vier Konservatorien in London?, Predicted Answer: das Royal College of Music, die Royal Academy of Music, das Trinity College of Music und die Guildhall School of Music and Drama\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann starb der Mann von Queen Victoria?, Predicted Answer: Prinz Albert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Kinder hatte Queen Victoria?, Predicted Answer: 78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Krankheit wurde vor seinem Tod bei Queen Victorias Ehemann festgestellt?, Predicted Answer: warmes Wasser\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Krankheiten werden heutzutage als Ursache für den Tod von Queen Victorias Mann vermutet?, Predicted Answer: übertrieben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann starb die Mutter von Queen Victoria?, Predicted Answer: Prinz Albert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war die schwierigste Krise in Queen Victorias Privatleben?, Predicted Answer: Dornenkrone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit wem hatte der älteste Sohn von Queen Victoria eine Affäre in der Zeit, als sein Vater starb?, Predicted Answer: Albert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso reiste Queen Victorias Mann kurz vor seinem Tod nach Cambridge?, Predicted Answer: Prinz Albert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Kleidung pflegte Queen Victoria nach dem Tod ihres Mannes zu tragen?, Predicted Answer: 385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo wurde Queen Victorias Mann beerdigt?, Predicted Answer: Louise Lehzen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was bezeichnete Queen Victoria die Krone in ihrer Witwenzeit?, Predicted Answer: Frau\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso nahm Queen Victorias Beliebtheit unter der Bevölkerung ab?, Predicted Answer: Noch am gleichen Vormittag empfing Victoria Premierminister Lord Melbourne und nahm an ihrer ersten Kronratssitzung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Besondere an niederländischen Schimpfwörtern?, Predicted Answer: die häufige Verwendung von Krankheiten als Beschimpfung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welcher Erweiterung werden auf Krankheiten basierende Schimpfwörter im Niederländischen häufig verwendet?, Predicted Answer: Wortschatz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Themenfelder werden im Niederländischen vor allem für Schimpfwörter benutzt?, Predicted Answer: transitive Verben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch was wird das Hochskalieren bei neueren HDTV-Auflösungen begünstigt?, Predicted Answer: landwirtschaftliche Fortschritte und die mittelalterliche Warmzeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo wurde der Prototyp von HDTV mit vierfacher Pixelzahl präsentiert?, Predicted Answer: CeBIT 2006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo soll HDTV mit vierfacher Pixelzahl eingesetzt werden?, Predicted Answer: Displays\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Auswirkungen kann USB 3.0 auf Bluetooth haben?, Predicted Answer: 2,4-GHz-Bereich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Linux-Versionen erlauben USB 3.0?, Predicted Answer: Kernel-Version 2.6.31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Sind USB 3.0.Stecker mit älteren Typen kompatibel?, Predicted Answer: Host\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde USB 3.0 präsentiert?, Predicted Answer: überträgt mit der Symbolrate 5 GBd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche großen Firmen gehören zum USB Implementers Forum?, Predicted Answer: HP, Microsoft und Intel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Übertragungsrate von USB 3.0?, Predicted Answer: 2400 Mbit/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher USB-Typ hat blaue Stecker?, Predicted Answer: USB 3.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde in England erstmals eine Sperrstunde eingeführt?, Predicted Answer: das 1066 von den Normannen erobert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso wurde 1915 in Großbritannien eine Sperrstunde eingeführt?, Predicted Answer: Pubs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ab wann war in englischen Pubs nach 1915 Sperrstunde?, Predicted Answer: gesetzlich eingeführt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wie wird die Forderung nach der Wiedereinführung der Sperrstunde in ENgland begründet?, Predicted Answer: Begründet wurde diese Entscheidung durch den Umstand\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit was wird in englischen Pubs zur letzten Runde aufgerufen?, Predicted Answer: Wirt Gehör\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war zur Zeit von Queen Victorias diamantenem Thronjubiläum Premierminister?, Predicted Answer: Lord Melbourne\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Position hatte Joseph Chamberlain unter Queen Victoria 1897?, Predicted Answer: Victoria in ihrer Kutsche sitzend teilnehmen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was sollte das 60. Thronjubiläum von Queen Victoria gefeiert nach Vorschlag von Lord Salisbury werden ?, Predicted Answer: ''Festival of the British Empire''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.82 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie alt war Queen Victoria an ihrem 60. Thronjubiläum?, Predicted Answer: 2012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welcher Krankheit litt Queen Victoria zur Zeit ihres 60. Regierunsjubiläums?, Predicted Answer: 385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welchem Tag wurden die Feierlichkeiten anlässlich von Queen Victorias 60. Thronjubiläum in London durchgeführt?, Predicted Answer: 1897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann war der Burenkrieg in Südafrika?, Predicted Answer: jüdischer „Bruderkrieg“ bezeichnet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurde Queen Victorias ältester Sohn genannt?, Predicted Answer: verantwortlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hatte Queen Victoria ihr 60. Thronjubiläum?, Predicted Answer: 2012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der \"Trail of Tears\"?, Predicted Answer: Umsiedlung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was verbot die Regierung 1880 in Oklahoma zum Schutz der indianischen Bevölkerung?, Predicted Answer: untersagte, kam es seitens der Bevölkerung immer wieder zu Übertretungen der Grenzen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wovon profitierte die Wirtschaft in Oklahoma Anfang des 20. Jhd?, Predicted Answer: 1940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wird als \"Vater der Route 66\" bezeichnet?, Predicted Answer: Bob Ewell\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann trat Oklahoma offiziell den Vereinigten Staaten bei?, Predicted Answer: Am 16. November 1907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was wurde Oklahoma Ende des 19. Jahrhunderts  bezeichnet?, Predicted Answer: Trail of Tears\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt die große Besiedlungswelle in Oklahoma Ende des 19. Jahrhunderts?, Predicted Answer: Tornados\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Gebäude in Oklahoma wurde 1995 durch einen Bombenanschlag zerstört?, Predicted Answer: lasts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Verbot galt in Oklahoma bis 1967?, Predicted Answer: 1967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was strebte die indianische Bevölkerung in Oklahoma Anfang des 20. Jhd. an?, Predicted Answer: Übertretungen der Grenzen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.17 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was brachte Oklahoma den Namen \"Dust Bowl\" ein?, Predicted Answer: Sooner State\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer repräsentiert die Großregion Melbourne?, Predicted Answer: Lord Mayor der City of Melbourne\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Liegt Bildung im Aufgabenbereich der Verwaltungsbezirke von Melbourne oder beim Bundesstaat?, Predicted Answer: bei der Regierung des Bundesstaates Victoria\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Bundesstaat liegt Melbourne?, Predicted Answer: Victoria\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welche Regionen ist dsa deutsche Generalkonsulat in Melbourne zuständig?, Predicted Answer: Victoria, South Australia, Tasmania und Western Australia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In was ist die Metropolregion im Melbourne gegliedert?, Predicted Answer: keine zentrale Verwaltung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann war der Terroranschlag, der das World Trade Center zerstörte?, Predicted Answer: nie dagewesenen Ausmaßes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde der Bombenanschlag in der Tiefgarage des WTC verübt?, Predicted Answer: erschüttert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen starben bei dem Anschlag 1993 auf das World Trade Center?, Predicted Answer: 360.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Ground Zero?, Predicted Answer: One World Trade Center\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das höchste Gebäude in den USA?, Predicted Answer: One World Trade Center\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.22 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde das One World Trade Center fertiggestellt?, Predicted Answer: 2014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo fand der Parteitag der Repubilkaner 2004 statt?, Predicted Answer: Madison Square Garden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer entwarf die Gedenkstätte für die Opfer des 11. September?, Predicted Answer: Director of National Intelligence\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ist das Memorial am Ground Zero gestaltet?, Predicted Answer: 2004 fiel auch die Entscheidung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann traf Hurrikan Sandy New York?, Predicted Answer: Der Hudson River\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann war die Börse in New York vor 2012 das letzte Mal wegen Unwetter geschlossen worden?, Predicted Answer: Die New York Stock Exchange\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Weswegen war die New York Stock Exchange 1888 geschlossen?, Predicted Answer: eines Unwetters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welcher Literauturströmung gehört Novalis?, Predicted Answer: einen gewissen Wohlstand\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann fand der Wiener Kongress statt?, Predicted Answer: dann auf dem Wiener Kongress 1815 dem dort gerade zu einem Grossherzogtum erhobenen wettinischen  Sachsen-Weimar-Eisenach zugeschlagen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo wurde die Sozialdemokratische Arbeiterpartei gegründet?, Predicted Answer: 1869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war ein Spitzname für Herzog Ernst II. von Sachsen-Coburg?, Predicted Answer: ein Kritiker preußischer Hegemonialpolitik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hieß der Vorgänger von Hertie?, Predicted Answer: Kaufhaus des Landes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus welchen Gruppierungen entstand die SPD?, Predicted Answer: Stimmen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches politische Konzept wurde um 1850 in den deutschen Fürstentümern diskutiert?, Predicted Answer: Einberufung des Erfurter Unionsparlaments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer verhinderte, dass Sachsen-Meiningen nach dem Krieg von 1866 von Preußen annektiert wurde?, Predicted Answer: Napoleon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso forderte Bismarck die Annexion von Sachsen-Meiningen und Reuß nach dem Krieg von 1866?, Predicted Answer: Gaddafi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.13 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer lud zum sogenannten Wartburgfest ein?, Predicted Answer: SG:PART\n",
            "                   'Liebst du mich?'                                                                          (Erelt, 2009, p. 16)\n",
            "           (23) Ta       lä-k-s                       ära   või?\n",
            "                   3SG    gehen-PAST-3SG weg oder\n",
            "                   'Sie/Er ist weggegangen, oder?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer prägte die Weimarer Klassik?, Predicted Answer: Einfluss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ab wann gab es die erste Zugstrecke in Thüringen?, Predicted Answer: kaum Bestrebungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welchen Industriezweig ist Jena bekannt?, Predicted Answer: Rundgängen und Exkursionen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer gründete den ersten Kindergarten in Deutschland?, Predicted Answer: Ernst-Wilhelm Arnoldi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was wird das Wiederaufleben des kulturellen Lebens in Weimar im 19. Jhd bezeichnet?, Predicted Answer: Ländlermusik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wen schlug Napoleon 1806 auf dem Gebiet des heutigen Thüringen?, Predicted Answer: Zur Napoleonischen Zeit bahnte sich 1806 die entscheidende Schlacht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Nachschlagewerk gibt das Bibliographische Institut heraus?, Predicted Answer: den Herausgeber von Meyers Konversations-Lexikon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchen Disziplinen spielt der Begriff Emotion eine Rolle?, Predicted Answer: vielen Kulturkreisen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ist der zeitliche Verlauf von Emotionen verglichen mit Stimmungen?, Predicted Answer: relativ kurz und intensiv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Sind Emotionen oder Stimmungen eher durch einen bestimmten Reiz ausgelöst?, Predicted Answer: Gleichermaßen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was unterscheidet Emotionen von Gefühlen?, Predicted Answer: die Regierung 1880 offiziell eine Besiedelung des Landes durch die Weißen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit was beschäftigt sich die Neurowissenschaft in Bezug auf Emotionen?, Predicted Answer: efferenten somatischen und vegetativen Reaktionen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welcher Art von Metall gehört Kupfer?, Predicted Answer: vielen anderen Schwermetallen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ist Kupfer gesundheitsschädlich?, Predicted Answer: 0,04 Gramm Kupfer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird die antibakterielle Wirkung von Kupfer bezeichnet?, Predicted Answer: In freier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wirkt Kupfer antibakteriell?, Predicted Answer: In freier, nicht an Proteine gebundener Form\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Gilt Leinenpflicht für Hunde deutschlandweit, Predicted Answer: Hans-Reinhart-Ring\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Müssen Hunde gegen Tollwut geimpft werden?, Predicted Answer: Abfallfresser\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo kann man Rettungshundeprüfungen machen?, Predicted Answer: nur in einer zugelassenen Rettungshundestaffel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo muss man Hundehaufen entfernen?, Predicted Answer: ein passiver Nurlese-RFID-Chip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche öffentlichen Radiosender gibt es in der Schweiz auf deutsch?, Predicted Answer: Bundesebene\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird das staatliche Radio in der Schweiz finanziert?, Predicted Answer: Rundfunkgebühren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann gibt es in der Schweiz private Radiostationen?, Predicted Answer: 1983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die UNIKOM in der Schweiz?, Predicted Answer: Willensnation'' geprägt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf welcher Frequenz senden die Radiosender in der Schweiz?, Predicted Answer: 50 Hertz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist Preisniveaustabilität?, Predicted Answer: vorgegebene Ziel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Inflationsrate will die EZB erreichen?, Predicted Answer: unter 2 % zu halten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welchen Anschlag beschuldigte Reagan Gaddafi?, Predicted Answer: Bombenanschlag\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Personen starben beim Lockerbie-Anschlag?, Predicted Answer: 270 Toten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Entschädigung wurde von Libyen für den Lockerbie-Anschlag gezahlt?, Predicted Answer: 2,46 Milliarden US-Dollar Entschädigung an die Hinterbliebenen der Opfer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie unterstütze Gaddafi die IRA?, Predicted Answer: phasenweise die IRA mit Waffenlieferungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum unterstütze al-Gaddafi die IRA?, Predicted Answer: phasenweise die IRA mit Waffenlieferungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Land soll am La Belle-Anschlag auch beteiligt gewesen sein?, Predicted Answer: Deutschland\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso soll Libyen anstelle von Iran und Syrien für den Lockerbie-Anschlag verantwortlich gemacht worden sein?, Predicted Answer: Gaddafi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von wo hatte die Abu Nidal-Gruppe hauptsächlich operiert?, Predicted Answer: Ronald Reagan Gaddafi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind Verbrechen gegen die Menschlichkeit?, Predicted Answer: breit angelegte oder systematische Übergriffe auf die Zivilbevölkerung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind Kriegsverbrechen?, Predicted Answer: kriminelle Handlungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt der Völkermord an den Juden durch die Nationalsozialisten?, Predicted Answer: Holocaust\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Abkommen werden Regeln zu Verbrechen während eines Krieges oder Konflikts festgelegt?, Predicted Answer: Verfassung des Gesamtstaates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist emotionale Intelligenz?, Predicted Answer: beschreibt die Fähigkeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Theorie liegt der emotionale Intelligenz zugrunde?, Predicted Answer: nicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hat die Theorie der mutliplen Intelligenzen aufgestellt?, Predicted Answer: Howard Gardner\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Komponenten haben Emotionen?, Predicted Answer: sensorische, kognitive, physiologische, motivationale und expressive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo hatten die meisten Stücke von Max Frisch ihre Uraufführung?, Predicted Answer: Zahlreiche Stücke von Bertolt Brecht erlebten hier ihre Uraufführung. Auch die meisten Stücke von Max Frisch und Friedrich Dürrenmatt wurden hier uraufgeführt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Auszeichnung erhielt das Schauspielhaus Zürich 2002 und 2003?, Predicted Answer: Theater des Jahres\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde das Schauspielhaus Zürich von \"Theater heute\" zum Theater des Jahres gewählt?, Predicted Answer: 2002 und 2003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde das Opernhaus in Zürich eröffnet?, Predicted Answer: 1891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Art von Stücken wird im Opernhaus Zürich gespielt?, Predicted Answer: Tanzgelegenheit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Kultureinrichtung in der Schweiz ist der Dadaismus entstanden?, Predicted Answer: – die nationale Identität basiert nicht auf einer gemeinsamen Sprache und Kultur, sondern unter anderem auf der gemeinsamen Geschichte, gemeinsamen Mythen, der freiheitlichen, basisdemokratischen und föderalistischen Tradition sowie zum Teil aus dem Gefühl, als neutraler und mehrsprachiger, auf sich selbst gestellter «Kleinstaat» in Europa einen «Sonderfall» zu bilden. Es liegt ein Direktorialsystem vor.\n",
            "Diese Voraussetzungen haben sich in einem in seiner Gesamtheit einzigartigen politischen System\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Hans-Reinhart-Ring?, Predicted Answer: die höchste Auszeichnung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Tier ist im Wappen von Bern zu sehen?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie weit zurück reichen Belege für einen Bär im Wappen von Bern?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sah das erste Wappen von Bern aus?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Stadt trägt das gleiche Wappen wie Bern in der Schweiz?, Predicted Answer: Nezahualcóyotl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie unterscheiden sich die Wappen von Bern und New Bern?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Stadtmarke von Bern?, Predicted Answer: Deutsch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurden Bern und der umliegende Kanton getrennt?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer benutzte den Begriff Energie zuerst in seiner naturwissenschaftlichen Bedeutung?, Predicted Answer: Julius Robert Mayer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann wird Energie als Begriff in der Physik benutzt?, Predicted Answer: 1807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bei welchen Körpern zeigen sich unterschiedliche WIrkungen bei gleichem Impuls?, Predicted Answer: unelastisc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche physikalische Größe wurde durch die Energie ergänzt?, Predicted Answer: Zeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie bezeichnete Leibniz die Größe Energie?, Predicted Answer: 1686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welchem Phänomen in der Mechanik forschte Leonhard Euler?, Predicted Answer: bei anderen analytischen Mechanikern des 18. Jahrhunderts wie Leonhard Euler (z. B. Behandlung der elastischen Deformation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche physikalische Definition von Arbeit wurde 1829 vorgeschlagen?, Predicted Answer: „Kraft mal Weg“, bzw. ) wurde auch 1829 gleichzeitig von Coriolis und Poncelet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.10 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer führte den Begriff kinetische Energie ein?, Predicted Answer: Daniel Bernoulli\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was behandelt eine bekannte Veröffentlichung von Carnot von 1824?, Predicted Answer: Diese Erkenntnisse\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer formalisierte Carnots Ergebnisse zur Dampfmaschine?, Predicted Answer: Émile Clapeyron\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Eigenschaft von Energie beschrieb Julius Robert Mayer 1841?, Predicted Answer: Die Wärmemenge\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Hauptsatz der Thermodynamik beschreibt das Prinzip der Energieerhaltung?, Predicted Answer: Erster\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In wiefern erweiterte Rudolf Clausius das Verständnis von Energie und Wärme?, Predicted Answer: ein Teil der Wärmeenergie in mechanische Arbeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was beschreibt der Zweite Hauptsatz der Thermodynamik?, Predicted Answer: widersprechen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen physikalischen Begriff prägte Clausius?, Predicted Answer: ein Teil der Wärmeenergie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer verfasste den zweiten Hauptsatz der Thermodynamik?, Predicted Answer: Clausius\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer schrieb 1847, dass es nicht möglich sei, ein Perpetuum Mobile zu konstruieren?, Predicted Answer: Hermann von Helmholtz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso trafen Helmholtz und Mayer unter etablierten Physikern in Deutschland auf Ablehnung?, Predicted Answer: ein noch weitergehender Nutzungsverzicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo hat der Trans Canada Highway seinen Anfangspunkt?, Predicted Answer: Mile One Centre\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Gebäude steht für den Anfang des Trans Canada Highway?, Predicted Answer: Mile One Centre\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Straße ist die drittlängste der Welt?, Predicted Answer: Trans Canada Highway\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Rang nimmt der Trans Canada Highway unter den längsten Straßen der Welt ein?, Predicted Answer: Flotte Liberias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.13 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Stadt startet der Trans Canada Highway?, Predicted Answer: 50 New Gower Street\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus welchen Quellen ist das heutige Recht in Israel beeinflusst?, Predicted Answer: osmanischer Zeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Israel gegründet?, Predicted Answer: aschkenasischen Juden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: in welchem Rechtsbereich ist in Israel die englische Rechtstradition noch deutlich zu sehen?, Predicted Answer: Das osmanische Recht ist nur noch in wenigen Bereichen relevant\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann ist englische Rechtssprechung in Israel nicht mehr gültig?, Predicted Answer: 1972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann lebte Willliam Apes?, Predicted Answer: ''The Experience of William Apes, a Native of the Forest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welchem Stamm gehörte William Apes?, Predicted Answer: den frühen Beispielen amerikanischer Literatur\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.92 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Einschränkungen gibt es bei der Weitergabe von manchen Geschichten der indianischen mündlichen Tradition?, Predicted Answer: erhebliche Energie-Einsparungspotenziale\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer übersetzte das Markus-Evangelium ins Mohawk?, Predicted Answer: Thayendanegea\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie war der bürgerliche Name von Thayendanegea?, Predicted Answer: Brant\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Amerikaner indianischer Abstammung erhielt 1969 den Pulitzer-Preis?, Predicted Answer: Der Kiowa N. Scott Momaday\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer schrieb \"The rebirth of Canada's Indians\"?, Predicted Answer: Harold Cardinal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Klimazone liegt Mexiko-Stadt?, Predicted Answer: Stadt Naucalpán\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist in Mexiko City Regenzeit?, Predicted Answer: sehr schwül\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Niedeschlagsphase ist in Mexiko-Stadt im Winter und Frühjahr?, Predicted Answer: trocken und kalt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.69 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Durchschnittstemperatur in Mexiko-Stadt?, Predicted Answer: regional jedoch sehr unterschiedlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Monat gibt es in Mexico City durchschnittlich die höchsten Temperaturen?, Predicted Answer: Frühjahrsmonaten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: in welchem Monat regnet es in Mexico-Stadt am meisten?, Predicted Answer: 400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.60 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Gruppe verlor im Zuge der Teilungen Polens ihre Adelstitel?, Predicted Answer: Friedrich der Große\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das deutsche Äquivalent der polnischen Endungen -ski, -cki und -icz?, Predicted Answer: „von“\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer regierte Preußen zur Zeit der ersten Teilung Polens 1772?, Predicted Answer: Friedrich der Große\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr war der Novemberaufstand gegen die russische Herrschaft in Polen?, Predicted Answer: 1830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Auftstand fand 1863 in Polen statt?, Predicted Answer: Juden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wohin floh die Fürstin Isabella Czartoryska im Zuge der gescheiterten polnischen Aufstände im 19. Jhd?, Predicted Answer: Bekannt wurde die Flucht der Fürstin Isabella Czartoryska ins österreichisch regierte Galizien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.61 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann dürfen Menschen in Nordirland der Labour Party beitreten?, Predicted Answer: 2003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.60 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Zeitraum ist der Roman \"Wer die Nachtigall stört\" verordnet?, Predicted Answer: Die Kinder des Kapitän Grant'' aus Jules Vernes Romantrilogie der Südhalbkugel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo spielt \"Wer die Nachtigall stört\"?, Predicted Answer: Boo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist die Erzählerin von \"Wer die Nachtigall stört\"?, Predicted Answer: Boo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt Scouts Vater in Wer die Nachtigall stört?, Predicted Answer: Beyoncé\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Beruf hat Scouts Vater in Wer die Nachtigall stört?, Predicted Answer: Beyoncé\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt der Nachbar von Scout in Wer die Nachtigall stört?, Predicted Answer: weitergegeben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird Tom Robinson in Wer die Nachtigall stört vorgeworfen?, Predicted Answer: Der Armee und anderen staatlichen Sicherheitsorganen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.59 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Idee folgt die Jury in Wer die Nachtigall stört bei der Verurteilung von Robinson?, Predicted Answer: dem ungeschriebenen Gesetz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was geschieht am Ende des Romans Wer die Nachtigall stört mit Robinson?, Predicted Answer: Atticus Finch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer greift Scout und ihren Bruder am Ende des Romans Wer die Nachtigall stört an?, Predicted Answer: Gott Apophis\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer rettet Scout und ihren Bruder vor Ewells Angriff in Wer die Nachtigall stört?, Predicted Answer: Am Ende des Romans begleitet Scout ihren Nachbarn Boo wieder zurück in sein Haus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.92 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Staats- und Regierungsform befürwortete Locke?, Predicted Answer: Second Treatise on Government entworfenen Staatstheorie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.61 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat Montesquieu die Persischen Briefe veröffentlicht?, Predicted Answer: 1721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.92 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welcher Aufgabe war Montesquieu am Gericht von Bordeaux betraut?, Predicted Answer: Studien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Worin besteht für Montesquieu politische Freiheit?, Predicted Answer: Hayek\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt das Buch von Montesquieu zur Staatstheorie?, Predicted Answer: Locke\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Airlines fliegen von dem St. John’s International Airport aus? , Predicted Answer: Air Canada, Air Canada Jazz, Air Saint-Pierre, Air Transat, CanJet, Continental Airlines, Porter Airlines, Provincial Airlines, Sunwing Airlines und Westjet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.21 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Städte innerhalb Kanada kann man von dem St. John's International Airport erreichen?, Predicted Answer: Weitere planmäßige Flugverbindungen zu Zielen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Städte außerhalb Kanada sind von dem St. John's International Airport erreichbar?, Predicted Answer: Weitere planmäßige Flugverbindungen zu Zielen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bedeutet Luxuspapiere?, Predicted Answer: Sich zu verständigen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Methoden wurden zur Veredelung der Luxuspapiere eingesetzt?, Predicted Answer: Bearbeitungsverfahren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchen Ländern wird das Papier in Innenräumen als Einrichtung verwendet?, Predicted Answer: Japan und China\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Prozent der Stimmen hat Miguel Angel Mancera bei den Wahlen bekommen?, Predicted Answer: 46,37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Prozent der Stimmen hat der Vorgänger von Miguel Angel Mancera bei den Wahlen bekommen?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war der Vorgänger von Marcelo Ebrard?, Predicted Answer: Alejandro Encinas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann gibt es einen Regierungschef in Mexiko-Stadt?, Predicted Answer: 1. Januar 1929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hat die Mexiko-Stadt vorher regiert, bevor es einen Stadtoberhaupt gab? , Predicted Answer: Miguel Ángel Mancera\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Bezirken gibt es heutzutage im Bundesbezirk neben Mexiko-Stadt?, Predicted Answer: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer regiert in den einzelnen Bezirken in Mexiko-Stadt?, Predicted Answer: Titos Regime\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war das Ziel der Verwaltungsreform 1982 in Mexiko-Stadt?, Predicted Answer: durch Dezentralisierung eine effizientere Verwaltung zu erreichen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war der erste frei gewählte Regierungschef der Mexiko-Stadt?, Predicted Answer: Cuauhtémoc Cárdenas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war der Vorgänger des ersten frei gewählten Regierungschefs von Mexiko-Stadt?, Predicted Answer: Cuauhtémoc Cárdenas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die regierende Partei von Mexiko-Stadt?, Predicted Answer: Stadt Naucalpán\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat Andrés Manuel López Obrador in den Präsidentschaftswahlen teilgenommen?, Predicted Answer: nur sehr knapp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Outdoorsportarten sind populär in North Carolina?, Predicted Answer: Great Smoky Mountains\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird der Breitensport in North Carolina gefördert?, Predicted Answer: überwiegend durch den gemeinnützigen Verband der North Carolina Amateur Sports (NCAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Sportveranstaltungen finden in North Carolina jährlich statt?, Predicted Answer: Wettbewerbe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür stellt der North Carolina Amateur Sports Mittel zur Verfügung?, Predicted Answer: einen Fonds auch Mittel für den Betrieb öffentlich zugängliche Sportstätten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum hat der Fürst Menschikow den Militär nach Konstantinopel entsandt? , Predicted Answer: Auftreten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was forderte Fürst Menschikow vom Sultan des Osmanischen Reiches 1853?, Predicted Answer: Auftreten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann reiste Menschikow aus dem Osmanischen Reich ab, nachdem seine Mission gescheitert ist?, Predicted Answer: Russland\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hat versucht russische Häfen 1854 in der Ostsee zu blockieren?, Predicted Answer: Charles John Napier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war der wichtigste militärische Berater vom Fürst Menschikow?, Predicted Answer: Iwan Fjodorowitsch Paskewitsch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum war die Raumfahrt in den 60ern so populär?\n",
            ", Predicted Answer: Jupiter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Recht befasst sich mit der Jagd?, Predicted Answer: Rechtsnormen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf was basiert das objektive Jagdrecht meistens?, Predicted Answer: weitergehende Regelungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was kommt meistens zum Fundament des objektiven Jagdrechts hinzu?, Predicted Answer: existieren oft weitergehende Regelungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann nimmt Guam an allen Olympischen Sommerspielen teil?, Predicted Answer: 1988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchen Vereinen ist die Guams Fußballnationalmannschaft ein Mitglied?, Predicted Answer: FIFA- und AFC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat Guam zum ersten Mal versucht in der Fußballweltmeisterschaft teilzunehmen?, Predicted Answer: 2002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat Guam in einem Spiel gegen Turkmenistan gewonnen?, Predicted Answer: 1:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Föderalismus im engeren Sinne?, Predicted Answer: erweiterte politische Volksrechte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bedeutet \"nachhaltiger Föderalismus\"?, Predicted Answer: ine freiheitliche (libertäre) Auffassung auf (Föderalismus von unten), auch als „nachhaltiger Föderalismus“ bezeichnet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie unterscheiden sich Gehirne von Männern und Frauen?, Predicted Answer: in der Größe und im Aufbau\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel wiegt das Gehirn eines Mannes durchschnittlich?, Predicted Answer: vergleichsweise gut entwickelt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.82 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie groß ist der Unterschied zwischen dem Gewicht des Gehirnes eines Mannes und einer Frau?, Predicted Answer: Das absolute Hirngewicht hat keine große Bedeutung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie schwer ist das Gehirn eines Blauwalles?, Predicted Answer: vergleichsweise gut entwickelt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchem Tier ähnelt sich der Hippocampus?, Predicted Answer: Seepferdchen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.92 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür ist der Hippocampus zuständig?, Predicted Answer: für das Lernen und die Erinnerungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Unterschied zwischen dem Hippocampus eines Mannes und einer Frau?, Predicted Answer: größer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür ist die Amygdala zuständig?, Predicted Answer: Ministerium (beziehungsweise – in Stadtstaaten – der Senator) für Wissenschaft\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Unterschied zwischen einer Amygdala eines Mannes und einer Frau?, Predicted Answer: Eisenhower\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie unterscheiden sich die beiden Hirnhemisphären im Bezug auf Sprache und Raumvorstellung bei Männern und Frauen?, Predicted Answer: in der Größe und im Aufbau\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie kann man den Unterschied in den beiden Hirnhemisphären von Männern und Frauen erklären?, Predicted Answer: Die Gehirne von Männern und Frauen unterscheiden sich in der Größe und im Aufbau\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie können die Geschlechtschromosomen die Entwicklung beeinflussen?, Predicted Answer: auf zwei Arten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ließ 1702 San Agustin zerstören?, Predicted Answer: Colonel James Moore\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann nahmen Franzosen die spanische Siedlung in Pensacola im Westen Floridas ein?, Predicted Answer: 1719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde San Agustin angegriffen und ausgeräubert?, Predicted Answer: 1586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo liegt Guinea-Bissau?, Predicted Answer: Botschaften und Generalkonsulate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Land grenzt an Guinea-Bissau im Norden?, Predicted Answer: Senegal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Land grenzt an Guinea-Bissau im Osten?, Predicted Answer: Guinea\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie groß ist Guinea-Bissau?, Predicted Answer: 13° und 17°\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Hauptstadt von Guinea- Bissau?, Predicted Answer: Koordinaten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird die Northwestern University auch gennant?, Predicted Answer: Kellogg School of Management (kurz: Kellogg) berühmt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Bundesstaat ist die Northwestern University angesiedelt?, Predicted Answer: Illinois\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Stadt ist die Northwestern University?, Predicted Answer: Illinois\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt das U-Bahnsystem in Chicago?, Predicted Answer: Chicago El\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welchem See liegt die Northwestern University?, Predicted Answer: 15.000 Studenten eingeschrieben und sie beschäftigt fast 7.100 Angestellte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Stadt ist der zentrale Campus der Northwestern University?, Predicted Answer: Nezahualcóyotl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie groß ist der Hauptcampus der Northwestern University?, Predicted Answer: einfach Northwestern) ist eine Privatuniversität im Staat Illinois in den USA mit einem Doppelcampus in Evanston und Chicago. Der Hauptcampus in Evanston misst 970.000 m²\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann gibt es die Kellogg School of Management an der NU?, Predicted Answer: 1908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.92 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Studierende gibt es an der Northwestern University?, Predicted Answer: 15.000 Studenten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ist die Northwestern eine private oder staatliche Universität?, Predicted Answer: Private Hochschule\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.11 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt die studentische Zeitung an der Northwestern University?, Predicted Answer: ''The Daily Northwestern\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die Association of American Universities gegründet?, Predicted Answer: Gründungsmitglied\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Land gab es die meisten Toten im Pazifikkrieg?, Predicted Answer: China\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Soldaten in China starben im Pazifikkrieg?, Predicted Answer: 4.000.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele japanische Soldaten fielen im Pazifikkrieg?, Predicted Answer: 20.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was versteht man unter der Lesbarkeit in der Architektur?, Predicted Answer: Entwurf eines Bauwerks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.69 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Themen sind seit den zunehmenden Debatten um die globale Erwarmung in der Architektur wichtig geworden?, Predicted Answer: gieverbrauchs von Gebäuden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was versteht man unter dem Begriff \"Solararchitektur\"?, Predicted Answer: Konzepte zusammengefasst\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was macht der Rettungsdienst als erstes, wenn ein Patient den Herzinfarkt hat?, Predicted Answer: nicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wozu dient eine medikamentöse Therapie beim Herzinfarkt in der Akutphase?, Predicted Answer: Eisenhower\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Medikamente werden beim Herzinfarkt eingesetzt?, Predicted Answer: Gruppensammelsteuerungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum wird die Therapie mit Sauerstoff beim Herzinfarkt nicht mehr durchgeführt?, Predicted Answer: hochentzündlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.82 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Medikamente können beim Herzinfarkt manchmal erforderlich sein?, Predicted Answer: keine Form von Wissen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurde Gaddafi getötet?, Predicted Answer: nachgesagt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Organisation hat geholfen Gaddafi 2011 zu finden, als er geflohen ist?, Predicted Answer: NATO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo wurde die Leihe von Gaddafi bestattet?, Predicted Answer: Abdel-Nasser-Moschee\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist die Literatur in Tibet sehr religiös geprägt geworden?, Predicted Answer: zutiefst religiös geprägte Literatur\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hat sich die Literatur in Tibet mit der Annexion des Landes durch China verändert? , Predicted Answer: Erst mit der Annexion Tibets durch die Volksrepublik China wurde die seit über 800 Jahren statisch festgeschriebene Tradition aufgebrochen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.14 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird unter der tibetischen Literatur verstanden?, Predicted Answer: Stichwort „tibetische Literatur“ meist der große Schatz religiöser Texte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hat das Famicon entworfen?, Predicted Answer: Gaddafi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Land hat man das Famicon verkauft?, Predicted Answer: Japan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hieß die erste Nintendo-Konsole?, Predicted Answer: R.O.B. beispielsweise Klötzchen hoch und öffnet damit im Spiel gleichzeitig eine versperrte Tür. Er wurde auf der Summer Consumer Electronics Show 1985 in Chicago vorgestellt und ließ die Verkaufszahlen des NES in den USA in die Höhe steigen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Zubehör hatte die erste Nintendo?, Predicted Answer: Nintendo Advanced Video System\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchen Paketen konnte man das Nintendo Entertainment System 1985 kaufen?, Predicted Answer: zwei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann reagiert das Immunsystem übermäßig auf bestimmte körperfremde Strukturen?, Predicted Answer: Jeder erneute Kontakt mit dem Allergen kann dann zu einer übermäßig starken Reaktion des Immunsystems führen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Grund von Autoimmunerkrankungen?, Predicted Answer: Zöliakie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die Beispiele für Autoimmunerkrankungen?, Predicted Answer: die Zöliakie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist ein Erfordernis für die Entstehung einer Allergie?, Predicted Answer: ein harmlos verlaufender Erstkontakt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.10 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Allergien treten am häufigsten auf?, Predicted Answer: Prostomium\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bei welchen Softwaretests wird die Automatisierung empfohlen?, Predicted Answer: eingeschleppte Krankheiten, Strafexpeditionen, Umsiedlungen und Zwangsarbeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wozu dienen Regressionstests beim Testen von Software?, Predicted Answer: November 2007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Wert ist extrem wichtig bei der Papierherstellung?, Predicted Answer: Zugfestigkeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.96 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wovon hängt die Zugfestigkeit von Papier ab?, Predicted Answer: vorwiegend von der flächenbezogenen Masse\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird die Zugfestigkeit von Papier gemessen?, Predicted Answer: In Japan und China\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bestimmt der spezifische Weiterreißwiderstand von Papier?, Predicted Answer: eine Zerreißprobe gemacht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird der spezifische Weiterreißwiderstand von Papier gemessen?, Predicted Answer: In Japan und China\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was macht der Berstwiderstand beim Papier?, Predicted Answer: den benötigten Druck\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird der Berstwiderstand beim Papier gemessen?, Predicted Answer: Der Druck\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist unter dem Spaltwiderstand beim Papier gemeint?, Predicted Answer: die Masse von 500 Bogen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie werden intensive Grüntöne bezeichnet?, Predicted Answer: Giftgrün\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Prozent der Bevölkerung sprechen Deutsch als Muttersprache?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die gesprochene Umgangssprache in Bern?, Predicted Answer: Berndeutsch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist eine der Besonderheiten des Berndeutsches?, Predicted Answer: die Übernahme einiger Wörter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wodurch zeichnen sich Chloroplasten und Mitochondrien aus?, Predicted Answer: eine Doppelmembran\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.82 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo liegt San Diego?, Predicted Answer: an einem künstlichen Hafenbecken an der Südspitze Kaliforniens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was grenzt an Westen von San Diego?, Predicted Answer: die Stadt vom Pazifischen Ozean begrenzt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was grenzt an Osten von San Diego?, Predicted Answer: bilden Berge sowie der Anza-Borrego-Wüstenpark eine natürliche Grenze\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In wie viele Teile wird San Diego geteilt?, Predicted Answer: zwei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der höchste Punkt San Diegos?, Predicted Answer: Cowles Mountain\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.92 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Fluss gibt es in San Diego?, Predicted Answer: an einem künstlichen Hafenbecken\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Hauptwerk von Charles Darwin?, Predicted Answer: ''Kritik der reinen Vernunft\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde \"Über die Entstehung der Arten\" veröffentlicht?, Predicted Answer: am 24. November 1859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was hat Charles Darwin in seinem Hauptwerk bewiesen?, Predicted Answer: zahlreiche Belege\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.60 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo hat Charles Darwin Belege für seine Theorie gesammelt?, Predicted Answer: zahlreiche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war die ursprüngliche Religion der Slawen?, Predicted Answer: derjenigen anderer früher indogermanischer Völker ähnlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.61 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welchem Namen haben die Slawen den Gott genannt?, Predicted Answer: gemeinsamen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche mythische Wesen wurden von den Slawen verehrt?, Predicted Answer: niederen Grades\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was brachten die Slawen den Göttern zum Opfer?, Predicted Answer: Gebet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was passiert mit der Seele nach dem Tod laut Slawen?, Predicted Answer: das Leben nicht auf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.11 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hat Tristan da Cunha in seinem Roman im Jahr 1838 ausführlich beschrieben?, Predicted Answer: Schwarzenegger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hat einen Roman über Tristan da Cunha geschrieben, der denselben Namen wie diese Inselgruppe trägt?, Predicted Answer: Primo Levi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.95 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Werk hat Jule Verne Tristan da Cunha dargestellt?, Predicted Answer: „Reflections on the Revolution in France“\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat der Österreichische Erbfolgekrieg stattgefunden?, Predicted Answer: Frieden von Aachen den Österreichischen Erbfolgekrieg (1740–1748) beendet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.93 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was beendete den Österreichischen Erbfolgekrieg?, Predicted Answer: der Frieden von Aachen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was hat Österreich versucht, um Schlesien zurückzugewinnen?, Predicted Answer: einen entscheidenden Schlag\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr verschlechterte sich der britisch- französische Konflikt in Nordamerika?, Predicted Answer: 1754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.69 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wollte das Bündnis von Frankreich und Preußen  Mitte des 18.Jahrhundert vermeiden? , Predicted Answer: Krieg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Worum ging es im Vertrag von Sankt Petersburg zwischen Großbritannien und Russland?, Predicted Answer: Napoleon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat Großbritannien die Westminister-Konvention mit Preußen geschlossen?, Predicted Answer: die gesamte deutsche Heereskraft vertragsgemäß unter der Führung des Königs von Preußen zusammengefasst\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was hat die Westminister-Konvention von 1756 garantiert?, Predicted Answer: geschlossenen sogenannten Westminister-Konvention vereinbarten beide Mächte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welchem Tag hat Großbritannien Frankreich 1756 den Krieg erklärt?, Predicted Answer: 17. Mai\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum glühen erhitzte Körper zunächst rot?, Predicted Answer: ein Körper beim Erhitzen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.27 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Sinneszellen im menschlichen Auge sind für das Rotsehen verantwortlich?, Predicted Answer: L-Zapfen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.10 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welcher Geschwindigkeit kann man Daten mithilfe eines USB-Sticks übertragen?, Predicted Answer: jeweiligen USB-Geschwindigkeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher im 14.Jahrhundert angelegte künstliche See in Jaisalmer wurde von der Bevölkerung gepflegt? , Predicted Answer: Namen Gadisar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war die Quelle des Trinkwassers in Jaisalmer?, Predicted Answer: eine blühende Handelsstadt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie nennt man religiöse Stiftungen in Iran?, Predicted Answer: isoliert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum werden religiöse Stiftungen in Iran kritisiert?, Predicted Answer: wechselvollen Geschichte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchen Bereichen der Wirtschaft haben religiöse Stiftungen in Iran herrschende Stellung?, Predicted Answer: Islam, Antiimperialismus und Führerschaft der Dritten Welt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die zwei größten religiösen Stiftungen in Iran?, Predicted Answer: Bonyāds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ist der Achtfache Pfad im Buddhismus geteilt?, Predicted Answer: dreigeteilt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Kern der Lehre des Buddha?, Predicted Answer: Vier Edlen Wahrheiten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Wirkung können manche für die Munitionsproduktion eingesetzte Metalle haben?, Predicted Answer: ökotoxische\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie kann das Geschossmaterial der Natur schaden? , Predicted Answer: die K-Schale nur 2 Elektronen aufnehmen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum wird die Verwendung von Blei in der Munition kritisiert?, Predicted Answer: aus Gründen des Umweltschutzes (siehe Bleibelastung der Umwelt) und gesundheitlichen Gründen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo finden Vakuumkondensatoren ihre Anwendung?, Predicted Answer: Die Verringerung von Wärmeströmung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann werden Vakuumkondensatoren eingesetzt?, Predicted Answer: vorzugsweise bei Sendern hoher Leistung eingesetzt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.60 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum werden Glimmerkondensatoren für hohe Anforderungen eingesetzt?, Predicted Answer: Zum Schutz von Personen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum werden Schutzringkondensatoren gebaut?, Predicted Answer: 1927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.95 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Schichten haben mehrlagige Leiterplatten?, Predicted Answer: 48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist ein Kurzschluss?, Predicted Answer: eine Verbindung zwischen zwei Punkten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie entsteht ein Kurzschluss?, Predicted Answer: Weidekonkurrenz und Überweidung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie funktionieren Kurzschlusstests?, Predicted Answer: Das gute Funktionieren eines Gebäudes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was bezeichnen die Demokraten bei Wahlen die im Ausland lebenden Wähler?, Predicted Answer: deutschstämmig\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele US-Amerikaner leben im Ausland?, Predicted Answer: wenige Migranten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war das Grundprinzip von Alfred North Whiteheads Schaffen?, Predicted Answer: Trail of Tears\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt das erste Werk von Whitehead im Bereich Naturphilosophie?, Predicted Answer: Principia Mathematica\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo ist die Yale University?, Predicted Answer: New Haven\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche ist die drittälteste Uni der USA?, Predicted Answer: Ivy League\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.94 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wessen Namen trägt die Yale University?, Predicted Answer: Bibliothekssystem\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Universität verfügt weltweit über das meiste Kapital?, Predicted Answer: Valencia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Ivy League?, Predicted Answer: Mitglied\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann gibt es die Association of American Universities?, Predicted Answer: 1900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches sind die drei wichtigsten Universitäten der USA?, Predicted Answer: Ivy-League\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele bücher hab es 2009 in den Bibliotheken von Yale?, Predicted Answer: 12,5 Millionen Bücher\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele US-Präsidenten haben in Yale studiert?, Predicted Answer: fünf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist armenische Kunst?, Predicted Answer: bildende\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sind Daten auf Laserdiscs gespeichert?, Predicted Answer: Interviews, Audiokommentare, entfallene Szenen und oft auch kleine Zeitschriften oder andere Gimmicks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Kann man eine Laserdisc als CD benutzen?, Predicted Answer: High-End-Usern\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bedeutet CAV bei Laserdiscs?, Predicted Answer: Constant Angular Velocity\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Form der Erkenntnis steht dem Empirismus gegenüber?, Predicted Answer: Common-Sense-Philosophie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso lehnt Leibniz empirisches WIssen ab?, Predicted Answer: Daniel Bernoulli\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird nach Descartes Erkenntnis generiert?, Predicted Answer: Intuition und Deduktion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.82 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ist das VErhältnis von Zonenzeit und Sonnenzeit?, Predicted Answer: Ronald Reagan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.92 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die MEZ?, Predicted Answer: normalen gesetzlichen Zeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Sommerzeit?, Predicted Answer: gleich der Zonenzeit der östlich benachbarten Zeitzone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.94 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was waren die Gründe für die Einführung der Sommerzeit?, Predicted Answer: etwa der Erste und der Zweite Weltkrieg sowie die Ölpreiskrise in den 1970er Jahren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso galt in der Tschechoslowakei 1946 eine Winterzeit?, Predicted Answer: In analoger Weise\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Standardzeit?, Predicted Answer: stark durch die britische Kultur geprägt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Sonnenzeit?, Predicted Answer: mittleren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurden die globalen Zeitzonen festgelegt?, Predicted Answer: Weiterhin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo wurde ein weltweites Zeitsystem festgelegt?, Predicted Answer: EZB-Rat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Zonenzeit?, Predicted Answer: einheitlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie groß ist der Zeitunterschied zwischen den Zonenzeiten?, Predicted Answer: insgesamt gering\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war die erste Funktion von Hunden für den Menschen?, Predicted Answer: Domestikation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.21 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: von wem stammen Hunde ab?, Predicted Answer: Abfallfresser\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Eigenschaft benötigen Hunde für die Treibjagd?, Predicted Answer: beispielsweise\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wozu wurden Dackel gezüchtet?, Predicted Answer: vorwiegend Pelztiere\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was trug bei der Kolonialisierung Amerikas durch die Europäer neben Krieg auch zur Ausschlöschung der indigenen Bevölkerung bei?, Predicted Answer: Die Gehirne von Männern und Frauen unterscheiden sich in der Größe und im Aufbau\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie groß schätze Alfred Kroeber die Bevölkerung  in Mittelamerika im Jahr 1492?, Predicted Answer: 1940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird heute in Bezug auf die Kolonisierung Amerikas als Mythos bezeichnet?, Predicted Answer: offen angezeigt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf wie viele Einwohner wird Mittelamerika zur Zeit der Kolonisierung durch die Europäer geschätzt?, Predicted Answer: ausweises\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer vernichtete die Azteken?, Predicted Answer: Hernán Cortés\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Soldaten hatte Hernan Cortes?, Predicted Answer: 500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Hochkultur in Amerika hat Pizarro vernichtet?, Predicted Answer: Inkas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Vertrag von Tordesillas?, Predicted Answer: Aufteilung der Welt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurden die Kinder indianischer Frauen mit europäsichen Kolonisatoren bezeichnet?, Predicted Answer: Paris und Berlin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Krankheiten grassierten in Nordamerika nach der Ankunft der Europäer?, Predicted Answer: Pocken, Masern und Grippe katastrophale Schäden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.69 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen sind in Amerika in der Kolonialzeit Schätzungen zufolgen an den Pocken gestorben?, Predicted Answer: zahlreiche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso waren die Krankheiten der Europäer für die indigene Bevölkerung in Amerika besonders schwerwiegend?, Predicted Answer: unabsehbar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.17 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sollen die Europäer absichtlich Pocken unter der indigenen Bevölkerung Amerikas verbreitet haben?, Predicted Answer: Opfer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann war die Schlacht von Mauvilla?, Predicted Answer: 1540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.21 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Seminolenkriege gab es?, Predicted Answer: drei Seminolenkriege (1817–1818, 1835–1842 und 1855–1858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann waren die Biberkriege?, Predicted Answer: noch rar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer führte die Apachen bis 1886 bei den Aufständen gegen die europäischen Siedler an?, Predicted Answer: Geronimo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann war der Aufstand der Sioux?, Predicted Answer: 1862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Massaker gegen die indianische Bevölkerung wurde 1890 begangen?, Predicted Answer: Wounded Knee\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Zinkfingerprotein?, Predicted Answer: Trail of Tears\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie tritt Zink im Blutkreislauf auf?, Predicted Answer: überwiegend an Albumin gebunden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Enzyme benötigen Zink?, Predicted Answer: wichtiger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür benötigt der Körper Zink?, Predicted Answer: Wärme\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Stadt steht das Alley Theatre, Predicted Answer: Downtown Houston\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was heißt Sowjet?, Predicted Answer: Rat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Verwaltungsebenen gab es in der Russischen Sowjetrepublik?, Predicted Answer: die göttliche Erleuchtung des Menschen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Institution sollte das Parlament in der Russischen Sowjetrepublik ersetzten?, Predicted Answer: FC Barcelona\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.15 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer durfte laut der Räteordnung der Russischen Sozialistischen Föderativen Sowjetrepulik wählen?, Predicted Answer: Alaska\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Prinzip führte Montesquieu in \"Vom Geist der Gesetze\" ein?, Predicted Answer: Standardwerk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die empfohlene Tagesdosis für Zink?, Predicted Answer: lag 1996 laut Weltgesundheitsorganisation für erwachsene Männer bei 15 mg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die Folgen von zu viel Zink?, Predicted Answer: Zinkfingerproteinen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ab wie viel Gramm ist Zink giftig?, Predicted Answer: 25 mg Zink pro Tag\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist Zinkfieber?, Predicted Answer: sogenannte „Zinkfieber“\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Kann Zink Durchfall auslösen?, Predicted Answer: vermutet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Epiglottis?, Predicted Answer: Ein Kehldeckel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wozu dient der Kehldeckel?, Predicted Answer: verschließt beim Schlucken den Kehlkopf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was unterscheidet Säugetiere von andern TIeren?, Predicted Answer: unterschiedlich die Gestalt und Lebensweise\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Henle'sche Schleife?, Predicted Answer: 100 g schwerer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Steuerungsmechanismen gibt es bei Aufzügen?, Predicted Answer: eklatante Mängel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Bedienmöglichkeiten gibt es bei Aufzügen?, Predicted Answer: eklatante Mängel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo werden Gruppensammelsteuerungen von Aufzügen benutzt?, Predicted Answer: eingesetzt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer verwaltet die Unis in Deutschland?, Predicted Answer: äsident a. D. Köhler\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist Träger der Eidgenössischen Technischen Hochschule Zürich?, Predicted Answer: Kantone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wem unterstehen die Universitäten in der Schweiz?, Predicted Answer: Kantone Träger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißen die Lehrer an der Uni?, Predicted Answer: energiereichen Beginn der Raumzeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was kann man laut Alexander Pashos aus Funden der Kleiderlaus schließen?, Predicted Answer: schätzen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Zeitpunkt wurden anhand von Genanalysen für das Auftreten von Kleidung festgestellt?, Predicted Answer: geschichtliche Zeitpunkt, seit dem Menschen regelmäßig Kleidung trugen, aus dem Auftreten der Kleiderlaus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Fundstelle Neumark-Nord?, Predicted Answer: ca. 200.000 Jahre alten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Besondere an der Fundstelle Neumark-Nord?, Predicted Answer: Mittelpaläolithikum\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Eigenschaft des Menschen wurde durch den Übergang von Fell zu Haut begünstigt?, Predicted Answer: eine Eigenwelt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Material wurde zuerst für Kleidung benutzt?, Predicted Answer: Nachteil\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Bedeutung hat die Entwicklung von Nähkunst in Bezug auf Kleidung?, Predicted Answer: groß\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurden erstmals Schafe als Haustiere gehalten?, Predicted Answer: heilig gehalten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Arten von frühen Verschlussmechanismen für Kleidung gab es?, Predicted Answer: weniger lang als größere Arten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Vor wie vielen Jahren wurden erstmals Pflanzen zur Herstellung von Kleidung benutzt?, Predicted Answer: 75.000 Jahren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer prägte den Begriff Wirkungsquantum?, Predicted Answer: Benjamin Franklin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird in der Physik als Wirkung bezeichnet?, Predicted Answer: überwiegend ohne eine genauere Definition einfach vorausgesetzt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr präsentierte Niels Bohr sein Atommodell erstmals?, Predicted Answer: 1913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer gilt als Begründer de Quantenmechanik?, Predicted Answer: Hamiltonoperator\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welchem Modell wurde Bohrs Atommodell 1917 erweitert?, Predicted Answer: nachdem es 1917 zum Bohr-Sommerfeldschen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist Spin von teilchen?, Predicted Answer: Energie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt Straßburg im lokalen Dialekt?, Predicted Answer: ''Schdroosburi''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.27 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo liegt Straßburg?, Predicted Answer: Aufgrund dessen versteht sich Straßburg als ''Hauptstadt Europas''.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo hat der Europäische Gerichtshof für Menschenrechte seinen SItz?, Predicted Answer: New York\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches europäische Gericht hat seinen Sitz in Straßburg?, Predicted Answer: UNO-Sitz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welhce Teile von Straßburg sind UNESCO-Weltkulturerbe?, Predicted Answer: Innenstadt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die Utrechter Union geschlossen?, Predicted Answer: 1579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Provinzen gehörten zur Republik der Vereinigten Niederlanden?, Predicted Answer: Holland, Zeeland und Utrecht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchen Bereichen wurde in der Republik der Vereinigten Niederlande auf Bundesebene entschieden?, Predicted Answer: Landesverteidigung oder die Außenpolitik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: War die Republik der Vereinigten Niederlande ein Zentralstaat?, Predicted Answer: Die Republik war kein Zentralstaat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso nahm Holland in den Vereinigten Provinzen eine Vormachtsstellung ein?, Predicted Answer: imperative\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Provinz der Republik Vereinigten Niederlanden hatte den meisten Einfluss?, Predicted Answer: Qiantang-Fluss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus welcher Adelsfamilie stammte der Statthalter der Republik der Vereinigten Provinzen?, Predicted Answer: Haus Oranien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Konflikt im Inland prägte die Republik der Vereinigten Provinzen?, Predicted Answer: Zypernkonflikts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ab wann war das Amt des Statthalters der Republik der Vereinigten Provinzen erblich?, Predicted Answer: offiziell\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo wurde Chopin geboren?, Predicted Answer: Żelazowa Wola\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Chopin getauft?, Predicted Answer: vermeiden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist Chopins Taufname?, Predicted Answer: grau-blaue Augen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Chopin geboren?, Predicted Answer: in Żelazowa Wola\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was gilt als Grund dafür, dass für Chopin zwei unterschiedliche Geburtstage bekannt sind?, Predicted Answer: Die Bronx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann war Kanye West Yeezus-Tour?, Predicted Answer: 2013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.13 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit wem hat Kanye West für sein Album Yeezus kooperiert?, Predicted Answer: Handschellen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welches Lied ließ Kanye West öffentlich Videos an Wände projizieren?, Predicted Answer: New Slaves\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was heißt Yeezus?, Predicted Answer: Kanye West\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Platzierung nahm West Album Yeezus auf den Billboard 200 ein?, Predicted Answer: ''4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt Kanye West 7. Album?, Predicted Answer: ''The Life of Pablo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann erschien \"The Life of Pablo\"?, Predicted Answer: am 14. Februar 2016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit was stellte The Life of Pablo einen Rekord auf?, Predicted Answer: 500.000 illegalen Downloads\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wodurch fand Kanye West Song Famous in den Medien große Beachtung?, Predicted Answer: Musikvideo für Aufsehen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welcher Tour war Kanye West Ende 2016 unterwegs?, Predicted Answer: Saint Pablo Tour\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.16 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso kam Kanye West nach dem Tourabbruch 2016 ins Krankenhaus? , Predicted Answer: gebracht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was hat Kanye West Psychose ausgelöst?, Predicted Answer: Promotionsphase\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo liegt Palermo?, Predicted Answer: im Schatten Neapels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hoch ist der Monte Pellegrino?, Predicted Answer: 600 Meter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was heißt Conca d'Oro?, Predicted Answer: Palermo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso wird die Gegend um Palermo Goldenes Becken genannt?, Predicted Answer: d’Oro\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen leben in der Metropolregion Palermo?, Predicted Answer: zahlreiche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wie viele Bezirke gibt es in Palermo?, Predicted Answer: acht Stadtbezirke (''circoscrizioni'') eingeteilt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt die Sammlung von Hirtengedichten von Vergil?, Predicted Answer: weitergegeben werden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie werden die Eklogen von Vergil auch genannt?, Predicted Answer: ''Stärke''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat Vergil die Eklogen geschrieben?, Predicted Answer: kein Ideologe gewesen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches politische Ereignis wird in der ersten Ekloge von Vergil aufgegriffen?, Predicted Answer: historischer Hintergrund\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso ist die Deutsche Bahn von der EEG-Umlage ausgenommen?, Predicted Answer: überwiegend befreit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie groß ist die EEG-Umlage, die die Deutsche Bahn bezahlt?, Predicted Answer: überwiegend befreit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wozu werden in Datenbanken auch die Zugriffe der Benutzer gespeichert?, Predicted Answer: Franzosen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch was werden die Bestandsdaten in Datenbanken gesichert?, Predicted Answer: UN-Friedenstruppen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso schränkt ein Backup die Arbeit mit einer Datenbank ein?, Predicted Answer: Eran Elhaik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Informationen werden in Datenbanken neben den eigentlichen Einträgen auch gespeichert?, Predicted Answer: ebenfalls Informationen über die Datenschemata und Zugriffsrechte von Benutzern\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo lag das Königreich Vijayanagar?, Predicted Answer: hinduistische\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was heißt Vijayanagar?, Predicted Answer: eine beachtliche Machtstellung in Südindien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bis wann bestand das Königreich Vijayanagar in Indien?, Predicted Answer: 1565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Nach wem war das Königreich Vijayanagar benannt?, Predicted Answer: einer gleichnamigen Stadt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war für den Untergang von Vijayanagar verantwortlich?, Predicted Answer: hinduistische Indien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer gründete das Vijayanagar-Königreich?, Predicted Answer: Der Süden Indiens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde der ägyptische König Faruk abgesetzt?, Predicted Answer: noch stärker von Johann\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist der nationalfeiertag in Ägypten?, Predicted Answer: 23. Juli 1952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer setzte den ägyptischen König 1952 ab?, Predicted Answer: die Bewegung der „Freien Offiziere\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer prägte die Republik Ägypten in ihrer Entstehungszeit?, Predicted Answer: General Muhammad Nagib\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer führte die Revolution in Ägypten an?, Predicted Answer: Muhammad Ali\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Sueskrise?, Predicted Answer: durch Intervention der UN beigelegt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann dürfen Frauen in Ägypten wählen?, Predicted Answer: unterhaltenen Salons\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Unterschied im Wahlrecht bestand in Ägypten zwischen Männern und Frauen bis 1979?, Predicted Answer: Männer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Vereinigung, die bis 1961 bestand, gehörte Ägypten an?, Predicted Answer: Vereinigten Arabischen Republik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann war der Sechstagekrieg?, Predicted Answer: 1967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welchem Krieg war Ägypten 1973 beteiligt?, Predicted Answer: Jom-Kippur-Krieg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.94 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann schlossen Ägypten und Israel einen Friedensvertrag?, Predicted Answer: 1979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was kennzeichnet die boreale Zone in den USA?, Predicted Answer: Deutschland\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bildet sich auf sandigen Böden in Fichtenwäldern?, Predicted Answer: Podsole\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus welchen Böden entsteht Braunerde?, Predicted Answer: silikatreichem und kalkarmen Substraten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf welchem Boden bildet sich Parabraunerde?, Predicted Answer: Aufzugsschachts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bei welchen pH-Werten findet Lessivierung statt?, Predicted Answer: 5–\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Bodentypen sind in den USA in subtropischen Wäldern zu finden?, Predicted Answer: Podsole und Braunpodsole\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Bodentyp ist in Florida verbreitet?, Predicted Answer: Juan Ponce de León\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Bodentyp ist im Mississippi-Delta zu finden?, Predicted Answer: proteins\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Religion gehören in der Republik Kongo die meisten Menschen an?, Predicted Answer: Christentum\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen in der Republik Kongo sind katholisch?, Predicted Answer: 70 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Prozent der Menschen in der Republik Kongo gehören keiner Religion an?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Religion ist in der Republik Kongo mit einem Anteil von unter 2 Prozent vertreten?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.27 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welchen Gott erinnerte Diokletian mit seinem selbstgewählten Namen?, Predicted Answer: höchsten Gott, den Urheber des Himmels und der Erde, des Lichts und des Gewitters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lautete der Name, den Diokletian für sich selbst wählte?, Predicted Answer: Iovius\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche religiösen Traditionen wurden unter Diokletian gefördert?, Predicted Answer: noch einmal stark\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso waren die frühen Christen im Römischen Reich Verfolgung ausgesetzt?, Predicted Answer: Gaius Marius\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher römische Kaiser erließ das Toleranzedikt?, Predicted Answer: Sesshō\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Vorteil bot sich durch die Annahme des Christentums für die römischen Kaiser?, Predicted Answer: Papst Leo der Große\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ab wann war im Römischen Reich die freie Ausübung aller Religionen erlaubt?, Predicted Answer: kaum Bestrebungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die christliche Religion zur Staatsreligion im Römischen Reich?, Predicted Answer: zerstört\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.69 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Zeit gilt als Hochzeit der Auseinandersetzungen zwischen Christentum und traditionellen Götterkulten im Römischen Reich?, Predicted Answer: Der Hellenismus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Um den Altar welcher Göttin kam es im 4. Jhd im römischen Senat zum Streit?, Predicted Answer: Victoria-Altar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.69 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Papst ließ um 600 n.Chr. Sardinien missionieren?, Predicted Answer: Kaiser Justinian\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher römische Kaiser befahl, dass alle Kinder getauft werden sollen?, Predicted Answer: Kaiser Justinian\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Wissenschaftler wird in Hannover im Georgengarten mit einem  Denkmal geehrt?, Predicted Answer: Gottfried Wilhelm Leibniz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Besondere an dem Leibniz-Denkmal in Hannover?, Predicted Answer: verbreitet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die Waterloosäule in Hannover erbaut?, Predicted Answer: Sie wurde in den Jahren 1825 bis 1832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welcher Stilrichtung gehört der Reese-Brunnen in Hannover?, Predicted Answer: Kubismus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo in Hannover stehen die Skulpturen von Niki de Saint Phalle?, Predicted Answer: Leibnizufer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Haltestelle in Hannover wurde von Frank Gehry entworfen?, Predicted Answer: Bus- und Stadtbahnhaltestellen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An was erinnern die Göttinger Sieben in Hannover?, Predicted Answer: Protest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welcher japanischen Stadt hat Hannover eine Städtepartnerschaft?, Predicted Answer: Jianye () verlegte, eine Stadt am Fuße von Jinling Yi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo leben die Lugbara?, Predicted Answer: US-Bürgern\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bedeutet transzendent bei Göttern?, Predicted Answer: Gott\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was schrieb Ramanuja über das Verhältnis der Menschen zu Gott?, Predicted Answer: einerseits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo lebt die immanente Gottheit der Lugbara auf der Erde?, Predicted Answer: Jesus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso lehnt Leibniz empirische Erkenntnisse ab?, Predicted Answer: Daniel Bernoulli\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist für Leibniz Grundlage allgemeiner Erkenntnisse, die über den Einzelfall hinausgehen?, Predicted Answer: Begriffsverhältnissen Notwendigkeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche philosophische Richtung stellt alle allgemein gültigen Aussagen infrage?, Predicted Answer: lose\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Induktionsproblem in der Philosophie?, Predicted Answer: problematisiert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher philosophischer Richtung ist Ernst Mach zuzuordnen?, Predicted Answer: nicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was besagt der Radikale Konstruktivismus?, Predicted Answer: Theorieansatz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist ein Induktionsschluss?, Predicted Answer: maßgeblichen Einfluss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war nach sowjetischer Geschichtsschreibung das Ziel der Außenpolitik der Sowjetunion vor dem 2. Weltkrieg?, Predicted Answer: Stalin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit wem strebte Stalin laut Gerhard Weinberg vor dem 2. Weltkrieg ein Bündnis an?, Predicted Answer: Hitler\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war laut Hermann Graml Stalins Ziel während eines Krieges zwischen Deutschland und den Westmächten?, Predicted Answer: Stalin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Prinzip vertrat die Sowjetunion vor dem 2. Weltkrieg in der Außenpolitik?, Predicted Answer: Stalin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was wollte Stalin laut Sergej Slutsch die Verhandlungen mit den Westmächten nutzen?, Predicted Answer: Krieg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird die These bezeichnet, Stalin habe absichtlich einen Krieg zwischen Deutschland und den Westmächten provozieren wollen?, Predicted Answer: Möglichkeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso wollte Stalin laut Tucker und Raack, dass es zum Krieg kam?, Predicted Answer: Hitler\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde der Nichtangriffspakt zwischen Deutschland und Polen geschlossen?, Predicted Answer: Stalin habe gehofft, einen Krieg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was beschreibt Pietrow-Ennker Stalins außenpolitisches Handeln vor dem 2. Weltkrieg?, Predicted Answer: erster grundlegend\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch was sah Stalin laut Historikern die Sowjetunion vor dem 2. Weltkrieg  umgeben?, Predicted Answer: geteilter Meinung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen außenpolitischen Leitsatz folgte Stalin, den er 1925 formuliert hatte?, Predicted Answer: Maxime\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war laut Teddy Uldricks Stalins außenpolitisches Ziel vor dem 2. WK?, Predicted Answer: rational und zweckorientiert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:02<00:00,  1.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war laut MIcheal Carley der ideologische Antrieb der Politik von England und Frankreich vor dem 2. Weltkrieg?, Predicted Answer: eine scharfe Kritik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch was kann Zeit in der Musik erfahrbar gemacht werden?, Predicted Answer: Volksmusik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Beziehung steht Zeit zur Musik?, Predicted Answer: Beispiel Tempus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was wird Musik in Hinblick auf ihr Fortbestehen oft bezeichnet?, Predicted Answer: klassisch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann entstand der A-cappella-Stil?, Predicted Answer: Zunächst verstand man darunter mehrstimmige Vokalmusik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die ursprüngliche Bedeutung von „a cappella“ ?, Predicted Answer: die Weltchronik des Eusebius\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hieß das Gebäude, das vor dem Buckingham Palace an dessen Standort stand?, Predicted Answer: Goring House\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde das Goring House gebaut?, Predicted Answer: 1927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ließ das Goring House erbauen?, Predicted Answer: John Sheffield\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde das erste Gebäude des Buckingham Palace errichtet?, Predicted Answer: 1633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer entwarf das erste Gebäude des Buckingham Palace?, Predicted Answer: Victoria\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Herrscher veranlasste den Neubau am Standort des Goring House?, Predicted Answer: Jai Singh II\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.82 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Form hatte das ursprüngliche Buckingham House?, Predicted Answer: Wissen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher König erwarb den Buckingham Palace 1761?, Predicted Answer: Georg III.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.12 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann kaufte König Georg III. die Residenz von Buckingham?, Predicted Answer: wirklich nicht ausdrücken\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war das BIP von Montana 2016?, Predicted Answer: USD 44.118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Bodenschätze gibt es in Montana?, Predicted Answer: reich an Bodenschätzen und anderen natürlichen Ressourcen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.82 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die Kupferproduktion in Anaconda geschlossen?, Predicted Answer: 1983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo in Montana wird vor allem Viehwirtschaft betrieben?, Predicted Answer: Baseball\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Prozent der Einwohner von Liberia waren 2017 nicht in dem Land geboren?, Predicted Answer: Ellen Johnson-Sirleaf nicht mehr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Land grenzt im Norden an Liberia?, Predicted Answer: Freeport Monrovia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo in Liberia lebt die Landbevölkerung vor allem?, Predicted Answer: Guinea\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Epoche ist das Konzept Adoleszenz zuzuordnen?, Predicted Answer: Niedergangs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Nach was benannte Spielberg seine Produktionsfirma Anfang der 1980er?, Predicted Answer: Powell und Weinberger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit wem gründete Spielberg Dreamworks?, Predicted Answer: Niederlage\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde DreamWorks verkauft?, Predicted Answer: 2005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso verkaufte Spielberg DreamWorks?, Predicted Answer: 2005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Studio kaufte DreamWorks?, Predicted Answer: 2005 wegen finanzieller Probleme an Paramount Pictures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt Spielbergs eigene Produktionsstudio?, Predicted Answer: weitergegeben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Amblin Partners gegründet?, Predicted Answer: Am 16. Dezember 2015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welcher Firma gehörte Jeff Skoll, als er mit Spielberg Amblin Partners gründete?, Predicted Answer: Participant Media\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hat das Logo von Windows 8 entworfen?, Predicted Answer: geometrische Form\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Schriftart ist das Windows 8-Logo gestaltet?, Predicted Answer: Bedienoberfläche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann ist in Illinois die Todesstrafe ausgesetzt?, Predicted Answer: Wiedereinführung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Die Todesstrafen von wie vielen Menschen wurden von Gouverneur George Ryan 2003 zu lebenslanger Haft umgewandelt?, Predicted Answer: 167 Todeskandidaten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Strafe erhielten 167 Menschen in Illinois 2003 anstatt der Todesstrafe?, Predicted Answer: wandelte daraufhin im Jahre 2003 die Strafe aller 167 Todeskandidaten in Illinois in lebenslange Haft\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Zeitung schrieb im Vorfeld des Moratoriums der Todesstrafe in Illinois über Probleme in der Justiz?, Predicted Answer: Wiedereinführung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.95 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Probleme des Justizsystems in Illinois wurde in einem Artikel des Chicago Tribune vor dem Todesstrafenmoratorium bemängelt?, Predicted Answer: 8. Juni 1977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Verurteilte wurde nach Recherchen von Studierenden in Illinois 1999 aus dem Todestrakt entlassen?, Predicted Answer: Anthony Porter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die Todesstrafe in Illinois offiziell abgeschafft?, Predicted Answer: ein Gesetz zur endgültigen Abschaffung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Bundesstaaten der USA hatten 2011 mit Illinois die Todesstrafe abgeschafft?, Predicted Answer: 2011 schaffte Illinois als 16. Staat die Todesstrafe ab. Anfang des Jahres 2011 verabschiedeten Repräsentantenhaus und Senat des Bundesstaates ein Gesetz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann begann die Heian-Epoche?, Predicted Answer: 794–1185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo war der Sitz des japanischen Kaisers in der Heian-Zeit?, Predicted Answer: Antoku\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch welches Ereignis wird der Beginn der Heian-Zeit markiert?, Predicted Answer: den Energieinhalt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Bedeutung hat die Heian-Zeit für die japanische Kultur?, Predicted Answer: Am Hof von Heian\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind berühmte Werke der japanischen Hofdamenliteratur aus der Heian-Zeit?, Predicted Answer: gepflegt wurde\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche japanische Schrift hat ihren Ursprung in der Heian-Zeit?, Predicted Answer: Aramäische\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso schufen Frauen in der Heian-Zeit eine neue Schrift?, Predicted Answer: Avestaschrift\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Familie erlangte in der Heian-Zeit in Japan große Macht?, Predicted Answer: Minamoto\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wodurch konnte die Familie Fujiwara in Japan in der Heian-Zeit besonders ihre Macht vergrößern?, Predicted Answer: anknüpfen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist ein Sessho im japanischen Kaiserreich?, Predicted Answer: Kaiser\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Amt wurde in Japan 1086 für ehemalige Monarchen eingeführt?, Predicted Answer: Amt des Exkaisers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wurde in Japan in der Heian-Zeit als Zahlungsmittel verwendet?, Predicted Answer: Reis\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.60 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Klans kämpften in Gempei-Krieg?, Predicted Answer: Machthunger und Expansionsgelüsten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Klan verlor den Gempei-Krieg?, Predicted Answer: Fürst Menschikow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Gebiet wollte Österreich an Frankreich übergeben für die Unterstützung im Siebenjährigen Krieg?, Predicted Answer: Frankreich würde nun Preußen in einem Krieg gegen Österreich nicht mehr beistehen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches war das umkämpfte Gebiet zwischen Preußen und Österreich im Siebenjährigen Krieg?, Predicted Answer: Friedrich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche strategische Bedeutung hatte die Okkupation  Sachsens für Preußen?, Predicted Answer: Schlüsselrolle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was wurde ein Single im Canadian Football früher bezeichnet?, Predicted Answer: Gridiron Football\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist ein Single im Canadian Football?, Predicted Answer: Ballsportart\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist im Football ein Touchdown?, Predicted Answer: PAT), gibt es einen Punkt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Punkte gibt ein Touchdown im Football?, Predicted Answer: drei Versuche (''Downs'') pro Angriffsspielzug statt vier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Punkte zählte ein Touchdown im Canadian Football vor 1904?, Predicted Answer: vier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt der Wurf, den ein Team beim Canadian Football nach erfolgreichem Touchdown erhält?, Predicted Answer: 1905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von wo wird bei erfolgreichem Touchdown beim Canadian football geworfen?, Predicted Answer: der Ball über die gegnerische Goalline getragen oder dahinter gefangen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt der Punkt nach dem Touchdown beim Canadian Football?, Predicted Answer: weitergegeben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde im Canadian Football eine feste Punktezählung eingeführt?, Predicted Answer: 1878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Liga spielt Racing Straßburg?, Predicted Answer: Ligue 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt der Frauenfußballverein von Straßburg?, Predicted Answer: ASPTT Strasbourg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat der Basketballverein aus Straßburg die Meisterschaft gewonnen?, Predicted Answer: 2004/05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf wann wurde die Ausgabe des neuen 100-Dollar-Scheins verschoben, der 2011 in Umlauf gebracht werden sollte?, Predicted Answer: Im Februar 2011 sollte eine mit zusätzlichen Sicherheitsmerkmalen ausgestattete Variante des 100-Dollar-Scheins in Umlauf gebracht werden, um der hohen Fälschungsrate entgegenzuwirken\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann werden US-Dollarnoten mit Sicherheitsaufdrucken versehen?, Predicted Answer: eingeatmet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Turnus werden US-Dollarnoten neu gestaltet, um die Fälschungssicherheit zu erhöhen?, Predicted Answer: Japan, Korea, Europa sowie auf Guam und Samoa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso ist der Sicherheitsfaden bei Banknoten fälschungssicher?, Predicted Answer: ein dünner Streifen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.22 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche US-Dollarscheine enthalten einen Sicherheitsfaden?, Predicted Answer: dünner Streifen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Besondere an Mikroschriften bei Geldscheinen?, Predicted Answer: 100 g schwerer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso sind Mikroschriften ein wirksames Mittel gegen Geldfälschungen?, Predicted Answer: Kampfspiele\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie werden Wasserzeichen erzeugt?, Predicted Answer: zusätzliches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welchen Sicherheitsmerkmalen sollte der 100-Dollarschein ausgestattet sein, der 2011 in Umlauf gebracht werden sollte?, Predicted Answer: zusätzlichen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso wurde die Ausgabe der 100-Dollarnote von 2011 verschoben?, Predicted Answer: Muammar al-Gaddafi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Bedeutung hatte das Jagen ab etwa 6500 v.Chr.?, Predicted Answer: China\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann war das Proto-Neolithikum?, Predicted Answer: noch nicht zur Jungsteinzeit gerechnet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.69 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurden die Werkzeuge aus Feuerstein in Proto-Neolithikum bearbeitet?, Predicted Answer: noch nicht geschliffen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus welcher Epoche stammt das erste nachgewiesene kultivierte Getreide?, Predicted Answer: Niedergangs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche technische Neuerung ist für das Keramische Neolithikum prägend?, Predicted Answer: Werkzeugherstellung durch geschliffene Steinindustrie und erste ungebrannte Keramik ist bekannt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Behausungen wurden im Präkeramischen Neolithikum A von sesshaften Menschen erbaut?, Predicted Answer: Die Grabungen in Jericho und Mureybet wurden von Jean Cauvin, Kathleen Kenyon und John Garstang durchgeführt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was stellen die Kunstgegenstände aus dem PPNA mehrheitlich dar?, Predicted Answer: einen Oberbegriff\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind Idole aus der Jungsteinzeit?, Predicted Answer: Stein oder Ton\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welche Epoche ist erstmals Tierhaltung von Menschen nachgewiesen?, Predicted Answer: Niedergangs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welchen Ausgrabungsorten forschten Cauvin, Kenyon und Garstang?, Predicted Answer: Jericho und Mureybet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bezeichnet in Mitteleuropa die Kupferzeit?, Predicted Answer: Früheste Kupferverarbeitung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche technische Errungenschaft wurde in der Kupfersteinzeit entwickelt?, Predicted Answer: ein seilloser Aufzug entwickelt und ein Prototyp aufgebaut\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann entdeckte Planck das Wirkungsquantum?, Predicted Answer: 1899 und 1900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Plancksche Wirkungsquantum?, Predicted Answer: das Verhältnis von Energie () und Frequenz () eines Photons\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Zweig der Physik etablierte Planck mit der Entdeckung des Wirkungsquantums?, Predicted Answer: Quantenphysik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches physikalische Prinzip begründet das Plancksche Wirkungsquantum?, Predicted Answer: Zeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie nannte Planck selbst das Wirkungsquantum?, Predicted Answer: alleine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso nannte Planck seine Entdeckung Wirkungsquantum?, Predicted Answer: 1899 und 1900 begründete die Quantenphysik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr fing erstmals eine Frau an bei IBM als Fachkraft zu arbeiten?, Predicted Answer: 1935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wer war 1935 Direktor von IBM?, Predicted Answer: Thomas J. Watson\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Personen hatten bis 2019 die Auszeichnung IBM Fellow erhalten?, Predicted Answer: 305 Mitarbeiter zum IBM Fellow ernannt, von denen heute noch 89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hat das die IBM Fellow-Auszeichnung initiiert?, Predicted Answer: IBM eine eigene höchste technische Karrierestufe und Auszeichnung. Seit T. J. Watson\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Merkmal hat IBM 1984 in seine Leitlinien gegen Diskriminierung aufgenommen?, Predicted Answer: die sexuelle Orientierung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchem Leitsatz folgt IBM seit 1953 bei der Auswahl von Mitarbeitern?, Predicted Answer: Formel  von Leibniz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was erklärte IBM am 10. Oktober 2005?, Predicted Answer: als erster multinational operierender Konzern\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welchem Reich gehörte Ägypten ab 525 v. Chr?, Predicted Answer: 1914\n",
            "1801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu dem Reich wessen Herrschers gehörte Ägypten ab 332 v. Chr?, Predicted Answer: 1914\n",
            "1801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Der Herrschers welches Reiches war Alexander der Große?, Predicted Answer: Kyros II\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann starb Alexander der Große?, Predicted Answer: gegründete Alexandria zu ihrer Hauptstadt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wurde nach Alexander dem Großen König von Ägypten?, Predicted Answer: Leo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange herrschten die Nachkommen von Ptolemäus I. in Ägypten?, Predicted Answer: ein pseudodemokratisches System\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Ägypten Teil des römischen Reiches?, Predicted Answer: schnell an Einfluss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war der letzte Nachfahre des ptolemäischen Herrscherfamilie, der in Ägypten regierte?, Predicted Answer: Husni Mubarak\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde das Römische Reich geteilt?, Predicted Answer: Die Stadt wurde im römischen Reich als ''Civitas Parisiorum'' oder ''Parisia'' bekannt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war die Hauptstadt der ägyptischen Provinz im Römischen Reich?, Predicted Answer: Duschanbe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Nach welchem Konzil entstand die koptische Kirche?, Predicted Answer: Reichskirche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war zur Zeit des Konzil von Chalcedon Papst?, Predicted Answer: Leo der Große\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Migrationsströme gab es aus Griechenland?, Predicted Answer: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war das Hauptzielland der griechischen Auswanderer zwischen 1850 und 1940?, Predicted Answer: rund 511.000 Menschen aus Griechenland ausgewandert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wohin flohen Kaufleute und Gelehrte aus Griechenland unter osmanischer Herrschaft?, Predicted Answer: byzantinische\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Nach welchem Ereignis im 20. Jhd verstärkte sich die Migration aus Griechenland?, Predicted Answer: Weltkrieg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war in der zweiten Hälfte des 20. Jhd Ziel der griechischen Emigranten?, Predicted Answer: die Blütezeit des Rittertums, des Lehnswesens und des Minnesangs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was verstehen sich viele griechisch-stämmigen Menschen im Ausland?, Predicted Answer: wiederhergestellte wahre Christenversammlung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.96 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war Anfang der 1980er Herausgeber von The Sun?, Predicted Answer: Kelvin MacKenzie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit was wurde Thatcher durch die Queen geehrt?, Predicted Answer: Begeisterung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür kritisierte die Queen Thatcher 1986 gerüchteweise?, Predicted Answer: The Smiths\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Premierminister schrieb Queen Elisabeth II. eine Rolle bei der Abschaffung des Apartheid-Regimes in Südafrika zu?, Predicted Answer: Brian Mulroney\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür wurde Queen Elisabeth II. 1987 in Kanada kritisiert?, Predicted Answer: Meech Lake Accord\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Meeck Lake Accord?, Predicted Answer: Trail of Tears\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr kam es zu einem Putsch auf Fidschi?, Predicted Answer: selben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Amt hatte Queen Elisabeth II vor dem Militärputsch von Fidschi 1987 dort?, Predicted Answer: Monarchin, die vor den Kongress der Vereinigten Staaten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welchen TV-Auftritt erfuhren die Queen und ihre Familie 1987 Häme?, Predicted Answer: viel Spott\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hielt Queen Elisabeth die erste Rede vor dem amerikanischen Kongress?, Predicted Answer: trat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.60 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der HLA-Komplex?, Predicted Answer: Human Leukocyte Antigen“-Komplex\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was entdeckte Astrid Fagraeus 1948?, Predicted Answer: Stalin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer entdeckte in den 1930ern H-2-Antigene?, Predicted Answer: Peter Alfred Gorer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welchen Tieren forschte Gorer in den 1930ern?, Predicted Answer: Studien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was erforschte Gorer in den 1930ern?, Predicted Answer: entdeckte in den 1930er Jahren bei Studien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Theorie formulierte Frank Macfarlane Burnet 1957 als Beitrag zur Immunologie?, Predicted Answer: Klon-Selektionstheorie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was entdeckten Isaacs und Lindenmann 1957 bei Forschungen zu Virusinfektionen?, Predicted Answer: Der Brite Alick Isaacs und der Schweizer Jean Lindenmann\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für was erhielt Stanley Cohen 1986 den Nobelpreis?, Predicted Answer: Entdeckung der Wachstumsfaktoren NGF und EGF\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.17 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wurde als Lymphokine bezeichnet?, Predicted Answer: Faktoren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Begriff ersetzte \"Lymphokine\"?, Predicted Answer: Dudley Dumonde\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was gilt als Beginn der modernen Immunologie?, Predicted Answer: Die Zeit um 1960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer entschlüsselte um 1960 den Aufbau von Antikörpern?, Predicted Answer: Rodney Porter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.13 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Immunzellen klassifizierte Jacques Miller?, Predicted Answer: Einteilung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welcher Unterteilung der Immunreaktion führten u.a. die Ergebnisse von Jacques Miller?, Predicted Answer: beans\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann erhielten Köhler und Milstein den Nobelpreis für Medizin?, Predicted Answer: 1984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Preis erhielten Köhler und Milstein 1984?, Predicted Answer: Nobelpreis für Physiologie oder Medizin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die European Autoimmunity Standardisation Initiative gegründet?, Predicted Answer: Seit 2002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie kann Zink nachgewiesen werden?, Predicted Answer: nur 30 Prozent\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was entsteht beim Zinknachweis mit Cobaltsalzlösung?, Predicted Answer: Ein einfacher Zinknachweis beruht auf dem Erhitzen einer Probe mit wenigen Tropfen einer verdünnten Lösung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für den Nachweis welcher Mengen von Zink wird die Graphitrohr-AAS benutzt?, Predicted Answer: Im Ultraspurenbereich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Methode benutzt man, um kleine Spuren von Zink nachzuweisen?, Predicted Answer: eine Sonderstellung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Kandidaten unterstütze Arnold Schwarzenegger bei den Präsidentschaftswahlen 2008?, Predicted Answer: John McCain\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welche Partei kandidierte John McCain 2008 als Präsident?, Predicted Answer: Schwarzenegger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso war es Arnold Schwarzenegger nicht möglich in den USA als Präsident zu kandidieren?, Predicted Answer: Einwanderer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso wollte Schwarzenegger 2016 nicht mehr die Republikaner wählen?, Predicted Answer: Voraussetzungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.17 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso wollte sich Robert de Niro vor der Wahl 2016 nicht mit Schwarzenegger fotografieren lassen?, Predicted Answer: weigerte De Niro sich, mit Schwarzenegger zusammen für ein Foto\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Staffel von The Apprentice moderierte Schwarzenegger?, Predicted Answer: The New Celebrity Apprentice\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Sender produziert The Apprentice?, Predicted Answer: NBC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Fernseh-Show moderierte Schwarzenegger 2017?, Predicted Answer: The Apprentice\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird Zucker für die Bierproduktion gewonnen?, Predicted Answer: schwefelfreies Lignin und schwefelfreie Hemicellulose\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.14 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Alkohol hat Bier?, Predicted Answer: 4,5 % und 6 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird alkoholfreies Bier hergestellt?, Predicted Answer: Getrunken wird traditionell Bier in den Variationen Lager, Ale und Bitter aus einer reichen Auswahl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Stoffe werden bei der Herstellung von Bier zugesetzt?, Predicted Answer: Hopfen oder andere Würzstoffe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird bei der Herstellung von Wein und Bier gegärt?, Predicted Answer: Getrunken wird traditionell Bier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Zucker wird bei der Weinproduktion vergoren?, Predicted Answer: Für Weine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war verunsichert wegen der Nachricht vom Abschluss des deutsch-sowjetischen Nichtangriffspaktes?, Predicted Answer: Stalin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Folge hatte die Unterzeichnung des deutsch-sowjetischen Nichtangriffspaktes in Frankreich?, Predicted Answer: Stalin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde der britisch-polnische Beistandspakt unterschrieben?, Predicted Answer: unterzeichnet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann haben Frankreich und England dem Deutschen Reich den Krieg erklärt?, Predicted Answer: Nach dem deutschen Überfall\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum hat sich die Beziehung zwischen dem Deutschen Reich und der Sowjetunion 1940 verschlechtert?, Predicted Answer: Stalin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was hat die Errichtung einer zusätzlichen Energiequelle für Bahnstrom in Ostösterreich erforderlich gemacht? , Predicted Answer: Die Abdeckung des erhöhten Strombedarfs wegen weiterer Elektrifizierungen, Verdichtung des Nahverkehrs, Geschwindigkeitserhöhungen und Komfortverbesserungen durch den Einsatz von klimatisierten Reisezugwagen machte die Errichtung einer zusätzlichen Energiequelle für Bahnstrom in Ostösterreich erforderlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo befindet sich das Umformerwerk Bergern?, Predicted Answer: Etwa sechs Kilometer westlich von Melk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurde der Standort des Umformerwerkes Bergern ausgewählt?, Predicted Answer: Etwa sechs Kilometer westlich von Melk wurde in den Jahren 1979 bis 1983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher deutscher König war der Förderer verschiedener Kampfspiele und Turniere im Mittelalter?, Predicted Answer: Johann Wilhelms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Prozent der liberianischen Bevölkerung lebt von der Landwirtschaft?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Hauptnahrungsmittel in Liberia?, Predicted Answer: Maniok, Reis, Mais und Süßkartoffeln\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Name für Maniok in Liberia?, Predicted Answer: Cassava\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welchen Orten in Liberia wird Maniok angebaut?, Predicted Answer: Bruttoregistertonnen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.22 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche in Liberia angebaute Produkte werden in die USA exportiert?, Predicted Answer: Zuckerrohr, Baumwolle, Kaffee, Kakao und Ölpalmprodukte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißen die zehn staatlichen Forstbezirken in Liberia?, Predicted Answer: stark zurückgegangen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist eine symptomlose Infektion?, Predicted Answer: Stumme\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bedeutet stille Feiung bei Infektionen?, Predicted Answer: nur eine stille Feiung statt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Zeitdimension von subklinischen Infektionen?, Predicted Answer: stark durch die britische Kultur geprägt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wodurch kennzeichnen sich subklinische Infektionen?, Predicted Answer: Vorgänge\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann brechen persistierende Infektionen wieder aus?, Predicted Answer: Einige dieser Gruppen starben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange überdauern Erreger bei persistierenden Infektionen im Körper?, Predicted Answer: Wärme\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bei welcher Art von Infektion befinden sich Wirt und Erreger in einem Gleichgewicht?, Predicted Answer: eingeschleppte Krankheiten, Strafexpeditionen, Umsiedlungen und Zwangsarbeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange besteht eine latente Infektion?, Predicted Answer: zeitlich unbegrenzt oder so lange\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie gelangen die Erreger tolerierter Infektionen häufig in den Körper?, Predicted Answer: nachweisbar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was deutet auf maskierte Infektionen hin?, Predicted Answer: stärker\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bei welcher Art von Infektion kann der Erreger nicht nachgewiesen werden?, Predicted Answer: Symptomen ungeklärter Ursache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Krankheitsanzeichen treten bei abortiven Infektionen auf?, Predicted Answer: keine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie werden manifeste Infektionen auch genannt?, Predicted Answer: Blades\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.95 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was kennzeichnet opportunistische Infektionen?, Predicted Answer: Umsturzversuch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum hatten die Soldaten der US-Army keinen Erfolg in der Schlacht von Mogadischu?, Predicted Answer: eine schlecht ausgerüstete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum wurde die US-amerikanische Einsatzbereitschaft in Somalia endgültig abgebrochen?, Predicted Answer: Clinton\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die CIA gegründet?, Predicted Answer: beschränkt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war der Vorgänger der CIA?, Predicted Answer: General David Petraeus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurde die CIA gegründet?, Predicted Answer: 18. September 1947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war der erste CIA-Direktor?, Predicted Answer: George Tenet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hat die Stelle des CIA-Direktors am längsten besetzt?, Predicted Answer: Gina Haspel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.11 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür war die CIA während des Koreakrieges zuständig?, Predicted Answer: für sämtliche nachrichtendien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann begann die CIA mit Spionageflügen im Ausland?, Predicted Answer: Luftraum\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo hat die CIA geheime Operationen während des Vietnamkrieges geführt?, Predicted Answer: Laos, Kambodscha und Nordvietnam\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wurde als erster ehemaliger CIA-Chef zum Präsidenten der USA gewählt?, Predicted Answer: George Bush\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Der Versuch eines Attentats 1995 im Hauptquartier der CIA hatte was als Folge? , Predicted Answer: Ziel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum ist das Attentat 1995 im Hauptquartier der CIA gescheitert?, Predicted Answer: das Ziel eines geplanten Attentats\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum trat der Direktor der CIA George Tenet zurück?, Predicted Answer: „persönlichen Gründen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann führt die CIA Operationen mit Drohnen aus?, Predicted Answer: erfolgreich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum musste der CIA-Direktor Porter Goss sein Amt Bush abgeben?, Predicted Answer: auf Druck der Regierung Bush sein Amt zur Verfügung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wurde 2009 als neuer CIA-Chef von Barack Obama nominiert?, Predicted Answer: Leon Panetta\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum ist David Petraeus 2012 von seinem Amt zurückgetreten? , Predicted Answer: ein Rücktrittsgesuch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wurde 2018 zum neuen Außenminister der USA ernannt? , Predicted Answer: Mike Pompeo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist derzeit der CIA-Chef?, Predicted Answer: Porter Goss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde über Sicherheitsrisiken von USB-Geräten berichtet?, Predicted Answer: gebootet werden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Sicherheitsrisiken kann ein USB-Gerät haben?, Predicted Answer: benutzen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum sind von einem USB-Stick ausgelöste  Virusangriffe schwer zu beheben?, Predicted Answer: Derartige Angriffe sind bisher schwer abwehrbar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird macOS gegen Virusangriffe geschützt?, Predicted Answer: kurz zuvor geschlossene Atomabkommen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum hilft die Neuinstallation des Betriebssystems bei der Beseitigung von Malware nicht?, Predicted Answer: Die Frage war nicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hat eine Lösung zur Schadensbehebung von Virusangriffen 2014 angekündigt?, Predicted Answer: Warren Buffett\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo haben sich Denker in der Zeit der Aufklärung getroffen?, Predicted Answer: viele Denker davon aus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.95 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum wurden während der Aufklärung in Deutschland Lesezirkel gebildet?, Predicted Answer: Bücher und Zeitschriften\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Lesegesellschaften gab es Ende des 18. Jahrhunderts in Deutschland?, Predicted Answer: 430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche literarische Formen zählten zu Hauptverbreitungsformen der Aufklärung?, Predicted Answer: Essay und Traktat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchen Ländern bildete sich keine Salonkultur während der Aufklärung?, Predicted Answer: Westeuropa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Frauen waren aktiv während der Frühaufklärung in Deutschland?, Predicted Answer: Hervorragende Beispiele\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie unterscheiden sich Ursäuger von anderen Säugetieren?, Predicted Answer: darin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Körperteil ist typisch für Ursäuger?, Predicted Answer: Schnabeltier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.27 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sehen Eier von Ursäugern aus?, Predicted Answer: Eier legen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sehen neugeschlüpfte Ursäuger aus?, Predicted Answer: nackt und klein\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Region lebt das Schnabeltier?, Predicted Answer: Basel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Gruppe aus Italien ist bekannt in der Welt von Wrestling?, Predicted Answer: Italian Championship Wrestling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die bekannteste italienische Wrestling-Liga?, Predicted Answer: Italian Championship Wrestling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo hat die WWE die Wrestling-Industrie expandiert?, Predicted Answer: europäischen Version ''Catchen'' auch in Deutschland\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird im Nahbereich einer Antenne erzeugt?, Predicted Answer: frequenzselektiv sein\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.14 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist Wilhelm IV. gestorben?, Predicted Answer: in der Nacht verstorben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Union endete mit der Thronübernahme durch Victoria?, Predicted Answer: Personalunion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat Victoria den Thron übernommen?, Predicted Answer: verantwortlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wohin verlegte Victoria 1837 ihren Hofstaat?, Predicted Answer: Bereits im Juli 1837 verlegte Victoria ihren Hofstaat vom Kensington Palace in den umgebauten und erweiterten Buckingham Palace\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist die Krönung von Victoria stattgefunden?, Predicted Answer: schwer getroffen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie fand die Bevölkerung die Prinzessin Victoria?, Predicted Answer: Premierminister Lord Melbourne\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.27 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Krone war speziell für Victoria angefertigt?, Predicted Answer: Dornenkrone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum ist es schwierig eine Definition von Gott aufzustellen?, Predicted Answer: sehr schwierig und vielleicht unmöglich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von welchen Wesen wird Gott in einigen Kulturen nicht unterschieden?, Predicted Answer: Lugbara\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißen politische Parteien, die die Arbeit freiwillig machen?, Predicted Answer: Nationale Einheitspartei (NUP), hervorgegangen aus der Burma Socialist Programme Party von General Ne Win, Union Solidarity and Development Association (USDA) (regierungsnah, jedoch offiziell ohne Parteienstatus) sowie die Nationale Liga für Demokratie (NLD) und weitere acht Minoritäten-Parteien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was zeichnet eine Wählerpartei aus?, Predicted Answer: Inhaltsfragen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie erfolgt die Finanzierung der Wählerparteien?, Predicted Answer: in großen Teilen aus externen Quellen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von wem wurden Wählerparteien gegründet?, Predicted Answer: Unter seiner Herrschaft\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.93 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Anhänger welcher politischer Strömung waren die meisten Wählerparteien?, Predicted Answer: Erweckungskirchen/christlichen Wiedergeburt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hat die ersten Arbeiterparteien gegründet?, Predicted Answer: Nu-Wrestling Evolution\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was zeichnet eine Mitgliederpartei aus?, Predicted Answer: Inhaltsfragen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.21 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind Beispiele für Volksparteien in Deutschland?, Predicted Answer: Friederike Caroline Neuber\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind Beispiele für Volksparteien in Österreich?, Predicted Answer: folgende Ziele\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus welcher Sprache kommt Katalanisch?, Predicted Answer: eigenen Sprache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann und wo wurde die katalanische Sprache zum ersten Mal erwähnt?, Predicted Answer: so stark gefördert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus welchem Jahrhundert stammen erste schriftliche Werke in der katalanischer Sprache?, Predicted Answer: 13. und 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hat die katalanische Sprache berühmt gemacht?, Predicted Answer: Franco-Diktatur\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die Sprachgrenze des Katalanischen festgelegt?, Predicted Answer: an Bedeutung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum ist die katalanische Sprache zwischen dem 13. und 15. Jahrhundert bedeutend geworden?, Predicted Answer: Raum\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann erschien das erste katalanische Wörterbuch?, Predicted Answer: sieben Wochen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche andere Sprache beinhaltete das erste zweisprachige katalanische Wörterbuch?, Predicted Answer: Bücher 1502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo kann man das erste katalanische Wörterbuch im Original finden?, Predicted Answer: Biblioteca de Catalun\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hatte das erste katalanische Wörterbuch hergestellt?, Predicted Answer: Joan (Johann) Rosembach\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wodurch wurde die katalanische Sprache durch kastilische als Literatursprache verdrängt?, Predicted Answer: Dadurch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat der spanische Erbfolgekrieg stattgefunden?, Predicted Answer: beendet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat Katalonien seine politische Eigenständigkeit verloren?, Predicted Answer: stark an Boden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist die kastilische Sprache gesetzliche Unterrichtssprache geworden?, Predicted Answer: Mit der Ausdehnung des Herrschaftsbereichs des Grafen von Barcelona und des nachfolgenden katalanisch-aragonesischen Staatenbunds in den Mittelmeerraum gewann auch die katalanische Sprache zwischen dem 13. und 15. Jahrhundert an Bedeutung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie nennt man den Tiefpunkt der katalanischen Sprachgeschichte?, Predicted Answer: erkenntnistheoretische Problem wird am Ende nicht gelöst\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann gewann das Katalanische nach seinem Tiefpunkt wieder an Bedeutung?, Predicted Answer: Schwarzenegger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie nennt man die Wiedergeburt der katalanischer Sprache?, Predicted Answer: erlernen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.69 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wodurch wurde die Blüte des Katalanischen in den 1930er zerstört?, Predicted Answer: durch den Spanischen Bürgerkrieg und den Sieg der nationalistischen und zentralistischen Franco-Diktatur\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurde die katalanische Sprache in den Anfangsjahren der Franco-Diktatur unterdrückt?, Predicted Answer: massiv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist der Diktator Franco gestorben?, Predicted Answer: 1939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum wird die katalanische Sprache seit den letzten 25 Jahren stark von der Regionalregierung gefördert?, Predicted Answer: Raum\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt der Prozess der Wiederherstellung der Bedeutung des Katalanischen?, Predicted Answer: noch immer im Gange\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Prozent der in Katalonien lebenden Menschen können Spanisch schreiben?, Predicted Answer: 95 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Prozent der katalanischen Bevölkerung können Katalanisch schreiben?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Beweis dafür, dass das Katalanische sich in den meisten Bereichen der Gesellschaft  durchgesetzt hat?, Predicted Answer: normalització\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie haben die Medien das Osmanische Reich im letzten Drittel des 19. Jahrhundert bezeichnet?, Predicted Answer: ''„Kranker Mann am Bosporus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche historische Quellen von Hellenismus gibt es?, Predicted Answer: wichtige\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.17 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum sind fast keine schriftliche Werke aus der Zeit des Hellenismus erhalten?, Predicted Answer: historische oder philosophische Schriften\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Autoren aus dem Hellenismus sind fragmentarisch erhalten?, Predicted Answer: Timaios von Tauromenion (345–250 v. Chr.), Duris von Samos (340–270 v. Chr.) und Hieronymos von Kardia (360–272 v. Chr.),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat das Militär in Putschen die politische Macht übernommen?, Predicted Answer: vorübergehend\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welchem Ereignis endete die Geschichte des Osmanischen Reiches?, Predicted Answer: Gründung der türkischen Republik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat das Osmanische Reich ein Heer gebildet, um die französische Armee aus Ägypten zu drängen?, Predicted Answer: Ägypten unter der Muhammad-Ali-Dynastie von seiner Gründung bis 1914\n",
            "1801 stellte das Reich eine Armee zusammen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ab wann war es im Osmanischen Reich möglich, das Privateigentum zu besitzen?, Predicted Answer: 1842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann besiegte die ägyptische Armee die osmanische in der Schlacht von Nisibis?, Predicted Answer: Die ägyptischen Truppen besiegten aber die osmanische Armee unter Hafiz Pasha in der Schlacht von Nisibis am 24. Juni 1839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde das Sueskanal fertiggebaut?, Predicted Answer: schnell an Einfluss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wurde in Ägypten im 19.Jahrhundert angebaut, das für Europa interessant war?, Predicted Answer: Baumwollanbau\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was führte zu Aufständen am Ende des 19.Jahrhundert in Ägypten?, Predicted Answer: Der wachsende wirtschaftliche und politische Einfluss europäischer Staaten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr ist Ägypten der britische Schutzstaat geworden?, Predicted Answer: 404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann herrschte das Osmanische Reich über Ägypten?, Predicted Answer: 1517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welche Teile wird North Carolina gegliedert?, Predicted Answer: drei wesentliche Teile gliedern: die Küstenebene am Atlantik, das Piedmont-Plateau im Hinterland und die Bergregion der Appalachen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sehen die Böden der atlantischen Küstenebene von North Carolina?, Predicted Answer: traditionell in North Carolina angesiedelt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür kann man die Böden der atlantischen Küstenebene von North Carolina verwenden?, Predicted Answer: Etwa zwei Drittel des Bundesstaates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist \"Outer Banks\" in North Carolina?, Predicted Answer: North Carolinas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Lagunen umgeben die \"Outer Banks\"?, Predicted Answer: zwei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum gibt es keinen bedeutenden Seehafen in North Carolina?, Predicted Answer: traditionell\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt der einzige größere Hafen von North Carolina?, Predicted Answer: Wilmington\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.21 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ist die geologische Struktur der atlantischen Küstenebene von North Carolina?, Predicted Answer: North Carolinas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was zeichnet die Piedmont-Region von North Carolina aus?, Predicted Answer: angesiedelt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sieht die Landschaft der Piedmont-Region von North Carolina aus?, Predicted Answer: hügelige\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die geologische Struktur der Piedmont-Region von North Carolina?, Predicted Answer: North Carolinas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Teil von North Carolina werden heutzutage verschiedene Baumaterialen abgebaut?, Predicted Answer: drei wesentliche Teile gliedern: die Küstenebene am Atlantik, das Piedmont-Plateau im Hinterland und die Bergregion der Appalachen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sehen die Böden in der Piedmont-Region von North Carolina aus?, Predicted Answer: bekannt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welche Obstsorten ist die Piedmont-Region bekannt?, Predicted Answer: Pfirsiche und Melonen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bildet die Westgrenze von North Carolina?, Predicted Answer: Die Great Smoky Mountains\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Bergzüge bilden die Berge auf dem Gebiet von North Carolina?, Predicted Answer: vier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der größte Gebirgszug in North Carolina?, Predicted Answer: Die Blue Ridge Mountains\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie werden die Great Smoky Mountains umgangssprachlich bezeichnet?, Predicted Answer: Smokies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der zweithöchste Gebirgszug in North Carolina?, Predicted Answer: Die Great Smoky Mountains\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der geologische Bestand vom \"Blue Ridge Belt\"?, Predicted Answer: Gürtel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der älteste Gebirgszug North Carolinas?, Predicted Answer: Die Great Smoky Mountains\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der wichtigste Wirtschaftszweig der Bergregion von North Carolina?, Predicted Answer: geworden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind Beispiele für Nutztiere?, Predicted Answer: gemeinsames Verrichten von Arbeit, die Organisation einer Veranstaltung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie nennt man den Verzehr von Insekten?, Predicted Answer: eine Volumenänderung des Dampfs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchen Ländern werden Insekten verzehrt?, Predicted Answer: 180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Insekten können als Haustiere gehalten werden?, Predicted Answer: Einige\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welchen Insekten sind Ameisen verwandt?, Predicted Answer: Kaukasiern und Aschkenasim\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Insekten können als Haustiere gehalten werden?, Predicted Answer: Einige\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Insekten werden in der Pharmazie benutzt?, Predicted Answer: 500 Arten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Insekten werden als Versuchstiere eingesetzt?, Predicted Answer: verschiedene\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Insekten spielen eine große Rolle in der Kriminalistik?, Predicted Answer: sehr viele\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Produktion können Schildläuse eingesetzt werden?, Predicted Answer: pharmazeutischen Industrie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.12 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Empfindlichkeit haben fotographische Aufnahmematerialen heutzutage? , Predicted Answer: Federal Reserve Notes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ermöglicht ein empfindlicherer Film?, Predicted Answer: freihändiges Fotografieren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist besser bei nierdigempfindlichen Filmen?, Predicted Answer: die Schärfe und die Auflösung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.69 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Zeitung in Großbritannien ist ähnlich zu BILD in Deutschland?, Predicted Answer: nicht möglich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Art von Zeitung ist \"The Sun\"?, Predicted Answer: das Tagblatt Dernières Nouvelles d’Alsace\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was zeichnet eine Boulevardzeitung aus?, Predicted Answer: Inhaltsfragen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer gibt die Zeitung \"The Sun\" heraus?, Predicted Answer: Kampagne\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann gibt es eine Sonntagsausgabe von der Zeitung \"The Sun\"?, Predicted Answer: 26. Februar 2012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was arbeitete Edmund Burke von 1765 bis 1766?, Predicted Answer: Privatsekretär\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Organisation war Burke ein Mitglied in London?, Predicted Answer: Bund der Freimaurer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche politische Werke stammen von Edmund Burke?, Predicted Answer: eine scharfe Kritik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Hauptwerk von Edmund Burke?, Predicted Answer: „Reflexionen“ von 1790, formulierte Burke eine scharfe Kritik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was beinhaltet das Hauptwerk von Edmund Burke?, Predicted Answer: eine scharfe Kritik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.15 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wovon ist die galicische Musik geprägt?, Predicted Answer: vom Einsatz von Dudelsack (galicisch ''Gaita''), Drehleier und Harfe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.13 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche international bekannte Musikgruppen spielen traditionelle galicische Musik?, Predicted Answer: Milladoiro oder Fuxan os Ventos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Nach wem ist der Bezirk Bronx in New York benannt?, Predicted Answer: ab den 1960er Jahren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr ist Bronx ein eigenständiger Stadtbezirk geworden?, Predicted Answer: 1874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.96 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Straftaten gehörten ab den 1960er in Bronx zum Alltag?, Predicted Answer: Bandenkriminalität, Autodiebstahl, Drogen und Raubüberfälle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat überwiegend die Mittelschicht in Bronx gewohnt?, Predicted Answer: ein Wohnort\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das größte menschliche Gen?, Predicted Answer: Dystrophin-Gen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Aminosäure hat das größte menschliche Gen?, Predicted Answer: Liberia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wodurch ist die Region der Mexiko-Stadt gefährdet?, Predicted Answer: Erdbeben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen wurden von einem Erdbeben  1985 in Mexiko-Stadt getötet?  , Predicted Answer: 25.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Gebäude waren von dem Erdbeben 1985 in Mexiko-Stadt geschadet?, Predicted Answer: 2.800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum kam es zu so vielen Toten nach dem Erdbeben 1985 in Mexiko-Stadt?, Predicted Answer: 2.800 Gebäuden zu Schäden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sieht die Landschaft der Mexiko-Stadt aus?, Predicted Answer: Erdbeben gefährdeten Region\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird in der Mexiko-Stadt angebaut?, Predicted Answer: Alltag\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Metalle sind in der Region der Mexiko-Stadt zu finden?, Predicted Answer: Erdbeben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann erschien der Soundtrack zum Film \"James Bond 007: Spectre\"?, Predicted Answer: Ende Oktober 2015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer singt im Soundtrack von \"James Bond 007: Spectre\"?, Predicted Answer: Sam Smith\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Preis gewann Sam Smith für seinen Soundtrack bei der Oscarverleihung 2016?, Predicted Answer: Filmsong\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde der Staat Rus am Dnepr gegründet?, Predicted Answer: Entstehung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf welchem Kontinent liegen die US-Bundesstaaten?, Predicted Answer: Nordamerikanischen Kontinent\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche US-Bundesstaaten bilden das \"Kernland\" der USA?, Predicted Answer: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sieht die Landschaft der USA aus?, Predicted Answer: North Carolina\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt der Vulkan auf Hawaii?, Predicted Answer: Mauna Loa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum distanzierte sich die evangelische Kirche von der römisch-katholischen?, Predicted Answer: deshalb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hat man die amerikanischen Anglikaner nach der Unabhängigkeitserklärung genannt?, Predicted Answer: ''Protestant Episcopal Church in the United States of America\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann sind Waldenser entstanden?, Predicted Answer: bereits im 12. Jahrhundert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Gruppen der evangelischen Konfessionsfamilie sind in der Reformationszeit in deutschsprachigen Ländern entstanden?, Predicted Answer: Mennoniten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die bekanntesten Reformatoren der Evangelisch-lutherischen Kirche?, Predicted Answer: Martin Luther und Philipp Melanchthon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die bekanntesten Reformatoren der Reformierten Kirche?, Predicted Answer: Martin Luther und Philipp Melanchthon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die bekanntesten Reformatoren der Anglikanischen Kirche?, Predicted Answer: Thomas Cranmer und Martin Bucer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie waren die deutschen evangelischen Landeskirchen organisiert?, Predicted Answer: in der Evangelischen Kirche in Deutschland\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchen Ländern wächst die Anzahl der evangelischen Kirchen besonders stark?, Predicted Answer: China und Lateinamerika\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchen Ländern ist die Mehrheit der Bevölkerung evangelisch?, Predicted Answer: Skandinavien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wird nach der Wiedervereinigung als \"Deutschen\" bezeichnet?, Predicted Answer: die Rede\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum kann es schwierig sein eine klare Definition von \"Deutschen\" zu geben?, Predicted Answer: religiöse Heimat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.13 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was passiert während der Regenzeit in Liberia?, Predicted Answer: das Pro-Kopf-Einkommen auf unter 125 Euro\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.93 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Hauptstadt von Liberia?, Predicted Answer: Flotte Liberias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie unterschiedet sich die Menge von Niederschlägen in verschiedenen Regionen von Liberia?, Predicted Answer: Liberias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Bereich von Liberia ist Trockenzeit zu beobachten?, Predicted Answer: Harmattan-Wind\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde der USB 1.0 eingeführt?, Predicted Answer: 1996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Unternehmen haben den USB 1.0 entwickelt?, Predicted Answer: Compaq, DEC, Intel, IBM, Microsoft, NEC und Nortel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hat viel zur Entwicklung vom USB 1.0 beigetragen?, Predicted Answer: Ajay Bhatt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Fortschritte wurden mit der Herstellung vom ersten USB gemacht?, Predicted Answer: die Schnittstelle eines Geräts mit „USB 2.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.92 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Sprachen spricht man in Mali?, Predicted Answer: 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die bedeutendste Sprache in Mali?, Predicted Answer: Bambara\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen sprechen in Mali Bambara als Muttersprache? , Predicted Answer: die zypriotische Mundart und sehr vereinzelt Pontisch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum spricht man im Norden Malis kein Bambara?, Predicted Answer: Mittel der Machtentfaltung der subsaharischen Völker\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Amtssprache Malis?, Predicted Answer: Verfassung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Sprachen werden in Mali als nationale Sprachen anerkannt?, Predicted Answer: 13 Sprachen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf welcher Sprache studiert man in Mali?, Predicted Answer: eigenen Sprache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum bleibt Französisch eine bedeutende Sprache in Mali?, Predicted Answer: Bambara\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurden Juden in Bern zum ersten Mal erwähnt?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.95 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war die Folge des Ritualmordes an einem Kind in Bern 1294?, Predicted Answer: tot aufgefunden worden war\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.61 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann gibt es in Bern wieder eine jüdische Gemeinde?, Predicted Answer: 1848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die erste Synagoge in Bern gebaut?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist das Fußballteam \"Irish\" aus der University of Notre Dame bekannt geworden?, Predicted Answer: Four Horsemen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann gewann das Fußballteam \"Irish\" die nationale Meisterschaft?, Predicted Answer: in der Saison 1924/1925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt der Film über das Fußballteam \"Irish\"?, Predicted Answer: Knute Rockne, All American\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lang ist die Straßenbahnstrecke in Mexiko-Stadt heutzutage?, Predicted Answer: 18 Kilometer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum ist der Verkehr in der Mexiko-Stadt oft blockiert?, Predicted Answer: Hauptverkehrszeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wurde in Mexiko-Stadt unternommen, um den Straßenverkehr zu entlasten?, Predicted Answer: der erste Streckenabschnitt der U-Bahn in Betrieb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Linien hat die Metro in Mexiko-Stadt?, Predicted Answer: elf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum ist die Metro in Mexiko-Stadt heutzutage völlig überfordert?, Predicted Answer: überfüllt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die Eisenbahn in Mexiko privatisiert?, Predicted Answer: nicht realisiert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann fuhr die erste Pferdestraßenbahn in Mexiko-Stadt?, Predicted Answer: 12. Dezember 1857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann fuhr die erste elektrische Straßenbahn in Mexiko-Stadt?, Predicted Answer: 15. Januar 1900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Unterschied zwischen den Deutschstämmigen und Volksdeutschen?, Predicted Answer: große\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Deutschen leben in der ganzen Welt?, Predicted Answer: einzigen deutschen Großstadt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißen die ins Ausland gezogene Menschen, die eine deutsche Staatsangehörigkeit besitzen?, Predicted Answer: Auslandsdeutsche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mithilfe welches Verfahrens kann schwefelfreies Lignin und schwefelfreie Hemicellulose gewonnen werden? , Predicted Answer: Recyclingverfahren, welches parallel zur Zellstoffproduktion abläuft, zurückgewonnen. Es werden schwefelfreies Lignin und schwefelfreie Hemicellulose gewonnen, die von der chemischen Industrie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bedeutet Kriegsverbrechen der Kategorie A?, Predicted Answer: Musik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißen die beiden internationalen Flughäfen in Tennessee?, Predicted Answer: Nashville International Airport und der Memphis International Airport\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche nationale Flughäfen gibt es in Tennessee?, Predicted Answer: bekannteren Unternehmen mit Sitz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Sportveranstaltung findet häufig in Miami statt?, Predicted Answer: Super Bowl der National Football League\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann existierte in Miami die Autorennstrecke Bayfront Park?, Predicted Answer: 2002 bis 2003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann gibt es den Begriff des religiösen oder spirituellen Naturalismus?, Predicted Answer: 1940er Jahren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist unter dem religiösen oder spirituellen Naturalismus zu verstehen?, Predicted Answer: Musik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist Gott im religiösen Naturalismus?, Predicted Answer: immateriell\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum trat Vilanova 2013 zurück?, Predicted Answer: Angebot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer gewann in der Champions League 2012/13?, Predicted Answer: Barcelona\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Punkte hat Barcelona in der Champions League 2012/13 gesammelt?, Predicted Answer: 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Unterschied zwischen dem traditionellen Wrestling und dem europäischen Catchen?, Predicted Answer: Zusammenarbeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist das amerikanische Wrestling in Deutschland populär geworden?, Predicted Answer: verhältnismäßig selten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Inwiefern unterscheidet sich das amerikanische und britische Wrestling?, Predicted Answer: Durchbruch des amerikanischen Wrestlings in Deutschland\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum war Wrestling 2000 nicht mehr so populär wie früher in Deutschland? , Predicted Answer: uninteressant\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche bekannten Wrestling-Ligen wurden in Deutschland gegründet?, Predicted Answer: eigenständige\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche deutsche Wrestling-Liga hat mit den amerikanischen Wrestling-Organisationen zusammengearbeitet?, Predicted Answer: Alex Wright\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Wrestling-Arten sind heutzutage populär in Deutschland?, Predicted Answer: Wrestling-Ligen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wonach ist Eisenhower 1961 umgezogen?, Predicted Answer: Ende seiner Präsidentschaft im Januar 1961 zog sich Eisenhower mit seiner Frau Mamie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.27 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist Eisenhower in den Ruhestand gegangen?, Predicted Answer: umstritten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist Eisenhower gestorben?, Predicted Answer: umstritten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo fand eine Trauerfeier von Eisenhower statt?, Predicted Answer: Washington National Cathedral\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum hat die Bevölkerung angefangen zu wachsen im Hochmittelalter?, Predicted Answer: begünstigt unter anderem durch landwirtschaftliche Fortschritte und die mittelalterliche Warmzeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Konflikt gab es im Hochmittelalter?, Predicted Answer: Die Rückeroberung der von den Mauren eroberten Gebiete auf der Iberischen Halbinsel durch die benachbarten christlichen Königreiche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Königreiche wurden im Zuge der Christianisierung gegründet?, Predicted Answer: neue Königreiche wie England\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das größte Blasmusikfestival der Welt?, Predicted Answer: Eidgenössische Musikfest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird die traditionelle Schweizer Volksmusik bezeichnet?, Predicted Answer: Ländlermusik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind typische schweizerische Instrumente?, Predicted Answer: das Alphorn und das Schwyzerörgeli\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Gruppen sind bekannt für ihre Schweizer Volksmusik?, Predicted Answer: einige\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde der Eidgenössische Jodlerverband gegründet?, Predicted Answer: 1910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum steht der Wasserstoff im Periodensystem in der ersten Hauptgruppe?, Predicted Answer: hochentzündlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Valenzelektronen hat Wasserstoff?, Predicted Answer: 1 Valenzelektron besitzt. Ähnlich wie die ebenfalls dort stehenden Alkalimetalle hat er in vielen Verbindungen die Oxidationszahl +1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie nennt man chemische Verbindungen mit der Oxidationszahl -1?, Predicted Answer: Ionenbindungen wie bei den Alkalimetallen, sondern kovalente Molekülbindungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum ist der Wasserstoff für die erste Hauptgruppe des Periodensystems nicht typisch?, Predicted Answer: hochentzündlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was führte zum Aufstand der Pariser Kommune?, Predicted Answer: Dies führte zu einem Aufstand\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat die Revolutionsregierung angefangen in Paris zu regieren?, Predicted Answer: übernahm in Paris eine Revolutionsregierung die Macht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen wurden während der sogenannten \"blutigen Woche\" in Paris getötet?, Predicted Answer: 25.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bis wann war das Leben der Juden in Deutschland erschwert?, Predicted Answer: erheblich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hat den klassischen Empirismus kritisiert?, Predicted Answer: Thesen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Einfluss hatte Hayek auf die Evolutionsökonomik?, Predicted Answer: wesentlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus welchen drei Wurzeln stammen die Werte nach Hayek?, Predicted Answer: den biologischen „vererbten“\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Arten von Ordnungen unterscheidet Hayek?, Predicted Answer: weniger lang als größere Arten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.95 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Papst hat als Erster eine Pilgerfahrt ins Heilige Land unternommen?, Predicted Answer: Kaiser\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wohin führte die Pilgerfahrt von Paul_VI?, Predicted Answer: SG:PART\n",
            "                   'Liebst du mich?'                                                                          (Erelt, 2009, p. 16)\n",
            "           (23) Ta       lä-k-s                       ära   või?\n",
            "                   3SG    gehen-PAST-3SG weg oder\n",
            "                   'Sie/Er ist weggegangen, oder?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.12 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wen traf Paul_VI während seiner Pilgerfahrt in Jerusalem?, Predicted Answer: zusammen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist mit Paul_VI während seiner letzten Auslandsreise in Manila passiert?, Predicted Answer: entging Paul VI. in der philippinischen Hauptstadt Manila\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die größte Sprache Indiens?, Predicted Answer: Hindi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Hauptsprache Himachal Pradeshs?, Predicted Answer: das Hindi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Prozent der Bevölkerung in Himachal Pradeshs sprechen Hindi als Muttersprache?, Predicted Answer: 89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Sprache verwenden die meisten Menschen in Himachal Pradeshs im Alltag?, Predicted Answer: einen der Dialekte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Prozent der Bevölkerung in Himachal Pradeshs sprechen Panjabi als Muttersprache?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Hauptsprache des indischen Bundesstaates Punjab?, Predicted Answer: Muttersprache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.21 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Teil von Himachal Pradeshs beherrscht man tibetobirmanische Sprachen?, Predicted Answer: Hochgebirge\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum gibt es sehr wenig tibetobirmanische Sprecher in Himachal Pradeshs?, Predicted Answer: 0,3 Prozent entfallen auf die Sprecher des Tibetischen unter der exiltibetischen Gemeinde\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird Englisch in Indien verwendet?, Predicted Answer: Englisch – obwohl nicht offiziell – wird inzwischen von 4,1 % der Bevölkerung als Muttersprache gesprochen und ist als Zweitsprache verbreitet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie kann man Apps in Windows 8 herunterladen?, Predicted Answer: Side-Loading\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer beendete die erste Republik in Nigeria?, Predicted Answer: Vereinigten Niederlande\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sah die Wirtschaft in den 1970er Jahren in Nigeria aus?, Predicted Answer: Nigeria wurde der größte Erdölexporteur Afrikas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurde mit Juden während des Nationalsozialismus umgegangen?, Predicted Answer: Ehen von Juden mit heidnischen Frauen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Nach welchem Gesetz konnten Juden ihre deutsche Nationalität während des Nationalsozialismus verlieren?, Predicted Answer: Gesellschaft\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bedeutet ''Network Centric Warfare''?, Predicted Answer: An einem praktischen Beispiel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür interessiert sich Elisabeth II in ihrer Freizeit?, Predicted Answer: Pferdesport\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welchen Päpsten hat sich Elisabeth II getroffen?, Predicted Answer: zahlreichen bekannten Künstlern\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Hundrasse mag Elisabeth II am meisten?, Predicted Answer: 1944 erhielt Elisabeth ihr erstes Wappen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum produzierte die BBC den Film \"Royal Family\"?, Predicted Answer: Zu diesem Zweck\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hieß der deutsche Schneider von Elisabeth II?, Predicted Answer: Karl-Ludwig Rehse\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr ist die Prinzessin Diana gestorben?, Predicted Answer: 1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Staatsbürgerschaften besaß Chopin?, Predicted Answer: Emigrant wie viele seiner Freunde\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat Chopin seinen französischen Reisepass bekommen?, Predicted Answer: einen Anspruch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum konnte Chopin eine französische Staatsbürgerschaft bekommen?, Predicted Answer: Anspruch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.17 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat Chopin seinen ersten französischen Pass bekommen?, Predicted Answer: ausgestellt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Opera und Orchestra befinden sich in Tucson?, Predicted Answer: Arizona Opera Company\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Theater gibt es in Tucson?, Predicted Answer: drei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.27 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Museen gibt es in Tucson?, Predicted Answer: drei Theater, die Arizona Theatre Company, das Invisible Theatre und das Gaslight Theatre\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Bauwerke und Stätte in Tucson sind im National Register of Historic Places angegeben?, Predicted Answer: 179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie funktioniert Joint-Stereo?, Predicted Answer: Intensitäts- und Mid/Side-Stereo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist Albanien aus dem Warschauer Pakt ausgetreten? , Predicted Answer: unter Bruch der Vertragsbestimmungen formell aus dem Bündnis aus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann sind die Warschauer-Pakt-Staaten in die Tschechoslowakische Sozialistische Republik einmarschiert?, Predicted Answer: Einmarsch der Truppen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hoch ist die tägliche Netzfrequenz des Bahnstromnetzes?, Predicted Answer: besonders\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bedeutet ein Umformer, der zum Leistungsausgleich eingesetzt wird?, Predicted Answer: Die Umformerwerke werden sukzessive durch Umrichterwerke\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hoch ist die Sollfrequenz der Bahnstromnetze in Deutschland?, Predicted Answer: 16,7 Hertz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Arten von Sperrschicht-Feldeffekttransistoren gibt es?, Predicted Answer: n-Kanal und p-Kanal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo werden Sperrschicht-Feldeffekttransistoren angewandt?, Predicted Answer: kombiniert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Beziehung hat Gott im naturwissenschaftlichen Deismus?, Predicted Answer: die Welt mit allen Naturgesetzen geschaffen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Aufgabe von dem Director of the Central Intelligence Agency?, Predicted Answer: zuständig\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind Dialekte im Bezug zu Vögeln?, Predicted Answer: Phönix, Greif, Ziz (Jüdisch), Roch (Arabisch), Feng (Chinesisch) oder Garuda (Indonesisch).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Ziel der Kommunikation?, Predicted Answer: Verständigung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Zweck der Kommunikation?, Predicted Answer: Verständigung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bedeutet Kommunikation  im handlungstheoretischen Kontext? , Predicted Answer: Ursprünglich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr wurde Straußburg die Hauptstadt von Elsaß-Lothringen?, Predicted Answer: 1871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was hat die Unzufriedenheit der elsässischen Bevölkerung nach der Annexion Elsass-Lothringens durch das Deutsche Reich gezeigt?, Predicted Answer: komplex\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Nach wem wurde die \"Kaiser-Wilhelm- Universität\" in Straußburg benannt?, Predicted Answer: Wilhelm I\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:02<00:00,  1.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Architekten haben sich mit der Neugestaltung von Straußburg nach dem Deutsch-Französischen Krieg beschäftigt?, Predicted Answer: Bestimmte Themen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie werden die NPOs finanziert?, Predicted Answer: über Mitgliederbeiträge, Spenden, Zuschüsse, Preise oder Gebühren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie groß ist der jährliche Umsatz von NPOs weltweit?, Predicted Answer: fast zwei Billionen US-Dollar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Dimensionen zählen für NPOs im Bereich der sozialen Arbeit?, Predicted Answer: Elefanten, Affen, Antilopen, Büffel, seltene Vögel sowie Warane und Flusspferde\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war der neue Trainer von FC Arcenal 1986?, Predicted Answer: Arsenals Formkurve\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was waren die ersten Schritte von Graham als Trainer von FC Arcenal?, Predicted Answer: Titelgewinn von George Graham sein\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange war George Graham der Trainer von FC Arcenal?, Predicted Answer: letzte Titelgewinn\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum wurde George Graham entlassen?, Predicted Answer: Arsenal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was versteht man unter Verifikationismus?, Predicted Answer: In der Forschung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist ein Satz sinnvoll unter der Annahme von Verifikationismus?, Predicted Answer: wahr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wohin exportierte Tibet ein Großteil des Holzes in 50ern?, Predicted Answer: Ega\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die Folgen des hohen Kahlschlags der Tibeter Wälder?, Predicted Answer: in Tibet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hat sich die Bevölkerung Tibets entwickelt?, Predicted Answer: unterschiedlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum gab es in Tibet eine Weidenkonkurrenz?, Predicted Answer: nicht weiter ausgedehnt werden. Es entsteht Weidekonkurrenz und Überweidung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie soll versucht werden die Steppen in Tibet zu entlasten?, Predicted Answer: nicht unterschätzt werden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was brauchte die Südbahn in den 50ern für die Strom Versorgung?, Predicted Answer: 1950er Jahren erforderlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo lag das Umformwerk Auhof?, Predicted Answer: 1956 den Betrieb mit zwei Umformersätzen auf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Umformsätze hatte das Umformwerk Auhof bei der Gründung?, Predicted Answer: zwei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde das Umformwerk Auhof Generalerneuert?, Predicted Answer: verwechselt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welcher Ländern schloss England vor den Weltkriegen eine Allianz?, Predicted Answer: europäische\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Land schien 1902 am wahrscheinlichsten der nächste Krieg Gegner Englands zu sein?, Predicted Answer: Großbritannien schloss neue Allianzen: 1902 mit Japan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Germanium durch Silizium bei der Produktion von Transistoren ersetzt?, Predicted Answer: überwiegend der Halbleiter Silizium sowohl bei Feldeffekttransistoren als auch Bipolartransistoren verwendet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Woraus wurden bipolare Transistoren zunächst hergestellt?, Predicted Answer: Halbleiter Germanium\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Woraus bestehen Feldeffekttransistoren und bipolare Transistoren heutzutage?, Predicted Answer: Unterschieden wird bei Feldeffekttransistoren darüber hinaus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür wird Siliziumgermanium bei Transistoren verwendet?, Predicted Answer: überwiegend\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann kommt Siliziumcarbid bei der Produktion von Transistoren zum Einsatz?, Predicted Answer: Anwendung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo können Transistoren aus Siliziumcarbid eingesetzt werden?, Predicted Answer: beispielsweise\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Arabischen Herrscher sahen den kurdischen Unabhängigkeitskrieg als etwas gutes?, Predicted Answer: Möglichkeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war 1996 Premierministier der Türkei?, Predicted Answer: Erbakan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo schlief Gaddafi meistens bei Auslandsreisen?, Predicted Answer: Beyoncé\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Gruppe schütze Gaddafi oft bei Auslandsreisen?, Predicted Answer: Einzelperson\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hieß das erste Libysche Auto?, Predicted Answer: Nagib Mahfuz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Können sich Schalwellen im Vakuum ausbreiten?, Predicted Answer: keine Form von Wissen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hat 2013 überprüft wie viele der beliebtesten YouTube-Videos in Deutschland verfügbar sind?, Predicted Answer: Opendatacity\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie konnte man in Deutschland gesperrte Videos auf YouTube schauen?, Predicted Answer: 62 % davon in Deutschland nicht verfügbar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die Sperre von manchen YouTube-Videos in Deutschland aufgehoben?, Predicted Answer: Im August 2008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Elemente nahmen die Stoiker für die Substanz Gottes an?, Predicted Answer: einige Politiker die Ausbreitung der tödlichen Epidemie oder nahmen sie in Kauf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher christliche Autor hielt Gott für materiell?, Predicted Answer: Brian Leftow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was spricht laut der Philosophie in der Tradition von Platon und Aristoteles für die Immaterialität Gottes?, Predicted Answer: Aus der Sicht späterer Philosophen schuf er damit die Philosophie der Metaphysik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo fand die Operation TA der Japaner statt?, Predicted Answer: Operation Take-Ichi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele starben bei der Operation TA?, Predicted Answer: Einige dieser Gruppen starben wieder aus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war die Operation Desecrate One?, Predicted Answer: begonnen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann sind die Fürstenstaaten Indiens von dem britischen Protektorat unabhängig?, Predicted Answer: abgesetzt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.10 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In wie viele Gruppen wurden die Staaten Indiens 1950 eingeteilt?, Predicted Answer: ausweises\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer herrschte über die B-Staaten ab 1950 in Indien?, Predicted Answer: Katharina II.,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann sind alle indischen Staaten gleichgesetzt?, Predicted Answer: über 800 Jahren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bekamen die 1956 abgesetzten Herrscher der indischen Staaten als Ausgleich?, Predicted Answer: Apanagen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel elektrischen Strom erzeugt Armenien?, Predicted Answer: 6.951 Milliarden kWh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo in Armenien wird der meiste Strom hergestellt?, Predicted Answer: Fußball\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Erdgas verbraucht Armenien?, Predicted Answer: 2.35 Milliarden m³\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Ebenen von Softwaretests gibt es?, Predicted Answer: eklatante Mängel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch was ist ein Regel-Abschluss bei Softwaretests definiert?, Predicted Answer: psychosozialen Veränderungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.96 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo ist die Starcevo-Kultur angesiedelt?, Predicted Answer: Caesars\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Kultur markiert die Jungsteinzeit in Griechenland?, Predicted Answer: Jordansmühler\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Gebiet wird die Bükker-Kultur verortet?, Predicted Answer: Nordungarn und der Slowakei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Phase der Jungsteinzeit markiert die Theiß-Kultur?, Predicted Answer: eine Eigenwelt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Kultur prägte die späte Jungsteinzeit in Serbien?, Predicted Answer: britische\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Wappen hat die Stadt Paris?, Predicted Answer: ein kleines\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der offizielle Leitspruch von Paris?, Predicted Answer: Stadt und ''Département''.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Farbe hat die Flagge von Paris?, Predicted Answer: blau-rote\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür stehen die Farben in der Pariser Flagge?, Predicted Answer: Paris und Berlin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Sportart war Arnold Schwarzeneggers Vater erfolgreich?, Predicted Answer: Mr. Olympia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Sportarten betätigte Arnold Schwarzenegger im Alter von 10 Jahren?, Predicted Answer: Ralph Schicha\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann war Arnold Schwarzenegger das erste Mal in einem Gewichtheber Studio? , Predicted Answer: 1966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Woher bekam Arnold Schwarzenegger Anfangs sein Wissen über das Bodybuilding?, Predicted Answer: Robert De Niro\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war am Anfang seiner Bodybuilding Karriere Arnold Schwarzeneggers Vorbild?, Predicted Answer: Schwarzenegger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war Arnold Schwarzeneggers erster großer Bodybuilding Wettbewerbs Sieg?, Predicted Answer: Sprungbrett\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit wie vielen Jahren gewann Arnold Schwarzenegger den Titel Mister Universum zum ersten mal?, Predicted Answer: 14 Jahren betrat der junge Arnold zum ersten Mal in seinem Leben ein Gewichtheberstudio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.21 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Arnold Schwarzenegger zum zweiten mal \"Mister Universum\"?, Predicted Answer: gekämpft\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Bodybuildingverband wurde populärer als NABBA?, Predicted Answer: Weltmeisterschaft\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Platz belegte Arnold Schwarzenegger bei seinem ersten IFBB Meisterschaft?, Predicted Answer: zweiten Platz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann gewann Arnold Schwarzenegger zum ersten mal die IFBB Weltmeisterschaft?, Predicted Answer: wiederum\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war der größte Bodybuilding Titel den man in den 60ern gewinnen konnte?, Predicted Answer: Mr. Universum\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wen musste Arnold Schwarzenegger für seinen ersten Mr. Olympia Titel schlagen?, Predicted Answer: Sydney\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie oft wurde Arnold Schwarzenegger Mr. Olympia?, Predicted Answer: wiederum\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit was fing Arnold Schwarzenegger ab 1975 an?, Predicted Answer: Jim Lorimer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hörte Arnold Schwarzenegger mit dem BB komplett auf?, Predicted Answer: Bestsellerautor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Krankenhäuser zählen zu den Verbund Klinikum Region Hannover?, Predicted Answer: weitere Krankenhäuser in unterschiedlicher Trägerschaft. Zum Verbund Klinikum Region Hannover gehören das Klinikum Nordstadt, das Klinikum Oststadt-Heidehaus und das Klinikum Siloah\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer versuchte Russlands Einfluss auf Tibet während des Great Games zu hindern?, Predicted Answer: einen starken diplomatischen Einfluss auf Tibet gewinnen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.12 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer führte den britischen Tibetfeldzug an?, Predicted Answer: Francis Younghusband\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war das Ziel des britischen Tibetfeldzugs?, Predicted Answer: den Osten Kanadas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was erreichten die Briten mit der Besetzung von der tibetischen Stadt Lhasa?, Predicted Answer: Einführung der tibetischen Schrift im 7. Jahrhundert eine zutiefst religiös geprägte Literatur\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann einigten sich Russland und England über ihre Interessen in Zentralasien?, Predicted Answer: 1907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.95 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum haben die chinesischen Truppen 1911 Tibet verlassen?, Predicted Answer: vom Nachschub\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Hauptreligion Liberias?, Predicted Answer: Staatsoberhaupt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.15 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist Liberias zweit größte Religion?, Predicted Answer: Flotte der Welt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Bistümer gibt es in Liberia?, Predicted Answer: drei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist die höchste Person in der Pfingstkirche Asemblies of God, Predicted Answer: Jude\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query:  Wie groß sind die Zeugen Jehovas in Liberia?, Predicted Answer: mehr als 6000 Gläubige\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo spielen die Detroit Red Wings heutzutage?, Predicted Answer: Joe Louis Arena\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.59 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Mannschaft aus Detroit spielt in der MLB?, Predicted Answer: hochklassigen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer gewann 2012 die MLB?, Predicted Answer: Detroit Tigers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.22 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt Detroits NBA Team?, Predicted Answer: Detroit Red Wings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele NBA-Championships konnten die Detroit Pistons gewinnen?, Predicted Answer: 2004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welcher Stelle in der Thronfolge war Elisabeth II. bei ihrer Geburt?, Predicted Answer: dritter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wan war Elisabeth II. das erste mal im \"Time\" Magazin auf der Titelseite?, Predicted Answer: Monarchin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.17 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war nach George V. König Englands?, Predicted Answer: (Erelt, 2009, p. 16)\n",
            "           (21) On             sul          täna  aega?\n",
            "                   sein.3SG   2SG:AD heute Zeit.PART                                                    \n",
            "                  'Hast du heute Zeit?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.15 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum dankte König Eduard VIII. ab?, Predicted Answer: Abgaben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer brachte Elisabeth II. Verfassungsgeschichte bei?, Predicted Answer: ihrer Herrschaft fünf außerordentliche Fernsehansprachen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum war Elisabeth II. in Pfadfindergruppen? , Predicted Answer: Monarchin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel verdient der Durchschnittliche Haushalt in Seattle?, Predicted Answer: 665'104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Anteil der Bevölkerung Seattles ist weiß?, Predicted Answer: der Tourismus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind bekannte Weinbaugebiete um Paris?, Predicted Answer: Paris MOU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Bakterien können nicht ohne Sauerstoff leben?, Predicted Answer: Die generelle Gabe von Sauerstoff wird wegen seiner möglicherweise schädlichen Auswirkungen allerdings nicht mehr empfohlen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Bakterien sterben von Sauerstoff?, Predicted Answer: aerobe Bakterien oder Aerobier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was können Bakterien mit Dauerstadium?, Predicted Answer: Manche Bakterien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Können Bakterien Photosynthese betreiben?, Predicted Answer: fähig\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ging der Britisch-Amerikanische Krieg 1812 aus?, Predicted Answer: ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war 1812 Präsident der USA?, Predicted Answer: James Madison\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wollte James Madison mit dem Krieg gegen die Briten erreichen?, Predicted Answer: hinausschieben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo fanden die meisten Schlachten des Britisch-Amerikanischen Krieges von 1812 statt?, Predicted Answer: an der Grenze\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der elementare Teil beim Coverage im Canadian Football?, Predicted Answer: Ballsportart\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche beiden Deckungsarten gibt es beim Canadian Football?, Predicted Answer: weniger Verzögerungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurde das Imperial College in London grgründet?, Predicted Answer: Eingangsportal des Imperial College, London\n",
            "Die Gründung erfolgte 1907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt der Haushund auf Latein?, Predicted Answer: weitergegeben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welcher Tierart gehört der Haushund?, Predicted Answer: 1700 solcher Geschmacksknospen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist ein Haushund?, Predicted Answer: Der Dingo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo ist der Sitz des französischen Staatspräsidenten?, Predicted Answer: New York\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer entwarf die Pläne für den Der Élysée-Palast?, Predicted Answer: Jeanne-Antoinette Poisson\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo liegt der Der Élysée-Palast?, Predicted Answer: nördlich der Seine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo sammelt sich die Französische Nationalversammlung?, Predicted Answer: Eisenhower\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Französische Herrscher lies die Bauten von Ange-Jacques Gabriel bauen?, Predicted Answer: Unter Ludwig XV.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist Frankreichs Ruhmeshalle?, Predicted Answer: erneut Ruhmeshalle Frankreichs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist im Panthéon in Paris bestattet?, Predicted Answer: Palais Bourbon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die Stadt Changsha von den Japanern eingenommen?, Predicted Answer: nicht einnehmen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Sieg öffnete den Japanern im Pazifikkrieg Zugang zu den Südostprovinzen Chinas?, Predicted Answer: Schwarzenegger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann nahm Japan die Stadt Zaoyang ein?, Predicted Answer: konnten die Stadt aber nicht einnehmen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war 1939 Außenminister der USA?, Predicted Answer: Cordell Hull\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welchen Nationen wollte Japan 1939 ein Bündnis eingehen?, Predicted Answer: Deutschland\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo kamen Japans Rohstoffe 1939 hauptsächlich her?, Predicted Answer: die Kriegsanstrengungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Schlacht nutzen die Japaner Giftgas 1939?, Predicted Answer: Nanchang\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo ist Humphrey Gilbert zu Tode gekommen?, Predicted Answer: England\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wurde 1603 Englischer König?, Predicted Answer: James VI\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer umsegelte als zweiter die Welt?, Predicted Answer: Landwirtschaft\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer regierte 1578 über England?, Predicted Answer: Humphrey Gilbert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wollte Humphrey Gilbert in der Karibik erreichen?, Predicted Answer: segelte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war Halbbruder von Walter Raleigh?, Predicted Answer: William Longespée\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was unterscheidet die Waldländer im Westen und Osten der USA?, Predicted Answer: verlief die Entwicklung in den einzelnen Reichen recht unterschiedlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Käufer kauften die Laserdisc am Anfang?, Predicted Answer: heftigen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum kauften User die Laserdisc?, Predicted Answer: Massenmedium war, gab es sie überwiegend nur in großen Metropolen in den Fachabteilungen der Elektromärkte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche deutsche Firmen machten die Laserdisc in Deutschland groß?, Predicted Answer: Große Städte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo konnte man Laserdiscs in Deutschland kaufen?, Predicted Answer: Mr. Olympia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war der Gegensatz zwischen VHS Kassetten und Laserdiscs?, Predicted Answer: oft nicht zu erwerben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von was wurde die Laserdisc ersetzt?, Predicted Answer: 1999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu was berechtigt eine Urheberrechtsverletzung?, Predicted Answer: Verbraucher. Bei Artikeln setzen sich die Vergütungsregeln des Deutschen Journalisten-Verbands als marktübliche Lizenzen durch. Es bleibt allerdings zu beachten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Basis für die Berechnung des Schadenerstsatzanspruches bei unrechtmäßig verwendeten Fotos?, Predicted Answer: dies ist in der Rechtsprechung umstritten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An was soll Schadenersatz für verletzte Lizenzen gemessen werden?, Predicted Answer: einem physikalischen System\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann darf Alaska bei den US-Präsidentschaftswahlen wählen?, Predicted Answer: erstmals\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Partei führt meistens in Alaska bei den Präsidentschaftswahlen?, Predicted Answer: Alaska Permanent Fund\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war der erfolgreichste Parteilose Kandidat für die US-Präsident Wahl in Alaska?, Predicted Answer: Ronald Reagan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Tierklasse dachte man ist das Vogelgehirn ähnlich?, Predicted Answer: schwerer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.10 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Vögel zählen zu den schlausten?, Predicted Answer: flugunfähige\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.82 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer befasste sich zuerst mit der Theorie der Rule of Law?, Predicted Answer: Albert Venn Dicey\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was gibt es im Pub üblicherweise zu essen?, Predicted Answer: 0,63 m/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bekommt der Sieger ein Pub-Quiz-Abends?, Predicted Answer: manchmal aber bis in den Morgen hinein, zu heftigen Schauern\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der pub-crawl?, Predicted Answer: weit verbreitet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ist in englischen Pubs das Rauchen erlaubt?, Predicted Answer: verpönt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird in einem Pub miteinander umgegangen? , Predicted Answer: viele Pubs an einem Abend hintereinander besucht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie kriegt man in einem Pub Getränke?, Predicted Answer: Loop-Quantengravitation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was gibt es in Pubs zu trinken?, Predicted Answer: Bier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von welchen Ländern ist Griechenlands Energieversorgung abhängig?, Predicted Answer: Wildarten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel der verbrauchten Energie stellte Griechenland 2010 im eigenen Land her?, Predicted Answer: Dublin-II-Verordnung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ist Griechenlands Energiehandelsbilanz?, Predicted Answer: negativ aus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo ist Griechenlands größtes WasserkraftwerK?, Predicted Answer: am Kremasta-Stausee\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie groß ist der Chapultepec-Park?, Predicted Answer: 400 Hektar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Abschnitt des Chapultepec-Park befindet sich der Zoo?, Predicted Answer: Am westlichen Seeufer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Monumento a los Niños Héroes?, Predicted Answer: ein Ehrenmal für die Kadetten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für wen wurde das Castillo im Chapultepec-Park gebaut?, Predicted Answer: 1785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist Mexiko-Stadts Haupt Zoo?, Predicted Answer: Zona Metropolitana de la Ciudad de México\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt die Parkeisenbahn des Chapultepec-Park?, Predicted Answer: weitergegeben werden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo befindet sich das Grab von Diego Rivera?, Predicted Answer: Panteón Civil de Dolores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was verschlechtere 1810 die Beziehung zwischen Frankreich und Russland?, Predicted Answer: 22. Februar 1810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Land verbündete sich 1812 mit Russland?, Predicted Answer: Schweden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war Napoleons Plan für den russischen \"Vaterlänidschen Krieg\"?, Predicted Answer: Sein Plan für den Feldzug in Russland, dort als ''Vaterländischer Krieg'' bezeichnet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Verletzte gab es bei der Schlacht von Borodino?, Predicted Answer: Napoleon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was zwang Napoleon aus Moskau abzuziehen?, Predicted Answer: weiteren Kampf Moskau einzunehmen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Soldaten Napoleons kamen bei seinem Russlandfeldzug zurück?, Predicted Answer: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die wärmste Temperatur in der Schweiz gemessen?, Predicted Answer: niedriger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie oft hagelt es in den Alpen?, Predicted Answer: Wien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Nebeltage gibt es in Zürich heutzutage durchschnittlich?, Predicted Answer: ausweises\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum gibt es heutzutage um Zürich weniger Nebel als noch vor 50 Jahren?, Predicted Answer: ebenfalls Ort vieler Erst- und Uraufführungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hoch lieg der Ort Säntis?, Predicted Answer: −7,2 °\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ist der Durchschnitts Niederschlagwert in der trockensten Region der Schweiz?, Predicted Answer: im Winter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Jahreszeit regnet es in der Schweiz am meisten?, Predicted Answer: 2010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo schneit es in der Schweiz am wenigsten?, Predicted Answer: Vergleichsweise selten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die wärmsten Orte der Schweiz?, Predicted Answer: Locarno-Monti und Lugano\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo wurde die kälteste Temperatur der Schweiz gemessen?, Predicted Answer: −27 °\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Stilrichtung kam nach dem Kubismus?, Predicted Answer: ''Après le cubisme\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer erfand den Begriff Purismus?, Predicted Answer: nicht nach Hause?'                                            (Erelt, 2009, p. 16)\n",
            "           (21) On             sul          täna  aega?\n",
            "                   sein.3SG   2SG:AD heute Zeit.PART                                                    \n",
            "                  'Hast du heute Zeit?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer herrschte 1956 über Ungarn?, Predicted Answer: Nagy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.13 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo wird Glas benutzt?\n",
            ", Predicted Answer: Kernbereiche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Rolle hatte der FC Barcelona im Straßenbahnboykott von 1951?, Predicted Answer: Verteidiger von Demokratie und Freiheit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wurde 1968 Präsident des FC Barcelona?, Predicted Answer: Narcís de Carreras\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was gab der FC Barcelona der Bevölkerung Kataloniens zur Zeit Francos?, Predicted Answer: noch keine richtigen Fußballfelder\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo kommt das Motto des FC Barcelona her?, Predicted Answer: Velòdrom de la Bonanova'', teilte sich der FC Barcelona mit dem ''FC Català\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was stärkte die liebe zum FC Barcelona als gesellschaftliche Institution für Katalonien?, Predicted Answer: Sprache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war Josip Broz Tito?, Predicted Answer: ein jugoslawischer kommunistischer Politiker\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Amt hatte Josip Broz Tito bis er starb?, Predicted Answer: ein Amt, das er bis zu seinem Tod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann trennte sich Josip Broz Tito von der Sowjetunion?, Predicted Answer: zeichnete sich durch einen starken Personenkult aus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo sind Perlhühner ursprünglich heimisch?, Predicted Answer: Wildgeflügel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie schwer ist ein Auerhahn?, Predicted Answer: kleiner\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Jahre trainiert man im Sport ca. um die Höchstleistung abrufen zu können?, Predicted Answer: beans\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Ziel der verlustfreien Datenkompression?, Predicted Answer: Unterstützung der allgemeinen Wirtschaftspolitik der EU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf welcher Theorie beruht die verlustfreie Datenkompression?, Predicted Answer: historischer geografischer Übereinkunft\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange ist die Schulpflicht Nigerias?, Predicted Answer: durchaus auch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele der Kinder Nigerias im Schulalter gehen zur Schule?, Predicted Answer: 50 Prozent\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Probleme haben die Schulen in Nigeria?, Predicted Answer: Bildungseinrichtungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo ist ein wichtiges islamisches Bildungszentrum in  Nigeria?, Predicted Answer: Ilorin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird die Urheberrechtsverletzung heutzutage verfoglt?, Predicted Answer: Verbraucher\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wird für Urheberrechts Verletzungen hauptsächlich verfolgt?, Predicted Answer: Iran\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann ist Iran die offizielle Bezeichnung für den Iran?, Predicted Answer: 1979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann hat Russland keine Sommerzeit mehr?, Predicted Answer: verwendet seit dem 26. Oktober 2014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie groß ist die Zeit Verschiebung zwischen der Weltzeit und der Osteuropäischen Normalzeit?, Predicted Answer: nirgends wesentlich größer als eine halbe Stunde\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wovon hängt die Lage des Faschings ab?, Predicted Answer: abhängig\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war im Jahr 600 Papst?, Predicted Answer: Portugal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange geht die christliche Fastenzeit normalerweise?, Predicted Answer: nicht voneinander zu trennen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist der Aschermittwoch?, Predicted Answer: Ende des Karnevals\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist Humanismus?, Predicted Answer: Bildungsbewegung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Renaissance Humanismus?, Predicted Answer: Untergang\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Zeitalter war vor dem Humanismus?, Predicted Answer: Mittelalter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurde das Mittelalter in der Renaissance angesehen?, Predicted Answer: nicht mehr zeitgemäß\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wodurch kamen die Schriften Griechenlands während des Humanismus in den Westen Europas?, Predicted Answer: dadurch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wen nahm der Humanismus als Vorbild?, Predicted Answer: Bastion des sunnitischen Islams\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann nannten sich die ersten Menschen Humanisten?, Predicted Answer: angesprochen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bedeutete der Begriff \"humanista\" als er das erste mal aufkam?, Predicted Answer: Brief\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Bezug hatte Papst Pius II. zu den Humanisten?, Predicted Answer: einen bedeutenden Humanisten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war ein Grund für den Niedergang des Renaissance Humanismus?, Predicted Answer: fließender Übergang\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo hat die US Army Rekrutierungsstellen?, Predicted Answer: vom Heer der Volksrepublik China, dem Indischen Heer sowie dem Heer Nordkoreas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind Voraussetzungen um dem dem US Army beizutreten?, Predicted Answer: juristischen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wirbt die US-Army für neue Rekruten?, Predicted Answer: übertroffen wird die U.S. Army vom Heer der Volksrepublik China, dem Indischen Heer sowie dem Heer Nordkoreas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wen Rekrutiert die US-Army seit 2006 häufiger als früher?, Predicted Answer: erfolgreich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.17 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Kann man der US-Army ohne High-School-Abschluss beitreten?, Predicted Answer: einen begrenzten Anteil\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Naturkatastrophe gibt es in Oklahoma oft?, Predicted Answer: wiederholt von Dürreperioden und Sandstürmen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die kälteste gemessene Temperatur Oklahomas?, Predicted Answer: mit einer Durchschnittstemperatur von 4 °C der Januar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die wärmste Temperatur Oklahomas gemessen?, Predicted Answer: −27 °\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches große Gebirge liegt in Oklahoma?, Predicted Answer: Tornado Alley liegt, besteht zu bestimmten Jahreszeiten erhöhte Gefahr durch Tornados\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann regnet es in Oklahoma?, Predicted Answer: Oklahoma wird immer wieder von verschiedenen Naturkatastrophen heimgesucht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird benutzt um einen Herzinfarkt Verdacht zu bestätigen?, Predicted Answer: Gamal Abdel Nasser\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An was erkennt man ein Herzinfarkt Verdacht beim EKG?, Predicted Answer: Anschluss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Amerikaner fühlen sich mehr als einer \"Rasse\" angehörig?, Predicted Answer: fast sieben Millionen US-Amerikaner zwei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann bekam ein Asteroid Feynmans Namen?, Predicted Answer: Cassava\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso trat Feynman aus der National Academy of Sciences aus?, Predicted Answer: 1954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Auszeichnung bekam Richard Feynman 1954?, Predicted Answer: Albert Einstein Award\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Auszeichnung wird sei 1993 im Andenken an Feynman vergeben?, Predicted Answer: proteins\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Russische Begriff für Aufklärung?, Predicted Answer: eine neue Bedeutung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer herrschte 1763 über Russland?, Predicted Answer: Paris\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer herrschte vor Katharina II. über Russland?, Predicted Answer: seit 1762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die Moskauer Universität gegründet?, Predicted Answer: 1755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Stadt verbreitete Johann Cristoph Berens die Aufklärung?, Predicted Answer: Sankt Petersburg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer endete die Russische Aufklärung?, Predicted Answer: Endgültig und abrupt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hatte 1647 in der Siedlung Nieuw Amsterdam für Ordnung zu sorgen?, Predicted Answer: Niederländische Westindien-Kompanie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was gab der Wall Street ihren Namen?, Predicted Answer: eine breite Kontinuität\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hieß die Siedlung die später zu New York City wurde ursprünglich?, Predicted Answer: König\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer nannte die Nieuw Amsterdam in New York um?, Predicted Answer: Befehlshaber James, Herzog von York, dem Bruder Charles’ II. von England, der später selbst König wurde. 1667 gaben die Niederländer alle Ansprüche auf die Kolonie im Frieden von Breda auf, in dem ihnen dafür die Rechte an Suriname zugesichert wurden. Im folgenden Dritten Englisch-Niederländischen Krieg nahmen die Niederländer 1673 durch Cornelis Evertsen die Kolonie kurzzeitig wieder ein\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.96 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann gaben die Niederländer die Rechte an New York City auf?, Predicted Answer: Newark Liberty International Airport\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was handelten Niederländer Anfang des 17. Jhd. mit  Indianern auf dem heutigen Land New York Citys?, Predicted Answer: einen lukrativen Fellhandel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer erhielt Anfang des 1614 ein Monopol für den Handel in dem Land des heutigen New York Citys?, Predicted Answer: Compagnie van Nieuwnederlant'' (Neuniederland-Kompanie) von den Generalstaaten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer erhielt 1621 einen Freibrief für den Handel in Amerika?, Predicted Answer: die WIC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde das Land des heutigen New York Citys kolonialisiert?, Predicted Answer: unamerikanische Stadt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für wie viel kaufte ein Niederländer den Indianer das Land Manhattans der Legende nach ab?, Predicted Answer: 1610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann lebte Ulrich von Wilamowitz-Moellendorff?, Predicted Answer: Wer Lohnarbeiter beschäftigte oder von Renten und Wertpapieren lebte, war ausgeschlossen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Einstellung hatte Hans Blüher gegenüber der humanistischen Bildung?, Predicted Answer: Erstarrung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer führte gleichzeitig wie Blüher Kritik an dem neuhumanistischen Schulsystem?, Predicted Answer: Egon Friedell\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer veröffentlichte \"The Tyranny of Greece over Germany\"?, Predicted Answer: 1934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Länder sind Teil der insulare Südostasiens?, Predicted Answer: Gliedstaaten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Länder sind ein Teil von Südostasien?, Predicted Answer: Gliedstaaten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist die zweite Mannschaft vom FC Everton?, Predicted Answer: Duncan Ferguson\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann waren die ersten Spiele der Zweitmannschaft vom FC Everton?, Predicted Answer: 1965, 1984 und 1998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer dominierte die Liga \"The Combination\" im Gründungsjahrzehnt?, Predicted Answer: 1890 gegründeten nationalen Liga „The Combination“ an und dominierte diese in der Folgezeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Liga spielten die Everton Reserves in den 50ern? , Predicted Answer: englischen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie alt sind die Reserve Spieler des FC Everton heutzutage normalerweise?, Predicted Answer: Abstieg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer trainiert die FC Everton Reserve Mannschaft 2019?, Predicted Answer: Duncan Ferguson\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche bekannten Spieler waren in der Everton Academy ausgebildet worden?, Predicted Answer: Wayne Rooney, Richard Dunne, Michael Ball, Gavin McCann, Francis Jeffers und in jüngerer Vergangenheit Tony Hibbert, Leon Osman, James Vaughan und Victor Anichebe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von was sind private Universitäten abhängig?, Predicted Answer: vom Kalender\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer darf in den Deutschland den Titel Universität besitzen?, Predicted Answer: private Hochschulen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was unterscheidet Staatsphilosophie und politische Philosophie?, Predicted Answer: Dieser enge Bezug\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit welchen Bereichen beschäftigt sich die politische Philosophie?, Predicted Answer: Politik, Recht und Geschichte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was muss der Mensch aus seinen natürlicher Umwelt herausziehen?, Predicted Answer: seine biologisch-physiologischen Bedürfnisse aus seiner natürlichen Umwelt heraus zu befriedigen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was zeigt das Kulturerzeugnisse nicht nur die Urbedürfnisse des Menschen stillen?, Predicted Answer: beispielsweise daran\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde der KGB in Estland verboten?, Predicted Answer: Am 23. August 1991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann trat Estland der NATO bei?, Predicted Answer: Mitglied\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.27 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann gibt es in Estland den Euro?, Predicted Answer: Existenz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist sowohl in der Bildenden Kunst als auch Comics wichtig?, Predicted Answer: einige Schnittmengen zwischen beiden Kunstformen. So ist in beiden die Wahl von Bildausschnitt, Perspektive und dargestelltem Moment bzw. Pose bedeutsam\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hatte den größten Einfluss auf den Handel in feudalistischen Ständestaat Polen-Litauen?, Predicted Answer: Antike\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie schränkte Deutschland die aschkenasischen Juden im 18. Jhd. ein?, Predicted Answer: deutlich enger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was für ein politisches System hat Tadschikistan laut Verfassung?, Predicted Answer: eine demokratische Präsidialrepublik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist Tadschikistans Nationalfeiertag?, Predicted Answer: 9. September\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welchem Land gehört die Provinz Berg-Badachschan?, Predicted Answer: den korruptesten der Welt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Emomalij Rahmon als Präsident Tadschikistans wiedergewählt?, Predicted Answer: 2013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann starb Gulmurod Chalimow?, Predicted Answer: Islamischen Staat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf was gab es in Tadschikistan am 4. Sept. 2015 einen bewaffneten überfall in Wachdat?, Predicted Answer: eine Kaserne bzw. ein Polizeirevier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war Anfang 2015 Vizeverteidigungsminister Tadschikistans?, Predicted Answer: John Kasich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo starb Abduchalim Nasarsoda?, Predicted Answer: Vizeverteidigungsminister\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war 2016 Generalstaatsanwalt Tadschikistans?, Predicted Answer: Jussuf Rachmon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.22 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer beschäftigt sich mit den Verschiedenen Emotions Arten?, Predicted Answer: Lehrenden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind Paul Ekmans sieben Basisemotionen?, Predicted Answer: empirisch nachgewiesen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was sehen sich die Zeugen Jehovas?, Predicted Answer: wiederhergestellte wahre Christenversammlung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist der treue und verständige Sklave der Zeugen Jehovas?, Predicted Answer: Gottes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.60 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer litt unter der \"Krise des 17. Jhd.\"?, Predicted Answer: Europa und die Mittelmeerregion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer regierte ende des 16. Jhd. im Osmanischen Reich?, Predicted Answer: Heinrichs IV.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wollten die Engländer von dem Osmanischen Reich?, Predicted Answer: eine Armee zusammen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie standen die Engländer zu islamischen Ländern im 17. Jhd.?, Predicted Answer: Myanmar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist Oberbefehlshaber des Ägyptischen Militärs?, Predicted Answer: George Washington\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ernennt die Gouverneure in Ägypten?, Predicted Answer: Sultan Mustafa IV.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war 2005 Präsident in Ägypten?, Predicted Answer: Hosni Mubarak\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso hat Mohammed Mursi das Amt als Präsident Ägyptens niedergelegt?, Predicted Answer: hester\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist Ägyptens Präsident?, Predicted Answer: Anwar as-Sadat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was für einen Glühfaden nutzen die ersten patentieren Glühlampen?, Predicted Answer: Platin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Gibt es immer noch Kohlenfadenlampen?, Predicted Answer: erhältlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Farbe hat das Licht von Kohlenfadenlampen?, Predicted Answer: rötliche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.10 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurde aus Osmium ein Glühfaden hergestellt?, Predicted Answer: Ein wichtiger Zwischenschritt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Glühfäden ersetzen die Kohleglühfäden?, Predicted Answer: noch empfindlicher\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann wird Florida von Menschen bewohnt?, Predicted Answer: mehreren tausend Jahren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Europäer entdeckte Florida?, Predicted Answer: Juan Ponce de León\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Florida entdeckt?, Predicted Answer: 1513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer sollte die Kolonie \"La Florida\" gründen?, Predicted Answer: Spanien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Weshalb musste Pánfilo de Narváez mit der Erkundung Floridas aufhören?, Predicted Answer: 1528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bei was starb De Soto?, Predicted Answer: Narváez landete auch De Soto an der Westküste\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie weit entwickelt sind Platzhocker Vögel beim schlüpfen?, Predicted Answer: intelligenter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo sind Platzhocker Vögel bis sie fliegen können?, Predicted Answer: intelligenter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer füttert Nesthocker Vögel so lange sie sich nicht selbstständig ernähren können?, Predicted Answer: die Jungvögel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo ist der Genetiker Harry Ostrer angestellt?, Predicted Answer: DNA von 237 Menschen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Gruppe ist die DNA von Juden ähnlich?, Predicted Answer: Bevölkerungsgruppe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel wollte die EZB monatlich ab März 2015 für den Ankauf von Wertpapieren ausgeben?, Predicted Answer: 60 Mrd. Euro\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel wollte die EZB insgesamt für das EAPP ausgeben?, Predicted Answer: 60 Mrd. Euro\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurden die Notwendigkeit der Ausgaben für die EAPP der EZB begründet?, Predicted Answer: diese Entscheidung durch den Umstand\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wollte die EZB mit dem EAPP erreichen?, Predicted Answer: ausgeben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:02<00:00,  1.27 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel investierten die USA in das ähnliche Prinzip, dass die EAPP abschaute, zwischen 2009 und 2014?, Predicted Answer: wom\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Er war 2015 Italienischer Finanzminister?, Predicted Answer: John Kasich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.27 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Einstellung hatte der Bundesbank-Präsident gegenüber dem EAPP Programm?, Predicted Answer: Zu den Gegnern des EZB-Anleihenkauf-Programms gehörte auch Bundesbank-Präsident und damit Mitglied des EZB-Rats Jens Weidmann\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das BVerfG?, Predicted Answer: Bundesverfassungsgericht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißen Valencias Universitäten?, Predicted Answer: Universität Valencia und Polytechnische Universität Valencia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Studenten hat Valencia?, Predicted Answer: 80.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Geld musste Spanien aufgrund der Sparpolitik 2012 einsparen?, Predicted Answer: ca. 40 Milliarden Euro\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo in Hannover findet man Bauten von Georg Ludwig Friedrich Laves?, Predicted Answer: das Gartenhaus der Kammerfrau von Beckedorf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Gebäude ist der Sitz des Niedersächsischen Landtages?, Predicted Answer: Hannover\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird für die Bestimmung des Osterdatums verwendet?, Predicted Answer: die Periode des Mondzirkels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie groß ist der Fehler bei der Bestimmung des Osterdatums?, Predicted Answer: bei Primaten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf was beruhen Browserdatenstatistiken?, Predicted Answer: Hochrechnungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was übermittelt ein Browser bei jeder Anfrage an den Server womit er sich identifizieren lässt?, Predicted Answer: User-Agent''-Headers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der meist benutzte Browser laut der Statistik von Netmarketshare von 2019?, Predicted Answer: abrufbar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird das Gewicht von Papier meistens angegeben?, Predicted Answer: Die Masse\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel wiegt ein A4 Blatt?, Predicted Answer: 1000 Blatt A4-Papier wiegen 5 kg, 200.000 Blatt A4-Papier wiegen rund eine Tonne\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird Papier von Pappe unterschieden?, Predicted Answer: flächenbezogenen Masse\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was versteht man in den USA unter dem Basisgewicht von Papier?, Predicted Answer: In den USA und in Ländern, die Papiere in US-Formaten verwenden, versteht man dagegen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welchem Sprachtyp gehört Russisch?, Predicted Answer: serbisch-russisch-kirchenslawische Mischsprache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Zeit Typen hat die deutsche Sprache?, Predicted Answer: nicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Autos werden von Ford südlich von Valencia gebaut?, Predicted Answer: Horchata\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Arbeitsplätze schafft das Ford Werk südlich von Valencia?, Predicted Answer: ˈlɛn(t)si̯a; spanisch ; valencianisch/katalanisch: València , deutsch veraltet: ''Valentz'') ist eine Großstadt im östlichen Teil Spaniens. Die Hauptstadt der autonomen Valencianischen Gemeinschaft und der Provinz Valencia liegt rund 320 km südöstlich der Landeshauptstadt Madrid an der Mündung des Turia ins Mittelmeer und ist mit  (Stand ) Einwohnern nach Madrid und Barcelona die drittgrößte Stadt des Landes. Im Großraum Valencia leben rund 2 Millionen Menschen.\n",
            "Valencia ist Sitz des römisch-katholischen Erzbistums Valencia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Regierungssystem hatte Polen ende des 18. Jahrhunderts?, Predicted Answer: North Carolina ein\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war der Hauptgegner der polnischen Aufklärung?, Predicted Answer: Ignacy Krasicki\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange war Stanslaw August Poniatowskis König von Polen?, Predicted Answer: erste moderne polnische Historiker\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer veröffentlichte die erste polnische Enzyklopädie?, Predicted Answer: Albert Einstein\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Voraussetzung für die Weitergabe von gelernten Aktionen bei Säugetieren?, Predicted Answer: das Leben in Gruppen mit Sozialstrukturen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann gibt es die Option eine Ausbildung in Teilzeit zu machen?, Predicted Answer: 1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird gebraucht im eine Ausbildung in Teilzeit zu machen?, Predicted Answer: betriebliche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Stunden wöchentlich muss man in der Ausbildung arbeiten um in der Regulären Zeit fertig werden zu dürfen?, Predicted Answer: beans\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt der Entwicklungszeitraum des Menschen in dem er Geschlechtsreif wird?, Predicted Answer: weitergegeben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das bekannteste Essen der valencianischen Küche?, Predicted Answer: das Reisgericht Paella\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist eine \"Paellera\"?, Predicted Answer: Pfanne\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.03 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Woher kommt der Reis Bomba?, Predicted Answer: Valencia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was für ein Gericht ist die Fideuà?, Predicted Answer: Reisgericht Paella\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist ein typisch valencianisches Gericht aus Erdmandeln?, Predicted Answer: die Horchata\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus welchem Land kommt Tigran Petrosjan?, Predicted Answer: Armenien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie oft hat die Armenische Fußballmannschaft in der WM Endrunde mitgespielt?, Predicted Answer: 1992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist Khoren Gevor größter Titel?, Predicted Answer: Europameister\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Staatsbürgerschaft verlor Arthur Abraham?, Predicted Answer: armenische\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was erschwerte die Entwicklung der Zentralafrikanischen Republik bis zur Unabhängigkeit hauptsächlich?, Predicted Answer: erschwerten die wirtschaftliche Entwicklung des Landes bereits während der Kolonialzeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche großen Probleme entstanden in der Zentralafrikanischen Republik seit der Unabhängigkeit?, Predicted Answer: nachlassende Verankerung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel der Einwohner der Zentralafrikanischen Republik leben auf dem Land?, Predicted Answer: wenige Migranten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist größte Wirtschaftszweig in der Zentralafrikanischen Republik?, Predicted Answer: Landwirtschaft\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sieht die Handelsbilanz der Zentralafrikanischen Republik aus?, Predicted Answer: Stalin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Touristen gab es in der Zentralafrikanischen Republik 2005?, Predicted Answer: 12.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu wem gehört Uramin?, Predicted Answer: den korruptesten der Welt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was brauch man seit 2004 beim EU-Grenzübertritt für seinen Hund?, Predicted Answer: ein EU-Heimtierausweis mit dem Nachweis einer gültigen Tollwutimpfung zur Identifikation mitgeführt werden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann wurde in Pennsylvania niemand mehr hingerichtet?, Predicted Answer: 1999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen sind in Pennsylvania in einer Todeszelle und warten auf die Hinrichtung?, Predicted Answer: sehr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war 2007 Gouverneur von Pennsylvania?, Predicted Answer: Tom Wolf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wurde nach Ed Rendell Gouverneur Pennsylvanias?, Predicted Answer: SG:PART\n",
            "                   'Liebst du mich?'                                                                          (Erelt, 2009, p. 16)\n",
            "           (23) Ta       lä-k-s                       ära   või?\n",
            "                   3SG    gehen-PAST-3SG weg oder\n",
            "                   'Sie/Er ist weggegangen, oder?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wurde nach Tom Corbett Gouverneur Pennsylvanias?, Predicted Answer: Mayella\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Haltung zur Todesstrafe hatte Tom Corbett während seiner Amtszeit als Gouverneur?, Predicted Answer: Wiedereinführung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher US-Bundestaat hat im Verhältnis zu den Einwohner am wenigsten Hinrichtungen?, Predicted Answer: Ohio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Universität war maßgebend beteiligt bei der ersten Unabhängigkeit Estlands?, Predicted Answer: Valencia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Estland das erste mal Unabhängig?, Predicted Answer: 1918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann trat Estland dem Völkerbund bei?, Predicted Answer: jährlich mindestens 5 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Kapazität hat eine Leidener Flasche, Predicted Answer: Kondensators\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus was wird eine Leidener Flasche gebaut?, Predicted Answer: einem Glasgefäß\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Isolator bei einer Leidener Flasche?, Predicted Answer: Das Glas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurde das Prinzip der Leidener Flasche entdeckt?, Predicted Answer: 1745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was schaffte Benjamin Franklin mit der Leidener Flasche und einem Drachen?, Predicted Answer: verband\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Einwohner hat die Metropolregion Greater Boston?, Predicted Answer: 4,4 Millionen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welcher Metropolregion gehört Brookline?, Predicted Answer: Greater Boston\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ergänzte das Modell eines Kurzzeitgedächtnis?, Predicted Answer: Baddeley\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Haben Tiere im Vergleich zu Menschen oft einen Herzinfakt?, Predicted Answer: ausweises\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Währungen sind Teil des Vergleich Korbes des USDX, Predicted Answer: Euro\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit wie vielen Währungen wird der US-Dollar beim USDX verglichen?, Predicted Answer: Euro\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann war die Glorious Revolution in England?, Predicted Answer: bereitete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür setzte sich John Milton während der Aufklärung ein?, Predicted Answer: Vertreter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: War die Glorious Revolution gewaltsam?, Predicted Answer: deutsche Heereskraft vertragsgemäß unter der Führung des Königs von Preußen zusammengefasst\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Woher kam König Wilhelm III.?, Predicted Answer: niederländischen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wurde 1689 König Englands?, Predicted Answer: nicht nach Hause?'                                            (Erelt, 2009, p. 16)\n",
            "           (21) On             sul          täna  aega?\n",
            "                   sein.3SG   2SG:AD heute Zeit.PART                                                    \n",
            "                  'Hast du heute Zeit?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann war Howard Kendall Trainer vom FC Everton?, Predicted Answer: Duncan Ferguson\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Position spielte Howard Kendall beim FC Everton?, Predicted Answer: Mittelfeld\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Liga spielten die Blackburn Rovers als Howard Kendall Trainer wurde?, Predicted Answer: dritten Liga\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ging das Fünftrunden Pokalspiel Rückspiel gegen Oxford United aus?, Predicted Answer: die Wende\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange war der FC Everton ungeschlagen nach dem Sieg gegen Oxford United im fünftrunden Pokalspiel?, Predicted Answer: nicht ungewöhnlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer gewann 1984 den FA Cup?, Predicted Answer: FC Everton\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer schoss die Tore im FA Cup Pokalfinale 1984?, Predicted Answer: FC Everton\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Gegen wen spielte der FC Everton 1984 im FA Cup Pokalfinale?, Predicted Answer: FC Watford\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wurde in der Saison 1984/85 von der PFA zu Englands Fußballer des Jahres gewählt?, Predicted Answer: Reid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war beim FC Everton Kapitän in der Saison 1984/85, Predicted Answer: Gary Lineker\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von welchem Verein wechselte Pat Van Den Hauwe zum FC Everton, Predicted Answer: einem anderen Namen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer gewann die englische Fußball Meisterschaft in der Saison 1984/85, Predicted Answer: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer gewann 1985 den FA Cup?, Predicted Answer: FC Everton\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welchem Verein wechselte Gary Lineker 1986?, Predicted Answer: FC Barcelona\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: zum wievielten mal hintereinander stand der FC Everton 1986 im FA Cup Finale?, Predicted Answer: an der Tabellenspitze\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welche Positionen wurde 1986 beim FC Everton hauptsächlich Spieler verplfichtet?, Predicted Answer: Gary Lineker\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Die wievielte Meisterschaft gewann der FC Everton 1987, Predicted Answer: englische\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Verein trainierte Howard Kendall nach dem FC Everton?, Predicted Answer: vielmehr investierte Kendall in Defensiv- und Mittelfeldspieler\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wann gab es in der Antarktis die ersten Eisflächen?, Predicted Answer: kaum Bestrebungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: welche Erdepoche war vor Miozän?, Predicted Answer: erdgeschichtlichen Epochen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ging es zur Erdepoche Miozän über?, Predicted Answer: die Senatsmehrheit schließlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.22 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann trennte sich die Antarktis von Südamerika?, Predicted Answer: die Drakestraße\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war vor dem Eis in der Antarktis?, Predicted Answer: Trail of Tears\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Weshalb gibt es kaum Pflanzen in der Antarktis?, Predicted Answer: quantifizierbaren Ausmaß\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Gegenteil von Glaziale?, Predicted Answer: Trail of Tears\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Haben wir im Moment eine Warm- oder Kaltzeit?, Predicted Answer: Winter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Fantastic Four #176 veröffentlicht?, Predicted Answer: 1976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo konnte man den Namen Marvel Comics in den Comics von Marvel Comics wieder finden?, Predicted Answer: Marvel-Superhelden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.95 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo steht der Schiedsrichter beim Canadian Football vor dem Snap?, Predicted Answer: Single''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer zählt mit dem Schiedsrichter vor dem Snap das Down beim Kanadischen Football?, Predicted Answer: Der Referee\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer überwacht vor dem Snap die Bewegungen der Offensive-Line-Spieler auf seiner Seite beim Kanadischen Football?, Predicted Answer: Der Referee\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Teil des Schiedsrichter Teams überwacht beim Kanadischen Football die Auswechslungen?, Predicted Answer: Fußballjargon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist beim Kanadischen Football für die Kontrolle der 20-Sekunden-Uhr zuständig?, Predicted Answer: verantwortlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo steht in dem Österreichischem Gesetz wie man Haushunde halten darf?, Predicted Answer: ''Polizei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie oft muss ein Haushund in Österreich täglich mindestens ausgeführt werden?, Predicted Answer: mehrmals\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ab wann darf man in Österreich Welpen von der Mutter entfernen?, Predicted Answer: nach acht Wochen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hoch ist die Strafe wenn man den Kot seines Hundes in Wien nicht entfernt?, Predicted Answer: nötig\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was machten die USA gegen die Piraten der  Barbareskenstaaten?, Predicted Answer: den Krieg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum brauchten die Amerikaner eine eigene See Armee?, Predicted Answer: Napoleon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war 1785 der US-Botschafter in Frankreich?, Predicted Answer: Thomas Jefferson\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf welche Art wollten die Amerikaner die Piraterie der Barbareskenstaaten anfangs verhindern?, Predicted Answer: diese Anmerkungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel kosteten die Tribut- und Lösegeldzahlungen die USA 1800?, Predicted Answer: 20 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wurde 1801 Präsident der USA?, Predicted Answer: Jefferson\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Über welche Schiffe hatte Edward Prieble den Oberbefehl im ersten Barbareskenkrieg?, Predicted Answer: Tripolis\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann war die Schlacht von Derna?, Predicted Answer: statt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann endete der Amerikanisch-Tripolitanische-Krieg?, Predicted Answer: mit einer Niederlage der französischen Streitkräfte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ab wann herrschte in Myanmar ein Militärdiktatur?, Predicted Answer: Monogamie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie nannte sich die Militärdiktatur in Myanmar?, Predicted Answer: Potential\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus wie vielen Ministern bestand das Kabinett während der Militärdiktatur in Myanmar?, Predicted Answer: 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Provinzen hat Galicien?, Predicted Answer: vier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Prozent der Fläche Spaniens hat Galicien?, Predicted Answer: 5,8 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Prozent der Ortschaften Spaniens liegen in Galicien?, Predicted Answer: 59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Flugstunden überlebte die Hündin Laika in der Erdumlaufbahn?, Predicted Answer: ausweises\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Woran starb die Hündin Laika?, Predicted Answer: Eisenhower\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war das \"Hilton Assignment\"?, Predicted Answer: ein Plan zur Machtübernahme in Libyen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde das \"Hilton Assignment\" ausgeführt?, Predicted Answer: 1999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer opferte 1988 sein Leben um Gaddafi vor einem Anschlag zu retten?, Predicted Answer: Gaddafi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was hat Die Sowjetunion 1943 mit der Tschechoslowakei geschlossen?, Predicted Answer: abgeschlossen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange waren das Abkommen der Sowjetunion und der DDR vom 12. März 1957 gültig?, Predicted Answer: Truppenstationierung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wollte 1963 dem Warschauer Pakt beitreten?, Predicted Answer: Mongolische Volksrepublik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum wäre für den beitritt der Mongolischen Volksrepublik zum Warschauer Pakt ein Sonderprotokoll nötig gewesen?, Predicted Answer: Dazu hätte ein Sonderprotokoll gefasst werden müssen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum ist die Mongolische Volksrepublik nicht dem Warschauer Pakt beigetreten?, Predicted Answer: Die Frage war nicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was hat die Mongolische Volksrepublik anstatt eines Beitritts in den Warschauer Pakt bekommen?, Predicted Answer: beizutreten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür steht KSZE?, Predicted Answer: Sicherheit und Zusammenarbeit in Europa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.82 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Womit kann man bei der \"Xbox Live Arcade\" spiele kaufen?, Predicted Answer: Arcade-Spiele für die Xbox 360 an. Über diesen Service können Benutzer mit einem Internetzugang gegen ein Entgelt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange kann ein aus dem \"Xbox Live Arcade\" gekauftes Spiel gespielt werden?, Predicted Answer: Arcade-Spiele für die Xbox 360 an. Über diesen Service können Benutzer mit einem Internetzugang gegen ein Entgelt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Spiel ist bei manchen Xbox Versionen bereits vorinstalliert?, Predicted Answer: Hexic HD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Spiel ist im \"Xbox Live Arcade\" bis jetzt Bestseller?, Predicted Answer: die Umsetzung des Kartenspiels Uno\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Sportart wird in der Minor League gespielt?\n",
            ", Predicted Answer: Teams\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Skigebiete hat Montana?, Predicted Answer: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.21 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum tragen Menschen Kleidung?, Predicted Answer: heutigen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Kleidungsstück schütz bei der Handhabung einer Motorsäge?, Predicted Answer: Schnittschutzhose\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Problem mit zu eng anliegender Kleidung?, Predicted Answer: Krankheiten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer führte das Deutsche Militär während der Deutsch Französischen Kriege an?, Predicted Answer: 1933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele der deutschen Pferde starben während des Deutsch Französischen Krieges?, Predicted Answer: 1871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Truppen hatten die Deutschen insgesamt im Deutsch Französischen Krieg?, Predicted Answer: Viele bekannte und erfahrene Offiziere des Heeres wie Robert E. Lee und Ulysses Grant, die teilweise Jahrzehnte in Kameradschaft gedient hatten, traten gegeneinander an\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wollte seinen Patriotismus Deutschland gegenüber durch die Teilnahme am Deutsch-Französischen-Krieg zeigen?, Predicted Answer: Wer in der Gesellschaft aufsteigen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele jüdische Soldaten hatte Deutschland im Deutsch-Französischen-Krieg?, Predicted Answer: Stalin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war der eigentliche Plan der Franzosen im Deutsch-Französischen-Krieg?, Predicted Answer: ''Vaterländischer Krieg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ist Frankreich offensiv, oder defensiv an den Deutsch-Französischen-Krieg herangegangen?, Predicted Answer: Defensiv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Truppen hatten die Franzosen am Anfang des Deutsch-Französischen-Krieges?, Predicted Answer: Viele bekannte und erfahrene Offiziere des Heeres wie Robert E. Lee und Ulysses Grant, die teilweise Jahrzehnte in Kameradschaft gedient hatten, traten gegeneinander an\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo war der Vorteil der Französischen Ausrüstung im Deutsch-Französischen-Krieg?, Predicted Answer: einzige strukturelle Vorteil der französischen Armee war die dem preußisch-deutschen Ausrüstungsstandard weit überlegene Infanteriebewaffnung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ab wann führte der preußische Generalstab eine eigene Eisenbahnsektion?, Predicted Answer: 1864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange brauchten die Franzosen um für den Deutsch-Französischen-Krieg Kriegsbereit zu sein?, Predicted Answer: untergeordneter Bedeutung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Kilometer hat das Straßennetz Portugals 2008?, Predicted Answer: 82.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer unterhält die kostenpflichtigen Straßen Portugals größtenteils?, Predicted Answer: Die Republik Guinea-Bissau\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist Exergie?, Predicted Answer: maximalen Arbeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie kann der exergetische Anteil bei einer konstant liegenden Wärmequelle berechnet werden?, Predicted Answer: Im ersten Fall\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird für die Berechnung der Carnot-Wirkungsgrad Methode benötigt?, Predicted Answer: Anteil über den Carnot-Wirkungsgrad aus der oberen Prozess-Temperatur und der Umgebungstemperatur bestimmt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Regionen hatte Eritrea vor der Verwaltungsreform von 1996?\n",
            ", Predicted Answer: sechs reduziert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Land kolonialisierte Eritrea?, Predicted Answer: Kaiser Haile Selassie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Hauptsatd großbritanniens, Predicted Answer: stark durch die britische Kultur geprägt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sieht die geologische Beschaffenheit Südostenglands aus?, Predicted Answer: Sedimentgestein\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Teil von Großbritannien liegt London?, Predicted Answer: größten Teil des öffentlichen Personennahverkehrs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Völker haben versucht, England zu erobern?, Predicted Answer: Briten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.16 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die erste Person in Alabama hingerichtet?, Predicted Answer: Jude erachtet wird, konnte je nach Gesellschaft darüber entscheiden, ob diese Person einen bestimmten Beruf ausüben, eine Ausbildung erhalten, an einem bestimmten Ort leben, in Haft gehalten, verbannt oder mit behördlicher Billigung ermordet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.75 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war ab 1927 die beliebteste Hinrichtungsmethode in Alabama?, Predicted Answer: Erhängen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher US-Staat ist der einzige bei dem der Richter Die Todesstrafe trotz anderem Urteil der Jury aussprechen kann?, Predicted Answer: Alabama\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür steht Grün als Signalfarbe?, Predicted Answer: Ministerium\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Farbe wird benutzt um Vorgänge zu zeigen, die erlaubt sind?, Predicted Answer: Grün\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist eine Grünewelle?, Predicted Answer: Oklahoma eine Sonderstellung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Hierarchiestufe hat Grün in deutschen Ämtern bei deren Farbcode?, Predicted Answer: streng\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die Leitlinie der AWMF zu Begutachtung von Schmerz zuletzt aktualisiert?, Predicted Answer: Am 31. Mai 2012 und am 7. November 2017 wurde die Leitlinie der AWMF zur ''Ärztlichen Begutachtung von Menschen mit chronischen Schmerzen'' aktualisiert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür ist die Leitlinie der AWMF wie Ärzte Schmerz begutachten sollen?, Predicted Answer: ''Ärztlichen Begutachtung von Menschen mit chronischen Schmerzen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo leben deutschstämmige in Tadschikistan heutzutage größteils?, Predicted Answer: Heute gehören deutschstämmige Menschen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer bewohnt heute die von Deutschen gegründete Stadt Taboschar in Tadschikistan?, Predicted Answer: Ehemalige deutsche Siedlungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Stadt ist die deutsche Botschaft in Tadschikistan?, Predicted Answer: Nezahualcóyotl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie werden die Alpen in Österreich, Südtirol und Deutschland unterteilt?, Predicted Answer: ''West-'' und ''Ostalpen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum werden die Alpen in \"West-\" und \"Ostalpen\" unterteilt?, Predicted Answer: Österreich, Südtirol und Deutschland\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist Programmiersprachen ähnlich?, Predicted Answer: BASIC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt die Legislative von Rajasthan?\n",
            ", Predicted Answer: aus einem Einkammernparlament, der ''Rajasthan Legislative Assembly'' oder ''Rajasthan Vidhan Sabha''.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange ist die Amtszeit Abgeordneter der Legislative Rajasthans?, Predicted Answer: alle fünf Jahre durch Direktwahl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo ist der Sitz der Legislative Rajasthans?, Predicted Answer: Jaipur\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wählt den Regierungschefs Rajasthans?, Predicted Answer: Chief Minister\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer steht über dem Regierungschefs Rajasthans in Rajasthans?, Predicted Answer: Chief Minister\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wovon ist Malis Literatur stark beeinflusst?, Predicted Answer: Tibet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mali war Kolonie von welchem Land?, Predicted Answer: England\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.16 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welche Sprache ist die meiste moderne Literatur Malis geschrieben?, Predicted Answer: französischer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist der Vater frankophoner malischer Literatur?, Predicted Answer: Mitbürger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Parteisystem hat Mali heutzutage?, Predicted Answer: Einparteienstaat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Unterschied zwischen der CIA und einem Nachrichtendienst?, Predicted Answer: ein ziviler Geheimdienst\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Inwiefern unterscheiden sich die CIA und NSA?, Predicted Answer: Mike Pompeo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchen Jahren fand in Hannover der Evangelische Kirchentag statt?, Predicted Answer: 1949, 1967, 1983 und 2005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was gehört zum Stadtkirchenverband Hannover?, Predicted Answer: Alle landeskirchlichen evangelischen Kirchengemeinden Hannovers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind Lon Fullers acht Prinzipien einer Rule of Law?, Predicted Answer: beschreibt in seinem Werk „The Morality of Law“\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind Orphan-Gene?, Predicted Answer: linienspezifisch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was unterscheidet Orphangene von anderen Genen?, Predicted Answer: In diesem Aspekt unterscheidet er sich vom Mahayana\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Gene haben Menschen, die bei Schimpansen nicht vorkommen?, Predicted Answer: genetische Vorgänge\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Gene haben Schimpansen, die bei Menschen nicht vorkommen?, Predicted Answer: 780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann gibt es in Hannover einen Oberbürgermeister, der direkt gewählt wird?, Predicted Answer: 1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange sollte die Amtszeit von Stefan Schostok dauern?, Predicted Answer: möglich hinausschieben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum hat Stefan Schostok sein Amt früher verlassen?, Predicted Answer: Im Oktober 2013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wurde als neuer Oberbürgermeister Hannovers 2019 ausgewählt?, Predicted Answer: Jude\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Aufgabe des Oberbürgermeisters in Hannover?, Predicted Answer: einen direkt gewählten hauptamtlichen Oberbürgermeister\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Einwohner hat Thüringen?, Predicted Answer: 2,14 Millionen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Bewohner Thüringens kommen aus dem Ausland?, Predicted Answer: Auslaufen des Solidarpaktes im Jahr 2019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Land liegt das Zentrum des alten Persiens heutzutage?, Predicted Answer: Iran\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Gebirge ist nördlich des Irans?, Predicted Answer: ein zeitweise deutlich größeres Gebiet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.27 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Länder liegen östlich des Irans?, Predicted Answer: Gliedstaaten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele iranischstämmige Menschen leben derzeit außerhalb des Iran?, Predicted Answer: etwa vier Millionen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.17 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wohin wandert die iranische Bevölkerung aus?, Predicted Answer: Zentralasien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.83 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Ergebnis der Auswanderung junger Menschen aus Iran? , Predicted Answer: isoliert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.21 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Ausländer lebten 2011 in Iran?, Predicted Answer: 1,7 Millionen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.96 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Woher kommen die meisten Ausländer in Iran?, Predicted Answer: knapp die Hälfte als Flüchtlinge\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum können sich Afghanen leicht im Iran integrieren?, Predicted Answer: relativ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche andere Nationen außer Afghanen leben im Iran?, Predicted Answer: 50.000 Iraker und 17.000 Pakistaner\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wanderte nach North Carolina Anfang des 20. Jahrhundert ein?, Predicted Answer: High Rock Mountain\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Gebiete in North Carolina wurden von den schottisch-irischen und nord-englischen Einwanderern besiedelt?, Predicted Answer: Möbel- und Textilproduktion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer siedelte östlich des heutigen Fayetteville im 18. Jahrhundert? , Predicted Answer: Walisische Einwanderer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welchem Ort von North Carolina haben sich die Hugenotten und Deutschschweizer niedergelassen?, Predicted Answer: West\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Unterschied zwischen elektrischen und reziprok- magnetischen Antennen?, Predicted Answer: große\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hoch ist der Feldwellenwiderstand im freien Raum?, Predicted Answer: 377 Ω\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann begann Frankreich Mali zu erobern?, Predicted Answer: 1899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.33 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum wollte Frankreich Mali erobern?, Predicted Answer: 1899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.27 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war der erste Gouverneur der Kolonie Französisch- Sudan?, Predicted Answer: Louis Albert Grodet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.12 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war die Hauptstadt der Kolonie Französisch- Sudan?, Predicted Answer: Bamako\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die Bahnlinie nach Dakar in Mali fertig gestellt?, Predicted Answer: 1904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was garantierte das aktive und passive allgemeine Wahlrecht im kolonisierten Mali?, Predicted Answer: 1956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.02 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde das Frauenwahlrecht im kolonisierten Mali eingeführt?, Predicted Answer: Damit war das Frauenwahlrecht eingeführt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann haben die Kolonien Senegal und Französisch- Sudan ihre Unabhängigkeit als Mali- Föderation bekommen?, Predicted Answer: vereinigten sich die Kolonien Senegal und Französisch-Sudan am 4. April 1956 und erklärten sich als Mali-Föderation am 20. Juni 1960 unabhängig\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.16 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann haben sich die Kolonien Senegal und Französisch- Sudan vereinigt?, Predicted Answer: am 4. April 1956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum zerbrach die Mali- Föderation 1960?, Predicted Answer: Unabhängigkeit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.15 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann erklärte die frühere Kolonie Französisch- Sudan endgültig ihre Unabhängigkeit?, Predicted Answer: 22. September 1960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.06s/ Batches]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Woran arbeitete von Neumann ab 1943?, Predicted Answer: Von Neumann\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war ein der Hauptarbeitsgebiete von Neumann bei der Army und Navy?, Predicted Answer: gefragter Berater\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie war von Neumann am Zweiten Weltkrieg beteiligt?, Predicted Answer: uklearbomben-Programms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Verfahren hat John von Neumann entwickelt?, Predicted Answer: Ideen schnell aufgriff und mit atemberaubender Geschwindigkeit eigene Theorien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum hatten andere Menschen Angst vor von Neumann?, Predicted Answer: Army und Navy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Inwiefern hat von Neumann bei dem Abwurf der Atombomben auf Japan mitgemacht?, Predicted Answer: Mitglied des Target Committee\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was spielt eine große Rolle in der Wirtschaft von Mali?, Predicted Answer: hatte diese Rolle bereits in der Vergangenheit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen in Mali sind im Bereich der Landwirtschaft beschäftigt?, Predicted Answer: 70 bis 80 % der erwerbstätigen Bevölkerung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Fläche kann für die Landwirtschaft im Mali genutzt werden?, Predicted Answer: gut drei Prozent\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Teil von Mali sind regelmäßig Dürren zu beobachten?, Predicted Answer: Ära Traorés\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum gibt es in der Region Gao keine regelmäßige Ernte mehr?, Predicted Answer: unterschiedlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.13 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird im Mali hauptsächlich angebaut?, Predicted Answer: Höhere Bildung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was hat man vor, mit dem Office du Niger im Mali zu machen?, Predicted Answer: nachgesagt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie stark ist die Zahl der Angler seit 1967 im Mali gestiegen?, Predicted Answer: wieder stark an, um 2010 95.640 t zu umfassen. Die Zahl der Fischer stieg seit 1967 von 70.000 auf über 500.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchen Gebieten von Deutschland wird der Karneval primär gefeiert?, Predicted Answer: katholischen Kantonen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird der Karneval in Sachsen und Brandenburg genannt?, Predicted Answer: Fasching\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.82 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist der Begriff \"Karneval\" in Deutschland entstanden?, Predicted Answer: erstmals Ende des 17. Jahrhunderts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Woher kommt das Wort \"Karneval\"?, Predicted Answer: starke interne Migration\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Hauptaufgabe von Thermal Vias?\n",
            ", Predicted Answer: Durchkontaktierungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Wärmeleitwert hat Kupfer?\n",
            ", Predicted Answer: 300 W/(m·K))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.11 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird bei Wassergekühlten Leiterplatten vor dem Zusammenbau getan?, Predicted Answer: feine Nuten an Ober- und Unterseite der Innenlagen gefräst\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist ein neues Prinzip um Leiterkarten besser zu kühlen?, Predicted Answer: Krieg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer herrschte zur Zeit der Luxemburgkrise in Preußen?, Predicted Answer: Katharina II.,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Bis wann war Luxemburg ein Teil deutschlands?, Predicted Answer: bisher nur im Planungsstadium\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was verlangte Frankreich von Preußen nach französisch- preußischen Verhandlungen 1866? , Predicted Answer: Erbfolgekrieg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für was war Wilhelm III. bereit Frankreich Luxemburg abzugeben, Predicted Answer: finanzielle Entschädigung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Gebiet beanspruchte Frankreich 1866?, Predicted Answer: Luxemburg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wessen Unterstützung wollte Frankreich bei den Bestrebungen, Luxemburg in französischen Besitz zu bringen?, Predicted Answer: Krieg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Durch welches Zusammentreffen wurde die Luxemburgkrise  beendet?, Predicted Answer: eine friedliche Beilegung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Unter wessen Herrschaft stand Luxemburg vor der Luxemburgkrise?, Predicted Answer: Satans\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr kam es zur Luxemburgkrise?, Predicted Answer: 1867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie verhinderte Bismarck den Verkauf von Luxemburg an Frankreich?, Predicted Answer: schleppender verlief\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was für einen Krieg führte Israel 1948?, Predicted Answer: dauerte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer erklärte Israel bei der Gründung den Krieg?, Predicted Answer: Chamenei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange ging der Israelische Unabhängigkeitskrieg?, Predicted Answer: zurückgeschlagen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo machte Israel große Ländergewinne währen des Unabhängigkeitskrieges 1948, Predicted Answer: Israel gegenüber dem Teilungsplan erhebliche Gebietsgewinne – vor allem im westlichen Galiläa um Akko und im nördlichen Negev – brachte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Araber flohen während des Unabhängigkeitskrieges 1948 aus Palästina?, Predicted Answer: 850.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Der Großteil der Israelischen Bevölkerung war ab 1949 teil welcher Religion?, Predicted Answer: religiöse Identität\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus welchem Grund gab es ab 1949 mehr Juden als Araber in Israel?, Predicted Answer: Westjordanland\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Partei gewann die Wahl zur Verfassungsgebenden Versammlung 1949 in Israel?, Predicted Answer: Mapei-Partei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Staaten führten die Suez-Kampagne?, Predicted Answer: Frankreich, Großbritannien und Israel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war der Plan der Suez-Kampagne?, Predicted Answer: Nach der Nationalisierung des Sueskanals\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum wurde die Suez-Kampagne beendet?, Predicted Answer: Nach der Nationalisierung des Sueskanals, die Ägypten gegen bestehendes Recht durchführte, beschlossen Frankreich, Großbritannien und Israel 1956 die Sues-Kampagne. Nach einem israelischen Angriff sollten die beiden ehemaligen Großmächte als scheinbar neutrale Kräfte intervenieren und das Kanalgebiet besetzen. Am 29. Oktober 1956 stießen israelische Truppen in den Gazastreifen und den Sinai vor, und am 5. November begannen die europäischen Truppen zu landen, doch die Kampagne musste beendet werden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer sorgt dafür, dass Israel Zugang zu Internationalen Wasserwegen hat?, Predicted Answer: Die USA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was umfasst die HDTV-Norm?, Predicted Answer: Unterscheidung eine Grundnomenklatur\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.96 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird die Bildwiederholungsrate angegeben?, Predicted Answer: halbiert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.82 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür steht \"i\" bei HDTV-Kennzeichnungen?, Predicted Answer: technische\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.15 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind Pixel?, Predicted Answer: 3840 × 2160 Pixel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Möglichkeiten des Bildaufbaus gibt es bei HDTV?, Predicted Answer: Grundnomenklatur\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist Materie in der klassischen Pyhsik?, Predicted Answer: tuberkulöse\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was hat die Definition von Materie in der modernen Physik stark beeinflusst?, Predicted Answer: inklusiver\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist alles Materie?, Predicted Answer: eine Sammelbezeichnung für alles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.10 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie oft muss eine Uhr im Jahr wegen der Sommerzeit umgestellt werden?, Predicted Answer: Russland\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Mexiko-Stadt in zwei Teile aufgeteilt?, Predicted Answer: nur sehr knapp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie groß war der um Mexiko-Stadt liegende Bezirk bei dessen Abtrennung von der Stadt?, Predicted Answer: Lutetia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt der Bezirk um Mexiko-Stadt bei der Abtrennung?, Predicted Answer: ''île de la Cité\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo siedeln die Menschen der Oberschicht in Mexiko-Stadt hauptsächlich?, Predicted Answer: im Westen und Süden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer machte den Westen Mexiko-Stadts zu einem beliebten Wohnviertel?, Predicted Answer: Kaiser Maximilian\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist im Norden Mexiko-Stadts?, Predicted Answer: Kaukasus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Einwohner hat die Stadt Naucalpán?, Predicted Answer: 792.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.15 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Metalle wurden in der Antarktika bis jetzt entdeckt?, Predicted Answer: keine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel Kohle wird unter dem Eis in der Antarktis erwartet?, Predicted Answer: einiger hundert Milliarden Tonnen Kohle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurden die Schätzungen der Bodenschätze in der Antarktis getroffen?, Predicted Answer: bereitwillig aufgegriffen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele von den Erdöl Lagerstätten in der Antarktis wurden bis jetzt gefunden?, Predicted Answer: keine entdeckt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Ziele verfolgt die iranische Außenpolitik seit der islamischen Revolution?, Predicted Answer: widersprüchliche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.60 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ist das Verhältnis Irans zur westlichen Welt?, Predicted Answer: vom Streit um das Atomprogramm dominiert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Bereich der Irans Politik wird international stark kritisiert?, Predicted Answer: Sprachgebrauch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist seit 2005 Die Exekutive Österreichs?, Predicted Answer: Hosni Mubarak\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wem ist die österreichische Justizwache unterstellt?, Predicted Answer: Bundesminister für Justiz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die Xbox 360 das erste mal öffentlich vorgestellt?, Predicted Answer: Im November 2007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf welchem Sender wurde die offizielle Präsentation der Xbox 360 im Mai im Fernsehen übertragen?, Predicted Answer: Xbox Live Arcade\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer stellte die Xbox 360 im Mai 2005 im Fernsehen vor?, Predicted Answer: Band The Killers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel später wurde die offizielle Präsentation der Xbox 360 in Europa ausgestrahlt?, Predicted Answer: einen Tag\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.69 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer schrieb \"Von den Umdrehungen der Himmelskörper\"?, Predicted Answer: Prokopios\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Unter welchem Kardinal arbeitete Aloisius Lilius, Predicted Answer: Vorsitz von Kardinal Guglielmo Sirleto\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wurde mit der mathematischen Seite der Erfindung des Gregorianischen Kalender beauftragt?, Predicted Answer: Christophorus Clavius\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Im Bezug auf Dauer kann Schmerz in welche Klassen aufgeteilt werden?, Predicted Answer: akut und chronisch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Art von Schmerz ist zeitlich begrenzt?, Predicted Answer: Chronischer Schmerz ist ein zeitlich länger andauernder Schmerz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Zeitraum zählt als Chronischer Schmerz?, Predicted Answer: ein zeitlich länger andauernder Schmerz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Funktion hat der Akute Schmerz?, Predicted Answer: Reaktion auf die oben erläuterte Schmerzentstehung und Schmerzweiterleitung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Art von Schmerzen ist multikausal?, Predicted Answer: Chronische Schmerzen haben – im Gegensatz zu akuten – fast nie nur eine einzige auslösende oder unterhaltende Ursache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.59 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Zu welcher Schmerzensgruppe gehören Phantomschmerzen?, Predicted Answer: CIA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange war Rebekah Wade wegen Körperverletzung verhaftet?, Predicted Answer: immer wieder\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist 2005 die Ehefrau von Ross Kemp?, Predicted Answer: Rebekah Wade\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sieht die Flamme von Wasserstoff aus?, Predicted Answer: kaum sichtbar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen MAK-Wert hat Wasserstoff?, Predicted Answer: ungiftig und schädigt auch nicht die Umwelt. Daher ist auch kein MAK-Wert festgelegt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heiß muss es sein um Wasserstoff in der Luft zu zünden?, Predicted Answer: im Sommer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum kann Wasserstoff durch manche Feststoffe durch?, Predicted Answer: hindurchdiffundieren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie darf man mit Wasserstofffahrzeugen in Tiefgaragen parken?, Predicted Answer: problemlos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.14 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Gleichrichter werden bei Gleichstrombahnen heute benutzt?, Predicted Answer: Richtern und Anwälten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Gleichrichter werden bei Gleichstrombahnen früher benutzt?, Predicted Answer: besonders von Richtern und Anwälten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.16 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie verglich Prokopios die Slawen und Anten?, Predicted Answer: dass Anten und Slawen in fast allen Dingen gleich gewesen seien, gleiche Bräuche gehabt und dieselbe Sprache gesprochen hätten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Woher kommen die meisten Jagdtouristen?, Predicted Answer: aus Europa und Nordamerika\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Sprache wurde ursprünglich für die Schriften  des Mahayana-Buddhismus verwendet?, Predicted Answer: diese Schrift\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie werden die religiösen Schriften im Buddhismus bezeichnet?, Predicted Answer: großen Hauptströme\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist ein Bodhisattva?, Predicted Answer: Wesen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die großen Strömungen im Mahayana-Buddhismus?, Predicted Answer: Indiens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bedeutet Mahayana?, Predicted Answer: Sich zu verständigen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf was geht der Mahayana-Buddhismus zurück?, Predicted Answer: die Mahasanghika\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.17 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird die Aktivität eines Gens kontrolliert?, Predicted Answer: über eine Vielzahl von Mechanismen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer herrschte über Liberia nach dem Zweiten Weltkrieg?, Predicted Answer: Freeport Monrovia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus welchem Grund wurde das Wirtschaftliche Wachstums Liberias nach dem Zweiten Weltkrieg zerstört?, Predicted Answer: Japan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist Präsident Liberias?, Predicted Answer: George Weah\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Platz belegt Liberia im Index für wirtschaftliche Freiheit?, Predicted Answer: Global Competitiveness Index\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was steht in Artikel vier des Warschauer Pakts?, Predicted Answer: Einmarsch der Truppen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.62 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wem Unterstanden die Truppen Des Warschauer Pakts letztendlich?, Predicted Answer: Einmarsch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie unterscheiden sich die Größen der Unterschiedlichen US-Dollar Scheine?, Predicted Answer: trotz unterschiedlichem Wert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.82 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie dick ist ein US-Dollar Schein?, Predicted Answer: 32,5 Milliarden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf welche Währung bezieht sich das US-Dollar Gesetz von 1965?, Predicted Answer: Nichtsdestoweniger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.31 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel kostet die Herstellung eines US-Dollar Scheins?, Predicted Answer: 2006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus was wird der US-Dollar hauptsächlich hergestellt?, Predicted Answer: Federal Reserve Notes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der wertvollste US-Dollar Schein?, Predicted Answer: unterschiedlichem Wert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt das Gebäude der Zentrale des FBIs?, Predicted Answer: weitergegeben werden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.27 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welcher Stadt liegt die Zentrale des FBI?, Predicted Answer: Mexiko\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.11 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ernennt den FBI-Direktor?, Predicted Answer: US-Präsidenten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.81 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wem ist der FBI-Direktor direkt untergestellt?, Predicted Answer: dem Justizminister\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Auslandsvertretungen hat das FBI?, Predicted Answer: 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo ist das HRT Team des FBI stationiert?, Predicted Answer: gut ausgerüstete Geiselbefreiungsteam\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.82 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Über welches Budget verfügt das FBI?, Predicted Answer: den ehemaligen hoch dekorierten Vietnamkämpfer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was erscheint auf dem Bildschirm nach dem Start der Xbox 360?, Predicted Answer: ''Xbox Live'', mit dessen Hilfe der Spieler sein Profil, seine Freundesliste und seine Nachrichten verwalten kann, ''Spiele'', ein Überblick\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.17 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Blade der Xbox 360 Benutzeroberfläche lassen sich die Einstellungen ändern?, Predicted Answer: sämtliche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.34 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie kann man ein Update für Xbox 360 herunterladen?, Predicted Answer: Entgelt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Genfer Konvention?, Predicted Answer: stark durch die britische Kultur geprägt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann gibt es in der Schweiz keine Todesstrafe mehr?, Predicted Answer: 1999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde die Genfer Konvention erstmlas beschlossen?, Predicted Answer: 1784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche staatlichen Einrichtungen der Schweiz sind mit dem Schutz der Menschenrechte befasst?, Predicted Answer: grobe Verletzungen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für was wurde die Schweiz mehrfach von Amnesty International gerügt?, Predicted Answer: Kritik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Non-Refoulement-Gebot?, Predicted Answer: Abschiebungsverbot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Jahr heirateten Prinz Charles und Lady Diana Spencer?, Predicted Answer: 1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer schoss auf die Queen im Juni 1981?, Predicted Answer: Michael Fagan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war 1982 Präsident der USA?, Predicted Answer: Ronald Reagan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An was starb Gamal Abdel Nasser?, Predicted Answer: Kopf der Revolution\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war Gamal Abdel Nasser Nachfolger als Präsident?, Predicted Answer: Anwar as-Sadat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Menschen machten am Trauerzug von Gamal Abdel Nasser mit?, Predicted Answer: fünf Millionen Menschen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.27 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo ist Gamal Abdel Nasser bestattet?, Predicted Answer: Abdel-Nasser-Moschee in Kairo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Kinder hatte Gamal Abdel Nasser?, Predicted Answer: zwei Töchter (Huda und Mona) sowie drei Söhne (Khaled, Abdul Hamid und Hakim Amer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.16 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum wurde ein Sohn Gamal Abdel Nasser zu Tode verurteilt?, Predicted Answer: Khaled\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer gab Israel Informationen über den Überraschungsangriff geplanten Jom-Kippur-Krieg?, Predicted Answer: Iran\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer herrscht laut den Zeugen Jehovas über alle nicht Mitglieder dieser?, Predicted Answer: die Parusie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist Jesus laut den Zeugen Jehovas unsichtbar zur Erde wiedergekommen?, Predicted Answer: unsichtbar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was soll in der Endschlacht von Harmagedon passieren?, Predicted Answer: alle Nicht-Gläubigen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt Beyoncés drittes Album?, Predicted Answer: 2008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Beyoncé Song, ihres dritten Albums, schaffte in den US Charts auf Platz eins?, Predicted Answer: Single Ladies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.95 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen Namen hatte Beyoncé dritte Welttour?, Predicted Answer: Lady Gaga\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Grammys gewann Beyoncé 2010?, Predicted Answer: sechsmal ausgezeichnet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Von welchen Künstlern ist der Song Telephone?, Predicted Answer: Lady Gaga\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.41 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo liegen Griechenlands meisten großen Flüsse?, Predicted Answer: Qiantang-Fluss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Tiefe hat der Trichonida-See?, Predicted Answer: 57 m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie stark wächst Estlands BIP seit dem Jahr 2000?, Predicted Answer: 5 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Land hatte 2006 das größte Wirtschaftswachstum der EU?, Predicted Answer: Estland\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie war 2008 der BIP Estlands?, Predicted Answer: erreichte Estland 2008 bereits einen Wert von knapp 68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie kam es zu dem Namen \"Baltische Tiger\"?, Predicted Answer: eingebracht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An was für Götter glaubten die Römer?, Predicted Answer: real existierend\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie interagierten die Götter der Römer mit der Welt?, Predicted Answer: monotheistischen Religion mit einem transzendenten Gott\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was zeigte sich Jupiter den Römern?, Predicted Answer: vergöttlichtes Gewitter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo hat Amylin Pharmaceuticals seinen Hauptsitz?, Predicted Answer: San Diego\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war die Arbeitslosenquote von San Diego 2003?, Predicted Answer: 4,3 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die größten Industriebranchen in San Diego?, Predicted Answer: zahlreiche Industriebetriebe und mehrere Arbeiterviertel sind hier zu finden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer ist der Gründer von Qualcomm?, Predicted Answer: Der Aufstieg San Diegos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.63 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo werden in San Diego Flugzeuge produziert?, Predicted Answer: Global Hawk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wem gehört das Ryan Aeronautical Center?, Predicted Answer: Ryan-Flugzeugwerke\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.92 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das BIP von San Diego?, Predicted Answer: Casa Museo Estudio de Diego Rivera y Frida Kahlo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Konflikt besteht zwischen Armenien und Aserbaidschan?, Predicted Answer: Bergkarabach\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist Berg Karabach?, Predicted Answer: Autonome Provinz Berg-Badachschan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Todesopfer gibt es in dem Konflikt um Berg Karabach?, Predicted Answer: 17.500 Armenier und 25.500 Aserbaidschaner\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie sind die Beziehungen zwischen Armenien und Aserbaidschan?, Predicted Answer: durch den Konflikt um Bergkarabach belastet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Republik Arzach?, Predicted Answer: international nicht anerkannt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.94 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Land erfolgt aktuell keine Zeitumstellung auf Sommerzeit?, Predicted Answer: Russland\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die Folgen einer fehlenden Zeitumstellung?, Predicted Answer: in Tibet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wozu dient die Zeitumstellung?, Predicted Answer: eine Anpassung des Lebensrhythmus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wonach richten sich die meisten Menschen in ihrem Tagesablauf?, Predicted Answer: Heute\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wofür ist der isochrone Transfer geeignet? , Predicted Answer: Daten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welche Geräte ist der isochrone Transfer verfügbar?, Predicted Answer: Full-Speed- und Hi-Speed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was passiert, wenn beim isochronen Transfer keine Datenrate zur Verfügung steht?, Predicted Answer: erhöht sich die Datenrate etwas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Daten können Full-Speed-Geräte pro Sekunde übertragen?, Predicted Answer: bis zu drei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Daten können Hi-Speed-Geräte pro Sekunde übertragen?, Predicted Answer: bis zu drei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was passiert, wenn in einem Gerät mehrere isochrone Endpunkte verfügbar sind?, Predicted Answer: Stehen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.97 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo finden isochrone Übertragungen ihre Anwendung?, Predicted Answer: Sperrschicht-FETs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo leben Säugetiere?, Predicted Answer: Beutelsäuger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die Heimat von Ursäugern?, Predicted Answer: sichere\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo leben Beutelsäuger?, Predicted Answer: einerseits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer gehörte zu den Höheren Säugetieren bis zur Ankunft des Menschen in Australien?, Predicted Answer: Mensch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchen Lebensräumen leben Säugertiere?, Predicted Answer: meisten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.80 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo kann man keine Säugetiere finden?, Predicted Answer: wenigen Regionen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Gruppe von Säugetieren lebt im Meer?, Predicted Answer: Mehrere\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer schlug die erste einheitliche Rechtschreibung für das Niederländische vor?, Predicted Answer: Sell\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt der von Hendrik Laurenszoon veröffentlichte Orthografieleitfaden?, Predicted Answer: Fleisch fort\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt die niederländische Bibelübersetzung von 1618?, Predicted Answer: wegen ihres weit verbreiteten Gebrauchs im bürgerlichen Unterricht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war ein Problem in Bezug auf die Rechtschreibung der Statenvertaling-Bibelübersetzung?, Predicted Answer: Auswirkung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann veröffentlichte Hendrik Laurenszoon Texte als Rechtschreibehilfe?, Predicted Answer: ein geplanter vierter Band nicht mehr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie werden ja oder nein Fragen im Estnischen gebildet?, Predicted Answer: jiu/ieu» für «ja» oder «Giel/Gieu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie werden Entscheidungsfragen im Estnischen gebildet?, Predicted Answer: Inhaltsfragen werden im Estnischen mit vorangestellten Fragepronomina und -proadverbien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der Fragepartikel für verneinte Fragen im Estnischen?, Predicted Answer: ''kas''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wird im Estnischen bei der Fragenbildung kein Fragepartikel verwendet?, Predicted Answer: Inhaltsfragen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird im Estnischen statt \"ega\" für Fragen verwendet?, Predicted Answer: kein Fragepartikel verwendet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind Inhaltsfragen?, Predicted Answer: zeichnen sich dadurch aus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie werden die Gruppierungen bei FA Cup festgelegt?, Predicted Answer: Arsenal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wird beim FA Cup ein Rückspiel gespielt?, Predicted Answer: Englands ausgetragen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was passiert beim FA Cup, wenn das Rückspiel unentschieden ist?, Predicted Answer: 2001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo wird das Finale des FA Cups gespielt?, Predicted Answer: Englands\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.69 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war das Besondere an dem FA Cup Finale von 2001?, Predicted Answer: Tottenham Hotspur\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die Bedingungen, damit ein Team am FA Cup teilnehmen kann?, Predicted Answer: Victoria\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Runden gibt es im FA Cup?, Predicted Answer: Wembley\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Teams dürfen am FA CUp teilnehmen?, Predicted Answer: Arsenal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann fängt der FA Cup an?, Predicted Answer: Halbfinale\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso spielen manche Teams im FA Cup nicht in allen Runden?, Predicted Answer: Profiligen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.57 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Ab welcher Runde spielen die Teams der Premier Leauge im FA Cup?, Predicted Answer: 60. Minute\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist dsa FInale des FA Cups?, Predicted Answer: Halbfinale\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was behauptet Tottenham Hotspur in Bezug auf ihren Sieg im FA Cup 1901?, Predicted Answer: beanspruchte für sich, als einzige Mannschaft\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.82 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welchem europäischen Wettbewerb kann der Sieger des FA Cup teilnehmen?, Predicted Answer: Vereinswettbewerben nicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.56 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was hat WikiLeaks über Beyonce veröffentlicht?, Predicted Answer: Dokumente\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was hat Beyonce mit dem Geld, das sie von Gadaffi bekommen hat, gemacht?, Predicted Answer: „ganze Felder des seelischen Geschehens“ verheert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer war nach ihrem Vater Beyoncés Manager?, Predicted Answer: Mathew\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Auszeichnung hat Beyonce 2013 bei den MTV Europe Music Awards bekommen?, Predicted Answer: Live-Performance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.30 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Weswegen hat sich Beyonce von ihrem Vater als Manager getrennt?, Predicted Answer: Streit „auf Geschäftsebene\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.96 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Beyonces viertes Album veröffenlicht?, Predicted Answer: 2008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Platzierung erreichte Beyonces Album \"4\" in den Billboard 200?, Predicted Answer: Platz 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.82 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Single hat Beyoncé veröffentlicht, als sie mit ihrem ersten Kind schwanger war?, Predicted Answer: Best Thing I Never Had''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die Perspektiven der menschlichen Kommunikation?, Predicted Answer: zwei Ebenen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.42 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was soll in einem Kommunikationsprozess erreicht werden?, Predicted Answer: Erst auf der Basis von Verständigung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.14 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Gebiete der USA liegen außerhalb des Hauptlandes?, Predicted Answer: Alaska und Hawaii\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lang ist die US - Kanadische Grenze?, Predicted Answer: 8893 Kilometer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die Nachbarländer der USA?, Predicted Answer: Die USA sind dem Florenreich der Holarktis zuzuordnen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Aus wie vielen Bundesstaaten besteht das USA Kernland?, Predicted Answer: Hawaii\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: An welche Ozeane grenzt die USA?, Predicted Answer: Abstand\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo liegt Hawaii?, Predicted Answer: tropischen Inseln von Hawaii mit dem 4170 Meter hohen Vulkan Mauna Loa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was trennt die USA und Russland geographisch?, Predicted Answer: Alaska liegt nordwestlich von Kanada und ist durch die Beringstraße\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer nahm in der Neuzeit Palermo ein?, Predicted Answer: Giuseppe Garibaldi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Stadt wurde vor Palermo in der Neuzeit oft bevorzugt?, Predicted Answer: 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Palermo Hauptstadt von der Region Sizilien?, Predicted Answer: 1946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.61 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie war Palermo vom zweiten Weltkrieg betroffen?, Predicted Answer: schwer beschädigt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer \"befreite\" Palermo von der Mafia?, Predicted Answer: Mitglied\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Britische Monarch herrschte am zweit längsten?, Predicted Answer: Colonel James Moore\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann waren Elisabeths II. besondere Fernsehansprachen?, Predicted Answer: fünf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.22 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo kommt ein drittel des deutschen Bahnstroms 2018 her?, Predicted Answer: Stand 2018 wird etwa ein Drittel des Bahnstroms über die Strombörse aus dem öffentlichen 50-Hz-Netz eingekauft\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Spannung hat das Stromnetz der Deutschen Bahn?, Predicted Answer: ''Gate''-Spannung geeigneter Polarität\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird die Wissenschaft durch Alfred Whitehead untersucht?, Predicted Answer: Teil des Lebensprozesses und ihre Methode der Erkenntnisgewinnung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer kommt zu ähnlichen wissenschaftlichen Ergebnissen wie Whitehead?, Predicted Answer: Paul Feyerabend und Kuhn\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bedeutet der Obskurantismus für Whitehead?, Predicted Answer: vor allem in der widersinnigen Leugnung der Zweckmäßigkeit der Natur\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.92 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bedeutet das Konzept der \"Blackness\" in den USA?, Predicted Answer: beschrieben\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bedeutet das Konzept \"acting white\"?, Predicted Answer: Der Kontrast zu ''Blackness\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer wurde als erster schwarze Präsident der USA genannt, obwohl er keine dunkle Haut hatte?, Predicted Answer: Bill Clinton\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was halten mache schwarze Aktivisten von Bill Clinton?, Predicted Answer: Einige schwarze Aktivisten fühlten sich dadurch beleidigt und behaupteten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum wurde Barack Obama während der Präsidentschaftswahlen 2008 politisch kritisiert?, Predicted Answer: Wahlkampfes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.92 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo liegt die Antarktis?, Predicted Answer: Alfred Kroeber\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Territorien gehören zur Antarktis?, Predicted Answer: Harvard University in Cambridge bei Boston, die Yale University in New Haven sowie die Princeton University in Princeton\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der nördlichste Punkt der Antarktis?, Predicted Answer: ''Prime Head''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der südlichste Punkt der Antarktis?, Predicted Answer: Prime Head\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die größeren nächstgelegenen Landmassen zur Antarktis?, Predicted Answer: Feuerland an der Südspitze Südamerikas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo liegt der nördlichste Punkt der Antarktis?, Predicted Answer: Seal Islands\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.16 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Währung nutzen die Norfolkinsel?, Predicted Answer: die Alliierten für Lieferungen nach China nutzen konnten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hoch ist die Arbeitslosigkeit auf den Norfolkinsel?, Predicted Answer: 1,6 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die wichtigste Wirtschaft der Norfolkinsel?, Predicted Answer: der Dienstleistungssektor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die beliebtesten Touristenattraktionen der Norforkinsel?, Predicted Answer: unterscheiden sich in der Größe und im Aufbau\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie kommt man auf die Norfolkinsel?, Predicted Answer: noch nicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann starb Athanasius der Große?, Predicted Answer: Patriarch von Alexandria\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche hohen Ämter hatte Athanasius der Große?, Predicted Answer: nichtlinearen Temperaturkoeffizienten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde der alexandrinische Presbyter Arius schuldig gesprochen?, Predicted Answer: namensgebende alexandrinische Presbyter Arius war dort verurteilt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Alfred Whitehead geboren?, Predicted Answer: Bekannt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo ist Alfred Whitehead gestorben?, Predicted Answer: Autor mehrerer Bücher über Erziehung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.43 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Für welches Werk ist Whitehead bekannt?, Predicted Answer: Principia Mathematica\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Mit wem arbeitete Alfred Whitehead an seinem bekannten Werk über Logik?, Predicted Answer: Principia Mathematica“ über Logik, das er zusammen mit seinem langjährigen Schüler und Freund Bertrand Russell\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.89 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Worum geht es im Werk \"Principia Mathematica\"?, Predicted Answer: nicht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat Alfred Whitehead in London gewohnt?, Predicted Answer: einen Namen als Naturphilosoph\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Als was war Alfred Whitehead in London bekannt?, Predicted Answer: Naturphilosoph\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.04 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat Whitehead angefangen an der Harvard University zu arbeiten?, Predicted Answer: weiteren Ausarbeitung seiner prozessphilosophischen Metaphysik widmen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt das philosophische Hauptwerk von Whitehead?, Predicted Answer: Principia Mathematica“ über Logik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Worüber schreibt Whitehead in seinem philosophischen Hauptwerk?, Predicted Answer: Logik\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welchen anderen Namen haben Feldeffekttransistoren?, Predicted Answer: Halbleiter Silizium\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist für Feldeffekttransistoren typisch?, Predicted Answer: Umsetzung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.26 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißen die drei Anschlüsse eines Feldeffekttransistors?, Predicted Answer: Débo, Fati, Teli, Korientze, Tanda, Do, Garou und Aougoundou\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.15 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wird der Widerstand eines Feldeffekttransistors gesteuert?, Predicted Answer: eine Spannung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Arten von Feldeffekttransistoren gibt es?, Predicted Answer: eklatante Mängel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was bedeutet die unbefleckte Empfängnis Mariens?, Predicted Answer: ein Dogma der Glaubenslehre der römisch-katholischen Kirche\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches religiöses Fest wird am 8.Dezember gefeiert?, Predicted Answer: Mariä Empfängnis\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.10 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das bedeutende Herkunftsland der Direktinvestitionen in Estland?, Predicted Answer: mit weitem Abstand Schweden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Investitionen in Estland stammen aus Deutschland?, Predicted Answer: 157 Mio. Euro\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.59 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchen Bereichen wurden die Investitionen in Estland aus Schweden getätigt?, Predicted Answer: Bankwesen und Telekommunikation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie hieß die heutige Hauptstadt von Montenegro in Jugoslawien?, Predicted Answer: Titograd statt Podgorica\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurden die Städte, die nach Tito benannt worden waren, wieder umbeannt?, Predicted Answer: ihre alten Namen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Berg war nach Tito benannt?, Predicted Answer: ein Berg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Tag war für die Titoverehrung besonders wichtig?, Predicted Answer: Reg Park\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Städte wurden in Jugoslawien trugen Titos Namen?, Predicted Answer: acht\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher Tag wurde in Jugoslwaien als Tag der Jugend gefeiert?, Predicted Answer: Chopin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.10 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer verlor viel durch das Wachstum der Literatur als Bildungsform?, Predicted Answer: Mitbürger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum kam es bei dem ausbreiten der Literatur kaum auf Wiederstand?, Predicted Answer: weltweit ausdehnen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist das Ziel nationalstaatlicher Bildungssysteme?, Predicted Answer: Einführung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.35 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war am Sozialen Aufstieg in westlichen Staaten im 19. Jhd. das schwerste?, Predicted Answer: Osmanische Reich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.90 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wieso war die Sprachentwicklung der Serben und Kroaten für 500 Jahre stark unterschiedlich?, Predicted Answer: lokaler Ebene\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.40 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum ging der Kokainhandel 2008 und 2009 in Guinea-Bissau zurück?, Predicted Answer: einem deutlichen Rückgang\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Auf welchem Land würde die Stadt Yecheng heutzutage liegen?, Predicted Answer: Nanjing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Nanjing das erste mal Hauptstadt Chinas?, Predicted Answer: Erstmals Hauptstadt wurde Nanjing 229 n. Chr.,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.21 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wer hat die Definitionen von Ethnien beim United State Census geschrieben?, Predicted Answer: United States Census Bureau und das Office of Management and Budget (OMB) der Bundesregierung der Vereinigten Staaten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welche zwei Ethnien Gruppen werden alle Amerikaner eingeteilt?, Predicted Answer: Hispano-oder-Latino und Nicht-Hispano-oder-Latino\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was machen die Schüler in Griechenland die nicht am Religionsunterricht teilnehmen?, Predicted Answer: Jeder Schüler, der nicht am Religionsunterricht teilnehmen will\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der höchste Rang in der griechischen Kirche?, Predicted Answer: Immaculata\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.28 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist die größte Religion Griechenlands?, Predicted Answer: Gefahren für die Freiheit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches griechische Ministerium befasst sich mit Religion?, Predicted Answer: Hayek\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche europäischen Länder haben eine offizielle Staatskirche?, Predicted Answer: Gliedstaaten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wem untersteht die Griechische orthodoxe Kirche zum Teil?, Predicted Answer: Staat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Volumen hat der Magen eines Menschen?, Predicted Answer: mehrkammeriger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie ist die Magenschleimhaut aufgebaut?, Predicted Answer: stark gefaltet und von zahlreichen Drüsenzellen durchsetzt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Arten von Drüsenzellen gibt es in der Magenschleimhaut?, Predicted Answer: eklatante Mängel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.94 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Zellen im Magen produzieren Säure?, Predicted Answer: Eukaryoten\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.70 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Art von Säure wird im Magen produziert?, Predicted Answer: Des Weiteren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.79 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche FUnktion hat Pepsin im Magen?, Predicted Answer: Konstruktion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der pH-Wert im Magen?, Predicted Answer: nötig\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.11 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was wird von den Nebenzellen im Magen produziert?, Predicted Answer: ein hydrogencarbonatreicher, zäher Schleim abgesondert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.39 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wozu dient der Schleim der Nebenzellen im Magen?, Predicted Answer: Der Ligastart verlief zunächst schleppend. Dann aber blieb das Team vom Jahreswechsel bis zum Mai 1985 in 18 Spielen ungeschlagen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel magensaft wird am Tag produziert?, Predicted Answer: VW Passat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist Chymus?, Predicted Answer: den Speisebrei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist der Schweizer Bundesfeiertag?, Predicted Answer: getragen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.64 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Feiertage gibt es in der Schweiz?, Predicted Answer: 2'126'400 Einwohner\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.25 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo wird in der Schweiz das Knabenschiessen gefeiert?, Predicted Answer: Zürich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo in der Schweiz wird Fronleichnam gefeiert?, Predicted Answer: Genf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann ist der Berchtoldstag?, Predicted Answer: umgekehrt ist der Berchtoldstag (zweiter Neujahrstag) weitgehend auf die protestantischen Kantone beschränkt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde der iPod 6G vorgestellt?, Predicted Answer: Steve Jobs am 5. September 2007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo wurde der iPod 6G vorgestellt?, Predicted Answer: Steve Jobs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viel SPeicherplatz hat der iPod 6G?, Predicted Answer: 120 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.24 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche iPod-Generation wird  classic genannt?, Predicted Answer: iPod 6G\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Mahmud Ahmadineschād zum Präsidenten wiedergewählt?, Predicted Answer: Wahl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was führte zu massiven Protesten 2009 in Iran?, Predicted Answer: Wiederwahl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.96 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Oppositioneller in Iran wurden 2011 mit dem Tod bedroht?, Predicted Answer: Beyoncé\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.05 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was war das Ergebnis der Radikalisierung in Iran 2009-2011?, Predicted Answer: Isolation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie wurde man bis 1999 in Florida hingerichtet?, Predicted Answer: Florida State Prison\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.82 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Methode der Hinrichtung wurde in Florida nach der Abschaffung des elektrischen Stuhls praktiziert? , Predicted Answer: Sekundärmethode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann hat die bisher letzte Hinrichtung in Florida stattgefunden?, Predicted Answer: im Mai 2019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welcher US-Bundesstaat hat mehr Hinrichtungen als Florida durchgeführt?, Predicted Answer: Florida\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.99 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele natürliche Isotope des Wasserstoffs gibt es?, Predicted Answer: drei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.58 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum reagieren die Isotope des Wasserstoffs chemisch so unterschiedlich?, Predicted Answer: ihre Lebenserwartung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Warum wird das einfachste Isotop des Wasserstoffs Protium genannt?, Predicted Answer: gelegentlich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Inwiefern unterscheidet sich das Isotop 1H von 2H?, Predicted Answer: 99,98 % den weitaus größten Anteil am irdisch vorkommenden Wasserstoff. Es ist nicht radioaktiv, also stabil.\n",
            " Das Isotop 2H hat neben dem Proton ein Neutron im Kern\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie heißt das dritte vorkommende Isotop des Wasserstoffs?, Predicted Answer: Tritium\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.08 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Isotop des Wasserstoffs ist radioaktiv?, Predicted Answer: Tritium\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.21 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo kann man das dritte Isotop des Wasserstoffs finden?, Predicted Answer: Tritium\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.46 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie lange leben Isotope des Wasserstoffs?, Predicted Answer: Tritium\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der bedeutendste Fluss Afrikas?, Predicted Answer: Nigeria\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.72 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wo hat der Fluss Niger seinen Anfang?, Predicted Answer: Gaddafi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welche zwei andere Flüsse wird der Niger bei Mopti zerteilt?, Predicted Answer: den Bara Issa und den Issa Ber\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.76 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der zweite wichtige Fluss Afrikas?, Predicted Answer: Nigeria\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.22 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was ist der größte See in Mali?, Predicted Answer: Hauptstadt der Kolonie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.73 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann gibt es schwere Dürren in Mali?, Predicted Answer: den 1930er Jahren\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.27 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Kultur lebte zuerst in Indien?, Predicted Answer: vedische\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.96 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Seit wann leben in Indien menschliche Kulturen?, Predicted Answer: vor über 20 Jahren damit begonnen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.51 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Indien war Kolonie von welchem Land?, Predicted Answer: Großbritannien\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welches Reich gründete sich im 4. Jhd. v. Chr. in Indien?, Predicted Answer: Maurya-Reich\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: In welchem Teil Indies entstand das tamilische Chola-Reich?, Predicted Answer: Süden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wie viele Dynastien regierten im 8. Jhd. über einen Großteil Indiens?, Predicted Answer: Rashtrakuta, Pala und Pratihara\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Welche Persönlichkeiten führten die Unabhängigkeit Indiens an?, Predicted Answer: 6 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.68 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Wann wurde Bangladesch gegründet?, Predicted Answer: neuen Staates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was sind die Hauptprobleme Indiens?, Predicted Answer: Heute\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def calculate_f1_score(gold_answers, predicted_answer):\n",
        "    gold_toks = Counter(gold_answers.lower().split())\n",
        "    pred_toks = Counter(predicted_answer.lower().split())\n",
        "    common = gold_toks & pred_toks\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = num_same / len(pred_toks)\n",
        "    recall = num_same / len(gold_toks)\n",
        "    return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "def extract_queries_answers_and_doc_ids(json_file):\n",
        "    with open(json_file, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "        return [(item['question'], item['answers'][0], ctx['passage_id'])\n",
        "                for item in data\n",
        "                for ctx in item['positive_ctxs']]\n",
        "\n",
        "f1_scores = []\n",
        "exact_matches = []\n",
        "\n",
        "queries_answers_and_doc_ids = (\n",
        "    extract_queries_answers_and_doc_ids(german_dpr_test_file) +\n",
        "    extract_queries_answers_and_doc_ids(german_quad_test_file)\n",
        ")\n",
        "\n",
        "for query, gold_answer, correct_doc_id in queries_answers_and_doc_ids:\n",
        "    retrieved_documents = retriever.retrieve(query)\n",
        "    predicted_answers = reader.predict(query, documents=retrieved_documents, top_k=1)\n",
        "    top_answer = predicted_answers['answers'][0].answer if predicted_answers['answers'] else \"\"\n",
        "\n",
        "    f1_scores.append(calculate_f1_score(gold_answer, top_answer))\n",
        "    exact_matches.append(gold_answer.lower().strip() == top_answer.lower().strip())\n",
        "\n",
        "avg_f1 = sum(f1_scores) / len(f1_scores) if f1_scores else 0\n",
        "exact_match_rate = sum(exact_matches) / len(exact_matches) if exact_matches else 0\n",
        "\n",
        "print(f\"Average F1-Score: {avg_f1}\")\n",
        "print(f\"Exact Match Rate: {exact_match_rate}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P9iUljKbL9xV",
        "outputId": "2afe3e02-ec3c-4eee-d25c-008955a6166d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:02<00:00,  1.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:02<00:00,  1.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.65 Batches/s]\n",
            "Inferencing Samples:   0%|          | 0/2 [00:00<?, ? Batches/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2c6c7a315b9e>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_doc_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries_answers_and_doc_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mretrieved_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mpredicted_answers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretrieved_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mtop_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_answers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpredicted_answers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answers'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/nodes/reader/farm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, query, documents, top_k)\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minput_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_batches_from_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             cur_predictions = self.inferencer.inference_from_objects(\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0mobjects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_json\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiprocessing_chunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/infer.py\u001b[0m in \u001b[0;36minference_from_objects\u001b[0;34m(self, objects, return_json, multiprocessing_chunksize)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;31m# then we can and should use inference from (input) objects!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;31m# logger.warning(\"QAInferencer.inference_from_objects() will soon be deprecated. Use QAInferencer.inference_from_dicts() instead\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         return self.inference_from_dicts(\n\u001b[0m\u001b[1;32m    519\u001b[0m             \u001b[0mdicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_json\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiprocessing_chunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiprocessing_chunksize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/infer.py\u001b[0m in \u001b[0;36minference_from_dicts\u001b[0;34m(self, dicts, return_json, multiprocessing_chunksize)\u001b[0m\n\u001b[1;32m    480\u001b[0m                                     \u001b[0mhas\u001b[0m \u001b[0mbeen\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \"\"\"\n\u001b[0;32m--> 482\u001b[0;31m         return Inferencer.inference_from_dicts(\n\u001b[0m\u001b[1;32m    483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_json\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiprocessing_chunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiprocessing_chunksize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/infer.py\u001b[0m in \u001b[0;36minference_from_dicts\u001b[0;34m(self, dicts, return_json, multiprocessing_chunksize)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0maggregate_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_heads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"aggregate_preds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_without_multiprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregate_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/infer.py\u001b[0m in \u001b[0;36m_inference_without_multiprocessing\u001b[0;34m(self, dicts, return_json, aggregate_preds)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# TODO change format of formatted_preds in QA (list of dicts)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maggregate_preds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0mpreds_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_predictions_and_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaskets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mpreds_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaskets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/infer.py\u001b[0m in \u001b[0;36m_get_predictions_and_aggregate\u001b[0;34m(self, dataset, tensor_names, baskets)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 )\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# preds = self.model.logits_to_preds(logits, **batch)[0] (This must somehow be useful for SQuAD)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m                 \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_to_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m                 \u001b[0munaggregated_preds_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/model/adaptive_model.py\u001b[0m in \u001b[0;36mlogits_to_preds\u001b[0;34m(self, logits, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# collect preds from all heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_for_head\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_to_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_for_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mall_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mall_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/model/prediction_head.py\u001b[0m in \u001b[0;36mlogits_to_preds\u001b[0;34m(self, logits, span_mask, start_of_word, seq_2_start_t, max_answer_length, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;31m# disqualify answers where answer span is greater than max_answer_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;31m# (set the upper triangular matrix to low value, excluding diagonal)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         indices_long_span = torch.triu_indices(\n\u001b[0m\u001b[1;32m    473\u001b[0m             \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_answer_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_end_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores = []\n",
        "exact_matches = []\n",
        "\n",
        "# Evaluation loop for the Reader\n",
        "for query, gold_answer, correct_doc_id in queries_answers_and_doc_ids:\n",
        "    retrieved_documents = retriever.retrieve(query)\n",
        "    predicted_answers = reader.predict(query, documents=retrieved_documents, top_k=1)\n",
        "    top_answer = predicted_answers['answers'][0].answer if predicted_answers['answers'] else \"\"\n",
        "\n",
        "    f1_scores.append(calculate_f1_score(gold_answer, top_answer))\n",
        "    exact_matches.append(gold_answer.lower().strip() == top_answer.lower().strip())\n",
        "\n",
        "avg_f1 = sum(f1_scores) / len(f1_scores) if f1_scores else 0\n",
        "exact_match_rate = sum(exact_matches) / len(exact_matches) if exact_matches else 0\n",
        "\n",
        "print(f\"Average F1-Score: {avg_f1}\")\n",
        "print(f\"Exact Match Rate: {exact_match_rate}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "id": "SwtS8w-sNZu5",
        "outputId": "03fc8e45-8d34-4cd5-bfb7-b084d64c2243"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.16 Batches/s]\n",
            "Inferencing Samples:   0%|          | 0/2 [00:00<?, ? Batches/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-5aa86fbd5d1f>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_doc_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries_answers_and_doc_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mretrieved_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpredicted_answers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretrieved_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtop_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_answers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpredicted_answers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answers'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/nodes/reader/farm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, query, documents, top_k)\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minput_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_batches_from_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             cur_predictions = self.inferencer.inference_from_objects(\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0mobjects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_json\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiprocessing_chunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/infer.py\u001b[0m in \u001b[0;36minference_from_objects\u001b[0;34m(self, objects, return_json, multiprocessing_chunksize)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;31m# then we can and should use inference from (input) objects!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;31m# logger.warning(\"QAInferencer.inference_from_objects() will soon be deprecated. Use QAInferencer.inference_from_dicts() instead\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         return self.inference_from_dicts(\n\u001b[0m\u001b[1;32m    519\u001b[0m             \u001b[0mdicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_json\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiprocessing_chunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiprocessing_chunksize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/infer.py\u001b[0m in \u001b[0;36minference_from_dicts\u001b[0;34m(self, dicts, return_json, multiprocessing_chunksize)\u001b[0m\n\u001b[1;32m    480\u001b[0m                                     \u001b[0mhas\u001b[0m \u001b[0mbeen\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \"\"\"\n\u001b[0;32m--> 482\u001b[0;31m         return Inferencer.inference_from_dicts(\n\u001b[0m\u001b[1;32m    483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_json\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiprocessing_chunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiprocessing_chunksize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/infer.py\u001b[0m in \u001b[0;36minference_from_dicts\u001b[0;34m(self, dicts, return_json, multiprocessing_chunksize)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0maggregate_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_heads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"aggregate_preds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_without_multiprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregate_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/infer.py\u001b[0m in \u001b[0;36m_inference_without_multiprocessing\u001b[0;34m(self, dicts, return_json, aggregate_preds)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# TODO change format of formatted_preds in QA (list of dicts)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maggregate_preds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0mpreds_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_predictions_and_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaskets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mpreds_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaskets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/infer.py\u001b[0m in \u001b[0;36m_get_predictions_and_aggregate\u001b[0;34m(self, dataset, tensor_names, baskets)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 )\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# preds = self.model.logits_to_preds(logits, **batch)[0] (This must somehow be useful for SQuAD)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m                 \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_to_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m                 \u001b[0munaggregated_preds_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/model/adaptive_model.py\u001b[0m in \u001b[0;36mlogits_to_preds\u001b[0;34m(self, logits, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# collect preds from all heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_for_head\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_to_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_for_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mall_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mall_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/model/prediction_head.py\u001b[0m in \u001b[0;36mlogits_to_preds\u001b[0;34m(self, logits, span_mask, start_of_word, seq_2_start_t, max_answer_length, **kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# Get the n_best candidate answers for each sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0msorted_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_candidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0mstart_end_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_end_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msample_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Error Analysis for Incorrect Predictions\n",
        "incorrect_predictions = []\n",
        "for query, gold_answer, correct_doc_id in queries_answers_and_doc_ids:\n",
        "    retrieved_documents = retriever.retrieve(query)\n",
        "    predicted_answers = reader.predict(query, documents=retrieved_documents, top_k=1)\n",
        "    top_answer = predicted_answers['answers'][0].answer if predicted_answers['answers'] else \"\"\n",
        "\n",
        "    if gold_answer.lower().strip() != top_answer.lower().strip():\n",
        "        incorrect_predictions.append({\n",
        "            \"query\": query,\n",
        "            \"gold_answer\": gold_answer,\n",
        "            \"predicted_answer\": top_answer,\n",
        "            \"is_correct_retrieval\": correct_doc_id in [doc.meta['passage_id'] for doc in retrieved_documents]\n",
        "        })\n",
        "\n",
        "# Examples of incorrect predictions\n",
        "for example in incorrect_predictions[:5]:\n",
        "    print(f\"Query: {example['query']}\")\n",
        "    print(f\"Gold Answer: {example['gold_answer']}\")\n",
        "    print(f\"Predicted Answer: {example['predicted_answer']}\")\n",
        "    print(f\"Correct Document Retrieved: {example['is_correct_retrieval']}\")\n",
        "    print(\"---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "xCtj8SS0R3fM",
        "outputId": "bb9f8848-f655-49df-bd17-4559fa81d862"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  2.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.16 Batches/s]\n",
            "Inferencing Samples:   0%|          | 0/2 [00:00<?, ? Batches/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f540aca30d6c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_doc_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries_answers_and_doc_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mretrieved_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpredicted_answers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretrieved_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtop_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_answers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpredicted_answers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answers'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/nodes/reader/farm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, query, documents, top_k)\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minput_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_batches_from_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             cur_predictions = self.inferencer.inference_from_objects(\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0mobjects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_json\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiprocessing_chunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/infer.py\u001b[0m in \u001b[0;36minference_from_objects\u001b[0;34m(self, objects, return_json, multiprocessing_chunksize)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;31m# then we can and should use inference from (input) objects!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;31m# logger.warning(\"QAInferencer.inference_from_objects() will soon be deprecated. Use QAInferencer.inference_from_dicts() instead\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         return self.inference_from_dicts(\n\u001b[0m\u001b[1;32m    519\u001b[0m             \u001b[0mdicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_json\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiprocessing_chunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiprocessing_chunksize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/infer.py\u001b[0m in \u001b[0;36minference_from_dicts\u001b[0;34m(self, dicts, return_json, multiprocessing_chunksize)\u001b[0m\n\u001b[1;32m    480\u001b[0m                                     \u001b[0mhas\u001b[0m \u001b[0mbeen\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \"\"\"\n\u001b[0;32m--> 482\u001b[0;31m         return Inferencer.inference_from_dicts(\n\u001b[0m\u001b[1;32m    483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_json\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiprocessing_chunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiprocessing_chunksize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/infer.py\u001b[0m in \u001b[0;36minference_from_dicts\u001b[0;34m(self, dicts, return_json, multiprocessing_chunksize)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0maggregate_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_heads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"aggregate_preds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_without_multiprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregate_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/infer.py\u001b[0m in \u001b[0;36m_inference_without_multiprocessing\u001b[0;34m(self, dicts, return_json, aggregate_preds)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# TODO change format of formatted_preds in QA (list of dicts)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maggregate_preds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0mpreds_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_predictions_and_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaskets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mpreds_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaskets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/infer.py\u001b[0m in \u001b[0;36m_get_predictions_and_aggregate\u001b[0;34m(self, dataset, tensor_names, baskets)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 )\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# preds = self.model.logits_to_preds(logits, **batch)[0] (This must somehow be useful for SQuAD)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m                 \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_to_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m                 \u001b[0munaggregated_preds_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/model/adaptive_model.py\u001b[0m in \u001b[0;36mlogits_to_preds\u001b[0;34m(self, logits, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# collect preds from all heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_for_head\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_to_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_for_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mall_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mall_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/haystack/modeling/model/prediction_head.py\u001b[0m in \u001b[0;36mlogits_to_preds\u001b[0;34m(self, logits, span_mask, start_of_word, seq_2_start_t, max_answer_length, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;31m# disqualify answers where answer span is greater than max_answer_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;31m# (set the upper triangular matrix to low value, excluding diagonal)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         indices_long_span = torch.triu_indices(\n\u001b[0m\u001b[1;32m    473\u001b[0m             \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_answer_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_end_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.utils import launch_es\n",
        "launch_es()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpYY3ma85TU_",
        "outputId": "4aebe591-35d4-482a-f21f-95f2d648ff11"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:haystack.utils.doc_store:Tried to start Elasticsearch through Docker but this failed. It is likely that there is already an existing Elasticsearch instance running. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import FARMReader\n",
        "\n",
        "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", top_k=5)\n",
        "\n",
        "for query, gold_answer, correct_doc_id in queries_answers_and_doc_ids:\n",
        "    retrieved_docs = retriever.retrieve(query)\n",
        "\n",
        "    predicted_answers = reader.predict(query, documents=retrieved_docs, top_k=1)\n",
        "\n",
        "    top_answer = predicted_answers['answers'][0].answer if predicted_answers['answers'] else \"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "JgPovZOW0RNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from haystack.eval import calculate_reader_metrics\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Load the SentenceTransformer model for SAS\n",
        "model = SentenceTransformer(\"cross-encoder/stsb-roberta-large\")\n",
        "\n",
        "sas_scores = []\n",
        "for prediction, label in zip(predictions, labels):\n",
        "    # Compute SAS\n",
        "    embedding1 = model.encode(prediction, convert_to_tensor=True)\n",
        "    embedding2 = model.encode(label, convert_to_tensor=True)\n",
        "    sas_score = util.pytorch_cos_sim(embedding1, embedding2)\n",
        "    sas_scores.append(sas_score.item())\n",
        "\n",
        "avg_sas_score = sum(sas_scores) / len(sas_scores)\n",
        "print(\"Average Semantic Answer Similarity:\", avg_sas_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "p0OzeFtOyR12",
        "outputId": "c297d74b-9ee7-4555-c122-6561b9e7a8b9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'haystack.eval'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f0834e731217>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhaystack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalculate_reader_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the SentenceTransformer model for SAS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cross-encoder/stsb-roberta-large\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'haystack.eval'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import FARMReader\n",
        "from haystack.document_stores import InMemoryDocumentStore\n",
        "from haystack.pipelines import ExtractiveQAPipeline\n",
        "\n",
        "document_store = InMemoryDocumentStore()\n",
        "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\")\n",
        "pipeline = ExtractiveQAPipeline(reader=reader, document_store=document_store)\n",
        "\n",
        "eval_result = pipeline.eval(document_store=document_store, label_index=\"label\", doc_index=\"doc\")\n",
        "print(\"Reader isolated evaluation result:\", eval_result)"
      ],
      "metadata": {
        "id": "NZ9cpE4hyVNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = eval_result.calculate_metrics(answer_scope=\"context\", document_scope=\"answer\")\n",
        "print(\"Evaluation metrics with advanced label scopes:\", metrics)"
      ],
      "metadata": {
        "id": "VpktIPfFyXSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = eval_result.generate_report(include_errors=True)\n",
        "print(\"Detailed Evaluation Report:\\n\", report)"
      ],
      "metadata": {
        "id": "Icw9eWNRyZte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from haystack.nodes import FARMReader\n",
        "\n",
        "mlflow.start_run(run_name=\"QA_Evaluation\")\n",
        "\n",
        "mlflow.log_param(\"reader_model\", \"deepset/roberta-base-squad2\")\n",
        "mlflow.log_metrics({\"average_sas_score\": avg_sas_score})\n",
        "\n",
        "mlflow.end_run()"
      ],
      "metadata": {
        "id": "L-Po4Sx5ybfM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}